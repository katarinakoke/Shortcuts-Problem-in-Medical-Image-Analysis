Running on desktop25:
stdin: is not a tty
Activating chexpert environment...
3
Using the specified args:
Namespace(cfg_path='/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/config/config_katkr.json', device_ids='0', logtofile=False, num_workers=2, pre_train=None, resume=0, save_path='/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/logdirs/logdir-30k-2', verbose=True)
{
    "base_path": "/home/data_shares/purrlab/CheXpert/CheXpert-v1.0-small",
    "train_csv": "/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/preprocess/datasets/biased_pneumothorax_dataset_train.csv",
    "dev_csv": "/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/preprocess/datasets/biased_pneumothorax_dataset_val.csv",
    "pred_csv": "/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/predictions/Pred_Biased_Sex_1_pos01.csv",
    "pred_model": "/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/logdirs/logdir-30k-2/Best_Biased_Sex_1_pos011.ckpt",
    "backbone": "densenet121",
    "sensitive_attribute": "Sex",
    "lambda_val": -0.05,
    "num_heads": 2,
    "width": 512,
    "height": 512,
    "long_side": 512,
    "fix_ratio": true,
    "pixel_mean": 128.0,
    "pixel_std": 64.0,
    "use_pixel_std": true,
    "use_equalizeHist": true,
    "use_transforms_type": "Aug",
    "gaussian_blur": 3,
    "border_pad": "pixel_mean",
    "num_classes": [
        1
    ],
    "batch_weight": true,
    "batch_weight_sensitive": true,
    "enhance_index": [
        2,
        6
    ],
    "enhance_times": 1,
    "pos_weight": [
        1
    ],
    "sensitive_pos_weight": [
        1
    ],
    "train_batch_size": 32,
    "dev_batch_size": 32,
    "pretrained": true,
    "log_every": 10,
    "test_every": 100,
    "epoch": 10,
    "norm_type": "BatchNorm",
    "global_pool": "PCAM",
    "fc_bn": true,
    "attention_map": "FPA",
    "lse_gamma": 0.5,
    "fc_drop": 0,
    "optimizer": "Adam",
    "criterion": "BCE",
    "sensitive_criterion": "BCE",
    "lr": 0.0001,
    "lr_factor": 0.1,
    "lr_epochs": [
        2
    ],
    "momentum": 0.9,
    "weight_decay": 0.0,
    "best_target": "auc",
    "save_top_k": 3,
    "save_index": [
        0
    ]
}
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 256, 256]           9,408
       BatchNorm2d-2         [-1, 64, 256, 256]             128
              ReLU-3         [-1, 64, 256, 256]               0
         MaxPool2d-4         [-1, 64, 128, 128]               0
       BatchNorm2d-5         [-1, 64, 128, 128]             128
              ReLU-6         [-1, 64, 128, 128]               0
            Conv2d-7        [-1, 128, 128, 128]           8,192
       BatchNorm2d-8        [-1, 128, 128, 128]             256
              ReLU-9        [-1, 128, 128, 128]               0
           Conv2d-10         [-1, 32, 128, 128]          36,864
      BatchNorm2d-11         [-1, 96, 128, 128]             192
             ReLU-12         [-1, 96, 128, 128]               0
           Conv2d-13        [-1, 128, 128, 128]          12,288
      BatchNorm2d-14        [-1, 128, 128, 128]             256
             ReLU-15        [-1, 128, 128, 128]               0
           Conv2d-16         [-1, 32, 128, 128]          36,864
      BatchNorm2d-17        [-1, 128, 128, 128]             256
             ReLU-18        [-1, 128, 128, 128]               0
           Conv2d-19        [-1, 128, 128, 128]          16,384
      BatchNorm2d-20        [-1, 128, 128, 128]             256
             ReLU-21        [-1, 128, 128, 128]               0
           Conv2d-22         [-1, 32, 128, 128]          36,864
      BatchNorm2d-23        [-1, 160, 128, 128]             320
             ReLU-24        [-1, 160, 128, 128]               0
           Conv2d-25        [-1, 128, 128, 128]          20,480
      BatchNorm2d-26        [-1, 128, 128, 128]             256
             ReLU-27        [-1, 128, 128, 128]               0
           Conv2d-28         [-1, 32, 128, 128]          36,864
      BatchNorm2d-29        [-1, 192, 128, 128]             384
             ReLU-30        [-1, 192, 128, 128]               0
           Conv2d-31        [-1, 128, 128, 128]          24,576
      BatchNorm2d-32        [-1, 128, 128, 128]             256
             ReLU-33        [-1, 128, 128, 128]               0
           Conv2d-34         [-1, 32, 128, 128]          36,864
      BatchNorm2d-35        [-1, 224, 128, 128]             448
             ReLU-36        [-1, 224, 128, 128]               0
           Conv2d-37        [-1, 128, 128, 128]          28,672
      BatchNorm2d-38        [-1, 128, 128, 128]             256
             ReLU-39        [-1, 128, 128, 128]               0
           Conv2d-40         [-1, 32, 128, 128]          36,864
      BatchNorm2d-41        [-1, 256, 128, 128]             512
             ReLU-42        [-1, 256, 128, 128]               0
           Conv2d-43        [-1, 128, 128, 128]          32,768
        AvgPool2d-44          [-1, 128, 64, 64]               0
      BatchNorm2d-45          [-1, 128, 64, 64]             256
             ReLU-46          [-1, 128, 64, 64]               0
           Conv2d-47          [-1, 128, 64, 64]          16,384
      BatchNorm2d-48          [-1, 128, 64, 64]             256
             ReLU-49          [-1, 128, 64, 64]               0
           Conv2d-50           [-1, 32, 64, 64]          36,864
      BatchNorm2d-51          [-1, 160, 64, 64]             320
             ReLU-52          [-1, 160, 64, 64]               0
           Conv2d-53          [-1, 128, 64, 64]          20,480
      BatchNorm2d-54          [-1, 128, 64, 64]             256
             ReLU-55          [-1, 128, 64, 64]               0
           Conv2d-56           [-1, 32, 64, 64]          36,864
      BatchNorm2d-57          [-1, 192, 64, 64]             384
             ReLU-58          [-1, 192, 64, 64]               0
           Conv2d-59          [-1, 128, 64, 64]          24,576
      BatchNorm2d-60          [-1, 128, 64, 64]             256
             ReLU-61          [-1, 128, 64, 64]               0
           Conv2d-62           [-1, 32, 64, 64]          36,864
      BatchNorm2d-63          [-1, 224, 64, 64]             448
             ReLU-64          [-1, 224, 64, 64]               0
           Conv2d-65          [-1, 128, 64, 64]          28,672
      BatchNorm2d-66          [-1, 128, 64, 64]             256
             ReLU-67          [-1, 128, 64, 64]               0
           Conv2d-68           [-1, 32, 64, 64]          36,864
      BatchNorm2d-69          [-1, 256, 64, 64]             512
             ReLU-70          [-1, 256, 64, 64]               0
           Conv2d-71          [-1, 128, 64, 64]          32,768
      BatchNorm2d-72          [-1, 128, 64, 64]             256
             ReLU-73          [-1, 128, 64, 64]               0
           Conv2d-74           [-1, 32, 64, 64]          36,864
      BatchNorm2d-75          [-1, 288, 64, 64]             576
             ReLU-76          [-1, 288, 64, 64]               0
           Conv2d-77          [-1, 128, 64, 64]          36,864
      BatchNorm2d-78          [-1, 128, 64, 64]             256
             ReLU-79          [-1, 128, 64, 64]               0
           Conv2d-80           [-1, 32, 64, 64]          36,864
      BatchNorm2d-81          [-1, 320, 64, 64]             640
             ReLU-82          [-1, 320, 64, 64]               0
           Conv2d-83          [-1, 128, 64, 64]          40,960
      BatchNorm2d-84          [-1, 128, 64, 64]             256
             ReLU-85          [-1, 128, 64, 64]               0
           Conv2d-86           [-1, 32, 64, 64]          36,864
      BatchNorm2d-87          [-1, 352, 64, 64]             704
             ReLU-88          [-1, 352, 64, 64]               0
           Conv2d-89          [-1, 128, 64, 64]          45,056
      BatchNorm2d-90          [-1, 128, 64, 64]             256
             ReLU-91          [-1, 128, 64, 64]               0
           Conv2d-92           [-1, 32, 64, 64]          36,864
      BatchNorm2d-93          [-1, 384, 64, 64]             768
             ReLU-94          [-1, 384, 64, 64]               0
           Conv2d-95          [-1, 128, 64, 64]          49,152
      BatchNorm2d-96          [-1, 128, 64, 64]             256
             ReLU-97          [-1, 128, 64, 64]               0
           Conv2d-98           [-1, 32, 64, 64]          36,864
      BatchNorm2d-99          [-1, 416, 64, 64]             832
            ReLU-100          [-1, 416, 64, 64]               0
          Conv2d-101          [-1, 128, 64, 64]          53,248
     BatchNorm2d-102          [-1, 128, 64, 64]             256
            ReLU-103          [-1, 128, 64, 64]               0
          Conv2d-104           [-1, 32, 64, 64]          36,864
     BatchNorm2d-105          [-1, 448, 64, 64]             896
            ReLU-106          [-1, 448, 64, 64]               0
          Conv2d-107          [-1, 128, 64, 64]          57,344
     BatchNorm2d-108          [-1, 128, 64, 64]             256
            ReLU-109          [-1, 128, 64, 64]               0
          Conv2d-110           [-1, 32, 64, 64]          36,864
     BatchNorm2d-111          [-1, 480, 64, 64]             960
            ReLU-112          [-1, 480, 64, 64]               0
          Conv2d-113          [-1, 128, 64, 64]          61,440
     BatchNorm2d-114          [-1, 128, 64, 64]             256
            ReLU-115          [-1, 128, 64, 64]               0
          Conv2d-116           [-1, 32, 64, 64]          36,864
     BatchNorm2d-117          [-1, 512, 64, 64]           1,024
            ReLU-118          [-1, 512, 64, 64]               0
          Conv2d-119          [-1, 256, 64, 64]         131,072
       AvgPool2d-120          [-1, 256, 32, 32]               0
     BatchNorm2d-121          [-1, 256, 32, 32]             512
            ReLU-122          [-1, 256, 32, 32]               0
          Conv2d-123          [-1, 128, 32, 32]          32,768
     BatchNorm2d-124          [-1, 128, 32, 32]             256
            ReLU-125          [-1, 128, 32, 32]               0
          Conv2d-126           [-1, 32, 32, 32]          36,864
     BatchNorm2d-127          [-1, 288, 32, 32]             576
            ReLU-128          [-1, 288, 32, 32]               0
          Conv2d-129          [-1, 128, 32, 32]          36,864
     BatchNorm2d-130          [-1, 128, 32, 32]             256
            ReLU-131          [-1, 128, 32, 32]               0
          Conv2d-132           [-1, 32, 32, 32]          36,864
     BatchNorm2d-133          [-1, 320, 32, 32]             640
            ReLU-134          [-1, 320, 32, 32]               0
          Conv2d-135          [-1, 128, 32, 32]          40,960
     BatchNorm2d-136          [-1, 128, 32, 32]             256
            ReLU-137          [-1, 128, 32, 32]               0
          Conv2d-138           [-1, 32, 32, 32]          36,864
     BatchNorm2d-139          [-1, 352, 32, 32]             704
            ReLU-140          [-1, 352, 32, 32]               0
          Conv2d-141          [-1, 128, 32, 32]          45,056
     BatchNorm2d-142          [-1, 128, 32, 32]             256
            ReLU-143          [-1, 128, 32, 32]               0
          Conv2d-144           [-1, 32, 32, 32]          36,864
     BatchNorm2d-145          [-1, 384, 32, 32]             768
            ReLU-146          [-1, 384, 32, 32]               0
          Conv2d-147          [-1, 128, 32, 32]          49,152
     BatchNorm2d-148          [-1, 128, 32, 32]             256
            ReLU-149          [-1, 128, 32, 32]               0
          Conv2d-150           [-1, 32, 32, 32]          36,864
     BatchNorm2d-151          [-1, 416, 32, 32]             832
            ReLU-152          [-1, 416, 32, 32]               0
          Conv2d-153          [-1, 128, 32, 32]          53,248
     BatchNorm2d-154          [-1, 128, 32, 32]             256
            ReLU-155          [-1, 128, 32, 32]               0
          Conv2d-156           [-1, 32, 32, 32]          36,864
     BatchNorm2d-157          [-1, 448, 32, 32]             896
            ReLU-158          [-1, 448, 32, 32]               0
          Conv2d-159          [-1, 128, 32, 32]          57,344
     BatchNorm2d-160          [-1, 128, 32, 32]             256
            ReLU-161          [-1, 128, 32, 32]               0
          Conv2d-162           [-1, 32, 32, 32]          36,864
     BatchNorm2d-163          [-1, 480, 32, 32]             960
            ReLU-164          [-1, 480, 32, 32]               0
          Conv2d-165          [-1, 128, 32, 32]          61,440
     BatchNorm2d-166          [-1, 128, 32, 32]             256
            ReLU-167          [-1, 128, 32, 32]               0
          Conv2d-168           [-1, 32, 32, 32]          36,864
     BatchNorm2d-169          [-1, 512, 32, 32]           1,024
            ReLU-170          [-1, 512, 32, 32]               0
          Conv2d-171          [-1, 128, 32, 32]          65,536
     BatchNorm2d-172          [-1, 128, 32, 32]             256
            ReLU-173          [-1, 128, 32, 32]               0
          Conv2d-174           [-1, 32, 32, 32]          36,864
     BatchNorm2d-175          [-1, 544, 32, 32]           1,088
            ReLU-176          [-1, 544, 32, 32]               0
          Conv2d-177          [-1, 128, 32, 32]          69,632
     BatchNorm2d-178          [-1, 128, 32, 32]             256
            ReLU-179          [-1, 128, 32, 32]               0
          Conv2d-180           [-1, 32, 32, 32]          36,864
     BatchNorm2d-181          [-1, 576, 32, 32]           1,152
            ReLU-182          [-1, 576, 32, 32]               0
          Conv2d-183          [-1, 128, 32, 32]          73,728
     BatchNorm2d-184          [-1, 128, 32, 32]             256
            ReLU-185          [-1, 128, 32, 32]               0
          Conv2d-186           [-1, 32, 32, 32]          36,864
     BatchNorm2d-187          [-1, 608, 32, 32]           1,216
            ReLU-188          [-1, 608, 32, 32]               0
          Conv2d-189          [-1, 128, 32, 32]          77,824
     BatchNorm2d-190          [-1, 128, 32, 32]             256
            ReLU-191          [-1, 128, 32, 32]               0
          Conv2d-192           [-1, 32, 32, 32]          36,864
     BatchNorm2d-193          [-1, 640, 32, 32]           1,280
            ReLU-194          [-1, 640, 32, 32]               0
          Conv2d-195          [-1, 128, 32, 32]          81,920
     BatchNorm2d-196          [-1, 128, 32, 32]             256
            ReLU-197          [-1, 128, 32, 32]               0
          Conv2d-198           [-1, 32, 32, 32]          36,864
     BatchNorm2d-199          [-1, 672, 32, 32]           1,344
            ReLU-200          [-1, 672, 32, 32]               0
          Conv2d-201          [-1, 128, 32, 32]          86,016
     BatchNorm2d-202          [-1, 128, 32, 32]             256
            ReLU-203          [-1, 128, 32, 32]               0
          Conv2d-204           [-1, 32, 32, 32]          36,864
     BatchNorm2d-205          [-1, 704, 32, 32]           1,408
            ReLU-206          [-1, 704, 32, 32]               0
          Conv2d-207          [-1, 128, 32, 32]          90,112
     BatchNorm2d-208          [-1, 128, 32, 32]             256
            ReLU-209          [-1, 128, 32, 32]               0
          Conv2d-210           [-1, 32, 32, 32]          36,864
     BatchNorm2d-211          [-1, 736, 32, 32]           1,472
            ReLU-212          [-1, 736, 32, 32]               0
          Conv2d-213          [-1, 128, 32, 32]          94,208
     BatchNorm2d-214          [-1, 128, 32, 32]             256
            ReLU-215          [-1, 128, 32, 32]               0
          Conv2d-216           [-1, 32, 32, 32]          36,864
     BatchNorm2d-217          [-1, 768, 32, 32]           1,536
            ReLU-218          [-1, 768, 32, 32]               0
          Conv2d-219          [-1, 128, 32, 32]          98,304
     BatchNorm2d-220          [-1, 128, 32, 32]             256
            ReLU-221          [-1, 128, 32, 32]               0
          Conv2d-222           [-1, 32, 32, 32]          36,864
     BatchNorm2d-223          [-1, 800, 32, 32]           1,600
            ReLU-224          [-1, 800, 32, 32]               0
          Conv2d-225          [-1, 128, 32, 32]         102,400
     BatchNorm2d-226          [-1, 128, 32, 32]             256
            ReLU-227          [-1, 128, 32, 32]               0
          Conv2d-228           [-1, 32, 32, 32]          36,864
     BatchNorm2d-229          [-1, 832, 32, 32]           1,664
            ReLU-230          [-1, 832, 32, 32]               0
          Conv2d-231          [-1, 128, 32, 32]         106,496
     BatchNorm2d-232          [-1, 128, 32, 32]             256
            ReLU-233          [-1, 128, 32, 32]               0
          Conv2d-234           [-1, 32, 32, 32]          36,864
     BatchNorm2d-235          [-1, 864, 32, 32]           1,728
            ReLU-236          [-1, 864, 32, 32]               0
          Conv2d-237          [-1, 128, 32, 32]         110,592
     BatchNorm2d-238          [-1, 128, 32, 32]             256
            ReLU-239          [-1, 128, 32, 32]               0
          Conv2d-240           [-1, 32, 32, 32]          36,864
     BatchNorm2d-241          [-1, 896, 32, 32]           1,792
            ReLU-242          [-1, 896, 32, 32]               0
          Conv2d-243          [-1, 128, 32, 32]         114,688
     BatchNorm2d-244          [-1, 128, 32, 32]             256
            ReLU-245          [-1, 128, 32, 32]               0
          Conv2d-246           [-1, 32, 32, 32]          36,864
     BatchNorm2d-247          [-1, 928, 32, 32]           1,856
            ReLU-248          [-1, 928, 32, 32]               0
          Conv2d-249          [-1, 128, 32, 32]         118,784
     BatchNorm2d-250          [-1, 128, 32, 32]             256
            ReLU-251          [-1, 128, 32, 32]               0
          Conv2d-252           [-1, 32, 32, 32]          36,864
     BatchNorm2d-253          [-1, 960, 32, 32]           1,920
            ReLU-254          [-1, 960, 32, 32]               0
          Conv2d-255          [-1, 128, 32, 32]         122,880
     BatchNorm2d-256          [-1, 128, 32, 32]             256
            ReLU-257          [-1, 128, 32, 32]               0
          Conv2d-258           [-1, 32, 32, 32]          36,864
     BatchNorm2d-259          [-1, 992, 32, 32]           1,984
            ReLU-260          [-1, 992, 32, 32]               0
          Conv2d-261          [-1, 128, 32, 32]         126,976
     BatchNorm2d-262          [-1, 128, 32, 32]             256
            ReLU-263          [-1, 128, 32, 32]               0
          Conv2d-264           [-1, 32, 32, 32]          36,864
     BatchNorm2d-265         [-1, 1024, 32, 32]           2,048
            ReLU-266         [-1, 1024, 32, 32]               0
          Conv2d-267          [-1, 512, 32, 32]         524,288
       AvgPool2d-268          [-1, 512, 16, 16]               0
     BatchNorm2d-269          [-1, 512, 16, 16]           1,024
            ReLU-270          [-1, 512, 16, 16]               0
          Conv2d-271          [-1, 128, 16, 16]          65,536
     BatchNorm2d-272          [-1, 128, 16, 16]             256
            ReLU-273          [-1, 128, 16, 16]               0
          Conv2d-274           [-1, 32, 16, 16]          36,864
     BatchNorm2d-275          [-1, 544, 16, 16]           1,088
            ReLU-276          [-1, 544, 16, 16]               0
          Conv2d-277          [-1, 128, 16, 16]          69,632
     BatchNorm2d-278          [-1, 128, 16, 16]             256
            ReLU-279          [-1, 128, 16, 16]               0
          Conv2d-280           [-1, 32, 16, 16]          36,864
     BatchNorm2d-281          [-1, 576, 16, 16]           1,152
            ReLU-282          [-1, 576, 16, 16]               0
          Conv2d-283          [-1, 128, 16, 16]          73,728
     BatchNorm2d-284          [-1, 128, 16, 16]             256
            ReLU-285          [-1, 128, 16, 16]               0
          Conv2d-286           [-1, 32, 16, 16]          36,864
     BatchNorm2d-287          [-1, 608, 16, 16]           1,216
            ReLU-288          [-1, 608, 16, 16]               0
          Conv2d-289          [-1, 128, 16, 16]          77,824
     BatchNorm2d-290          [-1, 128, 16, 16]             256
            ReLU-291          [-1, 128, 16, 16]               0
          Conv2d-292           [-1, 32, 16, 16]          36,864
     BatchNorm2d-293          [-1, 640, 16, 16]           1,280
            ReLU-294          [-1, 640, 16, 16]               0
          Conv2d-295          [-1, 128, 16, 16]          81,920
     BatchNorm2d-296          [-1, 128, 16, 16]             256
            ReLU-297          [-1, 128, 16, 16]               0
          Conv2d-298           [-1, 32, 16, 16]          36,864
     BatchNorm2d-299          [-1, 672, 16, 16]           1,344
            ReLU-300          [-1, 672, 16, 16]               0
          Conv2d-301          [-1, 128, 16, 16]          86,016
     BatchNorm2d-302          [-1, 128, 16, 16]             256
            ReLU-303          [-1, 128, 16, 16]               0
          Conv2d-304           [-1, 32, 16, 16]          36,864
     BatchNorm2d-305          [-1, 704, 16, 16]           1,408
            ReLU-306          [-1, 704, 16, 16]               0
          Conv2d-307          [-1, 128, 16, 16]          90,112
     BatchNorm2d-308          [-1, 128, 16, 16]             256
            ReLU-309          [-1, 128, 16, 16]               0
          Conv2d-310           [-1, 32, 16, 16]          36,864
     BatchNorm2d-311          [-1, 736, 16, 16]           1,472
            ReLU-312          [-1, 736, 16, 16]               0
          Conv2d-313          [-1, 128, 16, 16]          94,208
     BatchNorm2d-314          [-1, 128, 16, 16]             256
            ReLU-315          [-1, 128, 16, 16]               0
          Conv2d-316           [-1, 32, 16, 16]          36,864
     BatchNorm2d-317          [-1, 768, 16, 16]           1,536
            ReLU-318          [-1, 768, 16, 16]               0
          Conv2d-319          [-1, 128, 16, 16]          98,304
     BatchNorm2d-320          [-1, 128, 16, 16]             256
            ReLU-321          [-1, 128, 16, 16]               0
          Conv2d-322           [-1, 32, 16, 16]          36,864
     BatchNorm2d-323          [-1, 800, 16, 16]           1,600
            ReLU-324          [-1, 800, 16, 16]               0
          Conv2d-325          [-1, 128, 16, 16]         102,400
     BatchNorm2d-326          [-1, 128, 16, 16]             256
            ReLU-327          [-1, 128, 16, 16]               0
          Conv2d-328           [-1, 32, 16, 16]          36,864
     BatchNorm2d-329          [-1, 832, 16, 16]           1,664
            ReLU-330          [-1, 832, 16, 16]               0
          Conv2d-331          [-1, 128, 16, 16]         106,496
     BatchNorm2d-332          [-1, 128, 16, 16]             256
            ReLU-333          [-1, 128, 16, 16]               0
          Conv2d-334           [-1, 32, 16, 16]          36,864
     BatchNorm2d-335          [-1, 864, 16, 16]           1,728
            ReLU-336          [-1, 864, 16, 16]               0
          Conv2d-337          [-1, 128, 16, 16]         110,592
     BatchNorm2d-338          [-1, 128, 16, 16]             256
            ReLU-339          [-1, 128, 16, 16]               0
          Conv2d-340           [-1, 32, 16, 16]          36,864
     BatchNorm2d-341          [-1, 896, 16, 16]           1,792
            ReLU-342          [-1, 896, 16, 16]               0
          Conv2d-343          [-1, 128, 16, 16]         114,688
     BatchNorm2d-344          [-1, 128, 16, 16]             256
            ReLU-345          [-1, 128, 16, 16]               0
          Conv2d-346           [-1, 32, 16, 16]          36,864
     BatchNorm2d-347          [-1, 928, 16, 16]           1,856
            ReLU-348          [-1, 928, 16, 16]               0
          Conv2d-349          [-1, 128, 16, 16]         118,784
     BatchNorm2d-350          [-1, 128, 16, 16]             256
            ReLU-351          [-1, 128, 16, 16]               0
          Conv2d-352           [-1, 32, 16, 16]          36,864
     BatchNorm2d-353          [-1, 960, 16, 16]           1,920
            ReLU-354          [-1, 960, 16, 16]               0
          Conv2d-355          [-1, 128, 16, 16]         122,880
     BatchNorm2d-356          [-1, 128, 16, 16]             256
            ReLU-357          [-1, 128, 16, 16]               0
          Conv2d-358           [-1, 32, 16, 16]          36,864
     BatchNorm2d-359          [-1, 992, 16, 16]           1,984
            ReLU-360          [-1, 992, 16, 16]               0
          Conv2d-361          [-1, 128, 16, 16]         126,976
     BatchNorm2d-362          [-1, 128, 16, 16]             256
            ReLU-363          [-1, 128, 16, 16]               0
          Conv2d-364           [-1, 32, 16, 16]          36,864
     BatchNorm2d-365         [-1, 1024, 16, 16]           2,048
        DenseNet-366         [-1, 1024, 16, 16]               0
AdaptiveAvgPool2d-367           [-1, 1024, 1, 1]               0
          Conv2d-368           [-1, 1024, 1, 1]       1,049,600
     BatchNorm2d-369           [-1, 1024, 1, 1]           2,048
            ReLU-370           [-1, 1024, 1, 1]               0
  Conv2dNormRelu-371           [-1, 1024, 1, 1]               0
          Conv2d-372         [-1, 1024, 16, 16]       1,049,600
     BatchNorm2d-373         [-1, 1024, 16, 16]           2,048
            ReLU-374         [-1, 1024, 16, 16]               0
  Conv2dNormRelu-375         [-1, 1024, 16, 16]               0
          Conv2d-376              [-1, 1, 8, 8]          50,177
     BatchNorm2d-377              [-1, 1, 8, 8]               2
            ReLU-378              [-1, 1, 8, 8]               0
  Conv2dNormRelu-379              [-1, 1, 8, 8]               0
          Conv2d-380              [-1, 1, 4, 4]              26
     BatchNorm2d-381              [-1, 1, 4, 4]               2
            ReLU-382              [-1, 1, 4, 4]               0
  Conv2dNormRelu-383              [-1, 1, 4, 4]               0
          Conv2d-384              [-1, 1, 2, 2]              10
     BatchNorm2d-385              [-1, 1, 2, 2]               2
            ReLU-386              [-1, 1, 2, 2]               0
  Conv2dNormRelu-387              [-1, 1, 2, 2]               0
          Conv2d-388              [-1, 1, 2, 2]              10
     BatchNorm2d-389              [-1, 1, 2, 2]               2
            ReLU-390              [-1, 1, 2, 2]               0
  Conv2dNormRelu-391              [-1, 1, 2, 2]               0
          Conv2d-392              [-1, 1, 4, 4]              26
     BatchNorm2d-393              [-1, 1, 4, 4]               2
            ReLU-394              [-1, 1, 4, 4]               0
  Conv2dNormRelu-395              [-1, 1, 4, 4]               0
          Conv2d-396              [-1, 1, 8, 8]              50
     BatchNorm2d-397              [-1, 1, 8, 8]               2
            ReLU-398              [-1, 1, 8, 8]               0
  Conv2dNormRelu-399              [-1, 1, 8, 8]               0
       FPAModule-400         [-1, 1024, 16, 16]               0
    AttentionMap-401         [-1, 1024, 16, 16]               0
          Conv2d-402            [-1, 1, 16, 16]           1,025
        PcamPool-403           [-1, 1024, 1, 1]               0
      GlobalPool-404           [-1, 1024, 1, 1]               0
     BatchNorm2d-405           [-1, 1024, 1, 1]           2,048
          Conv2d-406              [-1, 1, 1, 1]           1,025
        PcamPool-407           [-1, 1024, 1, 1]               0
      GlobalPool-408           [-1, 1024, 1, 1]               0
          Linear-409                    [-1, 1]           1,025
================================================================
Total params: 9,112,586
Trainable params: 9,112,586
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 3.00
Forward/backward pass size (MB): 1551.09
Params size (MB): 34.76
Estimated Total Size (MB): 1588.85
----------------------------------------------------------------
INFO:root:2024-04-26 20:47:04, Train, Epoch : 1, Step : 10, Loss : 0.73272, Acc : 0.559, Sensitive_Loss : 0.64443, Sensitive_Acc : 18.800, Run Time : 14.27 sec
INFO:root:2024-04-26 20:47:15, Train, Epoch : 1, Step : 20, Loss : 0.65005, Acc : 0.625, Sensitive_Loss : 0.69813, Sensitive_Acc : 16.600, Run Time : 11.77 sec
INFO:root:2024-04-26 20:47:27, Train, Epoch : 1, Step : 30, Loss : 0.62373, Acc : 0.678, Sensitive_Loss : 0.66582, Sensitive_Acc : 15.200, Run Time : 11.79 sec
INFO:root:2024-04-26 20:47:38, Train, Epoch : 1, Step : 40, Loss : 0.62209, Acc : 0.678, Sensitive_Loss : 0.83871, Sensitive_Acc : 16.900, Run Time : 10.62 sec
INFO:root:2024-04-26 20:47:49, Train, Epoch : 1, Step : 50, Loss : 0.54631, Acc : 0.719, Sensitive_Loss : 0.85308, Sensitive_Acc : 14.800, Run Time : 11.76 sec
INFO:root:2024-04-26 20:48:01, Train, Epoch : 1, Step : 60, Loss : 0.54112, Acc : 0.734, Sensitive_Loss : 0.98159, Sensitive_Acc : 16.600, Run Time : 11.43 sec
INFO:root:2024-04-26 20:48:12, Train, Epoch : 1, Step : 70, Loss : 0.58112, Acc : 0.722, Sensitive_Loss : 1.02971, Sensitive_Acc : 16.100, Run Time : 11.30 sec
INFO:root:2024-04-26 20:48:24, Train, Epoch : 1, Step : 80, Loss : 0.59379, Acc : 0.719, Sensitive_Loss : 1.17589, Sensitive_Acc : 15.600, Run Time : 11.65 sec
INFO:root:2024-04-26 20:48:36, Train, Epoch : 1, Step : 90, Loss : 0.46887, Acc : 0.762, Sensitive_Loss : 1.43861, Sensitive_Acc : 15.600, Run Time : 11.89 sec
INFO:root:2024-04-26 20:48:46, Train, Epoch : 1, Step : 100, Loss : 0.50098, Acc : 0.747, Sensitive_Loss : 1.41139, Sensitive_Acc : 15.200, Run Time : 10.37 sec
INFO:root:2024-04-26 20:51:23, Dev, Step : 100, Loss : 0.62118, Acc : 0.725, Auc : 0.846, Sensitive_Loss : 1.82893, Sensitive_Acc : 15.714, Sensitive_Auc : 0.104, Mean auc: 0.846, Run Time : 156.74 sec
INFO:root:2024-04-26 20:51:23, Best, Step : 100, Loss : 0.62118, Acc : 0.725, Auc : 0.846, Sensitive_Loss : 1.82893, Sensitive_Acc : 15.714, Sensitive_Auc : 0.104, Best Auc : 0.846
INFO:root:2024-04-26 20:51:31, Train, Epoch : 1, Step : 110, Loss : 0.58798, Acc : 0.725, Sensitive_Loss : 1.64460, Sensitive_Acc : 15.300, Run Time : 165.17 sec
INFO:root:2024-04-26 20:51:44, Train, Epoch : 1, Step : 120, Loss : 0.56573, Acc : 0.753, Sensitive_Loss : 1.80396, Sensitive_Acc : 15.800, Run Time : 12.45 sec
INFO:root:2024-04-26 20:51:56, Train, Epoch : 1, Step : 130, Loss : 0.56056, Acc : 0.753, Sensitive_Loss : 1.84008, Sensitive_Acc : 16.600, Run Time : 12.41 sec
INFO:root:2024-04-26 20:52:08, Train, Epoch : 1, Step : 140, Loss : 0.52220, Acc : 0.769, Sensitive_Loss : 1.94656, Sensitive_Acc : 16.200, Run Time : 11.51 sec
INFO:root:2024-04-26 20:52:20, Train, Epoch : 1, Step : 150, Loss : 0.44760, Acc : 0.769, Sensitive_Loss : 2.12513, Sensitive_Acc : 17.800, Run Time : 12.64 sec
INFO:root:2024-04-26 20:52:33, Train, Epoch : 1, Step : 160, Loss : 0.48901, Acc : 0.747, Sensitive_Loss : 1.87241, Sensitive_Acc : 15.400, Run Time : 12.85 sec
INFO:root:2024-04-26 20:52:45, Train, Epoch : 1, Step : 170, Loss : 0.56392, Acc : 0.759, Sensitive_Loss : 1.76864, Sensitive_Acc : 16.400, Run Time : 12.23 sec
INFO:root:2024-04-26 20:52:58, Train, Epoch : 1, Step : 180, Loss : 0.51251, Acc : 0.772, Sensitive_Loss : 1.66308, Sensitive_Acc : 15.500, Run Time : 12.28 sec
INFO:root:2024-04-26 20:53:10, Train, Epoch : 1, Step : 190, Loss : 0.48536, Acc : 0.794, Sensitive_Loss : 1.46878, Sensitive_Acc : 16.900, Run Time : 12.39 sec
INFO:root:2024-04-26 20:53:22, Train, Epoch : 1, Step : 200, Loss : 0.47697, Acc : 0.759, Sensitive_Loss : 1.24308, Sensitive_Acc : 15.900, Run Time : 11.56 sec
INFO:root:2024-04-26 20:55:57, Dev, Step : 200, Loss : 0.50160, Acc : 0.784, Auc : 0.857, Sensitive_Loss : 1.27417, Sensitive_Acc : 15.343, Sensitive_Auc : 0.267, Mean auc: 0.857, Run Time : 155.64 sec
INFO:root:2024-04-26 20:55:58, Best, Step : 200, Loss : 0.50160, Acc : 0.784, Auc : 0.857, Sensitive_Loss : 1.27417, Sensitive_Acc : 15.343, Sensitive_Auc : 0.267, Best Auc : 0.857
INFO:root:2024-04-26 20:56:06, Train, Epoch : 1, Step : 210, Loss : 0.55870, Acc : 0.766, Sensitive_Loss : 0.94891, Sensitive_Acc : 14.700, Run Time : 164.90 sec
INFO:root:2024-04-26 20:56:19, Train, Epoch : 1, Step : 220, Loss : 0.53684, Acc : 0.753, Sensitive_Loss : 0.85245, Sensitive_Acc : 15.700, Run Time : 12.75 sec
INFO:root:2024-04-26 20:56:32, Train, Epoch : 1, Step : 230, Loss : 0.51634, Acc : 0.744, Sensitive_Loss : 0.77367, Sensitive_Acc : 15.900, Run Time : 12.46 sec
INFO:root:2024-04-26 20:56:44, Train, Epoch : 1, Step : 240, Loss : 0.53315, Acc : 0.787, Sensitive_Loss : 0.50232, Sensitive_Acc : 13.600, Run Time : 12.35 sec
INFO:root:2024-04-26 20:56:56, Train, Epoch : 1, Step : 250, Loss : 0.50095, Acc : 0.769, Sensitive_Loss : 0.58663, Sensitive_Acc : 15.100, Run Time : 12.30 sec
INFO:root:2024-04-26 20:57:08, Train, Epoch : 1, Step : 260, Loss : 0.63404, Acc : 0.694, Sensitive_Loss : 0.65562, Sensitive_Acc : 15.500, Run Time : 11.62 sec
INFO:root:2024-04-26 20:57:20, Train, Epoch : 1, Step : 270, Loss : 0.46436, Acc : 0.775, Sensitive_Loss : 0.61036, Sensitive_Acc : 17.100, Run Time : 11.67 sec
INFO:root:2024-04-26 20:57:32, Train, Epoch : 1, Step : 280, Loss : 0.41579, Acc : 0.825, Sensitive_Loss : 0.46518, Sensitive_Acc : 14.900, Run Time : 12.08 sec
INFO:root:2024-04-26 20:57:43, Train, Epoch : 1, Step : 290, Loss : 0.50787, Acc : 0.791, Sensitive_Loss : 0.57969, Sensitive_Acc : 17.200, Run Time : 11.76 sec
INFO:root:2024-04-26 20:57:56, Train, Epoch : 1, Step : 300, Loss : 0.56300, Acc : 0.706, Sensitive_Loss : 0.53246, Sensitive_Acc : 15.300, Run Time : 12.58 sec
INFO:root:2024-04-26 21:00:32, Dev, Step : 300, Loss : 0.50831, Acc : 0.772, Auc : 0.843, Sensitive_Loss : 0.57840, Sensitive_Acc : 15.921, Sensitive_Auc : 0.766, Mean auc: 0.843, Run Time : 156.28 sec
INFO:root:2024-04-26 21:00:41, Train, Epoch : 1, Step : 310, Loss : 0.53557, Acc : 0.769, Sensitive_Loss : 0.47496, Sensitive_Acc : 16.000, Run Time : 165.12 sec
INFO:root:2024-04-26 21:00:53, Train, Epoch : 1, Step : 320, Loss : 0.42309, Acc : 0.828, Sensitive_Loss : 0.43794, Sensitive_Acc : 16.900, Run Time : 12.08 sec
INFO:root:2024-04-26 21:01:06, Train, Epoch : 1, Step : 330, Loss : 0.50615, Acc : 0.778, Sensitive_Loss : 0.34535, Sensitive_Acc : 17.300, Run Time : 12.25 sec
INFO:root:2024-04-26 21:01:19, Train, Epoch : 1, Step : 340, Loss : 0.53996, Acc : 0.747, Sensitive_Loss : 0.40946, Sensitive_Acc : 16.300, Run Time : 13.14 sec
INFO:root:2024-04-26 21:01:31, Train, Epoch : 1, Step : 350, Loss : 0.45149, Acc : 0.803, Sensitive_Loss : 0.38374, Sensitive_Acc : 16.700, Run Time : 12.78 sec
INFO:root:2024-04-26 21:01:44, Train, Epoch : 1, Step : 360, Loss : 0.48407, Acc : 0.756, Sensitive_Loss : 0.39393, Sensitive_Acc : 13.600, Run Time : 12.61 sec
INFO:root:2024-04-26 21:01:57, Train, Epoch : 1, Step : 370, Loss : 0.42841, Acc : 0.787, Sensitive_Loss : 0.39077, Sensitive_Acc : 14.400, Run Time : 13.05 sec
INFO:root:2024-04-26 21:02:11, Train, Epoch : 1, Step : 380, Loss : 0.49055, Acc : 0.769, Sensitive_Loss : 0.37500, Sensitive_Acc : 17.100, Run Time : 13.57 sec
INFO:root:2024-04-26 21:02:23, Train, Epoch : 1, Step : 390, Loss : 0.45963, Acc : 0.762, Sensitive_Loss : 0.36490, Sensitive_Acc : 16.000, Run Time : 12.33 sec
INFO:root:2024-04-26 21:02:35, Train, Epoch : 1, Step : 400, Loss : 0.54115, Acc : 0.747, Sensitive_Loss : 0.36318, Sensitive_Acc : 15.000, Run Time : 12.23 sec
INFO:root:2024-04-26 21:05:11, Dev, Step : 400, Loss : 0.47985, Acc : 0.787, Auc : 0.866, Sensitive_Loss : 0.36650, Sensitive_Acc : 16.721, Sensitive_Auc : 0.935, Mean auc: 0.866, Run Time : 155.48 sec
INFO:root:2024-04-26 21:05:11, Best, Step : 400, Loss : 0.47985, Acc : 0.787, Auc : 0.866, Sensitive_Loss : 0.36650, Sensitive_Acc : 16.721, Sensitive_Auc : 0.935, Best Auc : 0.866
INFO:root:2024-04-26 21:05:20, Train, Epoch : 1, Step : 410, Loss : 0.49242, Acc : 0.759, Sensitive_Loss : 0.33213, Sensitive_Acc : 15.500, Run Time : 164.86 sec
INFO:root:2024-04-26 21:05:33, Train, Epoch : 1, Step : 420, Loss : 0.44835, Acc : 0.778, Sensitive_Loss : 0.32835, Sensitive_Acc : 15.800, Run Time : 12.55 sec
INFO:root:2024-04-26 21:05:45, Train, Epoch : 1, Step : 430, Loss : 0.48391, Acc : 0.787, Sensitive_Loss : 0.22670, Sensitive_Acc : 15.700, Run Time : 12.65 sec
INFO:root:2024-04-26 21:05:59, Train, Epoch : 1, Step : 440, Loss : 0.46368, Acc : 0.800, Sensitive_Loss : 0.26574, Sensitive_Acc : 16.000, Run Time : 13.28 sec
INFO:root:2024-04-26 21:06:11, Train, Epoch : 1, Step : 450, Loss : 0.47264, Acc : 0.766, Sensitive_Loss : 0.23460, Sensitive_Acc : 14.700, Run Time : 12.20 sec
INFO:root:2024-04-26 21:06:24, Train, Epoch : 1, Step : 460, Loss : 0.43143, Acc : 0.816, Sensitive_Loss : 0.22547, Sensitive_Acc : 16.200, Run Time : 13.32 sec
INFO:root:2024-04-26 21:06:37, Train, Epoch : 1, Step : 470, Loss : 0.57172, Acc : 0.741, Sensitive_Loss : 0.20968, Sensitive_Acc : 16.900, Run Time : 13.31 sec
INFO:root:2024-04-26 21:06:51, Train, Epoch : 1, Step : 480, Loss : 0.53636, Acc : 0.753, Sensitive_Loss : 0.26423, Sensitive_Acc : 15.500, Run Time : 13.73 sec
INFO:root:2024-04-26 21:07:03, Train, Epoch : 1, Step : 490, Loss : 0.53901, Acc : 0.756, Sensitive_Loss : 0.23972, Sensitive_Acc : 15.800, Run Time : 12.29 sec
INFO:root:2024-04-26 21:07:17, Train, Epoch : 1, Step : 500, Loss : 0.49528, Acc : 0.787, Sensitive_Loss : 0.27412, Sensitive_Acc : 16.800, Run Time : 13.70 sec
INFO:root:2024-04-26 21:09:53, Dev, Step : 500, Loss : 0.50929, Acc : 0.766, Auc : 0.855, Sensitive_Loss : 0.29025, Sensitive_Acc : 16.679, Sensitive_Auc : 0.943, Mean auc: 0.855, Run Time : 156.06 sec
INFO:root:2024-04-26 21:10:02, Train, Epoch : 1, Step : 510, Loss : 0.51143, Acc : 0.778, Sensitive_Loss : 0.29367, Sensitive_Acc : 15.000, Run Time : 165.22 sec
INFO:root:2024-04-26 21:10:16, Train, Epoch : 1, Step : 520, Loss : 0.44578, Acc : 0.794, Sensitive_Loss : 0.29076, Sensitive_Acc : 16.100, Run Time : 13.34 sec
INFO:root:2024-04-26 21:10:29, Train, Epoch : 1, Step : 530, Loss : 0.46720, Acc : 0.794, Sensitive_Loss : 0.27790, Sensitive_Acc : 14.300, Run Time : 13.18 sec
INFO:root:2024-04-26 21:10:41, Train, Epoch : 1, Step : 540, Loss : 0.44782, Acc : 0.797, Sensitive_Loss : 0.29317, Sensitive_Acc : 17.200, Run Time : 12.63 sec
INFO:root:2024-04-26 21:10:54, Train, Epoch : 1, Step : 550, Loss : 0.50902, Acc : 0.756, Sensitive_Loss : 0.21100, Sensitive_Acc : 16.800, Run Time : 12.36 sec
INFO:root:2024-04-26 21:11:07, Train, Epoch : 1, Step : 560, Loss : 0.46743, Acc : 0.778, Sensitive_Loss : 0.22532, Sensitive_Acc : 15.300, Run Time : 13.31 sec
INFO:root:2024-04-26 21:11:20, Train, Epoch : 1, Step : 570, Loss : 0.46989, Acc : 0.800, Sensitive_Loss : 0.20249, Sensitive_Acc : 17.300, Run Time : 13.16 sec
INFO:root:2024-04-26 21:11:34, Train, Epoch : 1, Step : 580, Loss : 0.51724, Acc : 0.775, Sensitive_Loss : 0.22796, Sensitive_Acc : 15.700, Run Time : 13.72 sec
INFO:root:2024-04-26 21:11:47, Train, Epoch : 1, Step : 590, Loss : 0.40286, Acc : 0.828, Sensitive_Loss : 0.21972, Sensitive_Acc : 16.400, Run Time : 13.47 sec
INFO:root:2024-04-26 21:12:00, Train, Epoch : 1, Step : 600, Loss : 0.46039, Acc : 0.766, Sensitive_Loss : 0.20535, Sensitive_Acc : 16.400, Run Time : 12.57 sec
INFO:root:2024-04-26 21:14:36, Dev, Step : 600, Loss : 0.47834, Acc : 0.790, Auc : 0.870, Sensitive_Loss : 0.23509, Sensitive_Acc : 17.021, Sensitive_Auc : 0.965, Mean auc: 0.870, Run Time : 156.13 sec
INFO:root:2024-04-26 21:14:37, Best, Step : 600, Loss : 0.47834, Acc : 0.790, Auc : 0.870, Sensitive_Loss : 0.23509, Sensitive_Acc : 17.021, Sensitive_Auc : 0.965, Best Auc : 0.870
INFO:root:2024-04-26 21:14:46, Train, Epoch : 1, Step : 610, Loss : 0.45357, Acc : 0.759, Sensitive_Loss : 0.24212, Sensitive_Acc : 15.000, Run Time : 165.97 sec
INFO:root:2024-04-26 21:14:59, Train, Epoch : 1, Step : 620, Loss : 0.45709, Acc : 0.825, Sensitive_Loss : 0.20711, Sensitive_Acc : 18.200, Run Time : 13.03 sec
INFO:root:2024-04-26 21:17:39
INFO:root:y_pred: [0.5132715  0.9567585  0.08282577 ... 0.6086836  0.00576146 0.75432485]
INFO:root:y_true: [0. 1. 0. ... 1. 0. 1.]
INFO:root:sensitive_y_pred: [8.43375802e-01 3.40493349e-03 3.65915596e-01 8.96661601e-04
 9.00000155e-01 4.22285218e-03 9.46334720e-01 5.98788857e-01
 2.68032681e-02 2.02508137e-01 9.65951979e-01 8.99775505e-01
 9.07345593e-01 6.07552290e-01 2.31492147e-01 7.92354822e-01
 9.37672317e-01 8.50354880e-02 2.98349530e-01 9.94284689e-01
 8.46507967e-01 1.60522461e-01 9.09341514e-01 5.85245430e-01
 7.44534671e-01 4.01665777e-01 4.00224840e-03 9.02636468e-01
 8.07628751e-01 4.01083976e-01 2.88419873e-01 2.58473814e-01
 4.07209635e-01 3.28189224e-01 3.88507284e-02 4.68541915e-03
 9.07449052e-02 6.73797056e-02 7.76806712e-01 8.12630713e-01
 4.65070025e-06 3.34695750e-03 9.13474500e-01 5.35749691e-03
 9.69857514e-01 9.49750662e-01 7.20452487e-01 9.81449068e-01
 1.27154261e-01 5.93015015e-01 9.83786404e-01 6.12374656e-02
 7.60566294e-01 4.63588983e-02 2.29738318e-04 4.16470552e-03
 5.94382733e-02 2.14683622e-01 3.50337359e-03 1.23575419e-01
 2.91195847e-02 2.98926979e-01 1.09880567e-02 8.62157226e-01
 2.06150025e-01 9.23025310e-01 9.57398396e-03 9.42254782e-01
 6.08261168e-01 7.42456615e-01 6.22968256e-01 4.95281577e-01
 6.83175325e-02 1.91367730e-01 2.97939423e-02 1.81011576e-02
 8.69416296e-02 1.10863417e-01 8.52522731e-04 8.34116578e-01
 9.28120852e-01 1.72515528e-03 2.35774562e-01 1.30237453e-02
 9.14166749e-01 8.40118676e-02 5.65421320e-02 1.24695823e-01
 8.15438330e-01 9.10243273e-01 9.15980279e-01 2.59870403e-02
 2.88435514e-03 8.46310556e-01 3.67589086e-01 1.38318446e-02
 9.71220911e-01 8.71487021e-01 3.87000702e-02 1.35599747e-01
 5.79388499e-01 4.24710095e-01 9.89015162e-01 8.54674876e-01
 8.48669268e-04 5.53237259e-01 4.16054696e-01 5.34779251e-01
 5.36478519e-01 4.19164920e-04 5.27771115e-01 8.97439659e-01
 2.46536925e-01 9.44451392e-01 3.57364237e-01 5.19462705e-01
 7.19784081e-01 7.68445611e-01 2.91043639e-01 1.55358061e-01
 9.20648217e-01 8.41922045e-01 1.40161765e-05 9.49338794e-01
 8.19993496e-01 1.76820502e-01 9.17912006e-01 2.37318575e-02
 2.53513139e-02 9.09719408e-01 9.15851712e-01 5.52105065e-03
 1.04268320e-01 4.88441214e-02 7.75623858e-01 9.54056740e-01
 6.76852405e-01 7.79562909e-03 3.99173051e-02 7.52700031e-01]
INFO:root:sensitive_y_true: [1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.
 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.]
INFO:root:2024-04-26 21:17:39, Dev, Step : 626, Loss : 0.51363, Acc : 0.758, Auc : 0.846, Sensitive_Loss : 0.26524, Sensitive_Acc : 16.879, Sensitive_Auc : 0.959, Mean auc: 0.846, Run Time : 152.53 sec
INFO:root:2024-04-26 21:17:46, Train, Epoch : 2, Step : 630, Loss : 0.16040, Acc : 0.316, Sensitive_Loss : 0.09053, Sensitive_Acc : 6.800, Run Time : 5.93 sec
INFO:root:2024-04-26 21:17:58, Train, Epoch : 2, Step : 640, Loss : 0.55216, Acc : 0.756, Sensitive_Loss : 0.19462, Sensitive_Acc : 14.400, Run Time : 12.10 sec
INFO:root:2024-04-26 21:18:09, Train, Epoch : 2, Step : 650, Loss : 0.47713, Acc : 0.775, Sensitive_Loss : 0.22672, Sensitive_Acc : 16.100, Run Time : 11.09 sec
INFO:root:2024-04-26 21:18:22, Train, Epoch : 2, Step : 660, Loss : 0.38751, Acc : 0.816, Sensitive_Loss : 0.20825, Sensitive_Acc : 13.800, Run Time : 12.09 sec
INFO:root:2024-04-26 21:18:32, Train, Epoch : 2, Step : 670, Loss : 0.39601, Acc : 0.828, Sensitive_Loss : 0.22500, Sensitive_Acc : 15.300, Run Time : 10.77 sec
INFO:root:2024-04-26 21:18:43, Train, Epoch : 2, Step : 680, Loss : 0.52484, Acc : 0.772, Sensitive_Loss : 0.17512, Sensitive_Acc : 14.700, Run Time : 11.00 sec
INFO:root:2024-04-26 21:18:55, Train, Epoch : 2, Step : 690, Loss : 0.45245, Acc : 0.816, Sensitive_Loss : 0.18571, Sensitive_Acc : 16.300, Run Time : 11.88 sec
INFO:root:2024-04-26 21:19:06, Train, Epoch : 2, Step : 700, Loss : 0.45377, Acc : 0.778, Sensitive_Loss : 0.17794, Sensitive_Acc : 15.700, Run Time : 10.96 sec
INFO:root:2024-04-26 21:21:42, Dev, Step : 700, Loss : 0.45389, Acc : 0.805, Auc : 0.881, Sensitive_Loss : 0.20999, Sensitive_Acc : 16.793, Sensitive_Auc : 0.963, Mean auc: 0.881, Run Time : 155.66 sec
INFO:root:2024-04-26 21:21:43, Best, Step : 700, Loss : 0.45389, Acc : 0.805, Auc : 0.881, Sensitive_Loss : 0.20999, Sensitive_Acc : 16.793, Sensitive_Auc : 0.963, Best Auc : 0.881
INFO:root:2024-04-26 21:21:52, Train, Epoch : 2, Step : 710, Loss : 0.48411, Acc : 0.794, Sensitive_Loss : 0.19372, Sensitive_Acc : 16.000, Run Time : 165.89 sec
INFO:root:2024-04-26 21:22:03, Train, Epoch : 2, Step : 720, Loss : 0.39349, Acc : 0.844, Sensitive_Loss : 0.14422, Sensitive_Acc : 14.800, Run Time : 11.20 sec
INFO:root:2024-04-26 21:22:16, Train, Epoch : 2, Step : 730, Loss : 0.44160, Acc : 0.806, Sensitive_Loss : 0.22832, Sensitive_Acc : 16.000, Run Time : 12.27 sec
INFO:root:2024-04-26 21:22:27, Train, Epoch : 2, Step : 740, Loss : 0.46678, Acc : 0.812, Sensitive_Loss : 0.13331, Sensitive_Acc : 17.200, Run Time : 11.87 sec
INFO:root:2024-04-26 21:22:38, Train, Epoch : 2, Step : 750, Loss : 0.52660, Acc : 0.766, Sensitive_Loss : 0.19926, Sensitive_Acc : 15.400, Run Time : 10.63 sec
INFO:root:2024-04-26 21:22:49, Train, Epoch : 2, Step : 760, Loss : 0.46288, Acc : 0.803, Sensitive_Loss : 0.15963, Sensitive_Acc : 15.400, Run Time : 10.68 sec
INFO:root:2024-04-26 21:23:00, Train, Epoch : 2, Step : 770, Loss : 0.45129, Acc : 0.784, Sensitive_Loss : 0.23285, Sensitive_Acc : 16.800, Run Time : 11.48 sec
INFO:root:2024-04-26 21:23:12, Train, Epoch : 2, Step : 780, Loss : 0.43647, Acc : 0.797, Sensitive_Loss : 0.14934, Sensitive_Acc : 17.800, Run Time : 11.76 sec
INFO:root:2024-04-26 21:23:24, Train, Epoch : 2, Step : 790, Loss : 0.47008, Acc : 0.806, Sensitive_Loss : 0.19286, Sensitive_Acc : 18.000, Run Time : 12.21 sec
INFO:root:2024-04-26 21:23:34, Train, Epoch : 2, Step : 800, Loss : 0.44662, Acc : 0.797, Sensitive_Loss : 0.20353, Sensitive_Acc : 15.200, Run Time : 10.31 sec
INFO:root:2024-04-26 21:26:11, Dev, Step : 800, Loss : 0.49900, Acc : 0.788, Auc : 0.886, Sensitive_Loss : 0.24270, Sensitive_Acc : 16.893, Sensitive_Auc : 0.970, Mean auc: 0.886, Run Time : 156.26 sec
INFO:root:2024-04-26 21:26:12, Best, Step : 800, Loss : 0.49900, Acc : 0.788, Auc : 0.886, Sensitive_Loss : 0.24270, Sensitive_Acc : 16.893, Sensitive_Auc : 0.970, Best Auc : 0.886
INFO:root:2024-04-26 21:26:20, Train, Epoch : 2, Step : 810, Loss : 0.46500, Acc : 0.781, Sensitive_Loss : 0.17101, Sensitive_Acc : 15.600, Run Time : 165.44 sec
INFO:root:2024-04-26 21:26:32, Train, Epoch : 2, Step : 820, Loss : 0.43999, Acc : 0.775, Sensitive_Loss : 0.22253, Sensitive_Acc : 17.400, Run Time : 12.38 sec
INFO:root:2024-04-26 21:26:43, Train, Epoch : 2, Step : 830, Loss : 0.47549, Acc : 0.803, Sensitive_Loss : 0.24326, Sensitive_Acc : 15.900, Run Time : 11.14 sec
INFO:root:2024-04-26 21:26:56, Train, Epoch : 2, Step : 840, Loss : 0.42134, Acc : 0.825, Sensitive_Loss : 0.20354, Sensitive_Acc : 15.900, Run Time : 12.42 sec
INFO:root:2024-04-26 21:27:07, Train, Epoch : 2, Step : 850, Loss : 0.45043, Acc : 0.787, Sensitive_Loss : 0.28395, Sensitive_Acc : 17.000, Run Time : 11.30 sec
INFO:root:2024-04-26 21:27:19, Train, Epoch : 2, Step : 860, Loss : 0.51292, Acc : 0.762, Sensitive_Loss : 0.23620, Sensitive_Acc : 16.200, Run Time : 11.57 sec
INFO:root:2024-04-26 21:27:30, Train, Epoch : 2, Step : 870, Loss : 0.39801, Acc : 0.809, Sensitive_Loss : 0.19254, Sensitive_Acc : 17.000, Run Time : 10.91 sec
INFO:root:2024-04-26 21:27:41, Train, Epoch : 2, Step : 880, Loss : 0.44174, Acc : 0.794, Sensitive_Loss : 0.20061, Sensitive_Acc : 16.400, Run Time : 11.64 sec
INFO:root:2024-04-26 21:27:53, Train, Epoch : 2, Step : 890, Loss : 0.38756, Acc : 0.787, Sensitive_Loss : 0.27855, Sensitive_Acc : 16.100, Run Time : 11.53 sec
INFO:root:2024-04-26 21:28:05, Train, Epoch : 2, Step : 900, Loss : 0.44916, Acc : 0.787, Sensitive_Loss : 0.25705, Sensitive_Acc : 15.400, Run Time : 11.71 sec
INFO:root:2024-04-26 21:30:40, Dev, Step : 900, Loss : 0.47274, Acc : 0.794, Auc : 0.876, Sensitive_Loss : 0.27842, Sensitive_Acc : 16.679, Sensitive_Auc : 0.970, Mean auc: 0.876, Run Time : 155.82 sec
INFO:root:2024-04-26 21:30:49, Train, Epoch : 2, Step : 910, Loss : 0.42769, Acc : 0.803, Sensitive_Loss : 0.22666, Sensitive_Acc : 15.600, Run Time : 164.58 sec
INFO:root:2024-04-26 21:31:01, Train, Epoch : 2, Step : 920, Loss : 0.44121, Acc : 0.794, Sensitive_Loss : 0.25771, Sensitive_Acc : 16.600, Run Time : 12.15 sec
INFO:root:2024-04-26 21:31:13, Train, Epoch : 2, Step : 930, Loss : 0.38198, Acc : 0.856, Sensitive_Loss : 0.20383, Sensitive_Acc : 16.900, Run Time : 11.42 sec
INFO:root:2024-04-26 21:31:24, Train, Epoch : 2, Step : 940, Loss : 0.43192, Acc : 0.806, Sensitive_Loss : 0.18638, Sensitive_Acc : 15.700, Run Time : 10.86 sec
INFO:root:2024-04-26 21:31:36, Train, Epoch : 2, Step : 950, Loss : 0.51434, Acc : 0.791, Sensitive_Loss : 0.20739, Sensitive_Acc : 16.200, Run Time : 12.23 sec
INFO:root:2024-04-26 21:31:47, Train, Epoch : 2, Step : 960, Loss : 0.44625, Acc : 0.791, Sensitive_Loss : 0.26421, Sensitive_Acc : 15.500, Run Time : 10.92 sec
INFO:root:2024-04-26 21:31:58, Train, Epoch : 2, Step : 970, Loss : 0.38488, Acc : 0.794, Sensitive_Loss : 0.15496, Sensitive_Acc : 16.400, Run Time : 11.40 sec
INFO:root:2024-04-26 21:32:10, Train, Epoch : 2, Step : 980, Loss : 0.40221, Acc : 0.816, Sensitive_Loss : 0.27536, Sensitive_Acc : 15.900, Run Time : 11.47 sec
INFO:root:2024-04-26 21:32:21, Train, Epoch : 2, Step : 990, Loss : 0.52151, Acc : 0.734, Sensitive_Loss : 0.22462, Sensitive_Acc : 16.000, Run Time : 11.14 sec
INFO:root:2024-04-26 21:32:32, Train, Epoch : 2, Step : 1000, Loss : 0.54988, Acc : 0.753, Sensitive_Loss : 0.23986, Sensitive_Acc : 16.800, Run Time : 11.44 sec
INFO:root:2024-04-26 21:35:08, Dev, Step : 1000, Loss : 0.50593, Acc : 0.764, Auc : 0.875, Sensitive_Loss : 0.32639, Sensitive_Acc : 16.714, Sensitive_Auc : 0.978, Mean auc: 0.875, Run Time : 155.82 sec
INFO:root:2024-04-26 21:35:17, Train, Epoch : 2, Step : 1010, Loss : 0.44748, Acc : 0.784, Sensitive_Loss : 0.21355, Sensitive_Acc : 18.200, Run Time : 164.56 sec
INFO:root:2024-04-26 21:35:28, Train, Epoch : 2, Step : 1020, Loss : 0.47353, Acc : 0.794, Sensitive_Loss : 0.19365, Sensitive_Acc : 16.200, Run Time : 11.15 sec
INFO:root:2024-04-26 21:35:40, Train, Epoch : 2, Step : 1030, Loss : 0.52825, Acc : 0.744, Sensitive_Loss : 0.21030, Sensitive_Acc : 16.400, Run Time : 12.19 sec
INFO:root:2024-04-26 21:35:52, Train, Epoch : 2, Step : 1040, Loss : 0.41348, Acc : 0.781, Sensitive_Loss : 0.24464, Sensitive_Acc : 17.300, Run Time : 11.45 sec
INFO:root:2024-04-26 21:36:04, Train, Epoch : 2, Step : 1050, Loss : 0.36393, Acc : 0.838, Sensitive_Loss : 0.20925, Sensitive_Acc : 15.800, Run Time : 12.22 sec
INFO:root:2024-04-26 21:36:15, Train, Epoch : 2, Step : 1060, Loss : 0.39981, Acc : 0.847, Sensitive_Loss : 0.14070, Sensitive_Acc : 16.100, Run Time : 11.02 sec
INFO:root:2024-04-26 21:36:27, Train, Epoch : 2, Step : 1070, Loss : 0.49347, Acc : 0.816, Sensitive_Loss : 0.20777, Sensitive_Acc : 15.800, Run Time : 11.87 sec
INFO:root:2024-04-26 21:36:38, Train, Epoch : 2, Step : 1080, Loss : 0.52735, Acc : 0.784, Sensitive_Loss : 0.17547, Sensitive_Acc : 15.800, Run Time : 11.68 sec
INFO:root:2024-04-26 21:36:49, Train, Epoch : 2, Step : 1090, Loss : 0.44727, Acc : 0.775, Sensitive_Loss : 0.20314, Sensitive_Acc : 15.800, Run Time : 11.08 sec
INFO:root:2024-04-26 21:37:01, Train, Epoch : 2, Step : 1100, Loss : 0.40061, Acc : 0.847, Sensitive_Loss : 0.17194, Sensitive_Acc : 16.700, Run Time : 11.38 sec
INFO:root:2024-04-26 21:39:37, Dev, Step : 1100, Loss : 0.45660, Acc : 0.801, Auc : 0.883, Sensitive_Loss : 0.29482, Sensitive_Acc : 16.464, Sensitive_Auc : 0.954, Mean auc: 0.883, Run Time : 155.85 sec
INFO:root:2024-04-26 21:39:45, Train, Epoch : 2, Step : 1110, Loss : 0.54161, Acc : 0.772, Sensitive_Loss : 0.24477, Sensitive_Acc : 16.500, Run Time : 163.94 sec
INFO:root:2024-04-26 21:39:57, Train, Epoch : 2, Step : 1120, Loss : 0.40468, Acc : 0.794, Sensitive_Loss : 0.21847, Sensitive_Acc : 16.200, Run Time : 12.08 sec
INFO:root:2024-04-26 21:40:08, Train, Epoch : 2, Step : 1130, Loss : 0.46871, Acc : 0.791, Sensitive_Loss : 0.17230, Sensitive_Acc : 14.600, Run Time : 11.40 sec
INFO:root:2024-04-26 21:40:19, Train, Epoch : 2, Step : 1140, Loss : 0.43076, Acc : 0.816, Sensitive_Loss : 0.14967, Sensitive_Acc : 14.900, Run Time : 10.96 sec
INFO:root:2024-04-26 21:40:31, Train, Epoch : 2, Step : 1150, Loss : 0.47878, Acc : 0.803, Sensitive_Loss : 0.21395, Sensitive_Acc : 14.900, Run Time : 11.97 sec
INFO:root:2024-04-26 21:40:43, Train, Epoch : 2, Step : 1160, Loss : 0.46953, Acc : 0.772, Sensitive_Loss : 0.23944, Sensitive_Acc : 16.200, Run Time : 11.77 sec
INFO:root:2024-04-26 21:40:54, Train, Epoch : 2, Step : 1170, Loss : 0.44229, Acc : 0.784, Sensitive_Loss : 0.21731, Sensitive_Acc : 15.900, Run Time : 11.13 sec
INFO:root:2024-04-26 21:41:05, Train, Epoch : 2, Step : 1180, Loss : 0.42546, Acc : 0.828, Sensitive_Loss : 0.23558, Sensitive_Acc : 17.400, Run Time : 11.35 sec
INFO:root:2024-04-26 21:41:17, Train, Epoch : 2, Step : 1190, Loss : 0.39017, Acc : 0.828, Sensitive_Loss : 0.20856, Sensitive_Acc : 16.900, Run Time : 11.49 sec
INFO:root:2024-04-26 21:41:28, Train, Epoch : 2, Step : 1200, Loss : 0.48578, Acc : 0.766, Sensitive_Loss : 0.15622, Sensitive_Acc : 15.700, Run Time : 11.44 sec
INFO:root:2024-04-26 21:44:12, Dev, Step : 1200, Loss : 0.45733, Acc : 0.799, Auc : 0.881, Sensitive_Loss : 0.19661, Sensitive_Acc : 16.693, Sensitive_Auc : 0.977, Mean auc: 0.881, Run Time : 163.34 sec
INFO:root:2024-04-26 21:44:20, Train, Epoch : 2, Step : 1210, Loss : 0.44809, Acc : 0.794, Sensitive_Loss : 0.21892, Sensitive_Acc : 16.400, Run Time : 171.90 sec
INFO:root:2024-04-26 21:44:32, Train, Epoch : 2, Step : 1220, Loss : 0.46874, Acc : 0.781, Sensitive_Loss : 0.19935, Sensitive_Acc : 16.200, Run Time : 11.74 sec
INFO:root:2024-04-26 21:44:43, Train, Epoch : 2, Step : 1230, Loss : 0.55048, Acc : 0.778, Sensitive_Loss : 0.27473, Sensitive_Acc : 15.900, Run Time : 11.46 sec
INFO:root:2024-04-26 21:44:56, Train, Epoch : 2, Step : 1240, Loss : 0.42385, Acc : 0.825, Sensitive_Loss : 0.23328, Sensitive_Acc : 18.200, Run Time : 12.21 sec
INFO:root:2024-04-26 21:45:07, Train, Epoch : 2, Step : 1250, Loss : 0.45191, Acc : 0.794, Sensitive_Loss : 0.20908, Sensitive_Acc : 16.500, Run Time : 11.04 sec
INFO:root:2024-04-26 21:47:49
INFO:root:y_pred: [0.1062399  0.92338425 0.06719988 ... 0.5171018  0.0090624  0.54953873]
INFO:root:y_true: [0. 1. 0. ... 1. 0. 1.]
INFO:root:sensitive_y_pred: [9.73733366e-01 2.58256478e-04 8.20125192e-02 1.35598588e-03
 9.86142814e-01 1.20763407e-05 9.94374871e-01 9.60158348e-01
 1.33053893e-02 3.58905137e-01 9.92705166e-01 9.92306054e-01
 9.69095290e-01 9.07603979e-01 3.75239998e-01 9.42578554e-01
 9.91953313e-01 3.07805073e-02 2.51568615e-01 9.88643110e-01
 9.33190703e-01 6.31488534e-03 9.94913816e-01 9.33542967e-01
 9.45293903e-01 9.05035913e-01 1.41536314e-02 9.78484154e-01
 9.50993836e-01 2.76849031e-01 2.42806241e-01 7.75805414e-02
 2.30237663e-01 3.27299476e-01 1.68809399e-01 2.08039139e-03
 3.07630748e-01 1.86028197e-01 9.69516337e-01 9.55442011e-01
 3.54761864e-09 1.86548768e-05 9.01055634e-01 1.26740225e-02
 9.96773899e-01 9.71680701e-01 8.96393955e-01 9.92197216e-01
 2.21271138e-03 9.32027578e-01 9.63119924e-01 1.74926877e-01
 1.80899546e-01 9.43707395e-03 1.59154399e-06 7.04475795e-04
 3.12224645e-02 6.86129908e-09 4.13516507e-04 1.71225816e-01
 1.09434791e-03 2.74124984e-02 2.05958102e-04 8.75592351e-01
 2.93965518e-01 9.88987744e-01 1.08957254e-04 9.85266685e-01
 9.08176661e-01 7.03709483e-01 3.61375988e-01 4.17597324e-01
 3.35657448e-02 1.51940286e-01 4.62461859e-02 1.86708305e-04
 1.93976448e-03 1.96963310e-01 1.56520680e-02 9.87083912e-01
 9.85755742e-01 6.84335316e-03 5.18538773e-01 3.77207936e-04
 6.78304374e-01 8.53879750e-01 1.27382159e-01 4.29835124e-03
 9.67364788e-01 9.62258875e-01 9.91070986e-01 2.45967018e-03
 7.75182340e-03 9.88110423e-01 5.39929152e-01 2.18063616e-03
 9.90457535e-01 9.91832852e-01 1.72933447e-04 2.11495999e-02
 9.43334222e-01 9.05535579e-01 9.56815362e-01 9.56559062e-01
 1.22202779e-04 9.45523381e-01 8.05406868e-01 9.43215013e-01
 8.73019874e-01 2.36933872e-07 7.99355388e-01 8.47747982e-01
 1.24168277e-01 9.91119683e-01 9.14520442e-01 9.50505257e-01
 9.83393967e-01 9.76854146e-01 1.58988699e-01 1.06278742e-02
 9.83282566e-01 9.83106732e-01 1.41680755e-06 9.36321914e-01
 9.86830056e-01 2.30925888e-01 9.91993427e-01 9.27795889e-04
 1.14802375e-01 5.07922292e-01 9.73808765e-01 3.11030191e-03
 3.14179547e-02 2.12129056e-02 9.82341528e-01 9.97136474e-01
 8.69835913e-01 5.40956680e-04 6.11847490e-02 9.05163884e-01]
INFO:root:sensitive_y_true: [1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.
 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.]
INFO:root:2024-04-26 21:47:49, Dev, Step : 1252, Loss : 0.49008, Acc : 0.782, Auc : 0.873, Sensitive_Loss : 0.19284, Sensitive_Acc : 16.893, Sensitive_Auc : 0.987, Mean auc: 0.873, Run Time : 161.46 sec
INFO:root:2024-04-26 21:48:01, Train, Epoch : 3, Step : 1260, Loss : 0.35009, Acc : 0.666, Sensitive_Loss : 0.11631, Sensitive_Acc : 12.400, Run Time : 10.80 sec
INFO:root:2024-04-26 21:48:13, Train, Epoch : 3, Step : 1270, Loss : 0.43743, Acc : 0.772, Sensitive_Loss : 0.20265, Sensitive_Acc : 15.400, Run Time : 11.49 sec
INFO:root:2024-04-26 21:48:26, Train, Epoch : 3, Step : 1280, Loss : 0.44572, Acc : 0.800, Sensitive_Loss : 0.13394, Sensitive_Acc : 16.300, Run Time : 13.08 sec
INFO:root:2024-04-26 21:48:37, Train, Epoch : 3, Step : 1290, Loss : 0.37704, Acc : 0.794, Sensitive_Loss : 0.17680, Sensitive_Acc : 16.500, Run Time : 10.99 sec
INFO:root:2024-04-26 21:48:48, Train, Epoch : 3, Step : 1300, Loss : 0.42760, Acc : 0.825, Sensitive_Loss : 0.15985, Sensitive_Acc : 15.900, Run Time : 11.41 sec
INFO:root:2024-04-26 21:51:23, Dev, Step : 1300, Loss : 0.45789, Acc : 0.793, Auc : 0.887, Sensitive_Loss : 0.16379, Sensitive_Acc : 16.821, Sensitive_Auc : 0.985, Mean auc: 0.887, Run Time : 154.82 sec
INFO:root:2024-04-26 21:51:24, Best, Step : 1300, Loss : 0.45789, Acc : 0.793, Auc : 0.887, Sensitive_Loss : 0.16379, Sensitive_Acc : 16.821, Sensitive_Auc : 0.985, Best Auc : 0.887
INFO:root:2024-04-26 21:51:33, Train, Epoch : 3, Step : 1310, Loss : 0.41159, Acc : 0.816, Sensitive_Loss : 0.16652, Sensitive_Acc : 15.300, Run Time : 164.52 sec
INFO:root:2024-04-26 21:51:44, Train, Epoch : 3, Step : 1320, Loss : 0.43667, Acc : 0.822, Sensitive_Loss : 0.19298, Sensitive_Acc : 15.600, Run Time : 11.58 sec
INFO:root:2024-04-26 21:51:54, Train, Epoch : 3, Step : 1330, Loss : 0.33639, Acc : 0.863, Sensitive_Loss : 0.14084, Sensitive_Acc : 15.500, Run Time : 10.24 sec
INFO:root:2024-04-26 21:52:07, Train, Epoch : 3, Step : 1340, Loss : 0.39943, Acc : 0.841, Sensitive_Loss : 0.13980, Sensitive_Acc : 16.800, Run Time : 12.07 sec
INFO:root:2024-04-26 21:52:18, Train, Epoch : 3, Step : 1350, Loss : 0.45485, Acc : 0.769, Sensitive_Loss : 0.18936, Sensitive_Acc : 14.800, Run Time : 11.35 sec
INFO:root:2024-04-26 21:52:29, Train, Epoch : 3, Step : 1360, Loss : 0.41877, Acc : 0.800, Sensitive_Loss : 0.17189, Sensitive_Acc : 16.400, Run Time : 11.46 sec
INFO:root:2024-04-26 21:52:41, Train, Epoch : 3, Step : 1370, Loss : 0.39166, Acc : 0.809, Sensitive_Loss : 0.14603, Sensitive_Acc : 16.200, Run Time : 11.71 sec
INFO:root:2024-04-26 21:52:52, Train, Epoch : 3, Step : 1380, Loss : 0.41083, Acc : 0.809, Sensitive_Loss : 0.21672, Sensitive_Acc : 18.300, Run Time : 11.21 sec
INFO:root:2024-04-26 21:53:04, Train, Epoch : 3, Step : 1390, Loss : 0.35520, Acc : 0.859, Sensitive_Loss : 0.16556, Sensitive_Acc : 16.100, Run Time : 11.76 sec
INFO:root:2024-04-26 21:53:15, Train, Epoch : 3, Step : 1400, Loss : 0.46481, Acc : 0.806, Sensitive_Loss : 0.17998, Sensitive_Acc : 18.000, Run Time : 11.05 sec
INFO:root:2024-04-26 21:55:50, Dev, Step : 1400, Loss : 0.43004, Acc : 0.808, Auc : 0.894, Sensitive_Loss : 0.15542, Sensitive_Acc : 16.764, Sensitive_Auc : 0.987, Mean auc: 0.894, Run Time : 154.44 sec
INFO:root:2024-04-26 21:55:50, Best, Step : 1400, Loss : 0.43004, Acc : 0.808, Auc : 0.894, Sensitive_Loss : 0.15542, Sensitive_Acc : 16.764, Sensitive_Auc : 0.987, Best Auc : 0.894
INFO:root:2024-04-26 21:55:59, Train, Epoch : 3, Step : 1410, Loss : 0.38523, Acc : 0.822, Sensitive_Loss : 0.16221, Sensitive_Acc : 16.200, Run Time : 163.60 sec
INFO:root:2024-04-26 21:56:11, Train, Epoch : 3, Step : 1420, Loss : 0.31620, Acc : 0.853, Sensitive_Loss : 0.14493, Sensitive_Acc : 17.700, Run Time : 12.58 sec
INFO:root:2024-04-26 21:56:22, Train, Epoch : 3, Step : 1430, Loss : 0.35713, Acc : 0.841, Sensitive_Loss : 0.18321, Sensitive_Acc : 17.100, Run Time : 10.83 sec
INFO:root:2024-04-26 21:56:33, Train, Epoch : 3, Step : 1440, Loss : 0.41494, Acc : 0.819, Sensitive_Loss : 0.14390, Sensitive_Acc : 16.800, Run Time : 10.62 sec
INFO:root:2024-04-26 21:56:44, Train, Epoch : 3, Step : 1450, Loss : 0.43154, Acc : 0.809, Sensitive_Loss : 0.16461, Sensitive_Acc : 15.600, Run Time : 11.22 sec
INFO:root:2024-04-26 21:56:56, Train, Epoch : 3, Step : 1460, Loss : 0.37762, Acc : 0.847, Sensitive_Loss : 0.13120, Sensitive_Acc : 16.500, Run Time : 11.68 sec
INFO:root:2024-04-26 21:57:07, Train, Epoch : 3, Step : 1470, Loss : 0.39569, Acc : 0.866, Sensitive_Loss : 0.12935, Sensitive_Acc : 16.400, Run Time : 11.14 sec
INFO:root:2024-04-26 21:57:19, Train, Epoch : 3, Step : 1480, Loss : 0.50824, Acc : 0.772, Sensitive_Loss : 0.16683, Sensitive_Acc : 17.300, Run Time : 12.19 sec
INFO:root:2024-04-26 21:57:30, Train, Epoch : 3, Step : 1490, Loss : 0.43396, Acc : 0.822, Sensitive_Loss : 0.14599, Sensitive_Acc : 15.400, Run Time : 11.51 sec
INFO:root:2024-04-26 21:57:42, Train, Epoch : 3, Step : 1500, Loss : 0.35854, Acc : 0.841, Sensitive_Loss : 0.16089, Sensitive_Acc : 16.300, Run Time : 11.53 sec
INFO:root:2024-04-26 22:00:17, Dev, Step : 1500, Loss : 0.42699, Acc : 0.815, Auc : 0.897, Sensitive_Loss : 0.16113, Sensitive_Acc : 16.850, Sensitive_Auc : 0.984, Mean auc: 0.897, Run Time : 155.12 sec
INFO:root:2024-04-26 22:00:18, Best, Step : 1500, Loss : 0.42699, Acc : 0.815, Auc : 0.897, Sensitive_Loss : 0.16113, Sensitive_Acc : 16.850, Sensitive_Auc : 0.984, Best Auc : 0.897
INFO:root:2024-04-26 22:00:27, Train, Epoch : 3, Step : 1510, Loss : 0.40014, Acc : 0.841, Sensitive_Loss : 0.16243, Sensitive_Acc : 16.800, Run Time : 164.92 sec
INFO:root:2024-04-26 22:00:39, Train, Epoch : 3, Step : 1520, Loss : 0.42080, Acc : 0.806, Sensitive_Loss : 0.19489, Sensitive_Acc : 16.700, Run Time : 11.82 sec
INFO:root:2024-04-26 22:00:50, Train, Epoch : 3, Step : 1530, Loss : 0.38443, Acc : 0.844, Sensitive_Loss : 0.15567, Sensitive_Acc : 15.500, Run Time : 11.10 sec
INFO:root:2024-04-26 22:01:02, Train, Epoch : 3, Step : 1540, Loss : 0.39573, Acc : 0.809, Sensitive_Loss : 0.17852, Sensitive_Acc : 16.500, Run Time : 12.02 sec
INFO:root:2024-04-26 22:01:13, Train, Epoch : 3, Step : 1550, Loss : 0.41738, Acc : 0.803, Sensitive_Loss : 0.16046, Sensitive_Acc : 16.700, Run Time : 11.02 sec
INFO:root:2024-04-26 22:01:25, Train, Epoch : 3, Step : 1560, Loss : 0.46688, Acc : 0.794, Sensitive_Loss : 0.19990, Sensitive_Acc : 16.200, Run Time : 11.71 sec
INFO:root:2024-04-26 22:01:36, Train, Epoch : 3, Step : 1570, Loss : 0.37608, Acc : 0.819, Sensitive_Loss : 0.17553, Sensitive_Acc : 13.900, Run Time : 11.79 sec
INFO:root:2024-04-26 22:01:46, Train, Epoch : 3, Step : 1580, Loss : 0.38775, Acc : 0.838, Sensitive_Loss : 0.16092, Sensitive_Acc : 14.900, Run Time : 10.04 sec
INFO:root:2024-04-26 22:01:58, Train, Epoch : 3, Step : 1590, Loss : 0.40982, Acc : 0.863, Sensitive_Loss : 0.12604, Sensitive_Acc : 15.900, Run Time : 11.83 sec
INFO:root:2024-04-26 22:02:10, Train, Epoch : 3, Step : 1600, Loss : 0.35884, Acc : 0.850, Sensitive_Loss : 0.17255, Sensitive_Acc : 16.400, Run Time : 11.63 sec
INFO:root:2024-04-26 22:04:45, Dev, Step : 1600, Loss : 0.43147, Acc : 0.814, Auc : 0.899, Sensitive_Loss : 0.16762, Sensitive_Acc : 16.864, Sensitive_Auc : 0.989, Mean auc: 0.899, Run Time : 154.86 sec
INFO:root:2024-04-26 22:04:45, Best, Step : 1600, Loss : 0.43147, Acc : 0.814, Auc : 0.899, Sensitive_Loss : 0.16762, Sensitive_Acc : 16.864, Sensitive_Auc : 0.989, Best Auc : 0.899
INFO:root:2024-04-26 22:04:54, Train, Epoch : 3, Step : 1610, Loss : 0.35588, Acc : 0.822, Sensitive_Loss : 0.18130, Sensitive_Acc : 15.800, Run Time : 164.14 sec
INFO:root:2024-04-26 22:05:05, Train, Epoch : 3, Step : 1620, Loss : 0.34565, Acc : 0.853, Sensitive_Loss : 0.17887, Sensitive_Acc : 17.600, Run Time : 11.14 sec
INFO:root:2024-04-26 22:05:16, Train, Epoch : 3, Step : 1630, Loss : 0.40641, Acc : 0.816, Sensitive_Loss : 0.14636, Sensitive_Acc : 15.700, Run Time : 10.96 sec
INFO:root:2024-04-26 22:05:28, Train, Epoch : 3, Step : 1640, Loss : 0.39236, Acc : 0.809, Sensitive_Loss : 0.17908, Sensitive_Acc : 15.800, Run Time : 12.08 sec
INFO:root:2024-04-26 22:05:39, Train, Epoch : 3, Step : 1650, Loss : 0.42527, Acc : 0.831, Sensitive_Loss : 0.11945, Sensitive_Acc : 17.900, Run Time : 11.04 sec
INFO:root:2024-04-26 22:05:51, Train, Epoch : 3, Step : 1660, Loss : 0.34244, Acc : 0.844, Sensitive_Loss : 0.14944, Sensitive_Acc : 16.100, Run Time : 11.50 sec
INFO:root:2024-04-26 22:06:02, Train, Epoch : 3, Step : 1670, Loss : 0.35166, Acc : 0.838, Sensitive_Loss : 0.13739, Sensitive_Acc : 16.100, Run Time : 11.07 sec
INFO:root:2024-04-26 22:06:14, Train, Epoch : 3, Step : 1680, Loss : 0.40563, Acc : 0.828, Sensitive_Loss : 0.14360, Sensitive_Acc : 15.500, Run Time : 11.77 sec
INFO:root:2024-04-26 22:06:26, Train, Epoch : 3, Step : 1690, Loss : 0.40733, Acc : 0.797, Sensitive_Loss : 0.23439, Sensitive_Acc : 16.300, Run Time : 12.03 sec
INFO:root:2024-04-26 22:06:37, Train, Epoch : 3, Step : 1700, Loss : 0.47128, Acc : 0.803, Sensitive_Loss : 0.11996, Sensitive_Acc : 16.000, Run Time : 11.82 sec
INFO:root:2024-04-26 22:09:14, Dev, Step : 1700, Loss : 0.41935, Acc : 0.821, Auc : 0.901, Sensitive_Loss : 0.14629, Sensitive_Acc : 16.921, Sensitive_Auc : 0.990, Mean auc: 0.901, Run Time : 157.03 sec
INFO:root:2024-04-26 22:09:15, Best, Step : 1700, Loss : 0.41935, Acc : 0.821, Auc : 0.901, Sensitive_Loss : 0.14629, Sensitive_Acc : 16.921, Sensitive_Auc : 0.990, Best Auc : 0.901
INFO:root:2024-04-26 22:09:24, Train, Epoch : 3, Step : 1710, Loss : 0.52630, Acc : 0.775, Sensitive_Loss : 0.19488, Sensitive_Acc : 16.900, Run Time : 166.12 sec
INFO:root:2024-04-26 22:09:36, Train, Epoch : 3, Step : 1720, Loss : 0.49108, Acc : 0.816, Sensitive_Loss : 0.14822, Sensitive_Acc : 16.600, Run Time : 12.43 sec
INFO:root:2024-04-26 22:09:48, Train, Epoch : 3, Step : 1730, Loss : 0.39923, Acc : 0.834, Sensitive_Loss : 0.17638, Sensitive_Acc : 16.100, Run Time : 12.07 sec
INFO:root:2024-04-26 22:10:00, Train, Epoch : 3, Step : 1740, Loss : 0.38004, Acc : 0.822, Sensitive_Loss : 0.15791, Sensitive_Acc : 16.100, Run Time : 11.58 sec
INFO:root:2024-04-26 22:10:11, Train, Epoch : 3, Step : 1750, Loss : 0.36829, Acc : 0.838, Sensitive_Loss : 0.20203, Sensitive_Acc : 16.900, Run Time : 11.83 sec
INFO:root:2024-04-26 22:10:24, Train, Epoch : 3, Step : 1760, Loss : 0.40712, Acc : 0.834, Sensitive_Loss : 0.16246, Sensitive_Acc : 15.400, Run Time : 12.73 sec
INFO:root:2024-04-26 22:10:36, Train, Epoch : 3, Step : 1770, Loss : 0.38150, Acc : 0.828, Sensitive_Loss : 0.14640, Sensitive_Acc : 15.700, Run Time : 11.82 sec
INFO:root:2024-04-26 22:10:48, Train, Epoch : 3, Step : 1780, Loss : 0.38993, Acc : 0.816, Sensitive_Loss : 0.15162, Sensitive_Acc : 16.500, Run Time : 11.68 sec
INFO:root:2024-04-26 22:11:00, Train, Epoch : 3, Step : 1790, Loss : 0.36732, Acc : 0.844, Sensitive_Loss : 0.14513, Sensitive_Acc : 16.300, Run Time : 12.27 sec
INFO:root:2024-04-26 22:11:12, Train, Epoch : 3, Step : 1800, Loss : 0.39729, Acc : 0.844, Sensitive_Loss : 0.09901, Sensitive_Acc : 16.700, Run Time : 12.04 sec
INFO:root:2024-04-26 22:13:47, Dev, Step : 1800, Loss : 0.40956, Acc : 0.825, Auc : 0.903, Sensitive_Loss : 0.13946, Sensitive_Acc : 16.893, Sensitive_Auc : 0.985, Mean auc: 0.903, Run Time : 155.24 sec
INFO:root:2024-04-26 22:13:48, Best, Step : 1800, Loss : 0.40956, Acc : 0.825, Auc : 0.903, Sensitive_Loss : 0.13946, Sensitive_Acc : 16.893, Sensitive_Auc : 0.985, Best Auc : 0.903
INFO:root:2024-04-26 22:13:57, Train, Epoch : 3, Step : 1810, Loss : 0.42793, Acc : 0.800, Sensitive_Loss : 0.16070, Sensitive_Acc : 17.700, Run Time : 164.75 sec
INFO:root:2024-04-26 22:14:08, Train, Epoch : 3, Step : 1820, Loss : 0.51231, Acc : 0.797, Sensitive_Loss : 0.13933, Sensitive_Acc : 17.600, Run Time : 11.40 sec
INFO:root:2024-04-26 22:14:21, Train, Epoch : 3, Step : 1830, Loss : 0.35687, Acc : 0.853, Sensitive_Loss : 0.16319, Sensitive_Acc : 16.100, Run Time : 12.54 sec
INFO:root:2024-04-26 22:14:33, Train, Epoch : 3, Step : 1840, Loss : 0.39682, Acc : 0.800, Sensitive_Loss : 0.18882, Sensitive_Acc : 17.400, Run Time : 11.79 sec
INFO:root:2024-04-26 22:14:44, Train, Epoch : 3, Step : 1850, Loss : 0.38434, Acc : 0.822, Sensitive_Loss : 0.17006, Sensitive_Acc : 16.900, Run Time : 11.69 sec
INFO:root:2024-04-26 22:14:56, Train, Epoch : 3, Step : 1860, Loss : 0.29985, Acc : 0.866, Sensitive_Loss : 0.19333, Sensitive_Acc : 16.600, Run Time : 11.92 sec
INFO:root:2024-04-26 22:15:08, Train, Epoch : 3, Step : 1870, Loss : 0.43326, Acc : 0.806, Sensitive_Loss : 0.14351, Sensitive_Acc : 15.800, Run Time : 12.14 sec
INFO:root:2024-04-26 22:17:51
INFO:root:y_pred: [0.25448784 0.8989874  0.05511014 ... 0.74677813 0.00851495 0.8719212 ]
INFO:root:y_true: [0. 1. 0. ... 1. 0. 1.]
INFO:root:sensitive_y_pred: [9.4921070e-01 7.5166310e-05 1.1799505e-01 2.5034944e-05 9.8979479e-01
 7.8507139e-07 9.9202067e-01 9.3033844e-01 2.7701289e-03 5.7034755e-01
 9.9591452e-01 9.9513632e-01 9.8137593e-01 7.9218447e-01 2.9820514e-01
 8.6516386e-01 9.8977739e-01 3.5213016e-02 4.9691061e-03 9.9562210e-01
 9.7110331e-01 6.5144104e-06 9.9645954e-01 7.8558683e-01 9.7411174e-01
 7.7287543e-01 4.2711932e-04 9.7308749e-01 9.4276118e-01 5.4376966e-01
 4.8541423e-02 3.1464458e-02 5.4464350e-03 9.8484606e-02 5.5708492e-01
 1.8030727e-05 1.8753108e-01 3.0590540e-03 9.6462184e-01 9.6842277e-01
 4.9898263e-11 2.3957689e-06 9.5839453e-01 6.0953810e-03 9.9705964e-01
 9.7513890e-01 8.8430405e-01 9.9203956e-01 1.0306735e-03 9.2229563e-01
 9.9332821e-01 1.5199381e-02 8.1696802e-01 1.4077003e-02 3.4875072e-08
 7.7622803e-03 2.0583841e-01 6.2073008e-07 1.0956874e-05 3.8378433e-04
 1.5966085e-04 3.1626311e-01 1.1818474e-04 9.8490036e-01 2.7040157e-01
 9.9014342e-01 5.1816944e-05 9.8235482e-01 8.0991310e-01 5.8294338e-01
 8.2162362e-01 5.0865942e-01 8.4486622e-03 6.5605082e-02 2.1868546e-03
 7.0862559e-04 5.2714337e-02 4.1068584e-01 1.0180668e-03 9.8621583e-01
 9.9385357e-01 2.2046126e-03 2.9957980e-01 2.2980690e-04 8.2963622e-01
 9.0979248e-01 4.1957811e-02 5.8504627e-03 9.5304102e-01 9.6712363e-01
 9.9027246e-01 1.2786168e-03 1.7294332e-03 9.8559028e-01 6.7771351e-01
 4.4374075e-04 9.9110377e-01 9.8805946e-01 1.1227986e-06 9.2232454e-05
 9.2940986e-01 8.7976438e-01 9.8874927e-01 9.8177403e-01 8.6202221e-05
 7.6636869e-01 6.8310702e-01 8.4398192e-01 8.5921472e-01 3.5179693e-07
 6.8812835e-01 9.9403208e-01 8.5577108e-03 9.9354810e-01 8.0446589e-01
 9.2675960e-01 9.1360152e-01 9.7893345e-01 7.0934340e-02 2.7317026e-01
 9.9343020e-01 9.9078768e-01 5.2548139e-09 8.7971586e-01 9.8151028e-01
 9.4100744e-02 9.8423171e-01 1.1121543e-03 6.7201740e-01 8.7020499e-01
 9.9061978e-01 3.6897371e-04 4.0138481e-04 3.3126338e-03 9.8752892e-01
 9.9805957e-01 8.6052740e-01 6.4910064e-04 2.1875738e-03 9.4127661e-01]
INFO:root:sensitive_y_true: [1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.
 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.]
INFO:root:2024-04-26 22:17:51, Dev, Step : 1878, Loss : 0.41152, Acc : 0.823, Auc : 0.903, Sensitive_Loss : 0.14621, Sensitive_Acc : 16.921, Sensitive_Auc : 0.985, Mean auc: 0.903, Run Time : 153.70 sec
INFO:root:2024-04-26 22:17:56, Train, Epoch : 4, Step : 1880, Loss : 0.10468, Acc : 0.166, Sensitive_Loss : 0.03960, Sensitive_Acc : 3.000, Run Time : 3.82 sec
INFO:root:2024-04-26 22:18:08, Train, Epoch : 4, Step : 1890, Loss : 0.34801, Acc : 0.838, Sensitive_Loss : 0.14189, Sensitive_Acc : 16.700, Run Time : 11.82 sec
INFO:root:2024-04-26 22:18:20, Train, Epoch : 4, Step : 1900, Loss : 0.34901, Acc : 0.847, Sensitive_Loss : 0.14519, Sensitive_Acc : 16.100, Run Time : 12.06 sec
INFO:root:2024-04-26 22:20:55, Dev, Step : 1900, Loss : 0.43296, Acc : 0.815, Auc : 0.902, Sensitive_Loss : 0.16725, Sensitive_Acc : 16.893, Sensitive_Auc : 0.983, Mean auc: 0.902, Run Time : 155.28 sec
INFO:root:2024-04-26 22:21:04, Train, Epoch : 4, Step : 1910, Loss : 0.31486, Acc : 0.847, Sensitive_Loss : 0.17782, Sensitive_Acc : 16.200, Run Time : 163.87 sec
INFO:root:2024-04-26 22:21:16, Train, Epoch : 4, Step : 1920, Loss : 0.38677, Acc : 0.856, Sensitive_Loss : 0.10374, Sensitive_Acc : 17.300, Run Time : 12.52 sec
INFO:root:2024-04-26 22:21:28, Train, Epoch : 4, Step : 1930, Loss : 0.38542, Acc : 0.819, Sensitive_Loss : 0.20626, Sensitive_Acc : 16.900, Run Time : 11.59 sec
INFO:root:2024-04-26 22:21:40, Train, Epoch : 4, Step : 1940, Loss : 0.37250, Acc : 0.859, Sensitive_Loss : 0.18044, Sensitive_Acc : 16.700, Run Time : 11.56 sec
INFO:root:2024-04-26 22:21:52, Train, Epoch : 4, Step : 1950, Loss : 0.45046, Acc : 0.809, Sensitive_Loss : 0.12490, Sensitive_Acc : 15.900, Run Time : 12.26 sec
INFO:root:2024-04-26 22:22:04, Train, Epoch : 4, Step : 1960, Loss : 0.31460, Acc : 0.841, Sensitive_Loss : 0.15640, Sensitive_Acc : 15.600, Run Time : 11.81 sec
INFO:root:2024-04-26 22:22:16, Train, Epoch : 4, Step : 1970, Loss : 0.34695, Acc : 0.853, Sensitive_Loss : 0.16099, Sensitive_Acc : 16.300, Run Time : 12.05 sec
INFO:root:2024-04-26 22:22:28, Train, Epoch : 4, Step : 1980, Loss : 0.34210, Acc : 0.841, Sensitive_Loss : 0.19815, Sensitive_Acc : 17.100, Run Time : 12.00 sec
INFO:root:2024-04-26 22:22:40, Train, Epoch : 4, Step : 1990, Loss : 0.41254, Acc : 0.809, Sensitive_Loss : 0.14521, Sensitive_Acc : 15.600, Run Time : 12.05 sec
INFO:root:2024-04-26 22:22:52, Train, Epoch : 4, Step : 2000, Loss : 0.38788, Acc : 0.800, Sensitive_Loss : 0.13996, Sensitive_Acc : 14.600, Run Time : 12.42 sec
INFO:root:2024-04-26 22:25:42, Dev, Step : 2000, Loss : 0.41475, Acc : 0.824, Auc : 0.903, Sensitive_Loss : 0.15228, Sensitive_Acc : 16.907, Sensitive_Auc : 0.986, Mean auc: 0.903, Run Time : 169.71 sec
INFO:root:2024-04-26 22:25:43, Best, Step : 2000, Loss : 0.41475, Acc : 0.824, Auc : 0.903, Sensitive_Loss : 0.15228, Sensitive_Acc : 16.907, Sensitive_Auc : 0.986, Best Auc : 0.903
INFO:root:2024-04-26 22:25:52, Train, Epoch : 4, Step : 2010, Loss : 0.38280, Acc : 0.819, Sensitive_Loss : 0.17390, Sensitive_Acc : 17.300, Run Time : 179.53 sec
INFO:root:2024-04-26 22:26:17, Train, Epoch : 4, Step : 2020, Loss : 0.37141, Acc : 0.828, Sensitive_Loss : 0.13657, Sensitive_Acc : 16.400, Run Time : 24.89 sec
INFO:root:2024-04-26 22:26:38, Train, Epoch : 4, Step : 2030, Loss : 0.39917, Acc : 0.828, Sensitive_Loss : 0.11190, Sensitive_Acc : 15.600, Run Time : 21.83 sec
INFO:root:2024-04-26 22:26:52, Train, Epoch : 4, Step : 2040, Loss : 0.44380, Acc : 0.841, Sensitive_Loss : 0.14244, Sensitive_Acc : 15.800, Run Time : 13.96 sec
INFO:root:2024-04-26 22:27:05, Train, Epoch : 4, Step : 2050, Loss : 0.38548, Acc : 0.856, Sensitive_Loss : 0.16100, Sensitive_Acc : 15.500, Run Time : 12.45 sec
INFO:root:2024-04-26 22:27:15, Train, Epoch : 4, Step : 2060, Loss : 0.38239, Acc : 0.825, Sensitive_Loss : 0.15693, Sensitive_Acc : 15.900, Run Time : 10.59 sec
INFO:root:2024-04-26 22:27:27, Train, Epoch : 4, Step : 2070, Loss : 0.40368, Acc : 0.806, Sensitive_Loss : 0.16335, Sensitive_Acc : 16.600, Run Time : 11.83 sec
INFO:root:2024-04-26 22:27:42, Train, Epoch : 4, Step : 2080, Loss : 0.41394, Acc : 0.825, Sensitive_Loss : 0.14691, Sensitive_Acc : 16.300, Run Time : 15.05 sec
INFO:root:2024-04-26 22:28:01, Train, Epoch : 4, Step : 2090, Loss : 0.37642, Acc : 0.828, Sensitive_Loss : 0.18889, Sensitive_Acc : 16.100, Run Time : 18.32 sec
INFO:root:2024-04-26 22:28:12, Train, Epoch : 4, Step : 2100, Loss : 0.37245, Acc : 0.850, Sensitive_Loss : 0.12604, Sensitive_Acc : 16.700, Run Time : 11.63 sec
INFO:root:2024-04-26 22:30:49, Dev, Step : 2100, Loss : 0.41086, Acc : 0.828, Auc : 0.905, Sensitive_Loss : 0.12974, Sensitive_Acc : 16.921, Sensitive_Auc : 0.989, Mean auc: 0.905, Run Time : 156.87 sec
INFO:root:2024-04-26 22:30:50, Best, Step : 2100, Loss : 0.41086, Acc : 0.828, Auc : 0.905, Sensitive_Loss : 0.12974, Sensitive_Acc : 16.921, Sensitive_Auc : 0.989, Best Auc : 0.905
INFO:root:2024-04-26 22:30:59, Train, Epoch : 4, Step : 2110, Loss : 0.37619, Acc : 0.819, Sensitive_Loss : 0.13715, Sensitive_Acc : 15.200, Run Time : 167.00 sec
INFO:root:2024-04-26 22:31:11, Train, Epoch : 4, Step : 2120, Loss : 0.46457, Acc : 0.819, Sensitive_Loss : 0.13658, Sensitive_Acc : 18.200, Run Time : 11.58 sec
INFO:root:2024-04-26 22:31:24, Train, Epoch : 4, Step : 2130, Loss : 0.37120, Acc : 0.825, Sensitive_Loss : 0.15648, Sensitive_Acc : 15.500, Run Time : 12.85 sec
INFO:root:2024-04-26 22:31:35, Train, Epoch : 4, Step : 2140, Loss : 0.39034, Acc : 0.812, Sensitive_Loss : 0.17546, Sensitive_Acc : 15.100, Run Time : 11.70 sec
INFO:root:2024-04-26 22:31:48, Train, Epoch : 4, Step : 2150, Loss : 0.40071, Acc : 0.825, Sensitive_Loss : 0.12990, Sensitive_Acc : 15.300, Run Time : 12.76 sec
INFO:root:2024-04-26 22:32:00, Train, Epoch : 4, Step : 2160, Loss : 0.39376, Acc : 0.841, Sensitive_Loss : 0.18565, Sensitive_Acc : 16.200, Run Time : 11.82 sec
INFO:root:2024-04-26 22:32:12, Train, Epoch : 4, Step : 2170, Loss : 0.37228, Acc : 0.841, Sensitive_Loss : 0.12927, Sensitive_Acc : 15.300, Run Time : 11.62 sec
INFO:root:2024-04-26 22:32:23, Train, Epoch : 4, Step : 2180, Loss : 0.36049, Acc : 0.816, Sensitive_Loss : 0.14102, Sensitive_Acc : 15.800, Run Time : 11.79 sec
INFO:root:2024-04-26 22:32:34, Train, Epoch : 4, Step : 2190, Loss : 0.40061, Acc : 0.859, Sensitive_Loss : 0.11702, Sensitive_Acc : 16.700, Run Time : 10.95 sec
INFO:root:2024-04-26 22:32:47, Train, Epoch : 4, Step : 2200, Loss : 0.39163, Acc : 0.838, Sensitive_Loss : 0.14440, Sensitive_Acc : 17.300, Run Time : 12.29 sec
INFO:root:2024-04-26 22:35:23, Dev, Step : 2200, Loss : 0.40381, Acc : 0.830, Auc : 0.906, Sensitive_Loss : 0.12861, Sensitive_Acc : 16.893, Sensitive_Auc : 0.989, Mean auc: 0.906, Run Time : 156.38 sec
INFO:root:2024-04-26 22:35:24, Best, Step : 2200, Loss : 0.40381, Acc : 0.830, Auc : 0.906, Sensitive_Loss : 0.12861, Sensitive_Acc : 16.893, Sensitive_Auc : 0.989, Best Auc : 0.906
INFO:root:2024-04-26 22:35:33, Train, Epoch : 4, Step : 2210, Loss : 0.27884, Acc : 0.875, Sensitive_Loss : 0.13484, Sensitive_Acc : 15.800, Run Time : 165.98 sec
INFO:root:2024-04-26 22:35:45, Train, Epoch : 4, Step : 2220, Loss : 0.33990, Acc : 0.853, Sensitive_Loss : 0.15511, Sensitive_Acc : 16.300, Run Time : 12.02 sec
INFO:root:2024-04-26 22:35:57, Train, Epoch : 4, Step : 2230, Loss : 0.44472, Acc : 0.819, Sensitive_Loss : 0.13753, Sensitive_Acc : 16.400, Run Time : 12.15 sec
INFO:root:2024-04-26 22:36:09, Train, Epoch : 4, Step : 2240, Loss : 0.36099, Acc : 0.841, Sensitive_Loss : 0.12823, Sensitive_Acc : 16.100, Run Time : 12.12 sec
INFO:root:2024-04-26 22:36:21, Train, Epoch : 4, Step : 2250, Loss : 0.32397, Acc : 0.859, Sensitive_Loss : 0.16218, Sensitive_Acc : 16.100, Run Time : 12.13 sec
INFO:root:2024-04-26 22:36:32, Train, Epoch : 4, Step : 2260, Loss : 0.35071, Acc : 0.831, Sensitive_Loss : 0.17771, Sensitive_Acc : 15.600, Run Time : 11.30 sec
INFO:root:2024-04-26 22:36:45, Train, Epoch : 4, Step : 2270, Loss : 0.36619, Acc : 0.825, Sensitive_Loss : 0.14889, Sensitive_Acc : 15.500, Run Time : 12.13 sec
INFO:root:2024-04-26 22:36:57, Train, Epoch : 4, Step : 2280, Loss : 0.38804, Acc : 0.850, Sensitive_Loss : 0.10489, Sensitive_Acc : 15.900, Run Time : 12.32 sec
INFO:root:2024-04-26 22:37:08, Train, Epoch : 4, Step : 2290, Loss : 0.37427, Acc : 0.847, Sensitive_Loss : 0.14088, Sensitive_Acc : 17.100, Run Time : 10.76 sec
INFO:root:2024-04-26 22:37:20, Train, Epoch : 4, Step : 2300, Loss : 0.37411, Acc : 0.847, Sensitive_Loss : 0.11896, Sensitive_Acc : 17.300, Run Time : 12.55 sec
INFO:root:2024-04-26 22:39:55, Dev, Step : 2300, Loss : 0.41528, Acc : 0.822, Auc : 0.906, Sensitive_Loss : 0.14256, Sensitive_Acc : 16.907, Sensitive_Auc : 0.975, Mean auc: 0.906, Run Time : 154.67 sec
INFO:root:2024-04-26 22:40:04, Train, Epoch : 4, Step : 2310, Loss : 0.34253, Acc : 0.844, Sensitive_Loss : 0.19331, Sensitive_Acc : 15.600, Run Time : 163.35 sec
INFO:root:2024-04-26 22:40:15, Train, Epoch : 4, Step : 2320, Loss : 0.34619, Acc : 0.822, Sensitive_Loss : 0.15593, Sensitive_Acc : 17.100, Run Time : 11.47 sec
INFO:root:2024-04-26 22:40:27, Train, Epoch : 4, Step : 2330, Loss : 0.38000, Acc : 0.825, Sensitive_Loss : 0.15317, Sensitive_Acc : 15.200, Run Time : 11.76 sec
INFO:root:2024-04-26 22:40:39, Train, Epoch : 4, Step : 2340, Loss : 0.41518, Acc : 0.831, Sensitive_Loss : 0.16553, Sensitive_Acc : 18.700, Run Time : 12.18 sec
INFO:root:2024-04-26 22:40:51, Train, Epoch : 4, Step : 2350, Loss : 0.41015, Acc : 0.841, Sensitive_Loss : 0.12341, Sensitive_Acc : 16.200, Run Time : 11.96 sec
INFO:root:2024-04-26 22:41:03, Train, Epoch : 4, Step : 2360, Loss : 0.38279, Acc : 0.819, Sensitive_Loss : 0.12610, Sensitive_Acc : 16.000, Run Time : 11.89 sec
INFO:root:2024-04-26 22:41:15, Train, Epoch : 4, Step : 2370, Loss : 0.39003, Acc : 0.847, Sensitive_Loss : 0.11383, Sensitive_Acc : 15.500, Run Time : 11.93 sec
INFO:root:2024-04-26 22:41:26, Train, Epoch : 4, Step : 2380, Loss : 0.38973, Acc : 0.850, Sensitive_Loss : 0.14691, Sensitive_Acc : 16.700, Run Time : 11.79 sec
INFO:root:2024-04-26 22:41:38, Train, Epoch : 4, Step : 2390, Loss : 0.35663, Acc : 0.847, Sensitive_Loss : 0.12380, Sensitive_Acc : 15.300, Run Time : 11.65 sec
INFO:root:2024-04-26 22:41:50, Train, Epoch : 4, Step : 2400, Loss : 0.41732, Acc : 0.844, Sensitive_Loss : 0.13609, Sensitive_Acc : 16.700, Run Time : 11.91 sec
INFO:root:2024-04-26 22:44:26, Dev, Step : 2400, Loss : 0.40048, Acc : 0.830, Auc : 0.907, Sensitive_Loss : 0.13181, Sensitive_Acc : 16.864, Sensitive_Auc : 0.980, Mean auc: 0.907, Run Time : 155.63 sec
INFO:root:2024-04-26 22:44:27, Best, Step : 2400, Loss : 0.40048, Acc : 0.830, Auc : 0.907, Sensitive_Loss : 0.13181, Sensitive_Acc : 16.864, Sensitive_Auc : 0.980, Best Auc : 0.907
INFO:root:2024-04-26 22:44:35, Train, Epoch : 4, Step : 2410, Loss : 0.32153, Acc : 0.850, Sensitive_Loss : 0.18634, Sensitive_Acc : 15.300, Run Time : 164.94 sec
INFO:root:2024-04-26 22:44:47, Train, Epoch : 4, Step : 2420, Loss : 0.35708, Acc : 0.847, Sensitive_Loss : 0.12593, Sensitive_Acc : 16.400, Run Time : 12.27 sec
INFO:root:2024-04-26 22:44:59, Train, Epoch : 4, Step : 2430, Loss : 0.39161, Acc : 0.844, Sensitive_Loss : 0.13001, Sensitive_Acc : 15.100, Run Time : 11.89 sec
INFO:root:2024-04-26 22:45:11, Train, Epoch : 4, Step : 2440, Loss : 0.45541, Acc : 0.803, Sensitive_Loss : 0.12929, Sensitive_Acc : 15.000, Run Time : 12.17 sec
INFO:root:2024-04-26 22:45:23, Train, Epoch : 4, Step : 2450, Loss : 0.38264, Acc : 0.822, Sensitive_Loss : 0.10993, Sensitive_Acc : 16.600, Run Time : 11.84 sec
INFO:root:2024-04-26 22:45:34, Train, Epoch : 4, Step : 2460, Loss : 0.29229, Acc : 0.853, Sensitive_Loss : 0.16943, Sensitive_Acc : 16.300, Run Time : 11.27 sec
INFO:root:2024-04-26 22:45:47, Train, Epoch : 4, Step : 2470, Loss : 0.37036, Acc : 0.812, Sensitive_Loss : 0.13192, Sensitive_Acc : 16.300, Run Time : 12.18 sec
INFO:root:2024-04-26 22:45:58, Train, Epoch : 4, Step : 2480, Loss : 0.40183, Acc : 0.850, Sensitive_Loss : 0.18193, Sensitive_Acc : 14.900, Run Time : 11.39 sec
INFO:root:2024-04-26 22:46:10, Train, Epoch : 4, Step : 2490, Loss : 0.35514, Acc : 0.834, Sensitive_Loss : 0.16285, Sensitive_Acc : 17.600, Run Time : 11.80 sec
INFO:root:2024-04-26 22:46:21, Train, Epoch : 4, Step : 2500, Loss : 0.33276, Acc : 0.863, Sensitive_Loss : 0.14571, Sensitive_Acc : 17.100, Run Time : 11.28 sec
INFO:root:2024-04-26 22:48:57, Dev, Step : 2500, Loss : 0.40667, Acc : 0.828, Auc : 0.905, Sensitive_Loss : 0.14933, Sensitive_Acc : 16.907, Sensitive_Auc : 0.978, Mean auc: 0.905, Run Time : 156.07 sec
INFO:root:2024-04-26 22:51:33
INFO:root:y_pred: [0.3016264  0.9232894  0.05622755 ... 0.8030008  0.00834553 0.9226506 ]
INFO:root:y_true: [0. 1. 0. ... 1. 0. 1.]
INFO:root:sensitive_y_pred: [9.45498049e-01 9.94301517e-05 4.72993478e-02 3.98909560e-06
 9.89699185e-01 1.34979871e-07 9.90633130e-01 9.30845141e-01
 5.20789810e-03 4.64428812e-01 9.94662762e-01 9.96902525e-01
 9.82375562e-01 7.42559075e-01 2.36855954e-01 7.94481695e-01
 9.90399063e-01 1.77282337e-02 1.28857023e-03 9.95112360e-01
 9.74505067e-01 9.71827740e-06 9.97490406e-01 6.95190251e-01
 9.77541029e-01 8.21857214e-01 1.63713499e-04 9.77567792e-01
 9.30760682e-01 8.57427478e-01 1.38004711e-02 3.77435461e-02
 1.30980238e-01 8.52349997e-02 5.92843056e-01 1.40453164e-06
 1.62997738e-01 3.65111767e-03 9.75449502e-01 9.72167730e-01
 1.06284974e-10 2.31735285e-05 9.79938090e-01 3.62932147e-03
 9.96535897e-01 9.59996641e-01 8.78384709e-01 9.93867218e-01
 3.08274268e-03 9.11867440e-01 9.95498538e-01 2.04620976e-03
 9.08024549e-01 7.22061517e-03 1.78667889e-07 1.69009331e-03
 1.52751952e-01 8.63758885e-07 7.91114871e-06 1.83638224e-06
 9.84650342e-06 6.63152874e-01 6.17665282e-05 9.90844548e-01
 3.60621959e-01 9.86769795e-01 1.30324770e-04 9.74120319e-01
 8.01509798e-01 4.50549304e-01 7.91630983e-01 3.82527381e-01
 3.54000810e-03 4.70279008e-02 7.40886782e-04 4.99712478e-04
 8.49231407e-02 4.28639233e-01 4.23544669e-04 9.83063757e-01
 9.91843045e-01 1.04029161e-04 4.78997648e-01 1.10185239e-04
 8.33697021e-01 9.47485447e-01 3.74038517e-02 8.89233872e-03
 9.44722295e-01 9.65319693e-01 9.85599041e-01 9.11148847e-04
 2.04921304e-03 9.88477767e-01 4.89322811e-01 5.19560592e-04
 9.87985194e-01 9.78131711e-01 1.02155875e-08 2.00971408e-04
 9.24524844e-01 8.91449809e-01 9.96234596e-01 9.88124847e-01
 1.36837480e-04 4.95305918e-02 5.77904403e-01 8.07796061e-01
 8.87034416e-01 8.99496536e-06 6.11222208e-01 9.96021807e-01
 1.17092934e-02 9.93604481e-01 7.67871261e-01 9.37899411e-01
 9.22464490e-01 9.80523646e-01 6.90751746e-02 3.04630578e-01
 9.92311776e-01 9.90214229e-01 1.16318719e-10 8.72651994e-01
 9.77309048e-01 1.02388903e-01 9.78426158e-01 5.65608963e-04
 1.91587150e-01 8.93653154e-01 9.91382897e-01 3.91151261e-04
 2.87304836e-04 2.61611509e-04 9.75885034e-01 9.98557031e-01
 8.80921066e-01 1.04890380e-04 5.24688257e-05 9.28849399e-01]
INFO:root:sensitive_y_true: [1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.
 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.]
INFO:root:2024-04-26 22:51:33, Dev, Step : 2504, Loss : 0.40183, Acc : 0.831, Auc : 0.906, Sensitive_Loss : 0.14365, Sensitive_Acc : 16.864, Sensitive_Auc : 0.980, Mean auc: 0.906, Run Time : 154.05 sec
INFO:root:2024-04-26 22:51:43, Train, Epoch : 5, Step : 2510, Loss : 0.22435, Acc : 0.491, Sensitive_Loss : 0.06509, Sensitive_Acc : 10.400, Run Time : 8.19 sec
INFO:root:2024-04-26 22:51:55, Train, Epoch : 5, Step : 2520, Loss : 0.35797, Acc : 0.847, Sensitive_Loss : 0.20774, Sensitive_Acc : 17.400, Run Time : 11.97 sec
INFO:root:2024-04-26 22:52:07, Train, Epoch : 5, Step : 2530, Loss : 0.34509, Acc : 0.844, Sensitive_Loss : 0.18330, Sensitive_Acc : 17.000, Run Time : 12.35 sec
INFO:root:2024-04-26 22:52:18, Train, Epoch : 5, Step : 2540, Loss : 0.31038, Acc : 0.863, Sensitive_Loss : 0.13088, Sensitive_Acc : 17.100, Run Time : 11.40 sec
INFO:root:2024-04-26 22:52:30, Train, Epoch : 5, Step : 2550, Loss : 0.34344, Acc : 0.856, Sensitive_Loss : 0.13678, Sensitive_Acc : 16.700, Run Time : 11.66 sec
INFO:root:2024-04-26 22:52:42, Train, Epoch : 5, Step : 2560, Loss : 0.29682, Acc : 0.875, Sensitive_Loss : 0.13987, Sensitive_Acc : 17.800, Run Time : 11.68 sec
INFO:root:2024-04-26 22:52:54, Train, Epoch : 5, Step : 2570, Loss : 0.37251, Acc : 0.825, Sensitive_Loss : 0.12136, Sensitive_Acc : 14.900, Run Time : 11.86 sec
INFO:root:2024-04-26 22:53:06, Train, Epoch : 5, Step : 2580, Loss : 0.35181, Acc : 0.853, Sensitive_Loss : 0.15122, Sensitive_Acc : 16.600, Run Time : 12.72 sec
INFO:root:2024-04-26 22:53:18, Train, Epoch : 5, Step : 2590, Loss : 0.37457, Acc : 0.841, Sensitive_Loss : 0.14860, Sensitive_Acc : 15.500, Run Time : 11.73 sec
INFO:root:2024-04-26 22:53:29, Train, Epoch : 5, Step : 2600, Loss : 0.39287, Acc : 0.841, Sensitive_Loss : 0.12274, Sensitive_Acc : 16.100, Run Time : 11.33 sec
INFO:root:2024-04-26 22:56:05, Dev, Step : 2600, Loss : 0.40013, Acc : 0.833, Auc : 0.908, Sensitive_Loss : 0.13104, Sensitive_Acc : 16.893, Sensitive_Auc : 0.986, Mean auc: 0.908, Run Time : 155.93 sec
INFO:root:2024-04-26 22:56:06, Best, Step : 2600, Loss : 0.40013, Acc : 0.833, Auc : 0.908, Sensitive_Loss : 0.13104, Sensitive_Acc : 16.893, Sensitive_Auc : 0.986, Best Auc : 0.908
INFO:root:2024-04-26 22:56:14, Train, Epoch : 5, Step : 2610, Loss : 0.35884, Acc : 0.819, Sensitive_Loss : 0.14033, Sensitive_Acc : 17.300, Run Time : 164.64 sec
INFO:root:2024-04-26 22:56:26, Train, Epoch : 5, Step : 2620, Loss : 0.42454, Acc : 0.797, Sensitive_Loss : 0.12854, Sensitive_Acc : 17.900, Run Time : 11.77 sec
INFO:root:2024-04-26 22:56:37, Train, Epoch : 5, Step : 2630, Loss : 0.39431, Acc : 0.841, Sensitive_Loss : 0.13494, Sensitive_Acc : 16.800, Run Time : 11.67 sec
INFO:root:2024-04-26 22:56:49, Train, Epoch : 5, Step : 2640, Loss : 0.33792, Acc : 0.844, Sensitive_Loss : 0.14675, Sensitive_Acc : 16.600, Run Time : 11.78 sec
INFO:root:2024-04-26 22:57:01, Train, Epoch : 5, Step : 2650, Loss : 0.33286, Acc : 0.863, Sensitive_Loss : 0.14820, Sensitive_Acc : 16.400, Run Time : 11.58 sec
INFO:root:2024-04-26 22:57:13, Train, Epoch : 5, Step : 2660, Loss : 0.30905, Acc : 0.878, Sensitive_Loss : 0.09154, Sensitive_Acc : 14.900, Run Time : 11.87 sec
INFO:root:2024-04-26 22:57:24, Train, Epoch : 5, Step : 2670, Loss : 0.35828, Acc : 0.844, Sensitive_Loss : 0.10426, Sensitive_Acc : 16.000, Run Time : 11.82 sec
INFO:root:2024-04-26 22:57:36, Train, Epoch : 5, Step : 2680, Loss : 0.35717, Acc : 0.834, Sensitive_Loss : 0.09033, Sensitive_Acc : 17.100, Run Time : 11.91 sec
INFO:root:2024-04-26 22:57:48, Train, Epoch : 5, Step : 2690, Loss : 0.33298, Acc : 0.875, Sensitive_Loss : 0.13281, Sensitive_Acc : 17.300, Run Time : 11.44 sec
INFO:root:2024-04-26 22:58:01, Train, Epoch : 5, Step : 2700, Loss : 0.31258, Acc : 0.872, Sensitive_Loss : 0.10076, Sensitive_Acc : 16.100, Run Time : 12.95 sec
INFO:root:2024-04-26 23:00:37, Dev, Step : 2700, Loss : 0.40273, Acc : 0.828, Auc : 0.907, Sensitive_Loss : 0.12841, Sensitive_Acc : 16.893, Sensitive_Auc : 0.986, Mean auc: 0.907, Run Time : 156.56 sec
INFO:root:2024-04-26 23:00:47, Train, Epoch : 5, Step : 2710, Loss : 0.31439, Acc : 0.881, Sensitive_Loss : 0.15275, Sensitive_Acc : 18.000, Run Time : 166.02 sec
INFO:root:2024-04-26 23:00:59, Train, Epoch : 5, Step : 2720, Loss : 0.30675, Acc : 0.859, Sensitive_Loss : 0.20378, Sensitive_Acc : 15.000, Run Time : 12.30 sec
INFO:root:2024-04-26 23:01:11, Train, Epoch : 5, Step : 2730, Loss : 0.37355, Acc : 0.831, Sensitive_Loss : 0.11165, Sensitive_Acc : 17.000, Run Time : 11.80 sec
INFO:root:2024-04-26 23:01:22, Train, Epoch : 5, Step : 2740, Loss : 0.30139, Acc : 0.844, Sensitive_Loss : 0.12439, Sensitive_Acc : 15.700, Run Time : 11.11 sec
INFO:root:2024-04-26 23:01:34, Train, Epoch : 5, Step : 2750, Loss : 0.38771, Acc : 0.838, Sensitive_Loss : 0.12614, Sensitive_Acc : 18.100, Run Time : 12.23 sec
INFO:root:2024-04-26 23:01:46, Train, Epoch : 5, Step : 2760, Loss : 0.29978, Acc : 0.866, Sensitive_Loss : 0.08852, Sensitive_Acc : 16.300, Run Time : 11.53 sec
INFO:root:2024-04-26 23:01:58, Train, Epoch : 5, Step : 2770, Loss : 0.35395, Acc : 0.850, Sensitive_Loss : 0.12395, Sensitive_Acc : 16.700, Run Time : 12.06 sec
INFO:root:2024-04-26 23:02:10, Train, Epoch : 5, Step : 2780, Loss : 0.34703, Acc : 0.853, Sensitive_Loss : 0.13086, Sensitive_Acc : 17.600, Run Time : 11.87 sec
INFO:root:2024-04-26 23:02:22, Train, Epoch : 5, Step : 2790, Loss : 0.36868, Acc : 0.831, Sensitive_Loss : 0.13862, Sensitive_Acc : 16.500, Run Time : 12.06 sec
INFO:root:2024-04-26 23:02:34, Train, Epoch : 5, Step : 2800, Loss : 0.45594, Acc : 0.791, Sensitive_Loss : 0.17460, Sensitive_Acc : 16.500, Run Time : 12.23 sec
INFO:root:2024-04-26 23:05:10, Dev, Step : 2800, Loss : 0.43778, Acc : 0.815, Auc : 0.903, Sensitive_Loss : 0.14613, Sensitive_Acc : 16.879, Sensitive_Auc : 0.973, Mean auc: 0.903, Run Time : 155.99 sec
INFO:root:2024-04-26 23:05:19, Train, Epoch : 5, Step : 2810, Loss : 0.38003, Acc : 0.869, Sensitive_Loss : 0.12531, Sensitive_Acc : 17.200, Run Time : 164.72 sec
INFO:root:2024-04-26 23:05:31, Train, Epoch : 5, Step : 2820, Loss : 0.38174, Acc : 0.834, Sensitive_Loss : 0.14755, Sensitive_Acc : 17.300, Run Time : 11.84 sec
INFO:root:2024-04-26 23:05:43, Train, Epoch : 5, Step : 2830, Loss : 0.43492, Acc : 0.806, Sensitive_Loss : 0.17688, Sensitive_Acc : 15.800, Run Time : 12.15 sec
INFO:root:2024-04-26 23:05:53, Train, Epoch : 5, Step : 2840, Loss : 0.35349, Acc : 0.838, Sensitive_Loss : 0.17910, Sensitive_Acc : 15.400, Run Time : 10.69 sec
INFO:root:2024-04-26 23:06:05, Train, Epoch : 5, Step : 2850, Loss : 0.34839, Acc : 0.825, Sensitive_Loss : 0.17427, Sensitive_Acc : 16.900, Run Time : 11.65 sec
INFO:root:2024-04-26 23:06:17, Train, Epoch : 5, Step : 2860, Loss : 0.34535, Acc : 0.850, Sensitive_Loss : 0.11805, Sensitive_Acc : 17.400, Run Time : 12.41 sec
INFO:root:2024-04-26 23:06:29, Train, Epoch : 5, Step : 2870, Loss : 0.34306, Acc : 0.831, Sensitive_Loss : 0.17043, Sensitive_Acc : 15.700, Run Time : 12.01 sec
INFO:root:2024-04-26 23:06:42, Train, Epoch : 5, Step : 2880, Loss : 0.35795, Acc : 0.853, Sensitive_Loss : 0.15454, Sensitive_Acc : 15.000, Run Time : 12.07 sec
INFO:root:2024-04-26 23:06:54, Train, Epoch : 5, Step : 2890, Loss : 0.39183, Acc : 0.838, Sensitive_Loss : 0.16559, Sensitive_Acc : 16.000, Run Time : 12.17 sec
INFO:root:2024-04-26 23:07:06, Train, Epoch : 5, Step : 2900, Loss : 0.35919, Acc : 0.847, Sensitive_Loss : 0.14466, Sensitive_Acc : 17.400, Run Time : 12.05 sec
INFO:root:2024-04-26 23:09:41, Dev, Step : 2900, Loss : 0.42495, Acc : 0.822, Auc : 0.907, Sensitive_Loss : 0.13766, Sensitive_Acc : 16.893, Sensitive_Auc : 0.980, Mean auc: 0.907, Run Time : 154.84 sec
INFO:root:2024-04-26 23:09:49, Train, Epoch : 5, Step : 2910, Loss : 0.35863, Acc : 0.841, Sensitive_Loss : 0.13337, Sensitive_Acc : 15.000, Run Time : 163.66 sec
INFO:root:2024-04-26 23:10:02, Train, Epoch : 5, Step : 2920, Loss : 0.31971, Acc : 0.853, Sensitive_Loss : 0.11724, Sensitive_Acc : 15.600, Run Time : 12.70 sec
INFO:root:2024-04-26 23:10:13, Train, Epoch : 5, Step : 2930, Loss : 0.35912, Acc : 0.844, Sensitive_Loss : 0.11870, Sensitive_Acc : 15.700, Run Time : 11.27 sec
INFO:root:2024-04-26 23:10:25, Train, Epoch : 5, Step : 2940, Loss : 0.33808, Acc : 0.856, Sensitive_Loss : 0.14791, Sensitive_Acc : 15.900, Run Time : 11.72 sec
INFO:root:2024-04-26 23:10:37, Train, Epoch : 5, Step : 2950, Loss : 0.34678, Acc : 0.866, Sensitive_Loss : 0.12728, Sensitive_Acc : 18.700, Run Time : 11.60 sec
INFO:root:2024-04-26 23:10:48, Train, Epoch : 5, Step : 2960, Loss : 0.34209, Acc : 0.841, Sensitive_Loss : 0.13924, Sensitive_Acc : 14.900, Run Time : 11.79 sec
INFO:root:2024-04-26 23:11:00, Train, Epoch : 5, Step : 2970, Loss : 0.37366, Acc : 0.847, Sensitive_Loss : 0.16420, Sensitive_Acc : 18.400, Run Time : 12.02 sec
INFO:root:2024-04-26 23:11:13, Train, Epoch : 5, Step : 2980, Loss : 0.39803, Acc : 0.822, Sensitive_Loss : 0.14834, Sensitive_Acc : 14.700, Run Time : 12.10 sec
INFO:root:2024-04-26 23:11:24, Train, Epoch : 5, Step : 2990, Loss : 0.33833, Acc : 0.831, Sensitive_Loss : 0.13438, Sensitive_Acc : 16.700, Run Time : 11.56 sec
INFO:root:2024-04-26 23:11:36, Train, Epoch : 5, Step : 3000, Loss : 0.42554, Acc : 0.822, Sensitive_Loss : 0.13405, Sensitive_Acc : 14.200, Run Time : 11.50 sec
INFO:root:2024-04-26 23:14:13, Dev, Step : 3000, Loss : 0.40295, Acc : 0.829, Auc : 0.908, Sensitive_Loss : 0.13244, Sensitive_Acc : 16.950, Sensitive_Auc : 0.983, Mean auc: 0.908, Run Time : 157.15 sec
INFO:root:2024-04-26 23:14:14, Best, Step : 3000, Loss : 0.40295, Acc : 0.829, Auc : 0.908, Sensitive_Loss : 0.13244, Sensitive_Acc : 16.950, Sensitive_Auc : 0.983, Best Auc : 0.908
INFO:root:2024-04-26 23:14:22, Train, Epoch : 5, Step : 3010, Loss : 0.36555, Acc : 0.850, Sensitive_Loss : 0.14949, Sensitive_Acc : 15.800, Run Time : 166.48 sec
INFO:root:2024-04-26 23:14:35, Train, Epoch : 5, Step : 3020, Loss : 0.40571, Acc : 0.841, Sensitive_Loss : 0.11624, Sensitive_Acc : 17.100, Run Time : 12.40 sec
INFO:root:2024-04-26 23:14:46, Train, Epoch : 5, Step : 3030, Loss : 0.35400, Acc : 0.841, Sensitive_Loss : 0.13582, Sensitive_Acc : 17.600, Run Time : 11.57 sec
INFO:root:2024-04-26 23:14:58, Train, Epoch : 5, Step : 3040, Loss : 0.35027, Acc : 0.847, Sensitive_Loss : 0.15739, Sensitive_Acc : 15.600, Run Time : 11.65 sec
INFO:root:2024-04-26 23:15:10, Train, Epoch : 5, Step : 3050, Loss : 0.34585, Acc : 0.847, Sensitive_Loss : 0.12952, Sensitive_Acc : 15.000, Run Time : 12.24 sec
INFO:root:2024-04-26 23:15:22, Train, Epoch : 5, Step : 3060, Loss : 0.45833, Acc : 0.791, Sensitive_Loss : 0.16149, Sensitive_Acc : 16.300, Run Time : 11.80 sec
INFO:root:2024-04-26 23:15:34, Train, Epoch : 5, Step : 3070, Loss : 0.41061, Acc : 0.825, Sensitive_Loss : 0.17591, Sensitive_Acc : 15.400, Run Time : 11.93 sec
INFO:root:2024-04-26 23:15:46, Train, Epoch : 5, Step : 3080, Loss : 0.31352, Acc : 0.863, Sensitive_Loss : 0.10499, Sensitive_Acc : 16.900, Run Time : 12.44 sec
INFO:root:2024-04-26 23:15:59, Train, Epoch : 5, Step : 3090, Loss : 0.36403, Acc : 0.859, Sensitive_Loss : 0.12229, Sensitive_Acc : 15.300, Run Time : 13.11 sec
INFO:root:2024-04-26 23:16:11, Train, Epoch : 5, Step : 3100, Loss : 0.30460, Acc : 0.856, Sensitive_Loss : 0.13095, Sensitive_Acc : 16.300, Run Time : 11.75 sec
INFO:root:2024-04-26 23:18:47, Dev, Step : 3100, Loss : 0.40522, Acc : 0.826, Auc : 0.909, Sensitive_Loss : 0.12640, Sensitive_Acc : 16.821, Sensitive_Auc : 0.985, Mean auc: 0.909, Run Time : 156.09 sec
INFO:root:2024-04-26 23:18:48, Best, Step : 3100, Loss : 0.40522, Acc : 0.826, Auc : 0.909, Sensitive_Loss : 0.12640, Sensitive_Acc : 16.821, Sensitive_Auc : 0.985, Best Auc : 0.909
INFO:root:2024-04-26 23:18:57, Train, Epoch : 5, Step : 3110, Loss : 0.37915, Acc : 0.838, Sensitive_Loss : 0.15289, Sensitive_Acc : 16.100, Run Time : 165.65 sec
INFO:root:2024-04-26 23:19:09, Train, Epoch : 5, Step : 3120, Loss : 0.34176, Acc : 0.844, Sensitive_Loss : 0.14773, Sensitive_Acc : 17.200, Run Time : 12.25 sec
INFO:root:2024-04-26 23:19:20, Train, Epoch : 5, Step : 3130, Loss : 0.37458, Acc : 0.828, Sensitive_Loss : 0.15044, Sensitive_Acc : 15.600, Run Time : 11.03 sec
INFO:root:2024-04-26 23:21:54
INFO:root:y_pred: [0.21931875 0.90369195 0.02582073 ... 0.7863616  0.01539021 0.91748405]
INFO:root:y_true: [0. 1. 0. ... 1. 0. 1.]
INFO:root:sensitive_y_pred: [9.6413755e-01 2.5751399e-06 4.5341298e-02 3.8812792e-07 9.9406260e-01
 9.7441230e-08 9.9167562e-01 9.5696282e-01 5.4174443e-03 4.3547449e-01
 9.9355668e-01 9.9809557e-01 9.8780316e-01 8.4112525e-01 3.0790535e-01
 8.4204632e-01 9.9558687e-01 4.2038364e-03 2.7062615e-02 9.9461764e-01
 9.9008864e-01 3.7012052e-07 9.9862087e-01 7.7501255e-01 9.8889983e-01
 8.6349499e-01 1.0197125e-04 9.8586398e-01 9.3206608e-01 8.1418306e-01
 7.7222562e-03 4.3707117e-03 1.7599929e-02 3.4442738e-02 5.7252896e-01
 4.7999026e-07 1.0754618e-01 1.4544956e-03 9.8288095e-01 9.8109883e-01
 7.4200672e-12 1.3636898e-05 9.8950481e-01 1.0570165e-03 9.9793470e-01
 9.6663463e-01 8.8968372e-01 9.9353564e-01 3.0164288e-03 9.6934712e-01
 9.9493057e-01 8.9833641e-04 9.7175509e-01 3.1410765e-03 1.9081085e-07
 2.3155921e-04 8.8130914e-02 7.2718115e-07 3.5863363e-06 4.5415536e-08
 1.0506752e-05 2.2612733e-03 7.3800779e-06 9.9178833e-01 3.9313060e-01
 9.9246937e-01 2.8180142e-05 9.8491341e-01 8.5912448e-01 3.5811722e-01
 7.8220069e-01 3.0428439e-01 3.9389487e-03 4.4627909e-02 7.0320338e-04
 2.1981648e-03 4.4333689e-02 2.8267577e-01 6.3733707e-05 9.8832357e-01
 9.9492836e-01 8.8187713e-05 3.2473907e-01 2.1006669e-04 8.7791741e-01
 8.6966252e-01 6.1234634e-02 7.9279710e-03 9.5008928e-01 9.8461771e-01
 9.9224609e-01 7.6826592e-04 5.5404432e-04 9.9137324e-01 3.6877301e-01
 2.5100962e-04 9.8955989e-01 9.8515284e-01 5.7961902e-10 7.0744907e-05
 9.6182513e-01 9.3892294e-01 9.9300671e-01 9.9288392e-01 4.9601967e-04
 1.1391521e-02 6.5561384e-01 8.6604798e-01 9.4031370e-01 6.1857595e-06
 7.2723413e-01 9.9459404e-01 1.2531430e-02 9.9560672e-01 8.8201773e-01
 9.7433293e-01 8.7254989e-01 9.9096805e-01 1.0545799e-01 5.4649615e-01
 9.9441457e-01 9.9274266e-01 1.7083703e-11 9.2788792e-01 9.8343581e-01
 5.4295804e-02 9.8530698e-01 2.7440223e-03 1.0618814e-03 8.2366920e-01
 9.9479127e-01 9.8147502e-05 2.5780721e-05 5.9114434e-05 9.8468137e-01
 9.9891448e-01 9.2367697e-01 2.5488953e-05 4.9899518e-04 9.6982992e-01]
INFO:root:sensitive_y_true: [1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.
 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.]
INFO:root:2024-04-26 23:21:54, Dev, Step : 3130, Loss : 0.41764, Acc : 0.825, Auc : 0.908, Sensitive_Loss : 0.12583, Sensitive_Acc : 16.821, Sensitive_Auc : 0.983, Mean auc: 0.908, Run Time : 153.62 sec
INFO:root:2024-04-26 23:22:09, Train, Epoch : 6, Step : 3140, Loss : 0.28049, Acc : 0.909, Sensitive_Loss : 0.14596, Sensitive_Acc : 15.700, Run Time : 14.10 sec
INFO:root:2024-04-26 23:22:20, Train, Epoch : 6, Step : 3150, Loss : 0.30870, Acc : 0.863, Sensitive_Loss : 0.09857, Sensitive_Acc : 14.900, Run Time : 11.00 sec
INFO:root:2024-04-26 23:22:31, Train, Epoch : 6, Step : 3160, Loss : 0.34974, Acc : 0.853, Sensitive_Loss : 0.11565, Sensitive_Acc : 15.200, Run Time : 11.34 sec
INFO:root:2024-04-26 23:22:44, Train, Epoch : 6, Step : 3170, Loss : 0.37116, Acc : 0.844, Sensitive_Loss : 0.12425, Sensitive_Acc : 16.700, Run Time : 12.50 sec
INFO:root:2024-04-26 23:22:56, Train, Epoch : 6, Step : 3180, Loss : 0.33703, Acc : 0.859, Sensitive_Loss : 0.11327, Sensitive_Acc : 15.000, Run Time : 12.09 sec
INFO:root:2024-04-26 23:23:08, Train, Epoch : 6, Step : 3190, Loss : 0.35635, Acc : 0.838, Sensitive_Loss : 0.10589, Sensitive_Acc : 15.900, Run Time : 11.74 sec
INFO:root:2024-04-26 23:23:19, Train, Epoch : 6, Step : 3200, Loss : 0.40890, Acc : 0.847, Sensitive_Loss : 0.16981, Sensitive_Acc : 18.300, Run Time : 11.38 sec
INFO:root:2024-04-26 23:25:55, Dev, Step : 3200, Loss : 0.41282, Acc : 0.828, Auc : 0.907, Sensitive_Loss : 0.12869, Sensitive_Acc : 16.921, Sensitive_Auc : 0.989, Mean auc: 0.907, Run Time : 156.03 sec
INFO:root:2024-04-26 23:26:03, Train, Epoch : 6, Step : 3210, Loss : 0.35830, Acc : 0.841, Sensitive_Loss : 0.11294, Sensitive_Acc : 15.300, Run Time : 164.44 sec
INFO:root:2024-04-26 23:26:16, Train, Epoch : 6, Step : 3220, Loss : 0.38065, Acc : 0.853, Sensitive_Loss : 0.11504, Sensitive_Acc : 16.000, Run Time : 12.96 sec
INFO:root:2024-04-26 23:26:28, Train, Epoch : 6, Step : 3230, Loss : 0.38124, Acc : 0.819, Sensitive_Loss : 0.13212, Sensitive_Acc : 16.200, Run Time : 11.75 sec
INFO:root:2024-04-26 23:26:39, Train, Epoch : 6, Step : 3240, Loss : 0.38052, Acc : 0.850, Sensitive_Loss : 0.11646, Sensitive_Acc : 15.500, Run Time : 10.89 sec
INFO:root:2024-04-26 23:26:52, Train, Epoch : 6, Step : 3250, Loss : 0.41600, Acc : 0.825, Sensitive_Loss : 0.16759, Sensitive_Acc : 17.700, Run Time : 12.68 sec
INFO:root:2024-04-26 23:27:03, Train, Epoch : 6, Step : 3260, Loss : 0.37013, Acc : 0.847, Sensitive_Loss : 0.09534, Sensitive_Acc : 17.900, Run Time : 11.31 sec
INFO:root:2024-04-26 23:27:14, Train, Epoch : 6, Step : 3270, Loss : 0.26506, Acc : 0.869, Sensitive_Loss : 0.15069, Sensitive_Acc : 19.300, Run Time : 10.93 sec
INFO:root:2024-04-26 23:27:27, Train, Epoch : 6, Step : 3280, Loss : 0.37737, Acc : 0.841, Sensitive_Loss : 0.14785, Sensitive_Acc : 16.300, Run Time : 12.69 sec
INFO:root:2024-04-26 23:27:38, Train, Epoch : 6, Step : 3290, Loss : 0.39652, Acc : 0.834, Sensitive_Loss : 0.12709, Sensitive_Acc : 16.000, Run Time : 11.63 sec
INFO:root:2024-04-26 23:27:51, Train, Epoch : 6, Step : 3300, Loss : 0.39213, Acc : 0.838, Sensitive_Loss : 0.12229, Sensitive_Acc : 16.100, Run Time : 12.44 sec
INFO:root:2024-04-26 23:30:27, Dev, Step : 3300, Loss : 0.39645, Acc : 0.831, Auc : 0.908, Sensitive_Loss : 0.12874, Sensitive_Acc : 16.821, Sensitive_Auc : 0.989, Mean auc: 0.908, Run Time : 156.16 sec
INFO:root:2024-04-26 23:30:35, Train, Epoch : 6, Step : 3310, Loss : 0.34426, Acc : 0.834, Sensitive_Loss : 0.10554, Sensitive_Acc : 16.500, Run Time : 164.08 sec
INFO:root:2024-04-26 23:30:46, Train, Epoch : 6, Step : 3320, Loss : 0.31020, Acc : 0.844, Sensitive_Loss : 0.13994, Sensitive_Acc : 16.200, Run Time : 11.41 sec
INFO:root:2024-04-26 23:30:58, Train, Epoch : 6, Step : 3330, Loss : 0.38075, Acc : 0.819, Sensitive_Loss : 0.12400, Sensitive_Acc : 16.400, Run Time : 11.98 sec
INFO:root:2024-04-26 23:31:10, Train, Epoch : 6, Step : 3340, Loss : 0.38042, Acc : 0.812, Sensitive_Loss : 0.12138, Sensitive_Acc : 15.500, Run Time : 12.09 sec
INFO:root:2024-04-26 23:31:22, Train, Epoch : 6, Step : 3350, Loss : 0.28383, Acc : 0.869, Sensitive_Loss : 0.12836, Sensitive_Acc : 16.800, Run Time : 12.14 sec
INFO:root:2024-04-26 23:31:34, Train, Epoch : 6, Step : 3360, Loss : 0.29621, Acc : 0.856, Sensitive_Loss : 0.10883, Sensitive_Acc : 17.000, Run Time : 11.78 sec
INFO:root:2024-04-26 23:31:45, Train, Epoch : 6, Step : 3370, Loss : 0.33848, Acc : 0.850, Sensitive_Loss : 0.12631, Sensitive_Acc : 16.200, Run Time : 11.22 sec
INFO:root:2024-04-26 23:31:57, Train, Epoch : 6, Step : 3380, Loss : 0.31028, Acc : 0.869, Sensitive_Loss : 0.16410, Sensitive_Acc : 16.300, Run Time : 11.86 sec
INFO:root:2024-04-26 23:32:09, Train, Epoch : 6, Step : 3390, Loss : 0.30426, Acc : 0.859, Sensitive_Loss : 0.10835, Sensitive_Acc : 17.000, Run Time : 12.16 sec
INFO:root:2024-04-26 23:32:20, Train, Epoch : 6, Step : 3400, Loss : 0.31238, Acc : 0.853, Sensitive_Loss : 0.12136, Sensitive_Acc : 16.900, Run Time : 10.92 sec
INFO:root:2024-04-26 23:34:57, Dev, Step : 3400, Loss : 0.39727, Acc : 0.830, Auc : 0.909, Sensitive_Loss : 0.12597, Sensitive_Acc : 16.879, Sensitive_Auc : 0.990, Mean auc: 0.909, Run Time : 156.66 sec
INFO:root:2024-04-26 23:35:06, Train, Epoch : 6, Step : 3410, Loss : 0.30717, Acc : 0.881, Sensitive_Loss : 0.14979, Sensitive_Acc : 16.600, Run Time : 165.38 sec
INFO:root:2024-04-26 23:35:18, Train, Epoch : 6, Step : 3420, Loss : 0.34281, Acc : 0.859, Sensitive_Loss : 0.13634, Sensitive_Acc : 16.400, Run Time : 12.49 sec
INFO:root:2024-04-26 23:35:30, Train, Epoch : 6, Step : 3430, Loss : 0.33204, Acc : 0.841, Sensitive_Loss : 0.14571, Sensitive_Acc : 15.600, Run Time : 11.72 sec
INFO:root:2024-04-26 23:35:42, Train, Epoch : 6, Step : 3440, Loss : 0.39342, Acc : 0.841, Sensitive_Loss : 0.10182, Sensitive_Acc : 17.200, Run Time : 12.26 sec
INFO:root:2024-04-26 23:35:55, Train, Epoch : 6, Step : 3450, Loss : 0.32972, Acc : 0.838, Sensitive_Loss : 0.13472, Sensitive_Acc : 17.200, Run Time : 12.39 sec
INFO:root:2024-04-26 23:36:06, Train, Epoch : 6, Step : 3460, Loss : 0.39016, Acc : 0.850, Sensitive_Loss : 0.15726, Sensitive_Acc : 15.400, Run Time : 11.63 sec
INFO:root:2024-04-26 23:36:19, Train, Epoch : 6, Step : 3470, Loss : 0.39333, Acc : 0.825, Sensitive_Loss : 0.12385, Sensitive_Acc : 16.900, Run Time : 12.36 sec
INFO:root:2024-04-26 23:36:30, Train, Epoch : 6, Step : 3480, Loss : 0.38514, Acc : 0.831, Sensitive_Loss : 0.13800, Sensitive_Acc : 15.800, Run Time : 10.94 sec
INFO:root:2024-04-26 23:36:42, Train, Epoch : 6, Step : 3490, Loss : 0.38340, Acc : 0.841, Sensitive_Loss : 0.15064, Sensitive_Acc : 16.100, Run Time : 12.00 sec
INFO:root:2024-04-26 23:36:53, Train, Epoch : 6, Step : 3500, Loss : 0.39653, Acc : 0.856, Sensitive_Loss : 0.08590, Sensitive_Acc : 18.100, Run Time : 11.65 sec
INFO:root:2024-04-26 23:39:29, Dev, Step : 3500, Loss : 0.39753, Acc : 0.831, Auc : 0.908, Sensitive_Loss : 0.12483, Sensitive_Acc : 16.950, Sensitive_Auc : 0.988, Mean auc: 0.908, Run Time : 156.26 sec
INFO:root:2024-04-26 23:39:38, Train, Epoch : 6, Step : 3510, Loss : 0.36194, Acc : 0.859, Sensitive_Loss : 0.16081, Sensitive_Acc : 17.200, Run Time : 165.01 sec
INFO:root:2024-04-26 23:39:51, Train, Epoch : 6, Step : 3520, Loss : 0.37438, Acc : 0.831, Sensitive_Loss : 0.13875, Sensitive_Acc : 16.900, Run Time : 12.83 sec
INFO:root:2024-04-26 23:40:03, Train, Epoch : 6, Step : 3530, Loss : 0.33437, Acc : 0.866, Sensitive_Loss : 0.11116, Sensitive_Acc : 18.200, Run Time : 12.33 sec
INFO:root:2024-04-26 23:40:14, Train, Epoch : 6, Step : 3540, Loss : 0.37908, Acc : 0.828, Sensitive_Loss : 0.15400, Sensitive_Acc : 17.600, Run Time : 10.77 sec
INFO:root:2024-04-26 23:40:26, Train, Epoch : 6, Step : 3550, Loss : 0.32569, Acc : 0.838, Sensitive_Loss : 0.14537, Sensitive_Acc : 16.100, Run Time : 11.81 sec
INFO:root:2024-04-26 23:40:38, Train, Epoch : 6, Step : 3560, Loss : 0.36971, Acc : 0.828, Sensitive_Loss : 0.13302, Sensitive_Acc : 15.800, Run Time : 12.36 sec
INFO:root:2024-04-26 23:40:50, Train, Epoch : 6, Step : 3570, Loss : 0.42112, Acc : 0.834, Sensitive_Loss : 0.12887, Sensitive_Acc : 16.400, Run Time : 11.17 sec
INFO:root:2024-04-26 23:41:01, Train, Epoch : 6, Step : 3580, Loss : 0.28941, Acc : 0.872, Sensitive_Loss : 0.19426, Sensitive_Acc : 18.500, Run Time : 11.56 sec
INFO:root:2024-04-26 23:41:14, Train, Epoch : 6, Step : 3590, Loss : 0.31135, Acc : 0.859, Sensitive_Loss : 0.12969, Sensitive_Acc : 14.500, Run Time : 12.54 sec
INFO:root:2024-04-26 23:41:25, Train, Epoch : 6, Step : 3600, Loss : 0.34968, Acc : 0.859, Sensitive_Loss : 0.16660, Sensitive_Acc : 17.500, Run Time : 11.67 sec
INFO:root:2024-04-26 23:44:01, Dev, Step : 3600, Loss : 0.40313, Acc : 0.828, Auc : 0.907, Sensitive_Loss : 0.13789, Sensitive_Acc : 16.907, Sensitive_Auc : 0.983, Mean auc: 0.907, Run Time : 155.78 sec
INFO:root:2024-04-26 23:44:09, Train, Epoch : 6, Step : 3610, Loss : 0.26372, Acc : 0.881, Sensitive_Loss : 0.15719, Sensitive_Acc : 16.000, Run Time : 164.08 sec
INFO:root:2024-04-26 23:44:22, Train, Epoch : 6, Step : 3620, Loss : 0.34548, Acc : 0.850, Sensitive_Loss : 0.13347, Sensitive_Acc : 17.200, Run Time : 12.60 sec
INFO:root:2024-04-26 23:44:34, Train, Epoch : 6, Step : 3630, Loss : 0.35726, Acc : 0.812, Sensitive_Loss : 0.14445, Sensitive_Acc : 18.000, Run Time : 12.40 sec
INFO:root:2024-04-26 23:44:46, Train, Epoch : 6, Step : 3640, Loss : 0.37355, Acc : 0.828, Sensitive_Loss : 0.14214, Sensitive_Acc : 16.800, Run Time : 11.36 sec
INFO:root:2024-04-26 23:44:58, Train, Epoch : 6, Step : 3650, Loss : 0.34461, Acc : 0.828, Sensitive_Loss : 0.10771, Sensitive_Acc : 17.000, Run Time : 11.79 sec
INFO:root:2024-04-26 23:45:10, Train, Epoch : 6, Step : 3660, Loss : 0.30705, Acc : 0.859, Sensitive_Loss : 0.11939, Sensitive_Acc : 16.700, Run Time : 11.98 sec
INFO:root:2024-04-26 23:45:20, Train, Epoch : 6, Step : 3670, Loss : 0.35905, Acc : 0.847, Sensitive_Loss : 0.10882, Sensitive_Acc : 16.700, Run Time : 10.93 sec
INFO:root:2024-04-26 23:45:33, Train, Epoch : 6, Step : 3680, Loss : 0.34279, Acc : 0.838, Sensitive_Loss : 0.10084, Sensitive_Acc : 16.000, Run Time : 12.29 sec
INFO:root:2024-04-26 23:45:44, Train, Epoch : 6, Step : 3690, Loss : 0.33478, Acc : 0.850, Sensitive_Loss : 0.12287, Sensitive_Acc : 18.400, Run Time : 11.30 sec
INFO:root:2024-04-26 23:45:56, Train, Epoch : 6, Step : 3700, Loss : 0.34044, Acc : 0.856, Sensitive_Loss : 0.10346, Sensitive_Acc : 15.800, Run Time : 11.87 sec
INFO:root:2024-04-26 23:48:32, Dev, Step : 3700, Loss : 0.41504, Acc : 0.826, Auc : 0.907, Sensitive_Loss : 0.12998, Sensitive_Acc : 16.907, Sensitive_Auc : 0.984, Mean auc: 0.907, Run Time : 156.49 sec
INFO:root:2024-04-26 23:48:41, Train, Epoch : 6, Step : 3710, Loss : 0.27580, Acc : 0.872, Sensitive_Loss : 0.11782, Sensitive_Acc : 15.200, Run Time : 165.33 sec
INFO:root:2024-04-26 23:48:54, Train, Epoch : 6, Step : 3720, Loss : 0.35260, Acc : 0.863, Sensitive_Loss : 0.10270, Sensitive_Acc : 15.300, Run Time : 12.34 sec
INFO:root:2024-04-26 23:49:05, Train, Epoch : 6, Step : 3730, Loss : 0.31389, Acc : 0.863, Sensitive_Loss : 0.15070, Sensitive_Acc : 14.400, Run Time : 11.32 sec
INFO:root:2024-04-26 23:49:17, Train, Epoch : 6, Step : 3740, Loss : 0.30894, Acc : 0.869, Sensitive_Loss : 0.12578, Sensitive_Acc : 15.200, Run Time : 12.23 sec
INFO:root:2024-04-26 23:49:29, Train, Epoch : 6, Step : 3750, Loss : 0.38753, Acc : 0.853, Sensitive_Loss : 0.13097, Sensitive_Acc : 17.200, Run Time : 11.57 sec
INFO:root:2024-04-26 23:52:08
INFO:root:y_pred: [0.09541605 0.9347976  0.01654713 ... 0.76497537 0.01023962 0.88722634]
INFO:root:y_true: [0. 1. 0. ... 1. 0. 1.]
INFO:root:sensitive_y_pred: [9.81351435e-01 6.06789968e-07 2.34028492e-02 1.29235730e-07
 9.96707559e-01 3.94612044e-07 9.93738651e-01 9.72683609e-01
 1.58815179e-02 4.89861697e-01 9.93954718e-01 9.98743355e-01
 9.94603932e-01 8.64984453e-01 3.77149463e-01 9.10947323e-01
 9.96657729e-01 2.38074851e-03 3.87737434e-03 9.97063935e-01
 9.91722167e-01 5.45080239e-03 9.99127448e-01 9.38623130e-01
 9.87273693e-01 8.96832287e-01 1.03153347e-04 9.90673363e-01
 9.41354454e-01 8.95661414e-01 1.04728611e-02 7.50017026e-03
 1.39509618e-01 9.63388477e-03 6.95348203e-01 7.82448024e-06
 2.55406126e-02 2.48266989e-03 9.87862706e-01 9.82302845e-01
 1.65390965e-10 3.01752652e-06 9.95927155e-01 2.14070617e-03
 9.98253763e-01 9.89928067e-01 8.87425721e-01 9.95857060e-01
 1.58304591e-02 9.71396148e-01 9.94624317e-01 4.73630964e-04
 9.88419652e-01 2.20460305e-03 3.64547446e-07 1.79747556e-04
 5.78856133e-02 6.54352407e-05 3.71975257e-05 9.29436681e-07
 3.37535865e-04 2.33800560e-02 1.82512085e-08 9.93614376e-01
 3.13024342e-01 9.93813992e-01 1.54847143e-07 9.88831997e-01
 8.97624671e-01 6.91704094e-01 5.68871975e-01 4.22229558e-01
 8.95642303e-03 5.67599796e-02 2.06542597e-03 2.42290227e-03
 4.61092070e-02 2.19320387e-01 9.79544275e-05 9.93831158e-01
 9.97056007e-01 1.15514267e-04 1.92918196e-01 2.38485445e-05
 9.06967938e-01 9.52688694e-01 1.03285946e-01 7.83292018e-03
 9.40521479e-01 9.85383272e-01 9.93813276e-01 2.34716758e-03
 8.13457300e-04 9.91650760e-01 8.60359967e-02 1.15050003e-03
 9.92968738e-01 9.87221301e-01 2.09069415e-10 2.74633546e-03
 9.66182709e-01 9.57640946e-01 9.95399892e-01 9.95195329e-01
 2.80511216e-03 4.44145650e-01 5.82225144e-01 9.05551016e-01
 9.32083607e-01 2.67669770e-06 7.33611882e-01 9.96853530e-01
 1.24246329e-02 9.97955441e-01 9.19663966e-01 9.75576222e-01
 9.10614967e-01 9.94655013e-01 1.12469710e-01 1.00397907e-01
 9.97575939e-01 9.95785534e-01 7.24629867e-09 9.37110364e-01
 9.88867462e-01 7.38224108e-03 9.88507748e-01 6.33788644e-04
 1.55408466e-02 9.78870630e-01 9.96342242e-01 1.48768377e-05
 4.21744771e-05 1.25929553e-04 9.80729759e-01 9.99299288e-01
 9.54256475e-01 7.86288991e-04 1.18124411e-02 9.84903336e-01]
INFO:root:sensitive_y_true: [1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.
 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.]
INFO:root:2024-04-26 23:52:08, Dev, Step : 3756, Loss : 0.42970, Acc : 0.822, Auc : 0.907, Sensitive_Loss : 0.12870, Sensitive_Acc : 16.907, Sensitive_Auc : 0.981, Mean auc: 0.907, Run Time : 153.24 sec
INFO:root:2024-04-26 23:52:15, Train, Epoch : 7, Step : 3760, Loss : 0.11636, Acc : 0.359, Sensitive_Loss : 0.05766, Sensitive_Acc : 7.700, Run Time : 5.98 sec
INFO:root:2024-04-26 23:52:27, Train, Epoch : 7, Step : 3770, Loss : 0.35554, Acc : 0.853, Sensitive_Loss : 0.18845, Sensitive_Acc : 16.200, Run Time : 11.85 sec
INFO:root:2024-04-26 23:52:38, Train, Epoch : 7, Step : 3780, Loss : 0.33203, Acc : 0.872, Sensitive_Loss : 0.11349, Sensitive_Acc : 15.000, Run Time : 11.05 sec
INFO:root:2024-04-26 23:52:50, Train, Epoch : 7, Step : 3790, Loss : 0.33562, Acc : 0.853, Sensitive_Loss : 0.13097, Sensitive_Acc : 17.000, Run Time : 12.51 sec
INFO:root:2024-04-26 23:53:02, Train, Epoch : 7, Step : 3800, Loss : 0.31748, Acc : 0.863, Sensitive_Loss : 0.11277, Sensitive_Acc : 16.200, Run Time : 11.34 sec
INFO:root:2024-04-26 23:55:38, Dev, Step : 3800, Loss : 0.41510, Acc : 0.820, Auc : 0.905, Sensitive_Loss : 0.12234, Sensitive_Acc : 16.907, Sensitive_Auc : 0.980, Mean auc: 0.905, Run Time : 156.11 sec
INFO:root:2024-04-26 23:55:47, Train, Epoch : 7, Step : 3810, Loss : 0.37833, Acc : 0.831, Sensitive_Loss : 0.10425, Sensitive_Acc : 16.900, Run Time : 164.69 sec
INFO:root:2024-04-26 23:55:59, Train, Epoch : 7, Step : 3820, Loss : 0.26625, Acc : 0.881, Sensitive_Loss : 0.10395, Sensitive_Acc : 16.400, Run Time : 12.06 sec
INFO:root:2024-04-26 23:56:11, Train, Epoch : 7, Step : 3830, Loss : 0.31882, Acc : 0.884, Sensitive_Loss : 0.09553, Sensitive_Acc : 17.000, Run Time : 12.56 sec
INFO:root:2024-04-26 23:56:23, Train, Epoch : 7, Step : 3840, Loss : 0.30295, Acc : 0.863, Sensitive_Loss : 0.12310, Sensitive_Acc : 17.900, Run Time : 11.45 sec
INFO:root:2024-04-26 23:56:34, Train, Epoch : 7, Step : 3850, Loss : 0.38983, Acc : 0.819, Sensitive_Loss : 0.13183, Sensitive_Acc : 16.300, Run Time : 11.71 sec
INFO:root:2024-04-26 23:56:47, Train, Epoch : 7, Step : 3860, Loss : 0.27997, Acc : 0.887, Sensitive_Loss : 0.09956, Sensitive_Acc : 16.900, Run Time : 12.34 sec
INFO:root:2024-04-26 23:56:59, Train, Epoch : 7, Step : 3870, Loss : 0.29728, Acc : 0.872, Sensitive_Loss : 0.13047, Sensitive_Acc : 17.500, Run Time : 11.96 sec
INFO:root:2024-04-26 23:57:11, Train, Epoch : 7, Step : 3880, Loss : 0.35952, Acc : 0.844, Sensitive_Loss : 0.10798, Sensitive_Acc : 16.900, Run Time : 11.93 sec
INFO:root:2024-04-26 23:57:22, Train, Epoch : 7, Step : 3890, Loss : 0.38271, Acc : 0.838, Sensitive_Loss : 0.08583, Sensitive_Acc : 16.600, Run Time : 11.60 sec
INFO:root:2024-04-26 23:57:35, Train, Epoch : 7, Step : 3900, Loss : 0.34097, Acc : 0.838, Sensitive_Loss : 0.07973, Sensitive_Acc : 16.300, Run Time : 12.59 sec
INFO:root:2024-04-27 00:00:11, Dev, Step : 3900, Loss : 0.40756, Acc : 0.826, Auc : 0.907, Sensitive_Loss : 0.12272, Sensitive_Acc : 16.950, Sensitive_Auc : 0.982, Mean auc: 0.907, Run Time : 156.40 sec
INFO:root:2024-04-27 00:00:20, Train, Epoch : 7, Step : 3910, Loss : 0.28453, Acc : 0.906, Sensitive_Loss : 0.10009, Sensitive_Acc : 16.500, Run Time : 164.82 sec
INFO:root:2024-04-27 00:00:31, Train, Epoch : 7, Step : 3920, Loss : 0.39456, Acc : 0.822, Sensitive_Loss : 0.08865, Sensitive_Acc : 16.900, Run Time : 11.80 sec
INFO:root:2024-04-27 00:00:44, Train, Epoch : 7, Step : 3930, Loss : 0.36725, Acc : 0.822, Sensitive_Loss : 0.12840, Sensitive_Acc : 16.700, Run Time : 12.57 sec
INFO:root:2024-04-27 00:00:56, Train, Epoch : 7, Step : 3940, Loss : 0.34356, Acc : 0.850, Sensitive_Loss : 0.12067, Sensitive_Acc : 17.000, Run Time : 11.76 sec
INFO:root:2024-04-27 00:01:07, Train, Epoch : 7, Step : 3950, Loss : 0.31382, Acc : 0.884, Sensitive_Loss : 0.11224, Sensitive_Acc : 15.700, Run Time : 11.39 sec
INFO:root:2024-04-27 00:01:20, Train, Epoch : 7, Step : 3960, Loss : 0.39254, Acc : 0.834, Sensitive_Loss : 0.09398, Sensitive_Acc : 16.200, Run Time : 12.59 sec
INFO:root:2024-04-27 00:01:32, Train, Epoch : 7, Step : 3970, Loss : 0.26128, Acc : 0.881, Sensitive_Loss : 0.12575, Sensitive_Acc : 16.500, Run Time : 11.97 sec
INFO:root:2024-04-27 00:01:44, Train, Epoch : 7, Step : 3980, Loss : 0.31723, Acc : 0.856, Sensitive_Loss : 0.08659, Sensitive_Acc : 16.000, Run Time : 11.91 sec
INFO:root:2024-04-27 00:01:55, Train, Epoch : 7, Step : 3990, Loss : 0.30929, Acc : 0.859, Sensitive_Loss : 0.15023, Sensitive_Acc : 14.500, Run Time : 11.56 sec
INFO:root:2024-04-27 00:02:07, Train, Epoch : 7, Step : 4000, Loss : 0.32228, Acc : 0.850, Sensitive_Loss : 0.09217, Sensitive_Acc : 16.000, Run Time : 11.80 sec
INFO:root:2024-04-27 00:04:45, Dev, Step : 4000, Loss : 0.40984, Acc : 0.828, Auc : 0.907, Sensitive_Loss : 0.12174, Sensitive_Acc : 16.950, Sensitive_Auc : 0.983, Mean auc: 0.907, Run Time : 158.21 sec
INFO:root:2024-04-27 00:04:54, Train, Epoch : 7, Step : 4010, Loss : 0.35642, Acc : 0.853, Sensitive_Loss : 0.13683, Sensitive_Acc : 15.200, Run Time : 167.28 sec
INFO:root:2024-04-27 00:05:05, Train, Epoch : 7, Step : 4020, Loss : 0.34094, Acc : 0.863, Sensitive_Loss : 0.09364, Sensitive_Acc : 15.600, Run Time : 11.12 sec
INFO:root:2024-04-27 00:05:18, Train, Epoch : 7, Step : 4030, Loss : 0.34081, Acc : 0.856, Sensitive_Loss : 0.13762, Sensitive_Acc : 16.200, Run Time : 12.43 sec
INFO:root:2024-04-27 00:05:29, Train, Epoch : 7, Step : 4040, Loss : 0.39458, Acc : 0.812, Sensitive_Loss : 0.11144, Sensitive_Acc : 17.600, Run Time : 11.75 sec
INFO:root:2024-04-27 00:05:42, Train, Epoch : 7, Step : 4050, Loss : 0.38864, Acc : 0.831, Sensitive_Loss : 0.09332, Sensitive_Acc : 17.000, Run Time : 12.09 sec
INFO:root:2024-04-27 00:05:54, Train, Epoch : 7, Step : 4060, Loss : 0.29102, Acc : 0.866, Sensitive_Loss : 0.15004, Sensitive_Acc : 16.800, Run Time : 12.30 sec
INFO:root:2024-04-27 00:06:06, Train, Epoch : 7, Step : 4070, Loss : 0.34277, Acc : 0.859, Sensitive_Loss : 0.12561, Sensitive_Acc : 17.800, Run Time : 12.06 sec
INFO:root:2024-04-27 00:06:17, Train, Epoch : 7, Step : 4080, Loss : 0.33356, Acc : 0.834, Sensitive_Loss : 0.12221, Sensitive_Acc : 16.400, Run Time : 11.58 sec
INFO:root:2024-04-27 00:06:30, Train, Epoch : 7, Step : 4090, Loss : 0.30772, Acc : 0.853, Sensitive_Loss : 0.10553, Sensitive_Acc : 14.900, Run Time : 12.24 sec
INFO:root:2024-04-27 00:06:41, Train, Epoch : 7, Step : 4100, Loss : 0.34750, Acc : 0.822, Sensitive_Loss : 0.13092, Sensitive_Acc : 15.500, Run Time : 11.56 sec
INFO:root:2024-04-27 00:09:17, Dev, Step : 4100, Loss : 0.40549, Acc : 0.829, Auc : 0.909, Sensitive_Loss : 0.12016, Sensitive_Acc : 16.964, Sensitive_Auc : 0.987, Mean auc: 0.909, Run Time : 155.99 sec
INFO:root:2024-04-27 00:09:26, Train, Epoch : 7, Step : 4110, Loss : 0.34885, Acc : 0.847, Sensitive_Loss : 0.17277, Sensitive_Acc : 17.300, Run Time : 164.47 sec
INFO:root:2024-04-27 00:09:38, Train, Epoch : 7, Step : 4120, Loss : 0.39771, Acc : 0.831, Sensitive_Loss : 0.11062, Sensitive_Acc : 17.500, Run Time : 12.23 sec
INFO:root:2024-04-27 00:09:50, Train, Epoch : 7, Step : 4130, Loss : 0.34960, Acc : 0.844, Sensitive_Loss : 0.12597, Sensitive_Acc : 17.400, Run Time : 12.07 sec
INFO:root:2024-04-27 00:10:02, Train, Epoch : 7, Step : 4140, Loss : 0.25811, Acc : 0.894, Sensitive_Loss : 0.08959, Sensitive_Acc : 16.800, Run Time : 12.10 sec
INFO:root:2024-04-27 00:10:13, Train, Epoch : 7, Step : 4150, Loss : 0.34097, Acc : 0.856, Sensitive_Loss : 0.09733, Sensitive_Acc : 16.700, Run Time : 11.26 sec
INFO:root:2024-04-27 00:10:25, Train, Epoch : 7, Step : 4160, Loss : 0.32332, Acc : 0.850, Sensitive_Loss : 0.10947, Sensitive_Acc : 14.200, Run Time : 11.87 sec
INFO:root:2024-04-27 00:10:37, Train, Epoch : 7, Step : 4170, Loss : 0.34295, Acc : 0.847, Sensitive_Loss : 0.10283, Sensitive_Acc : 15.700, Run Time : 11.79 sec
INFO:root:2024-04-27 00:10:49, Train, Epoch : 7, Step : 4180, Loss : 0.29364, Acc : 0.887, Sensitive_Loss : 0.09821, Sensitive_Acc : 15.900, Run Time : 12.02 sec
INFO:root:2024-04-27 00:11:01, Train, Epoch : 7, Step : 4190, Loss : 0.33001, Acc : 0.875, Sensitive_Loss : 0.11541, Sensitive_Acc : 16.200, Run Time : 11.74 sec
INFO:root:2024-04-27 00:11:13, Train, Epoch : 7, Step : 4200, Loss : 0.39837, Acc : 0.822, Sensitive_Loss : 0.12329, Sensitive_Acc : 16.900, Run Time : 11.74 sec
INFO:root:2024-04-27 00:13:50, Dev, Step : 4200, Loss : 0.40664, Acc : 0.830, Auc : 0.908, Sensitive_Loss : 0.13330, Sensitive_Acc : 16.950, Sensitive_Auc : 0.986, Mean auc: 0.908, Run Time : 157.33 sec
INFO:root:2024-04-27 00:13:59, Train, Epoch : 7, Step : 4210, Loss : 0.34770, Acc : 0.850, Sensitive_Loss : 0.12589, Sensitive_Acc : 15.100, Run Time : 165.94 sec
INFO:root:2024-04-27 00:14:11, Train, Epoch : 7, Step : 4220, Loss : 0.28398, Acc : 0.863, Sensitive_Loss : 0.14933, Sensitive_Acc : 16.000, Run Time : 12.20 sec
INFO:root:2024-04-27 00:14:23, Train, Epoch : 7, Step : 4230, Loss : 0.32499, Acc : 0.850, Sensitive_Loss : 0.14083, Sensitive_Acc : 15.400, Run Time : 12.37 sec
INFO:root:2024-04-27 00:14:34, Train, Epoch : 7, Step : 4240, Loss : 0.28873, Acc : 0.881, Sensitive_Loss : 0.09207, Sensitive_Acc : 16.200, Run Time : 11.40 sec
INFO:root:2024-04-27 00:14:46, Train, Epoch : 7, Step : 4250, Loss : 0.30535, Acc : 0.869, Sensitive_Loss : 0.11343, Sensitive_Acc : 16.700, Run Time : 11.40 sec
INFO:root:2024-04-27 00:14:58, Train, Epoch : 7, Step : 4260, Loss : 0.30700, Acc : 0.856, Sensitive_Loss : 0.16422, Sensitive_Acc : 17.200, Run Time : 12.16 sec
INFO:root:2024-04-27 00:15:10, Train, Epoch : 7, Step : 4270, Loss : 0.31534, Acc : 0.834, Sensitive_Loss : 0.12338, Sensitive_Acc : 15.000, Run Time : 12.31 sec
INFO:root:2024-04-27 00:15:22, Train, Epoch : 7, Step : 4280, Loss : 0.38552, Acc : 0.831, Sensitive_Loss : 0.14726, Sensitive_Acc : 17.700, Run Time : 12.11 sec
INFO:root:2024-04-27 00:15:34, Train, Epoch : 7, Step : 4290, Loss : 0.29402, Acc : 0.869, Sensitive_Loss : 0.12379, Sensitive_Acc : 17.000, Run Time : 11.98 sec
INFO:root:2024-04-27 00:15:46, Train, Epoch : 7, Step : 4300, Loss : 0.37393, Acc : 0.850, Sensitive_Loss : 0.10105, Sensitive_Acc : 18.200, Run Time : 11.38 sec
INFO:root:2024-04-27 00:18:23, Dev, Step : 4300, Loss : 0.40237, Acc : 0.829, Auc : 0.906, Sensitive_Loss : 0.11825, Sensitive_Acc : 16.893, Sensitive_Auc : 0.987, Mean auc: 0.906, Run Time : 157.35 sec
INFO:root:2024-04-27 00:18:32, Train, Epoch : 7, Step : 4310, Loss : 0.29553, Acc : 0.875, Sensitive_Loss : 0.09395, Sensitive_Acc : 17.400, Run Time : 166.04 sec
INFO:root:2024-04-27 00:18:44, Train, Epoch : 7, Step : 4320, Loss : 0.36298, Acc : 0.822, Sensitive_Loss : 0.10571, Sensitive_Acc : 17.400, Run Time : 12.16 sec
INFO:root:2024-04-27 00:18:55, Train, Epoch : 7, Step : 4330, Loss : 0.39504, Acc : 0.850, Sensitive_Loss : 0.12003, Sensitive_Acc : 17.500, Run Time : 11.15 sec
INFO:root:2024-04-27 00:19:07, Train, Epoch : 7, Step : 4340, Loss : 0.34631, Acc : 0.853, Sensitive_Loss : 0.09990, Sensitive_Acc : 14.900, Run Time : 11.81 sec
INFO:root:2024-04-27 00:19:19, Train, Epoch : 7, Step : 4350, Loss : 0.37037, Acc : 0.841, Sensitive_Loss : 0.11406, Sensitive_Acc : 15.900, Run Time : 12.14 sec
INFO:root:2024-04-27 00:19:31, Train, Epoch : 7, Step : 4360, Loss : 0.31955, Acc : 0.872, Sensitive_Loss : 0.09594, Sensitive_Acc : 16.000, Run Time : 11.87 sec
INFO:root:2024-04-27 00:19:43, Train, Epoch : 7, Step : 4370, Loss : 0.31908, Acc : 0.844, Sensitive_Loss : 0.11649, Sensitive_Acc : 16.300, Run Time : 12.45 sec
INFO:root:2024-04-27 00:19:55, Train, Epoch : 7, Step : 4380, Loss : 0.26317, Acc : 0.872, Sensitive_Loss : 0.14686, Sensitive_Acc : 16.200, Run Time : 11.36 sec
INFO:root:2024-04-27 00:22:30
INFO:root:y_pred: [0.14675662 0.9682008  0.01641964 ... 0.8470042  0.01312871 0.87547886]
INFO:root:y_true: [0. 1. 0. ... 1. 0. 1.]
INFO:root:sensitive_y_pred: [9.81857896e-01 4.79429389e-07 1.02388076e-02 3.08357819e-08
 9.96979356e-01 1.39920315e-08 9.91538465e-01 9.77739155e-01
 2.20333133e-02 4.66471791e-01 9.95535970e-01 9.99356210e-01
 9.92882133e-01 8.67094100e-01 2.85574138e-01 9.59984243e-01
 9.98613834e-01 5.65198436e-03 5.46600893e-02 9.97432172e-01
 9.86298501e-01 2.12129601e-03 9.98634636e-01 8.00101817e-01
 9.92172718e-01 9.35128748e-01 2.41245682e-04 9.90445137e-01
 9.02531385e-01 8.68064404e-01 9.34641063e-03 5.43203428e-02
 1.85911432e-02 1.34537108e-02 6.43292665e-02 6.72974875e-06
 2.09322125e-02 1.63467426e-03 9.94320750e-01 9.78272021e-01
 2.59319094e-10 1.18068037e-05 9.96098161e-01 2.18302384e-03
 9.98446882e-01 9.89000678e-01 9.16634560e-01 9.95574951e-01
 1.34765897e-02 9.81376290e-01 9.96779501e-01 9.65433865e-05
 9.38937008e-01 2.62144837e-03 8.94843240e-08 5.39553330e-05
 1.13704316e-01 1.92315674e-05 9.59426325e-06 3.23336144e-06
 4.56707385e-05 1.72032844e-02 6.22155127e-09 9.96186078e-01
 1.27988845e-01 9.95050251e-01 2.77001284e-08 9.89555776e-01
 9.08765197e-01 5.04328907e-01 7.14835346e-01 5.80457509e-01
 1.60699827e-03 1.75693743e-02 2.26519027e-04 2.26995465e-03
 3.57005075e-02 1.23037383e-01 4.13771631e-05 9.94950175e-01
 9.95910764e-01 2.75742677e-05 4.57626730e-01 5.41127993e-05
 9.71082211e-01 9.46559727e-01 1.28523782e-01 1.88374389e-02
 9.71919060e-01 9.79735255e-01 9.95490134e-01 1.33619842e-03
 1.82198174e-03 9.92718458e-01 1.63682953e-01 3.01488349e-03
 9.93922353e-01 9.87960219e-01 2.63810529e-10 4.09260509e-04
 9.54883635e-01 9.49901223e-01 9.97913897e-01 9.96616304e-01
 9.92542336e-05 1.66261219e-04 6.90549254e-01 9.12246048e-01
 9.55698133e-01 6.01497322e-06 7.94015586e-01 9.96603727e-01
 1.19368499e-02 9.97345746e-01 9.05685544e-01 9.84442651e-01
 9.11574066e-01 9.95898426e-01 1.17392451e-01 3.56574208e-01
 9.96728539e-01 9.93283510e-01 9.34251898e-10 9.40378606e-01
 9.91469562e-01 1.16726216e-02 9.86360192e-01 6.35002099e-04
 1.02994796e-02 9.89994586e-01 9.94766951e-01 2.21443997e-06
 1.23219856e-04 8.04704687e-05 9.80141759e-01 9.99234200e-01
 9.55034137e-01 3.44830478e-04 3.91392335e-02 9.78355050e-01]
INFO:root:sensitive_y_true: [1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.
 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.]
INFO:root:2024-04-27 00:22:30, Dev, Step : 4382, Loss : 0.41973, Acc : 0.823, Auc : 0.907, Sensitive_Loss : 0.13258, Sensitive_Acc : 16.921, Sensitive_Auc : 0.986, Mean auc: 0.907, Run Time : 153.20 sec
INFO:root:2024-04-27 00:22:42, Train, Epoch : 8, Step : 4390, Loss : 0.20529, Acc : 0.722, Sensitive_Loss : 0.09368, Sensitive_Acc : 12.900, Run Time : 11.00 sec
INFO:root:2024-04-27 00:22:54, Train, Epoch : 8, Step : 4400, Loss : 0.30204, Acc : 0.875, Sensitive_Loss : 0.11560, Sensitive_Acc : 16.000, Run Time : 12.02 sec
INFO:root:2024-04-27 00:26:08, Dev, Step : 4400, Loss : 0.40438, Acc : 0.830, Auc : 0.908, Sensitive_Loss : 0.12011, Sensitive_Acc : 16.950, Sensitive_Auc : 0.990, Mean auc: 0.908, Run Time : 193.74 sec
INFO:root:2024-04-27 00:26:17, Train, Epoch : 8, Step : 4410, Loss : 0.32373, Acc : 0.872, Sensitive_Loss : 0.11701, Sensitive_Acc : 16.100, Run Time : 202.92 sec
INFO:root:2024-04-27 00:26:29, Train, Epoch : 8, Step : 4420, Loss : 0.36541, Acc : 0.859, Sensitive_Loss : 0.11689, Sensitive_Acc : 17.000, Run Time : 11.59 sec
INFO:root:2024-04-27 00:26:41, Train, Epoch : 8, Step : 4430, Loss : 0.29747, Acc : 0.856, Sensitive_Loss : 0.09692, Sensitive_Acc : 16.900, Run Time : 12.06 sec
INFO:root:2024-04-27 00:26:52, Train, Epoch : 8, Step : 4440, Loss : 0.31420, Acc : 0.863, Sensitive_Loss : 0.08158, Sensitive_Acc : 17.400, Run Time : 11.32 sec
INFO:root:2024-04-27 00:27:12, Train, Epoch : 8, Step : 4450, Loss : 0.32294, Acc : 0.844, Sensitive_Loss : 0.12083, Sensitive_Acc : 16.000, Run Time : 19.82 sec
INFO:root:2024-04-27 00:27:23, Train, Epoch : 8, Step : 4460, Loss : 0.32710, Acc : 0.856, Sensitive_Loss : 0.12883, Sensitive_Acc : 16.900, Run Time : 11.18 sec
INFO:root:2024-04-27 00:27:35, Train, Epoch : 8, Step : 4470, Loss : 0.32268, Acc : 0.884, Sensitive_Loss : 0.09166, Sensitive_Acc : 16.900, Run Time : 12.14 sec
INFO:root:2024-04-27 00:27:48, Train, Epoch : 8, Step : 4480, Loss : 0.31342, Acc : 0.853, Sensitive_Loss : 0.12203, Sensitive_Acc : 16.900, Run Time : 12.28 sec
INFO:root:2024-04-27 00:27:59, Train, Epoch : 8, Step : 4490, Loss : 0.32305, Acc : 0.853, Sensitive_Loss : 0.11101, Sensitive_Acc : 16.500, Run Time : 11.59 sec
INFO:root:2024-04-27 00:28:12, Train, Epoch : 8, Step : 4500, Loss : 0.30606, Acc : 0.887, Sensitive_Loss : 0.07735, Sensitive_Acc : 17.000, Run Time : 12.45 sec
INFO:root:2024-04-27 00:30:48, Dev, Step : 4500, Loss : 0.42081, Acc : 0.822, Auc : 0.907, Sensitive_Loss : 0.12368, Sensitive_Acc : 16.950, Sensitive_Auc : 0.985, Mean auc: 0.907, Run Time : 155.75 sec
INFO:root:2024-04-27 00:30:56, Train, Epoch : 8, Step : 4510, Loss : 0.29557, Acc : 0.878, Sensitive_Loss : 0.10921, Sensitive_Acc : 16.400, Run Time : 164.53 sec
INFO:root:2024-04-27 00:31:08, Train, Epoch : 8, Step : 4520, Loss : 0.26777, Acc : 0.881, Sensitive_Loss : 0.08637, Sensitive_Acc : 15.900, Run Time : 11.88 sec
INFO:root:2024-04-27 00:31:20, Train, Epoch : 8, Step : 4530, Loss : 0.35649, Acc : 0.822, Sensitive_Loss : 0.09681, Sensitive_Acc : 17.200, Run Time : 12.08 sec
INFO:root:2024-04-27 00:31:32, Train, Epoch : 8, Step : 4540, Loss : 0.34805, Acc : 0.847, Sensitive_Loss : 0.13855, Sensitive_Acc : 17.300, Run Time : 12.19 sec
INFO:root:2024-04-27 00:31:45, Train, Epoch : 8, Step : 4550, Loss : 0.30147, Acc : 0.863, Sensitive_Loss : 0.13528, Sensitive_Acc : 15.600, Run Time : 12.47 sec
INFO:root:2024-04-27 00:31:57, Train, Epoch : 8, Step : 4560, Loss : 0.24481, Acc : 0.897, Sensitive_Loss : 0.10952, Sensitive_Acc : 17.700, Run Time : 12.23 sec
INFO:root:2024-04-27 00:32:09, Train, Epoch : 8, Step : 4570, Loss : 0.35520, Acc : 0.844, Sensitive_Loss : 0.11814, Sensitive_Acc : 17.200, Run Time : 11.93 sec
INFO:root:2024-04-27 00:32:21, Train, Epoch : 8, Step : 4580, Loss : 0.33367, Acc : 0.869, Sensitive_Loss : 0.11684, Sensitive_Acc : 15.400, Run Time : 11.63 sec
INFO:root:2024-04-27 00:32:33, Train, Epoch : 8, Step : 4590, Loss : 0.29689, Acc : 0.850, Sensitive_Loss : 0.14984, Sensitive_Acc : 14.500, Run Time : 12.16 sec
INFO:root:2024-04-27 00:32:45, Train, Epoch : 8, Step : 4600, Loss : 0.35060, Acc : 0.875, Sensitive_Loss : 0.12611, Sensitive_Acc : 17.300, Run Time : 11.98 sec
INFO:root:2024-04-27 00:35:21, Dev, Step : 4600, Loss : 0.44768, Acc : 0.818, Auc : 0.905, Sensitive_Loss : 0.13138, Sensitive_Acc : 16.907, Sensitive_Auc : 0.982, Mean auc: 0.905, Run Time : 156.14 sec
INFO:root:2024-04-27 00:35:30, Train, Epoch : 8, Step : 4610, Loss : 0.28858, Acc : 0.887, Sensitive_Loss : 0.14216, Sensitive_Acc : 17.100, Run Time : 165.50 sec
INFO:root:2024-04-27 00:35:42, Train, Epoch : 8, Step : 4620, Loss : 0.29536, Acc : 0.847, Sensitive_Loss : 0.12009, Sensitive_Acc : 17.600, Run Time : 11.49 sec
INFO:root:2024-04-27 00:35:54, Train, Epoch : 8, Step : 4630, Loss : 0.34550, Acc : 0.844, Sensitive_Loss : 0.07183, Sensitive_Acc : 17.000, Run Time : 12.08 sec
INFO:root:2024-04-27 00:36:07, Train, Epoch : 8, Step : 4640, Loss : 0.36438, Acc : 0.838, Sensitive_Loss : 0.12128, Sensitive_Acc : 17.200, Run Time : 12.85 sec
INFO:root:2024-04-27 00:36:19, Train, Epoch : 8, Step : 4650, Loss : 0.30355, Acc : 0.866, Sensitive_Loss : 0.08988, Sensitive_Acc : 16.900, Run Time : 11.93 sec
INFO:root:2024-04-27 00:36:30, Train, Epoch : 8, Step : 4660, Loss : 0.35776, Acc : 0.850, Sensitive_Loss : 0.10994, Sensitive_Acc : 15.300, Run Time : 11.60 sec
INFO:root:2024-04-27 00:36:43, Train, Epoch : 8, Step : 4670, Loss : 0.31083, Acc : 0.869, Sensitive_Loss : 0.11743, Sensitive_Acc : 16.000, Run Time : 12.19 sec
INFO:root:2024-04-27 00:36:55, Train, Epoch : 8, Step : 4680, Loss : 0.33378, Acc : 0.847, Sensitive_Loss : 0.16096, Sensitive_Acc : 15.500, Run Time : 12.24 sec
INFO:root:2024-04-27 00:37:07, Train, Epoch : 8, Step : 4690, Loss : 0.33101, Acc : 0.856, Sensitive_Loss : 0.09441, Sensitive_Acc : 16.300, Run Time : 12.44 sec
INFO:root:2024-04-27 00:37:19, Train, Epoch : 8, Step : 4700, Loss : 0.28128, Acc : 0.884, Sensitive_Loss : 0.06999, Sensitive_Acc : 15.100, Run Time : 12.23 sec
INFO:root:2024-04-27 00:39:56, Dev, Step : 4700, Loss : 0.44012, Acc : 0.815, Auc : 0.905, Sensitive_Loss : 0.12685, Sensitive_Acc : 16.879, Sensitive_Auc : 0.987, Mean auc: 0.905, Run Time : 156.50 sec
INFO:root:2024-04-27 00:40:04, Train, Epoch : 8, Step : 4710, Loss : 0.27108, Acc : 0.887, Sensitive_Loss : 0.08344, Sensitive_Acc : 16.800, Run Time : 164.93 sec
INFO:root:2024-04-27 00:40:17, Train, Epoch : 8, Step : 4720, Loss : 0.28965, Acc : 0.872, Sensitive_Loss : 0.09381, Sensitive_Acc : 16.000, Run Time : 12.58 sec
INFO:root:2024-04-27 00:40:29, Train, Epoch : 8, Step : 4730, Loss : 0.25468, Acc : 0.878, Sensitive_Loss : 0.10313, Sensitive_Acc : 17.200, Run Time : 11.96 sec
INFO:root:2024-04-27 00:40:41, Train, Epoch : 8, Step : 4740, Loss : 0.29038, Acc : 0.866, Sensitive_Loss : 0.11187, Sensitive_Acc : 15.700, Run Time : 11.93 sec
INFO:root:2024-04-27 00:40:53, Train, Epoch : 8, Step : 4750, Loss : 0.33720, Acc : 0.856, Sensitive_Loss : 0.10669, Sensitive_Acc : 16.800, Run Time : 12.19 sec
INFO:root:2024-04-27 00:41:05, Train, Epoch : 8, Step : 4760, Loss : 0.32300, Acc : 0.847, Sensitive_Loss : 0.08077, Sensitive_Acc : 16.000, Run Time : 12.10 sec
INFO:root:2024-04-27 00:41:18, Train, Epoch : 8, Step : 4770, Loss : 0.33808, Acc : 0.856, Sensitive_Loss : 0.13124, Sensitive_Acc : 16.000, Run Time : 12.38 sec
INFO:root:2024-04-27 00:41:30, Train, Epoch : 8, Step : 4780, Loss : 0.37648, Acc : 0.831, Sensitive_Loss : 0.09377, Sensitive_Acc : 16.300, Run Time : 12.25 sec
INFO:root:2024-04-27 00:41:42, Train, Epoch : 8, Step : 4790, Loss : 0.35869, Acc : 0.856, Sensitive_Loss : 0.13184, Sensitive_Acc : 17.000, Run Time : 11.81 sec
INFO:root:2024-04-27 00:41:54, Train, Epoch : 8, Step : 4800, Loss : 0.34039, Acc : 0.853, Sensitive_Loss : 0.07241, Sensitive_Acc : 17.200, Run Time : 12.05 sec
INFO:root:2024-04-27 00:44:30, Dev, Step : 4800, Loss : 0.43520, Acc : 0.816, Auc : 0.907, Sensitive_Loss : 0.11529, Sensitive_Acc : 16.850, Sensitive_Auc : 0.992, Mean auc: 0.907, Run Time : 156.55 sec
INFO:root:2024-04-27 00:44:39, Train, Epoch : 8, Step : 4810, Loss : 0.26121, Acc : 0.884, Sensitive_Loss : 0.08817, Sensitive_Acc : 16.200, Run Time : 164.98 sec
INFO:root:2024-04-27 00:44:50, Train, Epoch : 8, Step : 4820, Loss : 0.31108, Acc : 0.866, Sensitive_Loss : 0.08365, Sensitive_Acc : 15.600, Run Time : 11.80 sec
INFO:root:2024-04-27 00:45:03, Train, Epoch : 8, Step : 4830, Loss : 0.29868, Acc : 0.891, Sensitive_Loss : 0.08109, Sensitive_Acc : 16.300, Run Time : 12.31 sec
INFO:root:2024-04-27 00:45:15, Train, Epoch : 8, Step : 4840, Loss : 0.32842, Acc : 0.850, Sensitive_Loss : 0.12728, Sensitive_Acc : 16.900, Run Time : 12.23 sec
INFO:root:2024-04-27 00:45:27, Train, Epoch : 8, Step : 4850, Loss : 0.31418, Acc : 0.834, Sensitive_Loss : 0.08912, Sensitive_Acc : 16.200, Run Time : 11.82 sec
INFO:root:2024-04-27 00:45:39, Train, Epoch : 8, Step : 4860, Loss : 0.28760, Acc : 0.878, Sensitive_Loss : 0.12206, Sensitive_Acc : 16.300, Run Time : 12.37 sec
INFO:root:2024-04-27 00:45:51, Train, Epoch : 8, Step : 4870, Loss : 0.30548, Acc : 0.884, Sensitive_Loss : 0.10823, Sensitive_Acc : 17.400, Run Time : 11.63 sec
INFO:root:2024-04-27 00:46:02, Train, Epoch : 8, Step : 4880, Loss : 0.34707, Acc : 0.831, Sensitive_Loss : 0.07445, Sensitive_Acc : 17.300, Run Time : 11.30 sec
INFO:root:2024-04-27 00:46:14, Train, Epoch : 8, Step : 4890, Loss : 0.29416, Acc : 0.881, Sensitive_Loss : 0.07001, Sensitive_Acc : 15.500, Run Time : 12.03 sec
INFO:root:2024-04-27 00:46:26, Train, Epoch : 8, Step : 4900, Loss : 0.28267, Acc : 0.872, Sensitive_Loss : 0.10533, Sensitive_Acc : 15.900, Run Time : 12.00 sec
INFO:root:2024-04-27 00:49:02, Dev, Step : 4900, Loss : 0.43470, Acc : 0.820, Auc : 0.906, Sensitive_Loss : 0.11559, Sensitive_Acc : 16.907, Sensitive_Auc : 0.993, Mean auc: 0.906, Run Time : 156.02 sec
INFO:root:2024-04-27 00:49:10, Train, Epoch : 8, Step : 4910, Loss : 0.38939, Acc : 0.831, Sensitive_Loss : 0.07887, Sensitive_Acc : 15.100, Run Time : 164.36 sec
INFO:root:2024-04-27 00:49:23, Train, Epoch : 8, Step : 4920, Loss : 0.28484, Acc : 0.875, Sensitive_Loss : 0.22650, Sensitive_Acc : 17.100, Run Time : 12.48 sec
INFO:root:2024-04-27 00:49:34, Train, Epoch : 8, Step : 4930, Loss : 0.29860, Acc : 0.878, Sensitive_Loss : 0.09595, Sensitive_Acc : 16.100, Run Time : 11.26 sec
INFO:root:2024-04-27 00:49:46, Train, Epoch : 8, Step : 4940, Loss : 0.31863, Acc : 0.881, Sensitive_Loss : 0.10077, Sensitive_Acc : 17.100, Run Time : 12.03 sec
INFO:root:2024-04-27 00:49:58, Train, Epoch : 8, Step : 4950, Loss : 0.26703, Acc : 0.869, Sensitive_Loss : 0.18113, Sensitive_Acc : 17.900, Run Time : 12.18 sec
INFO:root:2024-04-27 00:50:10, Train, Epoch : 8, Step : 4960, Loss : 0.30126, Acc : 0.859, Sensitive_Loss : 0.08629, Sensitive_Acc : 16.600, Run Time : 11.71 sec
INFO:root:2024-04-27 00:50:22, Train, Epoch : 8, Step : 4970, Loss : 0.31832, Acc : 0.850, Sensitive_Loss : 0.12526, Sensitive_Acc : 15.800, Run Time : 12.05 sec
INFO:root:2024-04-27 00:50:34, Train, Epoch : 8, Step : 4980, Loss : 0.30471, Acc : 0.872, Sensitive_Loss : 0.11510, Sensitive_Acc : 15.900, Run Time : 11.88 sec
INFO:root:2024-04-27 00:50:46, Train, Epoch : 8, Step : 4990, Loss : 0.25995, Acc : 0.881, Sensitive_Loss : 0.10795, Sensitive_Acc : 14.800, Run Time : 11.52 sec
INFO:root:2024-04-27 00:50:57, Train, Epoch : 8, Step : 5000, Loss : 0.35338, Acc : 0.850, Sensitive_Loss : 0.09626, Sensitive_Acc : 18.500, Run Time : 11.73 sec
INFO:root:2024-04-27 00:53:34, Dev, Step : 5000, Loss : 0.41683, Acc : 0.829, Auc : 0.910, Sensitive_Loss : 0.11222, Sensitive_Acc : 16.907, Sensitive_Auc : 0.994, Mean auc: 0.910, Run Time : 156.81 sec
INFO:root:2024-04-27 00:53:35, Best, Step : 5000, Loss : 0.41683, Acc : 0.829, Auc : 0.910, Sensitive_Loss : 0.11222, Sensitive_Acc : 16.907, Sensitive_Auc : 0.994, Best Auc : 0.910
INFO:root:2024-04-27 00:56:15
INFO:root:y_pred: [0.18078738 0.9621652  0.03131544 ... 0.80140144 0.01362615 0.87959343]
INFO:root:y_true: [0. 1. 0. ... 1. 0. 1.]
INFO:root:sensitive_y_pred: [9.7816485e-01 3.9977189e-07 2.6999522e-02 1.8502473e-07 9.9673623e-01
 6.7797103e-08 9.9325472e-01 9.8128444e-01 1.6623793e-02 6.4236939e-01
 9.9499846e-01 9.9918646e-01 9.9418288e-01 9.0376407e-01 3.2762522e-01
 9.1159850e-01 9.9869603e-01 3.8218198e-03 3.8561728e-02 9.9774963e-01
 9.9549758e-01 5.4495240e-04 9.9898189e-01 9.1164261e-01 9.9409086e-01
 9.2676300e-01 9.0685833e-05 9.9401784e-01 9.4705200e-01 8.5861003e-01
 1.2758557e-02 4.0635052e-03 2.2425724e-03 1.2971992e-02 4.0088974e-02
 5.4634461e-07 8.8932075e-02 1.7241177e-03 9.9424732e-01 9.7826344e-01
 1.0380314e-13 4.7453850e-06 9.9523866e-01 2.5907294e-03 9.9850696e-01
 9.7789967e-01 9.2014486e-01 9.9435115e-01 8.2500689e-03 9.7764194e-01
 9.9685246e-01 4.4558931e-04 8.1719875e-01 1.4958929e-04 1.1528772e-07
 1.0693896e-03 7.0379682e-02 4.5625162e-05 5.6564554e-06 2.6567668e-07
 2.5855914e-05 1.4018389e-02 4.0370693e-08 9.9518138e-01 2.0351246e-01
 9.9530447e-01 2.4663788e-07 9.9061769e-01 9.0155810e-01 3.1627351e-01
 7.5969112e-01 1.8622431e-01 2.6391803e-03 2.0874238e-02 1.9270701e-04
 2.6145442e-03 3.7584420e-02 1.9595151e-01 7.5728283e-05 9.9508971e-01
 9.9578434e-01 6.2155494e-05 1.5044384e-01 4.8876100e-05 8.3483082e-01
 9.6318108e-01 2.1192321e-01 1.4387752e-02 9.6482885e-01 9.7935265e-01
 9.9665987e-01 2.1225370e-03 1.5697254e-02 9.9332631e-01 5.6669094e-02
 2.2267797e-03 9.9389762e-01 9.7860146e-01 7.3101386e-10 7.4007264e-03
 9.6865392e-01 9.5707357e-01 9.9679595e-01 9.9538112e-01 4.7401514e-05
 1.9096145e-05 7.0997030e-01 9.3142134e-01 9.5061326e-01 1.6423626e-06
 8.2478553e-01 9.9653912e-01 1.7696178e-02 9.9766302e-01 9.3069088e-01
 9.8582423e-01 8.8356262e-01 9.9519253e-01 7.7104598e-02 1.4534320e-01
 9.9692172e-01 9.9464297e-01 3.1746468e-09 9.3411857e-01 9.9097532e-01
 3.4093035e-03 9.9216706e-01 4.5980504e-04 3.6268320e-03 9.8297530e-01
 9.9638546e-01 2.6534610e-05 1.1575307e-05 2.6764660e-04 9.8093581e-01
 9.9886823e-01 9.6956527e-01 2.3000939e-03 2.4890823e-02 9.8597175e-01]
INFO:root:sensitive_y_true: [1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.
 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.]
INFO:root:2024-04-27 00:56:15, Dev, Step : 5008, Loss : 0.41290, Acc : 0.829, Auc : 0.910, Sensitive_Loss : 0.11505, Sensitive_Acc : 16.907, Sensitive_Auc : 0.993, Mean auc: 0.910, Run Time : 153.98 sec
INFO:root:2024-04-27 00:56:16, Best, Step : 5008, Loss : 0.41290, Acc : 0.829,Auc : 0.910, Best Auc : 0.910, Sensitive_Loss : 0.11505, Sensitive_Acc : 16.907, Sensitive_Auc : 0.993
INFO:root:2024-04-27 00:56:21, Train, Epoch : 9, Step : 5010, Loss : 0.04224, Acc : 0.178, Sensitive_Loss : 0.01083, Sensitive_Acc : 3.500, Run Time : 4.20 sec
INFO:root:2024-04-27 00:56:32, Train, Epoch : 9, Step : 5020, Loss : 0.37226, Acc : 0.859, Sensitive_Loss : 0.10759, Sensitive_Acc : 16.000, Run Time : 10.90 sec
INFO:root:2024-04-27 00:56:44, Train, Epoch : 9, Step : 5030, Loss : 0.28511, Acc : 0.887, Sensitive_Loss : 0.10216, Sensitive_Acc : 16.600, Run Time : 12.00 sec
INFO:root:2024-04-27 00:56:56, Train, Epoch : 9, Step : 5040, Loss : 0.25892, Acc : 0.894, Sensitive_Loss : 0.08945, Sensitive_Acc : 15.500, Run Time : 11.98 sec
INFO:root:2024-04-27 00:57:08, Train, Epoch : 9, Step : 5050, Loss : 0.33435, Acc : 0.850, Sensitive_Loss : 0.14379, Sensitive_Acc : 15.800, Run Time : 11.37 sec
INFO:root:2024-04-27 00:57:19, Train, Epoch : 9, Step : 5060, Loss : 0.28303, Acc : 0.881, Sensitive_Loss : 0.12146, Sensitive_Acc : 16.300, Run Time : 11.45 sec
INFO:root:2024-04-27 00:57:31, Train, Epoch : 9, Step : 5070, Loss : 0.31726, Acc : 0.887, Sensitive_Loss : 0.07105, Sensitive_Acc : 17.100, Run Time : 11.53 sec
INFO:root:2024-04-27 00:57:43, Train, Epoch : 9, Step : 5080, Loss : 0.30131, Acc : 0.903, Sensitive_Loss : 0.12984, Sensitive_Acc : 15.400, Run Time : 12.19 sec
INFO:root:2024-04-27 00:57:54, Train, Epoch : 9, Step : 5090, Loss : 0.25914, Acc : 0.866, Sensitive_Loss : 0.09463, Sensitive_Acc : 15.800, Run Time : 11.44 sec
INFO:root:2024-04-27 00:58:06, Train, Epoch : 9, Step : 5100, Loss : 0.22341, Acc : 0.919, Sensitive_Loss : 0.10297, Sensitive_Acc : 16.000, Run Time : 11.58 sec
INFO:root:2024-04-27 01:00:41, Dev, Step : 5100, Loss : 0.43661, Acc : 0.821, Auc : 0.907, Sensitive_Loss : 0.11999, Sensitive_Acc : 16.907, Sensitive_Auc : 0.989, Mean auc: 0.907, Run Time : 155.67 sec
INFO:root:2024-04-27 01:00:50, Train, Epoch : 9, Step : 5110, Loss : 0.32714, Acc : 0.881, Sensitive_Loss : 0.07799, Sensitive_Acc : 14.500, Run Time : 164.29 sec
INFO:root:2024-04-27 01:01:03, Train, Epoch : 9, Step : 5120, Loss : 0.30614, Acc : 0.872, Sensitive_Loss : 0.09922, Sensitive_Acc : 16.800, Run Time : 13.07 sec
INFO:root:2024-04-27 01:01:15, Train, Epoch : 9, Step : 5130, Loss : 0.33669, Acc : 0.847, Sensitive_Loss : 0.13431, Sensitive_Acc : 16.100, Run Time : 11.40 sec
INFO:root:2024-04-27 01:01:27, Train, Epoch : 9, Step : 5140, Loss : 0.34693, Acc : 0.859, Sensitive_Loss : 0.07307, Sensitive_Acc : 16.600, Run Time : 12.28 sec
INFO:root:2024-04-27 01:01:39, Train, Epoch : 9, Step : 5150, Loss : 0.29399, Acc : 0.897, Sensitive_Loss : 0.11499, Sensitive_Acc : 16.000, Run Time : 12.09 sec
INFO:root:2024-04-27 01:01:51, Train, Epoch : 9, Step : 5160, Loss : 0.26920, Acc : 0.856, Sensitive_Loss : 0.09197, Sensitive_Acc : 14.800, Run Time : 12.25 sec
INFO:root:2024-04-27 01:02:03, Train, Epoch : 9, Step : 5170, Loss : 0.26409, Acc : 0.859, Sensitive_Loss : 0.14761, Sensitive_Acc : 15.800, Run Time : 11.63 sec
INFO:root:2024-04-27 01:02:15, Train, Epoch : 9, Step : 5180, Loss : 0.37651, Acc : 0.847, Sensitive_Loss : 0.12103, Sensitive_Acc : 16.000, Run Time : 12.61 sec
INFO:root:2024-04-27 01:02:27, Train, Epoch : 9, Step : 5190, Loss : 0.27123, Acc : 0.878, Sensitive_Loss : 0.13720, Sensitive_Acc : 16.900, Run Time : 11.76 sec
INFO:root:2024-04-27 01:02:39, Train, Epoch : 9, Step : 5200, Loss : 0.28855, Acc : 0.875, Sensitive_Loss : 0.14020, Sensitive_Acc : 16.700, Run Time : 11.72 sec
INFO:root:2024-04-27 01:05:16, Dev, Step : 5200, Loss : 0.42735, Acc : 0.820, Auc : 0.905, Sensitive_Loss : 0.13358, Sensitive_Acc : 16.964, Sensitive_Auc : 0.985, Mean auc: 0.905, Run Time : 156.84 sec
INFO:root:2024-04-27 01:05:24, Train, Epoch : 9, Step : 5210, Loss : 0.25738, Acc : 0.887, Sensitive_Loss : 0.10999, Sensitive_Acc : 15.100, Run Time : 165.37 sec
INFO:root:2024-04-27 01:05:36, Train, Epoch : 9, Step : 5220, Loss : 0.29514, Acc : 0.866, Sensitive_Loss : 0.10335, Sensitive_Acc : 18.400, Run Time : 11.82 sec
INFO:root:2024-04-27 01:05:48, Train, Epoch : 9, Step : 5230, Loss : 0.32480, Acc : 0.875, Sensitive_Loss : 0.07304, Sensitive_Acc : 15.700, Run Time : 12.09 sec
INFO:root:2024-04-27 01:06:00, Train, Epoch : 9, Step : 5240, Loss : 0.29847, Acc : 0.838, Sensitive_Loss : 0.11522, Sensitive_Acc : 16.100, Run Time : 12.07 sec
INFO:root:2024-04-27 01:06:12, Train, Epoch : 9, Step : 5250, Loss : 0.30232, Acc : 0.878, Sensitive_Loss : 0.06752, Sensitive_Acc : 16.800, Run Time : 12.00 sec
INFO:root:2024-04-27 01:06:24, Train, Epoch : 9, Step : 5260, Loss : 0.25934, Acc : 0.897, Sensitive_Loss : 0.06751, Sensitive_Acc : 17.100, Run Time : 11.55 sec
INFO:root:2024-04-27 01:06:35, Train, Epoch : 9, Step : 5270, Loss : 0.29595, Acc : 0.850, Sensitive_Loss : 0.12473, Sensitive_Acc : 16.400, Run Time : 11.49 sec
INFO:root:2024-04-27 01:06:47, Train, Epoch : 9, Step : 5280, Loss : 0.40121, Acc : 0.819, Sensitive_Loss : 0.09628, Sensitive_Acc : 15.100, Run Time : 11.35 sec
INFO:root:2024-04-27 01:06:59, Train, Epoch : 9, Step : 5290, Loss : 0.29635, Acc : 0.863, Sensitive_Loss : 0.06828, Sensitive_Acc : 16.200, Run Time : 12.12 sec
INFO:root:2024-04-27 01:07:10, Train, Epoch : 9, Step : 5300, Loss : 0.30384, Acc : 0.872, Sensitive_Loss : 0.12218, Sensitive_Acc : 17.000, Run Time : 11.53 sec
INFO:root:2024-04-27 01:09:46, Dev, Step : 5300, Loss : 0.42492, Acc : 0.820, Auc : 0.906, Sensitive_Loss : 0.12222, Sensitive_Acc : 16.907, Sensitive_Auc : 0.991, Mean auc: 0.906, Run Time : 155.68 sec
INFO:root:2024-04-27 01:09:54, Train, Epoch : 9, Step : 5310, Loss : 0.32764, Acc : 0.859, Sensitive_Loss : 0.10921, Sensitive_Acc : 16.400, Run Time : 163.58 sec
INFO:root:2024-04-27 01:10:05, Train, Epoch : 9, Step : 5320, Loss : 0.34003, Acc : 0.856, Sensitive_Loss : 0.07012, Sensitive_Acc : 15.300, Run Time : 11.12 sec
INFO:root:2024-04-27 01:10:17, Train, Epoch : 9, Step : 5330, Loss : 0.30308, Acc : 0.822, Sensitive_Loss : 0.11196, Sensitive_Acc : 15.900, Run Time : 11.90 sec
INFO:root:2024-04-27 01:10:29, Train, Epoch : 9, Step : 5340, Loss : 0.27994, Acc : 0.878, Sensitive_Loss : 0.11347, Sensitive_Acc : 16.200, Run Time : 11.85 sec
INFO:root:2024-04-27 01:10:41, Train, Epoch : 9, Step : 5350, Loss : 0.25792, Acc : 0.875, Sensitive_Loss : 0.08890, Sensitive_Acc : 15.800, Run Time : 12.77 sec
INFO:root:2024-04-27 01:10:53, Train, Epoch : 9, Step : 5360, Loss : 0.30529, Acc : 0.863, Sensitive_Loss : 0.09909, Sensitive_Acc : 16.200, Run Time : 11.28 sec
INFO:root:2024-04-27 01:11:05, Train, Epoch : 9, Step : 5370, Loss : 0.26212, Acc : 0.881, Sensitive_Loss : 0.10690, Sensitive_Acc : 16.400, Run Time : 12.09 sec
INFO:root:2024-04-27 01:11:16, Train, Epoch : 9, Step : 5380, Loss : 0.29265, Acc : 0.866, Sensitive_Loss : 0.09300, Sensitive_Acc : 16.000, Run Time : 11.54 sec
INFO:root:2024-04-27 01:11:28, Train, Epoch : 9, Step : 5390, Loss : 0.38223, Acc : 0.847, Sensitive_Loss : 0.08364, Sensitive_Acc : 16.400, Run Time : 11.89 sec
INFO:root:2024-04-27 01:11:41, Train, Epoch : 9, Step : 5400, Loss : 0.31082, Acc : 0.866, Sensitive_Loss : 0.06775, Sensitive_Acc : 17.400, Run Time : 12.49 sec
INFO:root:2024-04-27 01:14:17, Dev, Step : 5400, Loss : 0.40903, Acc : 0.830, Auc : 0.907, Sensitive_Loss : 0.11747, Sensitive_Acc : 16.907, Sensitive_Auc : 0.993, Mean auc: 0.907, Run Time : 156.23 sec
INFO:root:2024-04-27 01:14:26, Train, Epoch : 9, Step : 5410, Loss : 0.29946, Acc : 0.875, Sensitive_Loss : 0.11154, Sensitive_Acc : 17.300, Run Time : 165.02 sec
INFO:root:2024-04-27 01:14:38, Train, Epoch : 9, Step : 5420, Loss : 0.30270, Acc : 0.878, Sensitive_Loss : 0.09982, Sensitive_Acc : 16.500, Run Time : 12.13 sec
INFO:root:2024-04-27 01:14:49, Train, Epoch : 9, Step : 5430, Loss : 0.34647, Acc : 0.841, Sensitive_Loss : 0.09163, Sensitive_Acc : 16.800, Run Time : 11.56 sec
INFO:root:2024-04-27 01:15:01, Train, Epoch : 9, Step : 5440, Loss : 0.24097, Acc : 0.872, Sensitive_Loss : 0.09122, Sensitive_Acc : 16.200, Run Time : 11.82 sec
INFO:root:2024-04-27 01:15:14, Train, Epoch : 9, Step : 5450, Loss : 0.26932, Acc : 0.887, Sensitive_Loss : 0.09292, Sensitive_Acc : 17.300, Run Time : 12.41 sec
INFO:root:2024-04-27 01:15:25, Train, Epoch : 9, Step : 5460, Loss : 0.27529, Acc : 0.872, Sensitive_Loss : 0.10280, Sensitive_Acc : 16.900, Run Time : 11.26 sec
INFO:root:2024-04-27 01:15:37, Train, Epoch : 9, Step : 5470, Loss : 0.35114, Acc : 0.872, Sensitive_Loss : 0.07935, Sensitive_Acc : 15.600, Run Time : 12.12 sec
INFO:root:2024-04-27 01:15:48, Train, Epoch : 9, Step : 5480, Loss : 0.26068, Acc : 0.897, Sensitive_Loss : 0.11177, Sensitive_Acc : 17.100, Run Time : 11.40 sec
INFO:root:2024-04-27 01:16:00, Train, Epoch : 9, Step : 5490, Loss : 0.33562, Acc : 0.853, Sensitive_Loss : 0.13066, Sensitive_Acc : 16.600, Run Time : 11.95 sec
INFO:root:2024-04-27 01:16:13, Train, Epoch : 9, Step : 5500, Loss : 0.29997, Acc : 0.863, Sensitive_Loss : 0.09565, Sensitive_Acc : 15.300, Run Time : 12.37 sec
INFO:root:2024-04-27 01:18:48, Dev, Step : 5500, Loss : 0.40433, Acc : 0.825, Auc : 0.907, Sensitive_Loss : 0.11007, Sensitive_Acc : 16.950, Sensitive_Auc : 0.992, Mean auc: 0.907, Run Time : 155.72 sec
INFO:root:2024-04-27 01:18:57, Train, Epoch : 9, Step : 5510, Loss : 0.38405, Acc : 0.847, Sensitive_Loss : 0.11557, Sensitive_Acc : 17.000, Run Time : 164.65 sec
INFO:root:2024-04-27 01:19:09, Train, Epoch : 9, Step : 5520, Loss : 0.29928, Acc : 0.869, Sensitive_Loss : 0.07700, Sensitive_Acc : 17.500, Run Time : 11.69 sec
INFO:root:2024-04-27 01:19:21, Train, Epoch : 9, Step : 5530, Loss : 0.32773, Acc : 0.847, Sensitive_Loss : 0.11787, Sensitive_Acc : 16.500, Run Time : 12.12 sec
INFO:root:2024-04-27 01:19:34, Train, Epoch : 9, Step : 5540, Loss : 0.34974, Acc : 0.872, Sensitive_Loss : 0.09552, Sensitive_Acc : 16.400, Run Time : 12.60 sec
INFO:root:2024-04-27 01:19:44, Train, Epoch : 9, Step : 5550, Loss : 0.31829, Acc : 0.875, Sensitive_Loss : 0.08733, Sensitive_Acc : 16.700, Run Time : 10.51 sec
INFO:root:2024-04-27 01:19:57, Train, Epoch : 9, Step : 5560, Loss : 0.34498, Acc : 0.863, Sensitive_Loss : 0.10660, Sensitive_Acc : 18.200, Run Time : 12.50 sec
INFO:root:2024-04-27 01:20:08, Train, Epoch : 9, Step : 5570, Loss : 0.30078, Acc : 0.894, Sensitive_Loss : 0.11836, Sensitive_Acc : 15.900, Run Time : 11.57 sec
INFO:root:2024-04-27 01:20:21, Train, Epoch : 9, Step : 5580, Loss : 0.23544, Acc : 0.903, Sensitive_Loss : 0.10656, Sensitive_Acc : 15.900, Run Time : 12.14 sec
INFO:root:2024-04-27 01:20:32, Train, Epoch : 9, Step : 5590, Loss : 0.29386, Acc : 0.900, Sensitive_Loss : 0.07191, Sensitive_Acc : 16.300, Run Time : 11.79 sec
INFO:root:2024-04-27 01:20:45, Train, Epoch : 9, Step : 5600, Loss : 0.26416, Acc : 0.878, Sensitive_Loss : 0.14751, Sensitive_Acc : 15.000, Run Time : 12.20 sec
INFO:root:2024-04-27 01:23:20, Dev, Step : 5600, Loss : 0.42184, Acc : 0.823, Auc : 0.907, Sensitive_Loss : 0.11482, Sensitive_Acc : 16.907, Sensitive_Auc : 0.989, Mean auc: 0.907, Run Time : 155.44 sec
INFO:root:2024-04-27 01:23:28, Train, Epoch : 9, Step : 5610, Loss : 0.32078, Acc : 0.844, Sensitive_Loss : 0.10162, Sensitive_Acc : 17.200, Run Time : 163.67 sec
INFO:root:2024-04-27 01:23:41, Train, Epoch : 9, Step : 5620, Loss : 0.30401, Acc : 0.875, Sensitive_Loss : 0.08558, Sensitive_Acc : 17.100, Run Time : 12.30 sec
INFO:root:2024-04-27 01:23:53, Train, Epoch : 9, Step : 5630, Loss : 0.30144, Acc : 0.887, Sensitive_Loss : 0.09867, Sensitive_Acc : 15.700, Run Time : 12.06 sec
INFO:root:2024-04-27 01:26:30
INFO:root:y_pred: [0.19238032 0.9687089  0.02104643 ... 0.7417533  0.03427042 0.91923344]
INFO:root:y_true: [0. 1. 0. ... 1. 0. 1.]
INFO:root:sensitive_y_pred: [9.81022298e-01 1.06327100e-07 8.07171687e-03 3.10481241e-08
 9.98752117e-01 6.40366160e-09 9.93285596e-01 9.81963038e-01
 1.17537584e-02 6.62478149e-01 9.96616066e-01 9.99169588e-01
 9.97005641e-01 9.24166739e-01 1.05878204e-01 9.55440283e-01
 9.99027967e-01 8.36307823e-04 6.98939711e-03 9.95759428e-01
 9.93393958e-01 1.43914844e-03 9.99439895e-01 9.34718728e-01
 9.90533829e-01 9.24122989e-01 5.99798841e-05 9.96912122e-01
 9.37729895e-01 8.81037772e-01 1.26742490e-03 2.13727751e-03
 3.82664484e-06 9.03410465e-03 2.80287005e-02 3.37112951e-08
 1.59657329e-01 1.51621155e-03 9.93378639e-01 9.73569751e-01
 1.81650586e-14 9.71318004e-05 9.95533586e-01 1.33644219e-03
 9.98604476e-01 9.74845648e-01 9.18033957e-01 9.94701803e-01
 7.23933429e-03 9.92630482e-01 9.96133327e-01 2.79713975e-04
 7.77851582e-01 3.75858399e-05 9.97033359e-11 1.00480929e-06
 1.65923893e-01 3.20159270e-05 2.16991975e-06 6.56403003e-08
 2.25808776e-06 6.26049144e-03 3.28930705e-09 9.97449338e-01
 1.99834839e-01 9.96219695e-01 7.57000933e-08 9.93795514e-01
 9.08606350e-01 5.74142694e-01 8.65652323e-01 3.09741706e-01
 8.63913228e-05 9.55168717e-03 6.27618101e-06 8.81290354e-04
 8.17608088e-03 1.33322865e-01 5.55031656e-05 9.94325459e-01
 9.98076797e-01 4.77215835e-05 2.35268652e-01 1.35916537e-06
 8.53589773e-01 9.71878529e-01 2.52330333e-01 1.32046221e-02
 9.54950094e-01 9.83614504e-01 9.96728897e-01 6.12228061e-04
 1.69456098e-02 9.91172731e-01 5.11204079e-03 8.73984944e-04
 9.90442455e-01 9.90422845e-01 3.41925641e-12 2.46336711e-08
 9.80776310e-01 9.59144652e-01 9.98608410e-01 9.93992269e-01
 2.65064728e-06 3.08661424e-06 7.25305557e-01 9.43951786e-01
 9.35536027e-01 2.17392153e-06 8.28321755e-01 9.97980893e-01
 6.37056604e-02 9.97861564e-01 9.46813107e-01 9.81619954e-01
 8.67974818e-01 9.96823430e-01 6.36312217e-02 3.38228315e-01
 9.98546004e-01 9.96221006e-01 1.65637531e-10 8.84028018e-01
 9.92124617e-01 2.97342776e-03 9.88670945e-01 2.93788762e-04
 3.58070922e-03 9.77184176e-01 9.96004999e-01 1.50089750e-06
 5.56483747e-06 7.19327363e-05 9.75337565e-01 9.99237061e-01
 9.62890863e-01 9.69770554e-05 1.55021071e-01 9.89323437e-01]
INFO:root:sensitive_y_true: [1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.
 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.]
INFO:root:2024-04-27 01:26:30, Dev, Step : 5634, Loss : 0.42360, Acc : 0.819, Auc : 0.907, Sensitive_Loss : 0.11773, Sensitive_Acc : 16.964, Sensitive_Auc : 0.990, Mean auc: 0.907, Run Time : 153.77 sec
INFO:root:2024-04-27 01:26:40, Train, Epoch : 10, Step : 5640, Loss : 0.16709, Acc : 0.522, Sensitive_Loss : 0.04141, Sensitive_Acc : 9.900, Run Time : 8.19 sec
INFO:root:2024-04-27 01:26:52, Train, Epoch : 10, Step : 5650, Loss : 0.25611, Acc : 0.894, Sensitive_Loss : 0.10003, Sensitive_Acc : 17.200, Run Time : 12.24 sec
INFO:root:2024-04-27 01:27:04, Train, Epoch : 10, Step : 5660, Loss : 0.28456, Acc : 0.891, Sensitive_Loss : 0.09446, Sensitive_Acc : 16.100, Run Time : 11.50 sec
INFO:root:2024-04-27 01:27:16, Train, Epoch : 10, Step : 5670, Loss : 0.26372, Acc : 0.853, Sensitive_Loss : 0.09717, Sensitive_Acc : 16.500, Run Time : 12.27 sec
INFO:root:2024-04-27 01:27:27, Train, Epoch : 10, Step : 5680, Loss : 0.24547, Acc : 0.900, Sensitive_Loss : 0.08722, Sensitive_Acc : 15.000, Run Time : 11.46 sec
INFO:root:2024-04-27 01:27:40, Train, Epoch : 10, Step : 5690, Loss : 0.26372, Acc : 0.897, Sensitive_Loss : 0.09312, Sensitive_Acc : 17.200, Run Time : 12.25 sec
INFO:root:2024-04-27 01:27:51, Train, Epoch : 10, Step : 5700, Loss : 0.31459, Acc : 0.863, Sensitive_Loss : 0.09306, Sensitive_Acc : 16.300, Run Time : 11.76 sec
INFO:root:2024-04-27 01:30:28, Dev, Step : 5700, Loss : 0.43775, Acc : 0.820, Auc : 0.905, Sensitive_Loss : 0.11893, Sensitive_Acc : 16.907, Sensitive_Auc : 0.987, Mean auc: 0.905, Run Time : 156.32 sec
INFO:root:2024-04-27 01:30:36, Train, Epoch : 10, Step : 5710, Loss : 0.27040, Acc : 0.878, Sensitive_Loss : 0.14738, Sensitive_Acc : 18.100, Run Time : 165.08 sec
INFO:root:2024-04-27 01:30:49, Train, Epoch : 10, Step : 5720, Loss : 0.26196, Acc : 0.891, Sensitive_Loss : 0.11630, Sensitive_Acc : 16.000, Run Time : 12.26 sec
INFO:root:2024-04-27 01:31:01, Train, Epoch : 10, Step : 5730, Loss : 0.25359, Acc : 0.897, Sensitive_Loss : 0.09525, Sensitive_Acc : 16.500, Run Time : 12.50 sec
INFO:root:2024-04-27 01:31:12, Train, Epoch : 10, Step : 5740, Loss : 0.26713, Acc : 0.875, Sensitive_Loss : 0.09368, Sensitive_Acc : 17.000, Run Time : 11.39 sec
INFO:root:2024-04-27 01:31:24, Train, Epoch : 10, Step : 5750, Loss : 0.36981, Acc : 0.866, Sensitive_Loss : 0.09164, Sensitive_Acc : 17.800, Run Time : 11.89 sec
INFO:root:2024-04-27 01:31:36, Train, Epoch : 10, Step : 5760, Loss : 0.29030, Acc : 0.878, Sensitive_Loss : 0.08432, Sensitive_Acc : 15.500, Run Time : 11.97 sec
INFO:root:2024-04-27 01:31:48, Train, Epoch : 10, Step : 5770, Loss : 0.22141, Acc : 0.906, Sensitive_Loss : 0.12515, Sensitive_Acc : 16.800, Run Time : 11.54 sec
INFO:root:2024-04-27 01:32:00, Train, Epoch : 10, Step : 5780, Loss : 0.36133, Acc : 0.875, Sensitive_Loss : 0.12728, Sensitive_Acc : 15.300, Run Time : 12.11 sec
INFO:root:2024-04-27 01:32:12, Train, Epoch : 10, Step : 5790, Loss : 0.33368, Acc : 0.872, Sensitive_Loss : 0.08787, Sensitive_Acc : 16.400, Run Time : 12.15 sec
INFO:root:2024-04-27 01:32:23, Train, Epoch : 10, Step : 5800, Loss : 0.35291, Acc : 0.825, Sensitive_Loss : 0.12249, Sensitive_Acc : 14.400, Run Time : 11.33 sec
INFO:root:2024-04-27 01:35:00, Dev, Step : 5800, Loss : 0.42456, Acc : 0.824, Auc : 0.905, Sensitive_Loss : 0.10545, Sensitive_Acc : 16.893, Sensitive_Auc : 0.993, Mean auc: 0.905, Run Time : 156.76 sec
INFO:root:2024-04-27 01:35:09, Train, Epoch : 10, Step : 5810, Loss : 0.24434, Acc : 0.906, Sensitive_Loss : 0.07951, Sensitive_Acc : 16.300, Run Time : 165.17 sec
INFO:root:2024-04-27 01:35:21, Train, Epoch : 10, Step : 5820, Loss : 0.35198, Acc : 0.850, Sensitive_Loss : 0.09642, Sensitive_Acc : 16.500, Run Time : 12.20 sec
INFO:root:2024-04-27 01:35:33, Train, Epoch : 10, Step : 5830, Loss : 0.31841, Acc : 0.881, Sensitive_Loss : 0.07325, Sensitive_Acc : 16.200, Run Time : 11.93 sec
INFO:root:2024-04-27 01:35:44, Train, Epoch : 10, Step : 5840, Loss : 0.30405, Acc : 0.891, Sensitive_Loss : 0.10743, Sensitive_Acc : 16.400, Run Time : 11.61 sec
INFO:root:2024-04-27 01:35:57, Train, Epoch : 10, Step : 5850, Loss : 0.29640, Acc : 0.869, Sensitive_Loss : 0.09319, Sensitive_Acc : 15.700, Run Time : 12.18 sec
INFO:root:2024-04-27 01:36:08, Train, Epoch : 10, Step : 5860, Loss : 0.33540, Acc : 0.878, Sensitive_Loss : 0.06971, Sensitive_Acc : 16.400, Run Time : 11.61 sec
INFO:root:2024-04-27 01:36:20, Train, Epoch : 10, Step : 5870, Loss : 0.23385, Acc : 0.887, Sensitive_Loss : 0.08639, Sensitive_Acc : 15.100, Run Time : 12.09 sec
INFO:root:2024-04-27 01:36:32, Train, Epoch : 10, Step : 5880, Loss : 0.32896, Acc : 0.853, Sensitive_Loss : 0.12583, Sensitive_Acc : 17.200, Run Time : 12.09 sec
INFO:root:2024-04-27 01:36:44, Train, Epoch : 10, Step : 5890, Loss : 0.27824, Acc : 0.884, Sensitive_Loss : 0.08013, Sensitive_Acc : 16.600, Run Time : 11.92 sec
INFO:root:2024-04-27 01:36:57, Train, Epoch : 10, Step : 5900, Loss : 0.28939, Acc : 0.866, Sensitive_Loss : 0.10185, Sensitive_Acc : 16.900, Run Time : 12.22 sec
INFO:root:2024-04-27 01:39:32, Dev, Step : 5900, Loss : 0.44859, Acc : 0.818, Auc : 0.907, Sensitive_Loss : 0.11347, Sensitive_Acc : 16.850, Sensitive_Auc : 0.991, Mean auc: 0.907, Run Time : 155.18 sec
INFO:root:2024-04-27 01:39:40, Train, Epoch : 10, Step : 5910, Loss : 0.27210, Acc : 0.859, Sensitive_Loss : 0.10615, Sensitive_Acc : 17.100, Run Time : 163.79 sec
INFO:root:2024-04-27 01:39:53, Train, Epoch : 10, Step : 5920, Loss : 0.30943, Acc : 0.834, Sensitive_Loss : 0.15070, Sensitive_Acc : 16.000, Run Time : 12.69 sec
INFO:root:2024-04-27 01:40:05, Train, Epoch : 10, Step : 5930, Loss : 0.29777, Acc : 0.900, Sensitive_Loss : 0.07076, Sensitive_Acc : 15.600, Run Time : 11.68 sec
INFO:root:2024-04-27 01:40:17, Train, Epoch : 10, Step : 5940, Loss : 0.22473, Acc : 0.912, Sensitive_Loss : 0.09713, Sensitive_Acc : 15.400, Run Time : 12.32 sec
INFO:root:2024-04-27 01:40:29, Train, Epoch : 10, Step : 5950, Loss : 0.28030, Acc : 0.869, Sensitive_Loss : 0.09161, Sensitive_Acc : 16.300, Run Time : 12.07 sec
INFO:root:2024-04-27 01:40:42, Train, Epoch : 10, Step : 5960, Loss : 0.31833, Acc : 0.866, Sensitive_Loss : 0.13182, Sensitive_Acc : 17.600, Run Time : 12.87 sec
INFO:root:2024-04-27 01:40:54, Train, Epoch : 10, Step : 5970, Loss : 0.25043, Acc : 0.897, Sensitive_Loss : 0.07449, Sensitive_Acc : 14.900, Run Time : 12.01 sec
INFO:root:2024-04-27 01:41:07, Train, Epoch : 10, Step : 5980, Loss : 0.33283, Acc : 0.856, Sensitive_Loss : 0.08790, Sensitive_Acc : 15.000, Run Time : 12.77 sec
INFO:root:2024-04-27 01:41:18, Train, Epoch : 10, Step : 5990, Loss : 0.31923, Acc : 0.850, Sensitive_Loss : 0.08358, Sensitive_Acc : 15.500, Run Time : 11.70 sec
INFO:root:2024-04-27 01:41:29, Train, Epoch : 10, Step : 6000, Loss : 0.32815, Acc : 0.834, Sensitive_Loss : 0.09946, Sensitive_Acc : 14.600, Run Time : 11.03 sec
INFO:root:2024-04-27 01:44:06, Dev, Step : 6000, Loss : 0.44496, Acc : 0.820, Auc : 0.905, Sensitive_Loss : 0.11565, Sensitive_Acc : 16.850, Sensitive_Auc : 0.990, Mean auc: 0.905, Run Time : 156.42 sec
INFO:root:2024-04-27 01:44:15, Train, Epoch : 10, Step : 6010, Loss : 0.29677, Acc : 0.847, Sensitive_Loss : 0.11347, Sensitive_Acc : 16.700, Run Time : 165.09 sec
INFO:root:2024-04-27 01:44:26, Train, Epoch : 10, Step : 6020, Loss : 0.24427, Acc : 0.897, Sensitive_Loss : 0.08703, Sensitive_Acc : 15.700, Run Time : 11.96 sec
INFO:root:2024-04-27 01:44:38, Train, Epoch : 10, Step : 6030, Loss : 0.29931, Acc : 0.878, Sensitive_Loss : 0.08463, Sensitive_Acc : 16.200, Run Time : 11.73 sec
INFO:root:2024-04-27 01:44:51, Train, Epoch : 10, Step : 6040, Loss : 0.34393, Acc : 0.859, Sensitive_Loss : 0.07856, Sensitive_Acc : 17.300, Run Time : 12.29 sec
INFO:root:2024-04-27 01:45:03, Train, Epoch : 10, Step : 6050, Loss : 0.32366, Acc : 0.866, Sensitive_Loss : 0.08712, Sensitive_Acc : 16.600, Run Time : 12.45 sec
INFO:root:2024-04-27 01:45:15, Train, Epoch : 10, Step : 6060, Loss : 0.23047, Acc : 0.897, Sensitive_Loss : 0.08214, Sensitive_Acc : 16.600, Run Time : 12.03 sec
INFO:root:2024-04-27 01:45:27, Train, Epoch : 10, Step : 6070, Loss : 0.25807, Acc : 0.878, Sensitive_Loss : 0.08566, Sensitive_Acc : 15.200, Run Time : 11.63 sec
INFO:root:2024-04-27 01:45:38, Train, Epoch : 10, Step : 6080, Loss : 0.29035, Acc : 0.872, Sensitive_Loss : 0.09923, Sensitive_Acc : 17.100, Run Time : 11.81 sec
INFO:root:2024-04-27 01:45:50, Train, Epoch : 10, Step : 6090, Loss : 0.34597, Acc : 0.841, Sensitive_Loss : 0.13390, Sensitive_Acc : 17.900, Run Time : 11.09 sec
INFO:root:2024-04-27 01:46:02, Train, Epoch : 10, Step : 6100, Loss : 0.28225, Acc : 0.878, Sensitive_Loss : 0.06547, Sensitive_Acc : 15.300, Run Time : 12.71 sec
INFO:root:2024-04-27 01:48:37, Dev, Step : 6100, Loss : 0.43611, Acc : 0.821, Auc : 0.908, Sensitive_Loss : 0.11527, Sensitive_Acc : 16.850, Sensitive_Auc : 0.993, Mean auc: 0.908, Run Time : 155.17 sec
INFO:root:2024-04-27 01:48:46, Train, Epoch : 10, Step : 6110, Loss : 0.32010, Acc : 0.850, Sensitive_Loss : 0.11753, Sensitive_Acc : 15.900, Run Time : 163.60 sec
INFO:root:2024-04-27 01:48:58, Train, Epoch : 10, Step : 6120, Loss : 0.28892, Acc : 0.875, Sensitive_Loss : 0.11111, Sensitive_Acc : 15.600, Run Time : 11.88 sec
INFO:root:2024-04-27 01:49:12, Train, Epoch : 10, Step : 6130, Loss : 0.25761, Acc : 0.859, Sensitive_Loss : 0.09594, Sensitive_Acc : 16.300, Run Time : 14.34 sec
INFO:root:2024-04-27 01:49:24, Train, Epoch : 10, Step : 6140, Loss : 0.31491, Acc : 0.856, Sensitive_Loss : 0.09088, Sensitive_Acc : 15.300, Run Time : 12.33 sec
INFO:root:2024-04-27 01:49:36, Train, Epoch : 10, Step : 6150, Loss : 0.24340, Acc : 0.906, Sensitive_Loss : 0.06676, Sensitive_Acc : 16.400, Run Time : 11.43 sec
INFO:root:2024-04-27 01:49:48, Train, Epoch : 10, Step : 6160, Loss : 0.25733, Acc : 0.881, Sensitive_Loss : 0.10294, Sensitive_Acc : 17.100, Run Time : 11.86 sec
INFO:root:2024-04-27 01:49:59, Train, Epoch : 10, Step : 6170, Loss : 0.27421, Acc : 0.872, Sensitive_Loss : 0.09341, Sensitive_Acc : 17.000, Run Time : 11.33 sec
INFO:root:2024-04-27 01:50:12, Train, Epoch : 10, Step : 6180, Loss : 0.38149, Acc : 0.844, Sensitive_Loss : 0.06819, Sensitive_Acc : 16.800, Run Time : 12.72 sec
INFO:root:2024-04-27 01:50:23, Train, Epoch : 10, Step : 6190, Loss : 0.33389, Acc : 0.853, Sensitive_Loss : 0.12576, Sensitive_Acc : 16.300, Run Time : 11.27 sec
INFO:root:2024-04-27 01:50:35, Train, Epoch : 10, Step : 6200, Loss : 0.27938, Acc : 0.897, Sensitive_Loss : 0.07593, Sensitive_Acc : 17.100, Run Time : 12.04 sec
INFO:root:2024-04-27 01:53:11, Dev, Step : 6200, Loss : 0.42823, Acc : 0.821, Auc : 0.907, Sensitive_Loss : 0.10241, Sensitive_Acc : 16.850, Sensitive_Auc : 0.993, Mean auc: 0.907, Run Time : 155.69 sec
INFO:root:2024-04-27 01:53:19, Train, Epoch : 10, Step : 6210, Loss : 0.30300, Acc : 0.897, Sensitive_Loss : 0.08620, Sensitive_Acc : 15.600, Run Time : 164.34 sec
INFO:root:2024-04-27 01:53:32, Train, Epoch : 10, Step : 6220, Loss : 0.31820, Acc : 0.866, Sensitive_Loss : 0.08939, Sensitive_Acc : 17.100, Run Time : 12.82 sec
INFO:root:2024-04-27 01:53:44, Train, Epoch : 10, Step : 6230, Loss : 0.38008, Acc : 0.844, Sensitive_Loss : 0.09442, Sensitive_Acc : 15.700, Run Time : 11.73 sec
INFO:root:2024-04-27 01:53:56, Train, Epoch : 10, Step : 6240, Loss : 0.28145, Acc : 0.863, Sensitive_Loss : 0.06473, Sensitive_Acc : 14.300, Run Time : 11.84 sec
INFO:root:2024-04-27 01:54:08, Train, Epoch : 10, Step : 6250, Loss : 0.29677, Acc : 0.875, Sensitive_Loss : 0.05718, Sensitive_Acc : 17.100, Run Time : 12.07 sec
INFO:root:2024-04-27 01:54:18, Train, Epoch : 10, Step : 6260, Loss : 0.26403, Acc : 0.900, Sensitive_Loss : 0.10691, Sensitive_Acc : 16.000, Run Time : 10.56 sec
INFO:root:2024-04-27 01:56:52
INFO:root:y_pred: [0.20577179 0.9797396  0.03644375 ... 0.83920664 0.03928745 0.9395353 ]
INFO:root:y_true: [0. 1. 0. ... 1. 0. 1.]
INFO:root:sensitive_y_pred: [9.7999221e-01 1.2910110e-07 2.2860682e-02 5.3123995e-07 9.9898618e-01
 4.3581707e-07 9.8951972e-01 9.8522967e-01 1.4273948e-02 7.9061478e-01
 9.9405259e-01 9.9938893e-01 9.9734604e-01 9.5276695e-01 1.3056001e-01
 9.4356287e-01 9.9929750e-01 5.7394635e-03 6.5668941e-02 9.9693406e-01
 9.9063081e-01 2.1501234e-02 9.9959999e-01 9.6925259e-01 9.9537826e-01
 9.5032078e-01 5.3685892e-04 9.9718529e-01 9.5305562e-01 8.6115295e-01
 1.4083990e-03 1.4012972e-02 2.2246778e-07 3.6957931e-02 3.4619078e-02
 5.6341014e-07 6.8662636e-02 5.3512775e-03 9.9565649e-01 9.7225100e-01
 3.1170832e-12 8.8534871e-06 9.9482852e-01 2.2860940e-03 9.9833637e-01
 9.7030973e-01 9.4014031e-01 9.9165690e-01 1.8681562e-02 9.9541855e-01
 9.9682283e-01 1.8097009e-04 7.3419911e-01 1.0255058e-04 1.3816303e-07
 4.0212322e-05 2.9224986e-01 2.0671810e-03 2.0656806e-05 3.0905449e-05
 7.2325340e-05 5.0612550e-02 5.5215672e-08 9.9528670e-01 2.6792446e-01
 9.9686193e-01 3.8880179e-07 9.8862141e-01 9.3239802e-01 7.3115444e-01
 8.2301110e-01 4.6804994e-01 3.6317247e-04 3.7879441e-02 3.1987135e-04
 3.5633675e-03 3.3089418e-02 2.6043612e-01 3.7287988e-04 9.9478734e-01
 9.9860853e-01 3.5706544e-04 4.9173835e-01 5.0503022e-05 5.3391629e-01
 9.7725874e-01 4.4083196e-01 3.6514446e-02 9.3620473e-01 9.8988557e-01
 9.9682152e-01 1.5936814e-03 3.0157708e-02 9.9542516e-01 1.5722131e-02
 3.8373689e-03 9.8956734e-01 9.9035269e-01 1.7213102e-10 2.5768750e-05
 9.8683703e-01 9.6268106e-01 9.9832612e-01 9.9707067e-01 2.8358779e-06
 2.4194037e-07 7.7158374e-01 9.6252286e-01 9.6370059e-01 3.3382764e-07
 9.0006620e-01 9.9838471e-01 1.0200377e-01 9.9722052e-01 9.6277142e-01
 9.8902929e-01 9.1772622e-01 9.9774915e-01 9.8741814e-02 1.7316881e-01
 9.9859136e-01 9.9706739e-01 4.7281102e-08 9.0641499e-01 9.9104464e-01
 1.8677926e-03 9.9148953e-01 8.2117721e-04 4.4256961e-03 9.8878622e-01
 9.9477541e-01 4.1891840e-06 4.0804785e-05 3.7722217e-04 9.6993935e-01
 9.9920875e-01 9.7093666e-01 1.7952578e-03 2.2651672e-02 9.8853356e-01]
INFO:root:sensitive_y_true: [1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.
 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.]
INFO:root:2024-04-27 01:56:52, Dev, Step : 6260, Loss : 0.42479, Acc : 0.828, Auc : 0.905, Sensitive_Loss : 0.11851, Sensitive_Acc : 16.964, Sensitive_Auc : 0.994, Mean auc: 0.905, Run Time : 153.48 sec
