Running on desktop18:
stdin: is not a tty
Activating chexpert environment...
2
Using the specified args:
Namespace(cfg_path='/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/config/config_katkr.json', device_ids='0', logtofile=False, num_workers=2, pre_train=None, resume=0, save_path='/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/logdirs/logdir-30k-2', verbose=True)
{
    "base_path": "/home/data_shares/purrlab/CheXpert/CheXpert-v1.0-small",
    "train_csv": "/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/preprocess/datasets/biased_pneumothorax_dataset_train.csv",
    "dev_csv": "/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/preprocess/datasets/biased_pneumothorax_dataset_val.csv",
    "pred_csv": "/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/predictions/Pred_Biased_Sex_1_pos01.csv",
    "pred_model": "/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/logdirs/logdir-30k-2/Best_Biased_Sex_1_pos011.ckpt",
    "backbone": "densenet121",
    "sensitive_attribute": "Sex",
    "lambda_val": 0.1,
    "num_heads": 2,
    "width": 512,
    "height": 512,
    "long_side": 512,
    "fix_ratio": true,
    "pixel_mean": 128.0,
    "pixel_std": 64.0,
    "use_pixel_std": true,
    "use_equalizeHist": true,
    "use_transforms_type": "Aug",
    "gaussian_blur": 3,
    "border_pad": "pixel_mean",
    "num_classes": [
        1
    ],
    "batch_weight": true,
    "batch_weight_sensitive": true,
    "enhance_index": [
        2,
        6
    ],
    "enhance_times": 1,
    "pos_weight": [
        1
    ],
    "sensitive_pos_weight": [
        1
    ],
    "train_batch_size": 32,
    "dev_batch_size": 32,
    "pretrained": true,
    "log_every": 10,
    "test_every": 100,
    "epoch": 10,
    "norm_type": "BatchNorm",
    "global_pool": "PCAM",
    "fc_bn": true,
    "attention_map": "FPA",
    "lse_gamma": 0.5,
    "fc_drop": 0,
    "optimizer": "Adam",
    "criterion": "BCE",
    "sensitive_criterion": "BCE",
    "lr": 0.0001,
    "lr_factor": 0.1,
    "lr_epochs": [
        2
    ],
    "momentum": 0.9,
    "weight_decay": 0.0,
    "best_target": "auc",
    "save_top_k": 3,
    "save_index": [
        0
    ]
}
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 256, 256]           9,408
       BatchNorm2d-2         [-1, 64, 256, 256]             128
              ReLU-3         [-1, 64, 256, 256]               0
         MaxPool2d-4         [-1, 64, 128, 128]               0
       BatchNorm2d-5         [-1, 64, 128, 128]             128
              ReLU-6         [-1, 64, 128, 128]               0
            Conv2d-7        [-1, 128, 128, 128]           8,192
       BatchNorm2d-8        [-1, 128, 128, 128]             256
              ReLU-9        [-1, 128, 128, 128]               0
           Conv2d-10         [-1, 32, 128, 128]          36,864
      BatchNorm2d-11         [-1, 96, 128, 128]             192
             ReLU-12         [-1, 96, 128, 128]               0
           Conv2d-13        [-1, 128, 128, 128]          12,288
      BatchNorm2d-14        [-1, 128, 128, 128]             256
             ReLU-15        [-1, 128, 128, 128]               0
           Conv2d-16         [-1, 32, 128, 128]          36,864
      BatchNorm2d-17        [-1, 128, 128, 128]             256
             ReLU-18        [-1, 128, 128, 128]               0
           Conv2d-19        [-1, 128, 128, 128]          16,384
      BatchNorm2d-20        [-1, 128, 128, 128]             256
             ReLU-21        [-1, 128, 128, 128]               0
           Conv2d-22         [-1, 32, 128, 128]          36,864
      BatchNorm2d-23        [-1, 160, 128, 128]             320
             ReLU-24        [-1, 160, 128, 128]               0
           Conv2d-25        [-1, 128, 128, 128]          20,480
      BatchNorm2d-26        [-1, 128, 128, 128]             256
             ReLU-27        [-1, 128, 128, 128]               0
           Conv2d-28         [-1, 32, 128, 128]          36,864
      BatchNorm2d-29        [-1, 192, 128, 128]             384
             ReLU-30        [-1, 192, 128, 128]               0
           Conv2d-31        [-1, 128, 128, 128]          24,576
      BatchNorm2d-32        [-1, 128, 128, 128]             256
             ReLU-33        [-1, 128, 128, 128]               0
           Conv2d-34         [-1, 32, 128, 128]          36,864
      BatchNorm2d-35        [-1, 224, 128, 128]             448
             ReLU-36        [-1, 224, 128, 128]               0
           Conv2d-37        [-1, 128, 128, 128]          28,672
      BatchNorm2d-38        [-1, 128, 128, 128]             256
             ReLU-39        [-1, 128, 128, 128]               0
           Conv2d-40         [-1, 32, 128, 128]          36,864
      BatchNorm2d-41        [-1, 256, 128, 128]             512
             ReLU-42        [-1, 256, 128, 128]               0
           Conv2d-43        [-1, 128, 128, 128]          32,768
        AvgPool2d-44          [-1, 128, 64, 64]               0
      BatchNorm2d-45          [-1, 128, 64, 64]             256
             ReLU-46          [-1, 128, 64, 64]               0
           Conv2d-47          [-1, 128, 64, 64]          16,384
      BatchNorm2d-48          [-1, 128, 64, 64]             256
             ReLU-49          [-1, 128, 64, 64]               0
           Conv2d-50           [-1, 32, 64, 64]          36,864
      BatchNorm2d-51          [-1, 160, 64, 64]             320
             ReLU-52          [-1, 160, 64, 64]               0
           Conv2d-53          [-1, 128, 64, 64]          20,480
      BatchNorm2d-54          [-1, 128, 64, 64]             256
             ReLU-55          [-1, 128, 64, 64]               0
           Conv2d-56           [-1, 32, 64, 64]          36,864
      BatchNorm2d-57          [-1, 192, 64, 64]             384
             ReLU-58          [-1, 192, 64, 64]               0
           Conv2d-59          [-1, 128, 64, 64]          24,576
      BatchNorm2d-60          [-1, 128, 64, 64]             256
             ReLU-61          [-1, 128, 64, 64]               0
           Conv2d-62           [-1, 32, 64, 64]          36,864
      BatchNorm2d-63          [-1, 224, 64, 64]             448
             ReLU-64          [-1, 224, 64, 64]               0
           Conv2d-65          [-1, 128, 64, 64]          28,672
      BatchNorm2d-66          [-1, 128, 64, 64]             256
             ReLU-67          [-1, 128, 64, 64]               0
           Conv2d-68           [-1, 32, 64, 64]          36,864
      BatchNorm2d-69          [-1, 256, 64, 64]             512
             ReLU-70          [-1, 256, 64, 64]               0
           Conv2d-71          [-1, 128, 64, 64]          32,768
      BatchNorm2d-72          [-1, 128, 64, 64]             256
             ReLU-73          [-1, 128, 64, 64]               0
           Conv2d-74           [-1, 32, 64, 64]          36,864
      BatchNorm2d-75          [-1, 288, 64, 64]             576
             ReLU-76          [-1, 288, 64, 64]               0
           Conv2d-77          [-1, 128, 64, 64]          36,864
      BatchNorm2d-78          [-1, 128, 64, 64]             256
             ReLU-79          [-1, 128, 64, 64]               0
           Conv2d-80           [-1, 32, 64, 64]          36,864
      BatchNorm2d-81          [-1, 320, 64, 64]             640
             ReLU-82          [-1, 320, 64, 64]               0
           Conv2d-83          [-1, 128, 64, 64]          40,960
      BatchNorm2d-84          [-1, 128, 64, 64]             256
             ReLU-85          [-1, 128, 64, 64]               0
           Conv2d-86           [-1, 32, 64, 64]          36,864
      BatchNorm2d-87          [-1, 352, 64, 64]             704
             ReLU-88          [-1, 352, 64, 64]               0
           Conv2d-89          [-1, 128, 64, 64]          45,056
      BatchNorm2d-90          [-1, 128, 64, 64]             256
             ReLU-91          [-1, 128, 64, 64]               0
           Conv2d-92           [-1, 32, 64, 64]          36,864
      BatchNorm2d-93          [-1, 384, 64, 64]             768
             ReLU-94          [-1, 384, 64, 64]               0
           Conv2d-95          [-1, 128, 64, 64]          49,152
      BatchNorm2d-96          [-1, 128, 64, 64]             256
             ReLU-97          [-1, 128, 64, 64]               0
           Conv2d-98           [-1, 32, 64, 64]          36,864
      BatchNorm2d-99          [-1, 416, 64, 64]             832
            ReLU-100          [-1, 416, 64, 64]               0
          Conv2d-101          [-1, 128, 64, 64]          53,248
     BatchNorm2d-102          [-1, 128, 64, 64]             256
            ReLU-103          [-1, 128, 64, 64]               0
          Conv2d-104           [-1, 32, 64, 64]          36,864
     BatchNorm2d-105          [-1, 448, 64, 64]             896
            ReLU-106          [-1, 448, 64, 64]               0
          Conv2d-107          [-1, 128, 64, 64]          57,344
     BatchNorm2d-108          [-1, 128, 64, 64]             256
            ReLU-109          [-1, 128, 64, 64]               0
          Conv2d-110           [-1, 32, 64, 64]          36,864
     BatchNorm2d-111          [-1, 480, 64, 64]             960
            ReLU-112          [-1, 480, 64, 64]               0
          Conv2d-113          [-1, 128, 64, 64]          61,440
     BatchNorm2d-114          [-1, 128, 64, 64]             256
            ReLU-115          [-1, 128, 64, 64]               0
          Conv2d-116           [-1, 32, 64, 64]          36,864
     BatchNorm2d-117          [-1, 512, 64, 64]           1,024
            ReLU-118          [-1, 512, 64, 64]               0
          Conv2d-119          [-1, 256, 64, 64]         131,072
       AvgPool2d-120          [-1, 256, 32, 32]               0
     BatchNorm2d-121          [-1, 256, 32, 32]             512
            ReLU-122          [-1, 256, 32, 32]               0
          Conv2d-123          [-1, 128, 32, 32]          32,768
     BatchNorm2d-124          [-1, 128, 32, 32]             256
            ReLU-125          [-1, 128, 32, 32]               0
          Conv2d-126           [-1, 32, 32, 32]          36,864
     BatchNorm2d-127          [-1, 288, 32, 32]             576
            ReLU-128          [-1, 288, 32, 32]               0
          Conv2d-129          [-1, 128, 32, 32]          36,864
     BatchNorm2d-130          [-1, 128, 32, 32]             256
            ReLU-131          [-1, 128, 32, 32]               0
          Conv2d-132           [-1, 32, 32, 32]          36,864
     BatchNorm2d-133          [-1, 320, 32, 32]             640
            ReLU-134          [-1, 320, 32, 32]               0
          Conv2d-135          [-1, 128, 32, 32]          40,960
     BatchNorm2d-136          [-1, 128, 32, 32]             256
            ReLU-137          [-1, 128, 32, 32]               0
          Conv2d-138           [-1, 32, 32, 32]          36,864
     BatchNorm2d-139          [-1, 352, 32, 32]             704
            ReLU-140          [-1, 352, 32, 32]               0
          Conv2d-141          [-1, 128, 32, 32]          45,056
     BatchNorm2d-142          [-1, 128, 32, 32]             256
            ReLU-143          [-1, 128, 32, 32]               0
          Conv2d-144           [-1, 32, 32, 32]          36,864
     BatchNorm2d-145          [-1, 384, 32, 32]             768
            ReLU-146          [-1, 384, 32, 32]               0
          Conv2d-147          [-1, 128, 32, 32]          49,152
     BatchNorm2d-148          [-1, 128, 32, 32]             256
            ReLU-149          [-1, 128, 32, 32]               0
          Conv2d-150           [-1, 32, 32, 32]          36,864
     BatchNorm2d-151          [-1, 416, 32, 32]             832
            ReLU-152          [-1, 416, 32, 32]               0
          Conv2d-153          [-1, 128, 32, 32]          53,248
     BatchNorm2d-154          [-1, 128, 32, 32]             256
            ReLU-155          [-1, 128, 32, 32]               0
          Conv2d-156           [-1, 32, 32, 32]          36,864
     BatchNorm2d-157          [-1, 448, 32, 32]             896
            ReLU-158          [-1, 448, 32, 32]               0
          Conv2d-159          [-1, 128, 32, 32]          57,344
     BatchNorm2d-160          [-1, 128, 32, 32]             256
            ReLU-161          [-1, 128, 32, 32]               0
          Conv2d-162           [-1, 32, 32, 32]          36,864
     BatchNorm2d-163          [-1, 480, 32, 32]             960
            ReLU-164          [-1, 480, 32, 32]               0
          Conv2d-165          [-1, 128, 32, 32]          61,440
     BatchNorm2d-166          [-1, 128, 32, 32]             256
            ReLU-167          [-1, 128, 32, 32]               0
          Conv2d-168           [-1, 32, 32, 32]          36,864
     BatchNorm2d-169          [-1, 512, 32, 32]           1,024
            ReLU-170          [-1, 512, 32, 32]               0
          Conv2d-171          [-1, 128, 32, 32]          65,536
     BatchNorm2d-172          [-1, 128, 32, 32]             256
            ReLU-173          [-1, 128, 32, 32]               0
          Conv2d-174           [-1, 32, 32, 32]          36,864
     BatchNorm2d-175          [-1, 544, 32, 32]           1,088
            ReLU-176          [-1, 544, 32, 32]               0
          Conv2d-177          [-1, 128, 32, 32]          69,632
     BatchNorm2d-178          [-1, 128, 32, 32]             256
            ReLU-179          [-1, 128, 32, 32]               0
          Conv2d-180           [-1, 32, 32, 32]          36,864
     BatchNorm2d-181          [-1, 576, 32, 32]           1,152
            ReLU-182          [-1, 576, 32, 32]               0
          Conv2d-183          [-1, 128, 32, 32]          73,728
     BatchNorm2d-184          [-1, 128, 32, 32]             256
            ReLU-185          [-1, 128, 32, 32]               0
          Conv2d-186           [-1, 32, 32, 32]          36,864
     BatchNorm2d-187          [-1, 608, 32, 32]           1,216
            ReLU-188          [-1, 608, 32, 32]               0
          Conv2d-189          [-1, 128, 32, 32]          77,824
     BatchNorm2d-190          [-1, 128, 32, 32]             256
            ReLU-191          [-1, 128, 32, 32]               0
          Conv2d-192           [-1, 32, 32, 32]          36,864
     BatchNorm2d-193          [-1, 640, 32, 32]           1,280
            ReLU-194          [-1, 640, 32, 32]               0
          Conv2d-195          [-1, 128, 32, 32]          81,920
     BatchNorm2d-196          [-1, 128, 32, 32]             256
            ReLU-197          [-1, 128, 32, 32]               0
          Conv2d-198           [-1, 32, 32, 32]          36,864
     BatchNorm2d-199          [-1, 672, 32, 32]           1,344
            ReLU-200          [-1, 672, 32, 32]               0
          Conv2d-201          [-1, 128, 32, 32]          86,016
     BatchNorm2d-202          [-1, 128, 32, 32]             256
            ReLU-203          [-1, 128, 32, 32]               0
          Conv2d-204           [-1, 32, 32, 32]          36,864
     BatchNorm2d-205          [-1, 704, 32, 32]           1,408
            ReLU-206          [-1, 704, 32, 32]               0
          Conv2d-207          [-1, 128, 32, 32]          90,112
     BatchNorm2d-208          [-1, 128, 32, 32]             256
            ReLU-209          [-1, 128, 32, 32]               0
          Conv2d-210           [-1, 32, 32, 32]          36,864
     BatchNorm2d-211          [-1, 736, 32, 32]           1,472
            ReLU-212          [-1, 736, 32, 32]               0
          Conv2d-213          [-1, 128, 32, 32]          94,208
     BatchNorm2d-214          [-1, 128, 32, 32]             256
            ReLU-215          [-1, 128, 32, 32]               0
          Conv2d-216           [-1, 32, 32, 32]          36,864
     BatchNorm2d-217          [-1, 768, 32, 32]           1,536
            ReLU-218          [-1, 768, 32, 32]               0
          Conv2d-219          [-1, 128, 32, 32]          98,304
     BatchNorm2d-220          [-1, 128, 32, 32]             256
            ReLU-221          [-1, 128, 32, 32]               0
          Conv2d-222           [-1, 32, 32, 32]          36,864
     BatchNorm2d-223          [-1, 800, 32, 32]           1,600
            ReLU-224          [-1, 800, 32, 32]               0
          Conv2d-225          [-1, 128, 32, 32]         102,400
     BatchNorm2d-226          [-1, 128, 32, 32]             256
            ReLU-227          [-1, 128, 32, 32]               0
          Conv2d-228           [-1, 32, 32, 32]          36,864
     BatchNorm2d-229          [-1, 832, 32, 32]           1,664
            ReLU-230          [-1, 832, 32, 32]               0
          Conv2d-231          [-1, 128, 32, 32]         106,496
     BatchNorm2d-232          [-1, 128, 32, 32]             256
            ReLU-233          [-1, 128, 32, 32]               0
          Conv2d-234           [-1, 32, 32, 32]          36,864
     BatchNorm2d-235          [-1, 864, 32, 32]           1,728
            ReLU-236          [-1, 864, 32, 32]               0
          Conv2d-237          [-1, 128, 32, 32]         110,592
     BatchNorm2d-238          [-1, 128, 32, 32]             256
            ReLU-239          [-1, 128, 32, 32]               0
          Conv2d-240           [-1, 32, 32, 32]          36,864
     BatchNorm2d-241          [-1, 896, 32, 32]           1,792
            ReLU-242          [-1, 896, 32, 32]               0
          Conv2d-243          [-1, 128, 32, 32]         114,688
     BatchNorm2d-244          [-1, 128, 32, 32]             256
            ReLU-245          [-1, 128, 32, 32]               0
          Conv2d-246           [-1, 32, 32, 32]          36,864
     BatchNorm2d-247          [-1, 928, 32, 32]           1,856
            ReLU-248          [-1, 928, 32, 32]               0
          Conv2d-249          [-1, 128, 32, 32]         118,784
     BatchNorm2d-250          [-1, 128, 32, 32]             256
            ReLU-251          [-1, 128, 32, 32]               0
          Conv2d-252           [-1, 32, 32, 32]          36,864
     BatchNorm2d-253          [-1, 960, 32, 32]           1,920
            ReLU-254          [-1, 960, 32, 32]               0
          Conv2d-255          [-1, 128, 32, 32]         122,880
     BatchNorm2d-256          [-1, 128, 32, 32]             256
            ReLU-257          [-1, 128, 32, 32]               0
          Conv2d-258           [-1, 32, 32, 32]          36,864
     BatchNorm2d-259          [-1, 992, 32, 32]           1,984
            ReLU-260          [-1, 992, 32, 32]               0
          Conv2d-261          [-1, 128, 32, 32]         126,976
     BatchNorm2d-262          [-1, 128, 32, 32]             256
            ReLU-263          [-1, 128, 32, 32]               0
          Conv2d-264           [-1, 32, 32, 32]          36,864
     BatchNorm2d-265         [-1, 1024, 32, 32]           2,048
            ReLU-266         [-1, 1024, 32, 32]               0
          Conv2d-267          [-1, 512, 32, 32]         524,288
       AvgPool2d-268          [-1, 512, 16, 16]               0
     BatchNorm2d-269          [-1, 512, 16, 16]           1,024
            ReLU-270          [-1, 512, 16, 16]               0
          Conv2d-271          [-1, 128, 16, 16]          65,536
     BatchNorm2d-272          [-1, 128, 16, 16]             256
            ReLU-273          [-1, 128, 16, 16]               0
          Conv2d-274           [-1, 32, 16, 16]          36,864
     BatchNorm2d-275          [-1, 544, 16, 16]           1,088
            ReLU-276          [-1, 544, 16, 16]               0
          Conv2d-277          [-1, 128, 16, 16]          69,632
     BatchNorm2d-278          [-1, 128, 16, 16]             256
            ReLU-279          [-1, 128, 16, 16]               0
          Conv2d-280           [-1, 32, 16, 16]          36,864
     BatchNorm2d-281          [-1, 576, 16, 16]           1,152
            ReLU-282          [-1, 576, 16, 16]               0
          Conv2d-283          [-1, 128, 16, 16]          73,728
     BatchNorm2d-284          [-1, 128, 16, 16]             256
            ReLU-285          [-1, 128, 16, 16]               0
          Conv2d-286           [-1, 32, 16, 16]          36,864
     BatchNorm2d-287          [-1, 608, 16, 16]           1,216
            ReLU-288          [-1, 608, 16, 16]               0
          Conv2d-289          [-1, 128, 16, 16]          77,824
     BatchNorm2d-290          [-1, 128, 16, 16]             256
            ReLU-291          [-1, 128, 16, 16]               0
          Conv2d-292           [-1, 32, 16, 16]          36,864
     BatchNorm2d-293          [-1, 640, 16, 16]           1,280
            ReLU-294          [-1, 640, 16, 16]               0
          Conv2d-295          [-1, 128, 16, 16]          81,920
     BatchNorm2d-296          [-1, 128, 16, 16]             256
            ReLU-297          [-1, 128, 16, 16]               0
          Conv2d-298           [-1, 32, 16, 16]          36,864
     BatchNorm2d-299          [-1, 672, 16, 16]           1,344
            ReLU-300          [-1, 672, 16, 16]               0
          Conv2d-301          [-1, 128, 16, 16]          86,016
     BatchNorm2d-302          [-1, 128, 16, 16]             256
            ReLU-303          [-1, 128, 16, 16]               0
          Conv2d-304           [-1, 32, 16, 16]          36,864
     BatchNorm2d-305          [-1, 704, 16, 16]           1,408
            ReLU-306          [-1, 704, 16, 16]               0
          Conv2d-307          [-1, 128, 16, 16]          90,112
     BatchNorm2d-308          [-1, 128, 16, 16]             256
            ReLU-309          [-1, 128, 16, 16]               0
          Conv2d-310           [-1, 32, 16, 16]          36,864
     BatchNorm2d-311          [-1, 736, 16, 16]           1,472
            ReLU-312          [-1, 736, 16, 16]               0
          Conv2d-313          [-1, 128, 16, 16]          94,208
     BatchNorm2d-314          [-1, 128, 16, 16]             256
            ReLU-315          [-1, 128, 16, 16]               0
          Conv2d-316           [-1, 32, 16, 16]          36,864
     BatchNorm2d-317          [-1, 768, 16, 16]           1,536
            ReLU-318          [-1, 768, 16, 16]               0
          Conv2d-319          [-1, 128, 16, 16]          98,304
     BatchNorm2d-320          [-1, 128, 16, 16]             256
            ReLU-321          [-1, 128, 16, 16]               0
          Conv2d-322           [-1, 32, 16, 16]          36,864
     BatchNorm2d-323          [-1, 800, 16, 16]           1,600
            ReLU-324          [-1, 800, 16, 16]               0
          Conv2d-325          [-1, 128, 16, 16]         102,400
     BatchNorm2d-326          [-1, 128, 16, 16]             256
            ReLU-327          [-1, 128, 16, 16]               0
          Conv2d-328           [-1, 32, 16, 16]          36,864
     BatchNorm2d-329          [-1, 832, 16, 16]           1,664
            ReLU-330          [-1, 832, 16, 16]               0
          Conv2d-331          [-1, 128, 16, 16]         106,496
     BatchNorm2d-332          [-1, 128, 16, 16]             256
            ReLU-333          [-1, 128, 16, 16]               0
          Conv2d-334           [-1, 32, 16, 16]          36,864
     BatchNorm2d-335          [-1, 864, 16, 16]           1,728
            ReLU-336          [-1, 864, 16, 16]               0
          Conv2d-337          [-1, 128, 16, 16]         110,592
     BatchNorm2d-338          [-1, 128, 16, 16]             256
            ReLU-339          [-1, 128, 16, 16]               0
          Conv2d-340           [-1, 32, 16, 16]          36,864
     BatchNorm2d-341          [-1, 896, 16, 16]           1,792
            ReLU-342          [-1, 896, 16, 16]               0
          Conv2d-343          [-1, 128, 16, 16]         114,688
     BatchNorm2d-344          [-1, 128, 16, 16]             256
            ReLU-345          [-1, 128, 16, 16]               0
          Conv2d-346           [-1, 32, 16, 16]          36,864
     BatchNorm2d-347          [-1, 928, 16, 16]           1,856
            ReLU-348          [-1, 928, 16, 16]               0
          Conv2d-349          [-1, 128, 16, 16]         118,784
     BatchNorm2d-350          [-1, 128, 16, 16]             256
            ReLU-351          [-1, 128, 16, 16]               0
          Conv2d-352           [-1, 32, 16, 16]          36,864
     BatchNorm2d-353          [-1, 960, 16, 16]           1,920
            ReLU-354          [-1, 960, 16, 16]               0
          Conv2d-355          [-1, 128, 16, 16]         122,880
     BatchNorm2d-356          [-1, 128, 16, 16]             256
            ReLU-357          [-1, 128, 16, 16]               0
          Conv2d-358           [-1, 32, 16, 16]          36,864
     BatchNorm2d-359          [-1, 992, 16, 16]           1,984
            ReLU-360          [-1, 992, 16, 16]               0
          Conv2d-361          [-1, 128, 16, 16]         126,976
     BatchNorm2d-362          [-1, 128, 16, 16]             256
            ReLU-363          [-1, 128, 16, 16]               0
          Conv2d-364           [-1, 32, 16, 16]          36,864
     BatchNorm2d-365         [-1, 1024, 16, 16]           2,048
        DenseNet-366         [-1, 1024, 16, 16]               0
AdaptiveAvgPool2d-367           [-1, 1024, 1, 1]               0
          Conv2d-368           [-1, 1024, 1, 1]       1,049,600
     BatchNorm2d-369           [-1, 1024, 1, 1]           2,048
            ReLU-370           [-1, 1024, 1, 1]               0
  Conv2dNormRelu-371           [-1, 1024, 1, 1]               0
          Conv2d-372         [-1, 1024, 16, 16]       1,049,600
     BatchNorm2d-373         [-1, 1024, 16, 16]           2,048
            ReLU-374         [-1, 1024, 16, 16]               0
  Conv2dNormRelu-375         [-1, 1024, 16, 16]               0
          Conv2d-376              [-1, 1, 8, 8]          50,177
     BatchNorm2d-377              [-1, 1, 8, 8]               2
            ReLU-378              [-1, 1, 8, 8]               0
  Conv2dNormRelu-379              [-1, 1, 8, 8]               0
          Conv2d-380              [-1, 1, 4, 4]              26
     BatchNorm2d-381              [-1, 1, 4, 4]               2
            ReLU-382              [-1, 1, 4, 4]               0
  Conv2dNormRelu-383              [-1, 1, 4, 4]               0
          Conv2d-384              [-1, 1, 2, 2]              10
     BatchNorm2d-385              [-1, 1, 2, 2]               2
            ReLU-386              [-1, 1, 2, 2]               0
  Conv2dNormRelu-387              [-1, 1, 2, 2]               0
          Conv2d-388              [-1, 1, 2, 2]              10
     BatchNorm2d-389              [-1, 1, 2, 2]               2
            ReLU-390              [-1, 1, 2, 2]               0
  Conv2dNormRelu-391              [-1, 1, 2, 2]               0
          Conv2d-392              [-1, 1, 4, 4]              26
     BatchNorm2d-393              [-1, 1, 4, 4]               2
            ReLU-394              [-1, 1, 4, 4]               0
  Conv2dNormRelu-395              [-1, 1, 4, 4]               0
          Conv2d-396              [-1, 1, 8, 8]              50
     BatchNorm2d-397              [-1, 1, 8, 8]               2
            ReLU-398              [-1, 1, 8, 8]               0
  Conv2dNormRelu-399              [-1, 1, 8, 8]               0
       FPAModule-400         [-1, 1024, 16, 16]               0
    AttentionMap-401         [-1, 1024, 16, 16]               0
          Conv2d-402            [-1, 1, 16, 16]           1,025
        PcamPool-403           [-1, 1024, 1, 1]               0
      GlobalPool-404           [-1, 1024, 1, 1]               0
     BatchNorm2d-405           [-1, 1024, 1, 1]           2,048
          Conv2d-406              [-1, 1, 1, 1]           1,025
        PcamPool-407           [-1, 1024, 1, 1]               0
      GlobalPool-408           [-1, 1024, 1, 1]               0
          Linear-409                    [-1, 1]           1,025
================================================================
Total params: 9,112,586
Trainable params: 9,112,586
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 3.00
Forward/backward pass size (MB): 1551.09
Params size (MB): 34.76
Estimated Total Size (MB): 1588.85
----------------------------------------------------------------
INFO:root:2024-04-27 08:58:17, Train, Epoch : 1, Step : 10, Loss : 0.72485, Acc : 0.578, Sensitive_Loss : 0.63401, Sensitive_Acc : 17.000, Run Time : 23.33 sec
INFO:root:2024-04-27 08:58:35, Train, Epoch : 1, Step : 20, Loss : 0.65577, Acc : 0.634, Sensitive_Loss : 0.63227, Sensitive_Acc : 14.500, Run Time : 17.95 sec
INFO:root:2024-04-27 08:58:52, Train, Epoch : 1, Step : 30, Loss : 0.61975, Acc : 0.697, Sensitive_Loss : 0.57610, Sensitive_Acc : 15.600, Run Time : 17.37 sec
INFO:root:2024-04-27 08:59:10, Train, Epoch : 1, Step : 40, Loss : 0.63955, Acc : 0.709, Sensitive_Loss : 0.51412, Sensitive_Acc : 15.400, Run Time : 17.61 sec
INFO:root:2024-04-27 08:59:28, Train, Epoch : 1, Step : 50, Loss : 0.51347, Acc : 0.734, Sensitive_Loss : 0.46261, Sensitive_Acc : 16.300, Run Time : 18.32 sec
INFO:root:2024-04-27 08:59:46, Train, Epoch : 1, Step : 60, Loss : 0.61220, Acc : 0.713, Sensitive_Loss : 0.40216, Sensitive_Acc : 15.500, Run Time : 18.06 sec
INFO:root:2024-04-27 09:00:04, Train, Epoch : 1, Step : 70, Loss : 0.50681, Acc : 0.775, Sensitive_Loss : 0.39402, Sensitive_Acc : 15.100, Run Time : 17.38 sec
INFO:root:2024-04-27 09:00:21, Train, Epoch : 1, Step : 80, Loss : 0.63285, Acc : 0.741, Sensitive_Loss : 0.33825, Sensitive_Acc : 15.000, Run Time : 17.62 sec
INFO:root:2024-04-27 09:00:39, Train, Epoch : 1, Step : 90, Loss : 0.51510, Acc : 0.766, Sensitive_Loss : 0.31731, Sensitive_Acc : 16.400, Run Time : 17.68 sec
INFO:root:2024-04-27 09:00:56, Train, Epoch : 1, Step : 100, Loss : 0.47388, Acc : 0.781, Sensitive_Loss : 0.33752, Sensitive_Acc : 16.900, Run Time : 17.38 sec
INFO:root:2024-04-27 09:05:00, Dev, Step : 100, Loss : 0.56245, Acc : 0.740, Auc : 0.857, Sensitive_Loss : 0.36517, Sensitive_Acc : 16.443, Sensitive_Auc : 0.951, Mean auc: 0.857, Run Time : 243.87 sec
INFO:root:2024-04-27 09:05:01, Best, Step : 100, Loss : 0.56245, Acc : 0.740, Auc : 0.857, Sensitive_Loss : 0.36517, Sensitive_Acc : 16.443, Sensitive_Auc : 0.951, Best Auc : 0.857
INFO:root:2024-04-27 09:05:15, Train, Epoch : 1, Step : 110, Loss : 0.54158, Acc : 0.741, Sensitive_Loss : 0.29930, Sensitive_Acc : 16.100, Run Time : 258.36 sec
INFO:root:2024-04-27 09:05:32, Train, Epoch : 1, Step : 120, Loss : 0.52707, Acc : 0.791, Sensitive_Loss : 0.32117, Sensitive_Acc : 17.000, Run Time : 17.74 sec
INFO:root:2024-04-27 09:05:51, Train, Epoch : 1, Step : 130, Loss : 0.58842, Acc : 0.734, Sensitive_Loss : 0.29192, Sensitive_Acc : 16.000, Run Time : 18.49 sec
INFO:root:2024-04-27 09:06:08, Train, Epoch : 1, Step : 140, Loss : 0.47737, Acc : 0.772, Sensitive_Loss : 0.31666, Sensitive_Acc : 16.400, Run Time : 17.33 sec
INFO:root:2024-04-27 09:06:25, Train, Epoch : 1, Step : 150, Loss : 0.55954, Acc : 0.731, Sensitive_Loss : 0.29047, Sensitive_Acc : 14.700, Run Time : 17.19 sec
INFO:root:2024-04-27 09:06:44, Train, Epoch : 1, Step : 160, Loss : 0.53146, Acc : 0.759, Sensitive_Loss : 0.27471, Sensitive_Acc : 15.400, Run Time : 18.16 sec
INFO:root:2024-04-27 09:07:02, Train, Epoch : 1, Step : 170, Loss : 0.54500, Acc : 0.756, Sensitive_Loss : 0.28886, Sensitive_Acc : 16.300, Run Time : 17.95 sec
INFO:root:2024-04-27 09:07:19, Train, Epoch : 1, Step : 180, Loss : 0.49885, Acc : 0.766, Sensitive_Loss : 0.27278, Sensitive_Acc : 16.400, Run Time : 16.99 sec
INFO:root:2024-04-27 09:07:36, Train, Epoch : 1, Step : 190, Loss : 0.49469, Acc : 0.778, Sensitive_Loss : 0.25127, Sensitive_Acc : 15.800, Run Time : 17.73 sec
INFO:root:2024-04-27 09:07:53, Train, Epoch : 1, Step : 200, Loss : 0.43355, Acc : 0.797, Sensitive_Loss : 0.29929, Sensitive_Acc : 15.100, Run Time : 16.71 sec
INFO:root:2024-04-27 09:11:59, Dev, Step : 200, Loss : 0.50364, Acc : 0.774, Auc : 0.867, Sensitive_Loss : 0.36317, Sensitive_Acc : 16.850, Sensitive_Auc : 0.979, Mean auc: 0.867, Run Time : 246.23 sec
INFO:root:2024-04-27 09:12:00, Best, Step : 200, Loss : 0.50364, Acc : 0.774, Auc : 0.867, Sensitive_Loss : 0.36317, Sensitive_Acc : 16.850, Sensitive_Auc : 0.979, Best Auc : 0.867
INFO:root:2024-04-27 09:12:12, Train, Epoch : 1, Step : 210, Loss : 0.45437, Acc : 0.800, Sensitive_Loss : 0.22089, Sensitive_Acc : 14.000, Run Time : 259.15 sec
INFO:root:2024-04-27 09:12:30, Train, Epoch : 1, Step : 220, Loss : 0.53345, Acc : 0.762, Sensitive_Loss : 0.24493, Sensitive_Acc : 17.200, Run Time : 17.34 sec
INFO:root:2024-04-27 09:12:47, Train, Epoch : 1, Step : 230, Loss : 0.40358, Acc : 0.781, Sensitive_Loss : 0.23485, Sensitive_Acc : 17.500, Run Time : 17.82 sec
INFO:root:2024-04-27 09:13:04, Train, Epoch : 1, Step : 240, Loss : 0.49919, Acc : 0.772, Sensitive_Loss : 0.26783, Sensitive_Acc : 16.400, Run Time : 17.00 sec
INFO:root:2024-04-27 09:13:23, Train, Epoch : 1, Step : 250, Loss : 0.42254, Acc : 0.791, Sensitive_Loss : 0.25050, Sensitive_Acc : 16.600, Run Time : 18.42 sec
INFO:root:2024-04-27 09:13:39, Train, Epoch : 1, Step : 260, Loss : 0.54851, Acc : 0.725, Sensitive_Loss : 0.26757, Sensitive_Acc : 17.000, Run Time : 16.44 sec
INFO:root:2024-04-27 09:13:58, Train, Epoch : 1, Step : 270, Loss : 0.47303, Acc : 0.778, Sensitive_Loss : 0.26443, Sensitive_Acc : 16.300, Run Time : 19.06 sec
INFO:root:2024-04-27 09:14:16, Train, Epoch : 1, Step : 280, Loss : 0.39946, Acc : 0.803, Sensitive_Loss : 0.26881, Sensitive_Acc : 16.800, Run Time : 17.34 sec
INFO:root:2024-04-27 09:14:33, Train, Epoch : 1, Step : 290, Loss : 0.48462, Acc : 0.822, Sensitive_Loss : 0.23064, Sensitive_Acc : 15.500, Run Time : 17.28 sec
INFO:root:2024-04-27 09:14:51, Train, Epoch : 1, Step : 300, Loss : 0.46430, Acc : 0.803, Sensitive_Loss : 0.21222, Sensitive_Acc : 15.600, Run Time : 17.73 sec
INFO:root:2024-04-27 09:18:55, Dev, Step : 300, Loss : 0.49244, Acc : 0.787, Auc : 0.872, Sensitive_Loss : 0.23830, Sensitive_Acc : 16.800, Sensitive_Auc : 0.976, Mean auc: 0.872, Run Time : 244.62 sec
INFO:root:2024-04-27 09:18:56, Best, Step : 300, Loss : 0.49244, Acc : 0.787, Auc : 0.872, Sensitive_Loss : 0.23830, Sensitive_Acc : 16.800, Sensitive_Auc : 0.976, Best Auc : 0.872
INFO:root:2024-04-27 09:19:08, Train, Epoch : 1, Step : 310, Loss : 0.38788, Acc : 0.809, Sensitive_Loss : 0.27097, Sensitive_Acc : 15.400, Run Time : 257.29 sec
INFO:root:2024-04-27 09:19:25, Train, Epoch : 1, Step : 320, Loss : 0.51331, Acc : 0.750, Sensitive_Loss : 0.22987, Sensitive_Acc : 17.400, Run Time : 17.41 sec
INFO:root:2024-04-27 09:19:42, Train, Epoch : 1, Step : 330, Loss : 0.44531, Acc : 0.803, Sensitive_Loss : 0.22714, Sensitive_Acc : 15.500, Run Time : 16.87 sec
INFO:root:2024-04-27 09:19:58, Train, Epoch : 1, Step : 340, Loss : 0.57933, Acc : 0.728, Sensitive_Loss : 0.21401, Sensitive_Acc : 17.200, Run Time : 16.15 sec
INFO:root:2024-04-27 09:20:15, Train, Epoch : 1, Step : 350, Loss : 0.49130, Acc : 0.769, Sensitive_Loss : 0.23649, Sensitive_Acc : 14.700, Run Time : 16.30 sec
INFO:root:2024-04-27 09:20:32, Train, Epoch : 1, Step : 360, Loss : 0.44250, Acc : 0.822, Sensitive_Loss : 0.18566, Sensitive_Acc : 16.200, Run Time : 17.10 sec
INFO:root:2024-04-27 09:20:48, Train, Epoch : 1, Step : 370, Loss : 0.48017, Acc : 0.769, Sensitive_Loss : 0.21511, Sensitive_Acc : 16.000, Run Time : 16.36 sec
INFO:root:2024-04-27 09:21:07, Train, Epoch : 1, Step : 380, Loss : 0.53020, Acc : 0.731, Sensitive_Loss : 0.26092, Sensitive_Acc : 16.300, Run Time : 19.14 sec
INFO:root:2024-04-27 09:21:24, Train, Epoch : 1, Step : 390, Loss : 0.45874, Acc : 0.794, Sensitive_Loss : 0.21480, Sensitive_Acc : 16.400, Run Time : 16.43 sec
INFO:root:2024-04-27 09:21:42, Train, Epoch : 1, Step : 400, Loss : 0.43478, Acc : 0.800, Sensitive_Loss : 0.22806, Sensitive_Acc : 16.300, Run Time : 17.96 sec
INFO:root:2024-04-27 09:25:47, Dev, Step : 400, Loss : 0.50155, Acc : 0.773, Auc : 0.860, Sensitive_Loss : 0.22548, Sensitive_Acc : 16.536, Sensitive_Auc : 0.983, Mean auc: 0.860, Run Time : 244.94 sec
INFO:root:2024-04-27 09:25:58, Train, Epoch : 1, Step : 410, Loss : 0.45860, Acc : 0.784, Sensitive_Loss : 0.18944, Sensitive_Acc : 15.700, Run Time : 256.45 sec
INFO:root:2024-04-27 09:26:17, Train, Epoch : 1, Step : 420, Loss : 0.51141, Acc : 0.741, Sensitive_Loss : 0.21513, Sensitive_Acc : 17.300, Run Time : 18.87 sec
INFO:root:2024-04-27 09:26:32, Train, Epoch : 1, Step : 430, Loss : 0.47510, Acc : 0.762, Sensitive_Loss : 0.27396, Sensitive_Acc : 16.300, Run Time : 15.49 sec
INFO:root:2024-04-27 09:26:49, Train, Epoch : 1, Step : 440, Loss : 0.50882, Acc : 0.762, Sensitive_Loss : 0.22148, Sensitive_Acc : 16.700, Run Time : 16.92 sec
INFO:root:2024-04-27 09:27:07, Train, Epoch : 1, Step : 450, Loss : 0.42600, Acc : 0.797, Sensitive_Loss : 0.23315, Sensitive_Acc : 16.400, Run Time : 17.18 sec
INFO:root:2024-04-27 09:27:23, Train, Epoch : 1, Step : 460, Loss : 0.42260, Acc : 0.806, Sensitive_Loss : 0.22287, Sensitive_Acc : 15.800, Run Time : 16.86 sec
INFO:root:2024-04-27 09:27:41, Train, Epoch : 1, Step : 470, Loss : 0.50533, Acc : 0.778, Sensitive_Loss : 0.24700, Sensitive_Acc : 14.000, Run Time : 17.82 sec
INFO:root:2024-04-27 09:27:58, Train, Epoch : 1, Step : 480, Loss : 0.39243, Acc : 0.806, Sensitive_Loss : 0.21178, Sensitive_Acc : 14.400, Run Time : 16.37 sec
INFO:root:2024-04-27 09:28:14, Train, Epoch : 1, Step : 490, Loss : 0.44650, Acc : 0.806, Sensitive_Loss : 0.20567, Sensitive_Acc : 16.400, Run Time : 16.81 sec
INFO:root:2024-04-27 09:28:31, Train, Epoch : 1, Step : 500, Loss : 0.45491, Acc : 0.766, Sensitive_Loss : 0.15522, Sensitive_Acc : 16.900, Run Time : 16.12 sec
INFO:root:2024-04-27 09:32:37, Dev, Step : 500, Loss : 0.52249, Acc : 0.763, Auc : 0.877, Sensitive_Loss : 0.20205, Sensitive_Acc : 16.750, Sensitive_Auc : 0.981, Mean auc: 0.877, Run Time : 246.59 sec
INFO:root:2024-04-27 09:32:38, Best, Step : 500, Loss : 0.52249, Acc : 0.763, Auc : 0.877, Sensitive_Loss : 0.20205, Sensitive_Acc : 16.750, Sensitive_Auc : 0.981, Best Auc : 0.877
INFO:root:2024-04-27 09:32:49, Train, Epoch : 1, Step : 510, Loss : 0.43685, Acc : 0.803, Sensitive_Loss : 0.23047, Sensitive_Acc : 17.200, Run Time : 258.89 sec
INFO:root:2024-04-27 09:33:08, Train, Epoch : 1, Step : 520, Loss : 0.47999, Acc : 0.787, Sensitive_Loss : 0.19654, Sensitive_Acc : 16.200, Run Time : 18.21 sec
INFO:root:2024-04-27 09:33:23, Train, Epoch : 1, Step : 530, Loss : 0.44790, Acc : 0.794, Sensitive_Loss : 0.17320, Sensitive_Acc : 17.700, Run Time : 15.67 sec
INFO:root:2024-04-27 09:33:41, Train, Epoch : 1, Step : 540, Loss : 0.47307, Acc : 0.781, Sensitive_Loss : 0.17910, Sensitive_Acc : 17.400, Run Time : 18.00 sec
INFO:root:2024-04-27 09:33:56, Train, Epoch : 1, Step : 550, Loss : 0.51730, Acc : 0.772, Sensitive_Loss : 0.21942, Sensitive_Acc : 17.300, Run Time : 14.90 sec
INFO:root:2024-04-27 09:34:14, Train, Epoch : 1, Step : 560, Loss : 0.44597, Acc : 0.787, Sensitive_Loss : 0.18255, Sensitive_Acc : 17.100, Run Time : 18.00 sec
INFO:root:2024-04-27 09:34:32, Train, Epoch : 1, Step : 570, Loss : 0.49945, Acc : 0.794, Sensitive_Loss : 0.19380, Sensitive_Acc : 16.100, Run Time : 17.70 sec
INFO:root:2024-04-27 09:34:49, Train, Epoch : 1, Step : 580, Loss : 0.51529, Acc : 0.756, Sensitive_Loss : 0.20168, Sensitive_Acc : 16.000, Run Time : 17.03 sec
INFO:root:2024-04-27 09:35:07, Train, Epoch : 1, Step : 590, Loss : 0.46423, Acc : 0.753, Sensitive_Loss : 0.17608, Sensitive_Acc : 16.800, Run Time : 17.71 sec
INFO:root:2024-04-27 09:35:23, Train, Epoch : 1, Step : 600, Loss : 0.43541, Acc : 0.803, Sensitive_Loss : 0.17667, Sensitive_Acc : 14.600, Run Time : 16.55 sec
INFO:root:2024-04-27 09:39:29, Dev, Step : 600, Loss : 0.45138, Acc : 0.801, Auc : 0.881, Sensitive_Loss : 0.18448, Sensitive_Acc : 17.021, Sensitive_Auc : 0.983, Mean auc: 0.881, Run Time : 245.36 sec
INFO:root:2024-04-27 09:39:29, Best, Step : 600, Loss : 0.45138, Acc : 0.801, Auc : 0.881, Sensitive_Loss : 0.18448, Sensitive_Acc : 17.021, Sensitive_Auc : 0.983, Best Auc : 0.881
INFO:root:2024-04-27 09:39:41, Train, Epoch : 1, Step : 610, Loss : 0.42011, Acc : 0.784, Sensitive_Loss : 0.19436, Sensitive_Acc : 15.600, Run Time : 257.87 sec
INFO:root:2024-04-27 09:39:56, Train, Epoch : 1, Step : 620, Loss : 0.46121, Acc : 0.794, Sensitive_Loss : 0.22594, Sensitive_Acc : 16.200, Run Time : 15.26 sec
INFO:root:2024-04-27 09:44:06
INFO:root:y_pred: [0.07822587 0.84806895 0.02522195 ... 0.6380276  0.04103078 0.60228443]
INFO:root:y_true: [0. 1. 0. ... 1. 0. 1.]
INFO:root:sensitive_y_pred: [9.98394907e-01 8.68247764e-04 1.55122757e-01 1.95312649e-02
 9.87548590e-01 6.79643732e-03 9.99794781e-01 9.91019309e-01
 5.08036977e-03 3.33734304e-01 9.68303382e-01 9.99154687e-01
 9.94246781e-01 8.59915853e-01 9.35733765e-02 7.38721192e-01
 9.95975673e-01 1.94692705e-02 6.91145778e-01 8.89710307e-01
 9.96157110e-01 7.34748878e-03 9.98340726e-01 9.95081425e-01
 9.96449113e-01 9.61706519e-01 3.93059105e-02 9.88131642e-01
 9.94703114e-01 4.00008708e-02 2.03628466e-02 1.13915808e-01
 7.51664713e-02 7.62721971e-02 8.15153420e-02 2.13748589e-03
 1.16687343e-01 1.13505416e-01 9.98710155e-01 9.94236290e-01
 1.73481458e-05 1.06541777e-03 8.96776497e-01 1.71761180e-03
 9.98789251e-01 9.82764125e-01 9.97941673e-01 9.98101771e-01
 2.26891600e-03 9.73439813e-01 9.94104207e-01 1.63287185e-02
 8.02306294e-01 1.78371789e-03 1.24910718e-03 6.35489166e-01
 5.97243793e-02 1.55289436e-03 8.04645475e-04 1.22940183e-01
 3.61201242e-02 4.14239079e-01 1.02023400e-01 6.23208940e-01
 3.59548330e-01 9.98906493e-01 1.52988164e-02 9.98306274e-01
 8.67717683e-01 4.20542389e-01 5.17766893e-01 6.37679040e-01
 1.69823468e-01 2.88408082e-02 1.87943473e-01 1.69065417e-04
 1.92442294e-02 9.93879437e-02 4.56875190e-02 9.98097122e-01
 9.98686850e-01 8.08382500e-03 2.10435435e-01 3.59197594e-02
 6.94679141e-01 8.92721057e-01 5.51738665e-02 9.84630361e-02
 9.91709650e-01 9.99136031e-01 9.99197781e-01 8.41850881e-03
 1.88065127e-01 9.97537851e-01 7.48227894e-01 1.86781213e-02
 9.81187344e-01 9.96638417e-01 6.27788762e-03 1.50417924e-01
 9.93410289e-01 9.33483005e-01 9.74951208e-01 9.87577975e-01
 4.93275141e-03 1.02176450e-01 9.88661408e-01 9.93958712e-01
 9.63553905e-01 5.83424771e-05 8.36977601e-01 9.94565487e-01
 2.45556571e-02 9.98600066e-01 9.96424258e-01 9.69206929e-01
 7.84072161e-01 9.96450424e-01 1.40972346e-01 1.42789620e-03
 9.95130539e-01 9.99629974e-01 1.21609832e-04 9.98674750e-01
 9.99752343e-01 1.78672090e-01 9.75823343e-01 1.38195261e-01
 1.13490652e-02 9.88502026e-01 9.90922391e-01 9.36391875e-02
 2.40537478e-03 4.97607663e-02 9.97736216e-01 9.68660533e-01
 9.82959270e-01 1.49691559e-03 2.25885734e-01 9.37194228e-01]
INFO:root:sensitive_y_true: [1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.
 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.]
INFO:root:2024-04-27 09:44:06, Dev, Step : 626, Loss : 0.49353, Acc : 0.785, Auc : 0.874, Sensitive_Loss : 0.18772, Sensitive_Acc : 16.993, Sensitive_Auc : 0.991, Mean auc: 0.874, Run Time : 240.62 sec
INFO:root:2024-04-27 09:44:17, Train, Epoch : 2, Step : 630, Loss : 0.18557, Acc : 0.331, Sensitive_Loss : 0.04143, Sensitive_Acc : 6.500, Run Time : 9.19 sec
INFO:root:2024-04-27 09:44:33, Train, Epoch : 2, Step : 640, Loss : 0.38337, Acc : 0.850, Sensitive_Loss : 0.21274, Sensitive_Acc : 14.800, Run Time : 16.74 sec
INFO:root:2024-04-27 09:44:50, Train, Epoch : 2, Step : 650, Loss : 0.34030, Acc : 0.834, Sensitive_Loss : 0.24330, Sensitive_Acc : 17.200, Run Time : 17.01 sec
INFO:root:2024-04-27 09:45:08, Train, Epoch : 2, Step : 660, Loss : 0.38401, Acc : 0.834, Sensitive_Loss : 0.16823, Sensitive_Acc : 15.100, Run Time : 17.23 sec
INFO:root:2024-04-27 09:45:25, Train, Epoch : 2, Step : 670, Loss : 0.43934, Acc : 0.828, Sensitive_Loss : 0.15909, Sensitive_Acc : 16.500, Run Time : 17.52 sec
INFO:root:2024-04-27 09:45:42, Train, Epoch : 2, Step : 680, Loss : 0.45563, Acc : 0.791, Sensitive_Loss : 0.17930, Sensitive_Acc : 15.800, Run Time : 17.00 sec
INFO:root:2024-04-27 09:45:59, Train, Epoch : 2, Step : 690, Loss : 0.51027, Acc : 0.753, Sensitive_Loss : 0.25645, Sensitive_Acc : 14.800, Run Time : 17.21 sec
INFO:root:2024-04-27 09:46:15, Train, Epoch : 2, Step : 700, Loss : 0.39138, Acc : 0.803, Sensitive_Loss : 0.16227, Sensitive_Acc : 15.600, Run Time : 16.03 sec
INFO:root:2024-04-27 09:50:22, Dev, Step : 700, Loss : 0.46808, Acc : 0.795, Auc : 0.873, Sensitive_Loss : 0.19516, Sensitive_Acc : 16.700, Sensitive_Auc : 0.987, Mean auc: 0.873, Run Time : 246.28 sec
INFO:root:2024-04-27 09:50:35, Train, Epoch : 2, Step : 710, Loss : 0.46404, Acc : 0.797, Sensitive_Loss : 0.18750, Sensitive_Acc : 15.700, Run Time : 259.77 sec
INFO:root:2024-04-27 09:50:52, Train, Epoch : 2, Step : 720, Loss : 0.40558, Acc : 0.831, Sensitive_Loss : 0.15716, Sensitive_Acc : 16.500, Run Time : 16.50 sec
INFO:root:2024-04-27 09:51:09, Train, Epoch : 2, Step : 730, Loss : 0.41078, Acc : 0.812, Sensitive_Loss : 0.17889, Sensitive_Acc : 15.900, Run Time : 17.18 sec
INFO:root:2024-04-27 09:51:27, Train, Epoch : 2, Step : 740, Loss : 0.38547, Acc : 0.828, Sensitive_Loss : 0.20137, Sensitive_Acc : 16.800, Run Time : 17.82 sec
INFO:root:2024-04-27 09:51:44, Train, Epoch : 2, Step : 750, Loss : 0.45860, Acc : 0.791, Sensitive_Loss : 0.14737, Sensitive_Acc : 15.800, Run Time : 17.08 sec
INFO:root:2024-04-27 09:52:02, Train, Epoch : 2, Step : 760, Loss : 0.45264, Acc : 0.803, Sensitive_Loss : 0.19619, Sensitive_Acc : 14.200, Run Time : 18.02 sec
INFO:root:2024-04-27 09:52:19, Train, Epoch : 2, Step : 770, Loss : 0.41600, Acc : 0.819, Sensitive_Loss : 0.13924, Sensitive_Acc : 16.600, Run Time : 17.25 sec
INFO:root:2024-04-27 09:52:36, Train, Epoch : 2, Step : 780, Loss : 0.41054, Acc : 0.803, Sensitive_Loss : 0.12747, Sensitive_Acc : 16.100, Run Time : 16.75 sec
INFO:root:2024-04-27 09:52:53, Train, Epoch : 2, Step : 790, Loss : 0.36690, Acc : 0.831, Sensitive_Loss : 0.17996, Sensitive_Acc : 16.800, Run Time : 17.17 sec
INFO:root:2024-04-27 09:53:11, Train, Epoch : 2, Step : 800, Loss : 0.42938, Acc : 0.809, Sensitive_Loss : 0.13831, Sensitive_Acc : 16.900, Run Time : 17.77 sec
INFO:root:2024-04-27 09:57:14, Dev, Step : 800, Loss : 0.44453, Acc : 0.804, Auc : 0.884, Sensitive_Loss : 0.16674, Sensitive_Acc : 16.936, Sensitive_Auc : 0.990, Mean auc: 0.884, Run Time : 243.70 sec
INFO:root:2024-04-27 09:57:16, Best, Step : 800, Loss : 0.44453, Acc : 0.804, Auc : 0.884, Sensitive_Loss : 0.16674, Sensitive_Acc : 16.936, Sensitive_Auc : 0.990, Best Auc : 0.884
INFO:root:2024-04-27 09:57:28, Train, Epoch : 2, Step : 810, Loss : 0.38573, Acc : 0.825, Sensitive_Loss : 0.14280, Sensitive_Acc : 15.800, Run Time : 257.37 sec
INFO:root:2024-04-27 09:57:45, Train, Epoch : 2, Step : 820, Loss : 0.40931, Acc : 0.847, Sensitive_Loss : 0.14744, Sensitive_Acc : 17.400, Run Time : 17.11 sec
INFO:root:2024-04-27 09:58:03, Train, Epoch : 2, Step : 830, Loss : 0.40082, Acc : 0.803, Sensitive_Loss : 0.12589, Sensitive_Acc : 15.400, Run Time : 17.31 sec
INFO:root:2024-04-27 09:58:20, Train, Epoch : 2, Step : 840, Loss : 0.52887, Acc : 0.781, Sensitive_Loss : 0.15972, Sensitive_Acc : 17.400, Run Time : 17.23 sec
INFO:root:2024-04-27 09:58:37, Train, Epoch : 2, Step : 850, Loss : 0.47857, Acc : 0.794, Sensitive_Loss : 0.13888, Sensitive_Acc : 17.300, Run Time : 16.90 sec
INFO:root:2024-04-27 09:58:55, Train, Epoch : 2, Step : 860, Loss : 0.39636, Acc : 0.831, Sensitive_Loss : 0.18655, Sensitive_Acc : 16.100, Run Time : 18.20 sec
INFO:root:2024-04-27 09:59:11, Train, Epoch : 2, Step : 870, Loss : 0.37173, Acc : 0.816, Sensitive_Loss : 0.12572, Sensitive_Acc : 16.600, Run Time : 16.36 sec
INFO:root:2024-04-27 09:59:28, Train, Epoch : 2, Step : 880, Loss : 0.42960, Acc : 0.825, Sensitive_Loss : 0.16439, Sensitive_Acc : 16.200, Run Time : 16.96 sec
INFO:root:2024-04-27 09:59:46, Train, Epoch : 2, Step : 890, Loss : 0.37484, Acc : 0.841, Sensitive_Loss : 0.15856, Sensitive_Acc : 17.500, Run Time : 17.62 sec
INFO:root:2024-04-27 10:00:03, Train, Epoch : 2, Step : 900, Loss : 0.40535, Acc : 0.809, Sensitive_Loss : 0.16170, Sensitive_Acc : 16.600, Run Time : 17.21 sec
INFO:root:2024-04-27 10:04:08, Dev, Step : 900, Loss : 0.46067, Acc : 0.799, Auc : 0.878, Sensitive_Loss : 0.16986, Sensitive_Acc : 16.950, Sensitive_Auc : 0.990, Mean auc: 0.878, Run Time : 245.14 sec
INFO:root:2024-04-27 10:04:20, Train, Epoch : 2, Step : 910, Loss : 0.47115, Acc : 0.806, Sensitive_Loss : 0.19151, Sensitive_Acc : 15.500, Run Time : 256.73 sec
INFO:root:2024-04-27 10:04:38, Train, Epoch : 2, Step : 920, Loss : 0.46328, Acc : 0.769, Sensitive_Loss : 0.13933, Sensitive_Acc : 15.800, Run Time : 17.72 sec
INFO:root:2024-04-27 10:04:54, Train, Epoch : 2, Step : 930, Loss : 0.39792, Acc : 0.841, Sensitive_Loss : 0.15065, Sensitive_Acc : 17.000, Run Time : 16.98 sec
INFO:root:2024-04-27 10:05:12, Train, Epoch : 2, Step : 940, Loss : 0.44461, Acc : 0.794, Sensitive_Loss : 0.14504, Sensitive_Acc : 15.700, Run Time : 17.38 sec
INFO:root:2024-04-27 10:05:30, Train, Epoch : 2, Step : 950, Loss : 0.46048, Acc : 0.784, Sensitive_Loss : 0.12844, Sensitive_Acc : 16.300, Run Time : 18.13 sec
INFO:root:2024-04-27 10:05:47, Train, Epoch : 2, Step : 960, Loss : 0.49717, Acc : 0.803, Sensitive_Loss : 0.12091, Sensitive_Acc : 15.800, Run Time : 16.64 sec
INFO:root:2024-04-27 10:06:03, Train, Epoch : 2, Step : 970, Loss : 0.39898, Acc : 0.844, Sensitive_Loss : 0.11515, Sensitive_Acc : 15.100, Run Time : 16.19 sec
INFO:root:2024-04-27 10:06:21, Train, Epoch : 2, Step : 980, Loss : 0.33774, Acc : 0.838, Sensitive_Loss : 0.12516, Sensitive_Acc : 17.300, Run Time : 18.08 sec
INFO:root:2024-04-27 10:06:37, Train, Epoch : 2, Step : 990, Loss : 0.49330, Acc : 0.803, Sensitive_Loss : 0.15009, Sensitive_Acc : 15.300, Run Time : 16.59 sec
INFO:root:2024-04-27 10:06:55, Train, Epoch : 2, Step : 1000, Loss : 0.39460, Acc : 0.834, Sensitive_Loss : 0.18640, Sensitive_Acc : 16.600, Run Time : 17.29 sec
INFO:root:2024-04-27 10:11:00, Dev, Step : 1000, Loss : 0.47942, Acc : 0.790, Auc : 0.890, Sensitive_Loss : 0.20304, Sensitive_Acc : 16.750, Sensitive_Auc : 0.991, Mean auc: 0.890, Run Time : 244.84 sec
INFO:root:2024-04-27 10:11:00, Best, Step : 1000, Loss : 0.47942, Acc : 0.790, Auc : 0.890, Sensitive_Loss : 0.20304, Sensitive_Acc : 16.750, Sensitive_Auc : 0.991, Best Auc : 0.890
INFO:root:2024-04-27 10:11:13, Train, Epoch : 2, Step : 1010, Loss : 0.34637, Acc : 0.822, Sensitive_Loss : 0.14780, Sensitive_Acc : 17.100, Run Time : 258.27 sec
INFO:root:2024-04-27 10:11:29, Train, Epoch : 2, Step : 1020, Loss : 0.47861, Acc : 0.791, Sensitive_Loss : 0.12288, Sensitive_Acc : 17.000, Run Time : 16.34 sec
INFO:root:2024-04-27 10:11:47, Train, Epoch : 2, Step : 1030, Loss : 0.42113, Acc : 0.816, Sensitive_Loss : 0.13463, Sensitive_Acc : 16.400, Run Time : 17.55 sec
INFO:root:2024-04-27 10:12:04, Train, Epoch : 2, Step : 1040, Loss : 0.49008, Acc : 0.794, Sensitive_Loss : 0.12749, Sensitive_Acc : 15.000, Run Time : 17.32 sec
INFO:root:2024-04-27 10:12:22, Train, Epoch : 2, Step : 1050, Loss : 0.51690, Acc : 0.791, Sensitive_Loss : 0.09070, Sensitive_Acc : 18.400, Run Time : 17.77 sec
INFO:root:2024-04-27 10:12:40, Train, Epoch : 2, Step : 1060, Loss : 0.42726, Acc : 0.772, Sensitive_Loss : 0.15004, Sensitive_Acc : 15.300, Run Time : 18.10 sec
INFO:root:2024-04-27 10:12:56, Train, Epoch : 2, Step : 1070, Loss : 0.38528, Acc : 0.812, Sensitive_Loss : 0.13128, Sensitive_Acc : 16.700, Run Time : 15.84 sec
INFO:root:2024-04-27 10:13:13, Train, Epoch : 2, Step : 1080, Loss : 0.42300, Acc : 0.812, Sensitive_Loss : 0.17524, Sensitive_Acc : 16.200, Run Time : 16.82 sec
INFO:root:2024-04-27 10:13:31, Train, Epoch : 2, Step : 1090, Loss : 0.41026, Acc : 0.831, Sensitive_Loss : 0.17419, Sensitive_Acc : 16.900, Run Time : 18.32 sec
INFO:root:2024-04-27 10:13:48, Train, Epoch : 2, Step : 1100, Loss : 0.44353, Acc : 0.822, Sensitive_Loss : 0.18833, Sensitive_Acc : 17.500, Run Time : 17.26 sec
INFO:root:2024-04-27 10:17:53, Dev, Step : 1100, Loss : 0.52859, Acc : 0.764, Auc : 0.895, Sensitive_Loss : 0.24336, Sensitive_Acc : 16.721, Sensitive_Auc : 0.992, Mean auc: 0.895, Run Time : 244.90 sec
INFO:root:2024-04-27 10:17:54, Best, Step : 1100, Loss : 0.52859, Acc : 0.764, Auc : 0.895, Sensitive_Loss : 0.24336, Sensitive_Acc : 16.721, Sensitive_Auc : 0.992, Best Auc : 0.895
INFO:root:2024-04-27 10:18:09, Train, Epoch : 2, Step : 1110, Loss : 0.42047, Acc : 0.803, Sensitive_Loss : 0.19661, Sensitive_Acc : 16.200, Run Time : 260.28 sec
INFO:root:2024-04-27 10:18:25, Train, Epoch : 2, Step : 1120, Loss : 0.34903, Acc : 0.828, Sensitive_Loss : 0.12616, Sensitive_Acc : 17.400, Run Time : 15.95 sec
INFO:root:2024-04-27 10:18:42, Train, Epoch : 2, Step : 1130, Loss : 0.42279, Acc : 0.831, Sensitive_Loss : 0.13578, Sensitive_Acc : 16.300, Run Time : 17.62 sec
INFO:root:2024-04-27 10:18:59, Train, Epoch : 2, Step : 1140, Loss : 0.42678, Acc : 0.834, Sensitive_Loss : 0.14518, Sensitive_Acc : 16.500, Run Time : 17.04 sec
INFO:root:2024-04-27 10:19:16, Train, Epoch : 2, Step : 1150, Loss : 0.47572, Acc : 0.759, Sensitive_Loss : 0.18795, Sensitive_Acc : 16.600, Run Time : 16.90 sec
INFO:root:2024-04-27 10:19:33, Train, Epoch : 2, Step : 1160, Loss : 0.45204, Acc : 0.809, Sensitive_Loss : 0.16718, Sensitive_Acc : 14.200, Run Time : 17.12 sec
INFO:root:2024-04-27 10:19:52, Train, Epoch : 2, Step : 1170, Loss : 0.38774, Acc : 0.850, Sensitive_Loss : 0.16935, Sensitive_Acc : 17.100, Run Time : 18.28 sec
INFO:root:2024-04-27 10:20:10, Train, Epoch : 2, Step : 1180, Loss : 0.45868, Acc : 0.809, Sensitive_Loss : 0.12372, Sensitive_Acc : 16.100, Run Time : 18.10 sec
INFO:root:2024-04-27 10:20:27, Train, Epoch : 2, Step : 1190, Loss : 0.43761, Acc : 0.806, Sensitive_Loss : 0.11862, Sensitive_Acc : 15.200, Run Time : 17.63 sec
INFO:root:2024-04-27 10:20:44, Train, Epoch : 2, Step : 1200, Loss : 0.51330, Acc : 0.756, Sensitive_Loss : 0.11986, Sensitive_Acc : 15.900, Run Time : 16.48 sec
INFO:root:2024-04-27 10:24:48, Dev, Step : 1200, Loss : 0.49314, Acc : 0.780, Auc : 0.880, Sensitive_Loss : 0.27947, Sensitive_Acc : 16.807, Sensitive_Auc : 0.993, Mean auc: 0.880, Run Time : 244.56 sec
INFO:root:2024-04-27 10:25:02, Train, Epoch : 2, Step : 1210, Loss : 0.49287, Acc : 0.778, Sensitive_Loss : 0.11921, Sensitive_Acc : 16.200, Run Time : 258.00 sec
INFO:root:2024-04-27 10:25:17, Train, Epoch : 2, Step : 1220, Loss : 0.48267, Acc : 0.791, Sensitive_Loss : 0.14853, Sensitive_Acc : 15.800, Run Time : 15.61 sec
INFO:root:2024-04-27 10:25:35, Train, Epoch : 2, Step : 1230, Loss : 0.41875, Acc : 0.809, Sensitive_Loss : 0.16883, Sensitive_Acc : 15.000, Run Time : 18.09 sec
INFO:root:2024-04-27 10:25:54, Train, Epoch : 2, Step : 1240, Loss : 0.50735, Acc : 0.812, Sensitive_Loss : 0.10338, Sensitive_Acc : 16.000, Run Time : 18.15 sec
INFO:root:2024-04-27 10:26:10, Train, Epoch : 2, Step : 1250, Loss : 0.37938, Acc : 0.828, Sensitive_Loss : 0.11207, Sensitive_Acc : 15.700, Run Time : 16.64 sec
INFO:root:2024-04-27 10:30:26
INFO:root:y_pred: [0.02937417 0.9046917  0.0317955  ... 0.74641657 0.01116604 0.7982714 ]
INFO:root:y_true: [0. 1. 0. ... 1. 0. 1.]
INFO:root:sensitive_y_pred: [9.96792138e-01 1.30198940e-04 7.57652760e-01 6.93372125e-03
 9.99917030e-01 1.24765956e-03 9.99995351e-01 9.99963641e-01
 1.00328494e-03 8.36378336e-01 9.98991191e-01 9.99905705e-01
 9.98400152e-01 9.98176455e-01 1.68171883e-01 9.83540118e-01
 9.99822795e-01 2.07313299e-02 9.32052732e-01 9.01085138e-01
 9.99881506e-01 1.68494470e-02 9.99790967e-01 9.98391330e-01
 9.97419477e-01 9.98631418e-01 7.79673085e-03 9.99919534e-01
 9.99881148e-01 8.85001779e-01 3.18644755e-02 5.61074376e-01
 6.75482824e-02 8.72756243e-02 2.63009340e-01 2.99722864e-03
 8.02172869e-02 5.76693788e-02 9.99828815e-01 9.99612749e-01
 3.92768343e-05 2.04976212e-04 9.66705918e-01 2.33536912e-03
 9.99928832e-01 9.74979460e-01 9.98808742e-01 9.97461319e-01
 2.72397068e-04 9.96735513e-01 9.94947672e-01 4.11769748e-01
 8.96504402e-01 1.00785564e-03 9.50962678e-03 1.25110313e-01
 6.89317193e-03 9.15000029e-03 6.95834344e-04 1.84198081e-01
 1.47168608e-02 1.48274675e-01 1.93860874e-01 9.85348403e-01
 6.24260008e-01 9.99965906e-01 4.19129943e-03 9.99855638e-01
 9.94846821e-01 4.16031986e-01 9.90847111e-01 4.79963660e-01
 3.19857091e-01 6.84933126e-01 3.73053784e-03 1.07971800e-03
 2.77685165e-01 4.23509479e-01 3.05617228e-02 9.99958277e-01
 9.99737680e-01 1.45924464e-03 2.17366233e-01 4.28485172e-03
 8.74033868e-01 6.08079076e-01 4.12816182e-02 9.56205726e-02
 9.99654055e-01 9.98859525e-01 9.99984145e-01 1.33510390e-02
 4.29339632e-02 9.94116783e-01 7.80342519e-01 3.00868861e-02
 9.99059975e-01 9.99918342e-01 1.45851141e-02 1.80726036e-01
 9.99359071e-01 9.95572925e-01 9.96671140e-01 9.99014378e-01
 2.24844622e-03 6.01253152e-01 9.96840239e-01 9.99712884e-01
 9.94231462e-01 1.79671988e-05 9.97536659e-01 9.99588430e-01
 4.22034085e-01 9.99912143e-01 9.99924183e-01 9.99582708e-01
 7.50469565e-01 9.99967098e-01 1.11580454e-01 8.06367695e-02
 9.99872923e-01 9.99947071e-01 2.15449661e-04 9.97517943e-01
 9.99998093e-01 1.52160823e-01 9.99274075e-01 5.76495789e-02
 9.27826855e-03 9.64158297e-01 9.97929335e-01 3.59635763e-02
 7.30359033e-02 2.60987639e-01 9.99290228e-01 9.99144912e-01
 9.98522460e-01 2.84533892e-02 1.01049788e-01 9.64694381e-01]
INFO:root:sensitive_y_true: [1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.
 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.]
INFO:root:2024-04-27 10:30:26, Dev, Step : 1252, Loss : 0.46943, Acc : 0.795, Auc : 0.897, Sensitive_Loss : 0.19655, Sensitive_Acc : 16.721, Sensitive_Auc : 0.992, Mean auc: 0.897, Run Time : 254.09 sec
INFO:root:2024-04-27 10:30:28, Best, Step : 1252, Loss : 0.46943, Acc : 0.795,Auc : 0.897, Best Auc : 0.897, Sensitive_Loss : 0.19655, Sensitive_Acc : 16.721, Sensitive_Auc : 0.992
INFO:root:2024-04-27 10:30:46, Train, Epoch : 3, Step : 1260, Loss : 0.31700, Acc : 0.662, Sensitive_Loss : 0.11397, Sensitive_Acc : 13.700, Run Time : 16.19 sec
INFO:root:2024-04-27 10:31:04, Train, Epoch : 3, Step : 1270, Loss : 0.38842, Acc : 0.834, Sensitive_Loss : 0.12156, Sensitive_Acc : 16.100, Run Time : 18.36 sec
INFO:root:2024-04-27 10:31:23, Train, Epoch : 3, Step : 1280, Loss : 0.40680, Acc : 0.838, Sensitive_Loss : 0.12565, Sensitive_Acc : 15.200, Run Time : 18.52 sec
INFO:root:2024-04-27 10:31:39, Train, Epoch : 3, Step : 1290, Loss : 0.41412, Acc : 0.838, Sensitive_Loss : 0.16174, Sensitive_Acc : 15.500, Run Time : 16.06 sec
INFO:root:2024-04-27 10:31:57, Train, Epoch : 3, Step : 1300, Loss : 0.38252, Acc : 0.834, Sensitive_Loss : 0.07264, Sensitive_Acc : 15.900, Run Time : 17.89 sec
INFO:root:2024-04-27 10:36:01, Dev, Step : 1300, Loss : 0.43748, Acc : 0.807, Auc : 0.902, Sensitive_Loss : 0.14148, Sensitive_Acc : 16.921, Sensitive_Auc : 0.995, Mean auc: 0.902, Run Time : 244.06 sec
INFO:root:2024-04-27 10:36:01, Best, Step : 1300, Loss : 0.43748, Acc : 0.807, Auc : 0.902, Sensitive_Loss : 0.14148, Sensitive_Acc : 16.921, Sensitive_Auc : 0.995, Best Auc : 0.902
INFO:root:2024-04-27 10:36:14, Train, Epoch : 3, Step : 1310, Loss : 0.34968, Acc : 0.866, Sensitive_Loss : 0.15734, Sensitive_Acc : 15.500, Run Time : 257.28 sec
INFO:root:2024-04-27 10:36:32, Train, Epoch : 3, Step : 1320, Loss : 0.41871, Acc : 0.822, Sensitive_Loss : 0.12011, Sensitive_Acc : 16.700, Run Time : 18.15 sec
INFO:root:2024-04-27 10:36:50, Train, Epoch : 3, Step : 1330, Loss : 0.42194, Acc : 0.831, Sensitive_Loss : 0.11760, Sensitive_Acc : 15.500, Run Time : 18.09 sec
INFO:root:2024-04-27 10:37:07, Train, Epoch : 3, Step : 1340, Loss : 0.45543, Acc : 0.797, Sensitive_Loss : 0.12632, Sensitive_Acc : 18.000, Run Time : 16.88 sec
INFO:root:2024-04-27 10:37:25, Train, Epoch : 3, Step : 1350, Loss : 0.33498, Acc : 0.844, Sensitive_Loss : 0.09533, Sensitive_Acc : 17.100, Run Time : 17.89 sec
INFO:root:2024-04-27 10:37:41, Train, Epoch : 3, Step : 1360, Loss : 0.41447, Acc : 0.828, Sensitive_Loss : 0.09701, Sensitive_Acc : 15.600, Run Time : 16.31 sec
INFO:root:2024-04-27 10:37:59, Train, Epoch : 3, Step : 1370, Loss : 0.38469, Acc : 0.847, Sensitive_Loss : 0.17455, Sensitive_Acc : 16.900, Run Time : 17.62 sec
INFO:root:2024-04-27 10:38:17, Train, Epoch : 3, Step : 1380, Loss : 0.35302, Acc : 0.850, Sensitive_Loss : 0.13874, Sensitive_Acc : 15.100, Run Time : 18.29 sec
INFO:root:2024-04-27 10:38:34, Train, Epoch : 3, Step : 1390, Loss : 0.39471, Acc : 0.828, Sensitive_Loss : 0.08815, Sensitive_Acc : 16.600, Run Time : 16.63 sec
INFO:root:2024-04-27 10:38:52, Train, Epoch : 3, Step : 1400, Loss : 0.34250, Acc : 0.859, Sensitive_Loss : 0.07874, Sensitive_Acc : 15.400, Run Time : 18.12 sec
INFO:root:2024-04-27 10:42:57, Dev, Step : 1400, Loss : 0.41968, Acc : 0.815, Auc : 0.904, Sensitive_Loss : 0.13708, Sensitive_Acc : 16.921, Sensitive_Auc : 0.996, Mean auc: 0.904, Run Time : 245.65 sec
INFO:root:2024-04-27 10:42:58, Best, Step : 1400, Loss : 0.41968, Acc : 0.815, Auc : 0.904, Sensitive_Loss : 0.13708, Sensitive_Acc : 16.921, Sensitive_Auc : 0.996, Best Auc : 0.904
INFO:root:2024-04-27 10:43:11, Train, Epoch : 3, Step : 1410, Loss : 0.31742, Acc : 0.844, Sensitive_Loss : 0.08401, Sensitive_Acc : 14.900, Run Time : 259.17 sec
INFO:root:2024-04-27 10:43:28, Train, Epoch : 3, Step : 1420, Loss : 0.38429, Acc : 0.869, Sensitive_Loss : 0.08860, Sensitive_Acc : 16.600, Run Time : 17.53 sec
INFO:root:2024-04-27 10:43:47, Train, Epoch : 3, Step : 1430, Loss : 0.39418, Acc : 0.847, Sensitive_Loss : 0.08416, Sensitive_Acc : 16.400, Run Time : 18.25 sec
INFO:root:2024-04-27 10:44:03, Train, Epoch : 3, Step : 1440, Loss : 0.31774, Acc : 0.847, Sensitive_Loss : 0.10460, Sensitive_Acc : 16.200, Run Time : 16.28 sec
INFO:root:2024-04-27 10:44:21, Train, Epoch : 3, Step : 1450, Loss : 0.35433, Acc : 0.800, Sensitive_Loss : 0.15487, Sensitive_Acc : 15.000, Run Time : 18.34 sec
INFO:root:2024-04-27 10:44:38, Train, Epoch : 3, Step : 1460, Loss : 0.34143, Acc : 0.841, Sensitive_Loss : 0.06330, Sensitive_Acc : 15.300, Run Time : 16.58 sec
INFO:root:2024-04-27 10:44:56, Train, Epoch : 3, Step : 1470, Loss : 0.32593, Acc : 0.859, Sensitive_Loss : 0.11413, Sensitive_Acc : 16.000, Run Time : 17.89 sec
INFO:root:2024-04-27 10:45:13, Train, Epoch : 3, Step : 1480, Loss : 0.38044, Acc : 0.838, Sensitive_Loss : 0.12807, Sensitive_Acc : 17.100, Run Time : 17.58 sec
INFO:root:2024-04-27 10:45:30, Train, Epoch : 3, Step : 1490, Loss : 0.32177, Acc : 0.856, Sensitive_Loss : 0.10688, Sensitive_Acc : 17.100, Run Time : 16.74 sec
INFO:root:2024-04-27 10:45:47, Train, Epoch : 3, Step : 1500, Loss : 0.40897, Acc : 0.787, Sensitive_Loss : 0.14536, Sensitive_Acc : 16.800, Run Time : 16.79 sec
INFO:root:2024-04-27 10:49:53, Dev, Step : 1500, Loss : 0.44305, Acc : 0.804, Auc : 0.905, Sensitive_Loss : 0.16781, Sensitive_Acc : 16.907, Sensitive_Auc : 0.995, Mean auc: 0.905, Run Time : 245.95 sec
INFO:root:2024-04-27 10:49:54, Best, Step : 1500, Loss : 0.44305, Acc : 0.804, Auc : 0.905, Sensitive_Loss : 0.16781, Sensitive_Acc : 16.907, Sensitive_Auc : 0.995, Best Auc : 0.905
INFO:root:2024-04-27 10:50:06, Train, Epoch : 3, Step : 1510, Loss : 0.35507, Acc : 0.825, Sensitive_Loss : 0.12370, Sensitive_Acc : 14.500, Run Time : 258.65 sec
INFO:root:2024-04-27 10:50:23, Train, Epoch : 3, Step : 1520, Loss : 0.38185, Acc : 0.838, Sensitive_Loss : 0.08731, Sensitive_Acc : 14.800, Run Time : 16.97 sec
INFO:root:2024-04-27 10:50:40, Train, Epoch : 3, Step : 1530, Loss : 0.33204, Acc : 0.847, Sensitive_Loss : 0.12541, Sensitive_Acc : 17.800, Run Time : 17.24 sec
INFO:root:2024-04-27 10:50:57, Train, Epoch : 3, Step : 1540, Loss : 0.34481, Acc : 0.834, Sensitive_Loss : 0.13154, Sensitive_Acc : 16.600, Run Time : 16.96 sec
INFO:root:2024-04-27 10:51:14, Train, Epoch : 3, Step : 1550, Loss : 0.37513, Acc : 0.841, Sensitive_Loss : 0.12414, Sensitive_Acc : 17.400, Run Time : 16.79 sec
INFO:root:2024-04-27 10:51:33, Train, Epoch : 3, Step : 1560, Loss : 0.42906, Acc : 0.812, Sensitive_Loss : 0.07980, Sensitive_Acc : 16.500, Run Time : 19.09 sec
INFO:root:2024-04-27 10:51:50, Train, Epoch : 3, Step : 1570, Loss : 0.35680, Acc : 0.844, Sensitive_Loss : 0.08712, Sensitive_Acc : 16.100, Run Time : 17.37 sec
INFO:root:2024-04-27 10:52:07, Train, Epoch : 3, Step : 1580, Loss : 0.35743, Acc : 0.828, Sensitive_Loss : 0.11785, Sensitive_Acc : 15.700, Run Time : 17.31 sec
INFO:root:2024-04-27 10:52:25, Train, Epoch : 3, Step : 1590, Loss : 0.43157, Acc : 0.819, Sensitive_Loss : 0.11691, Sensitive_Acc : 17.200, Run Time : 17.19 sec
INFO:root:2024-04-27 10:52:41, Train, Epoch : 3, Step : 1600, Loss : 0.32013, Acc : 0.850, Sensitive_Loss : 0.14429, Sensitive_Acc : 17.500, Run Time : 16.66 sec
INFO:root:2024-04-27 10:56:46, Dev, Step : 1600, Loss : 0.43015, Acc : 0.811, Auc : 0.905, Sensitive_Loss : 0.15714, Sensitive_Acc : 16.879, Sensitive_Auc : 0.995, Mean auc: 0.905, Run Time : 244.89 sec
INFO:root:2024-04-27 10:56:59, Train, Epoch : 3, Step : 1610, Loss : 0.31438, Acc : 0.863, Sensitive_Loss : 0.14984, Sensitive_Acc : 19.000, Run Time : 257.82 sec
INFO:root:2024-04-27 10:57:16, Train, Epoch : 3, Step : 1620, Loss : 0.32008, Acc : 0.838, Sensitive_Loss : 0.09321, Sensitive_Acc : 16.000, Run Time : 17.07 sec
INFO:root:2024-04-27 10:57:33, Train, Epoch : 3, Step : 1630, Loss : 0.34121, Acc : 0.822, Sensitive_Loss : 0.10122, Sensitive_Acc : 16.300, Run Time : 17.09 sec
INFO:root:2024-04-27 10:57:50, Train, Epoch : 3, Step : 1640, Loss : 0.43577, Acc : 0.803, Sensitive_Loss : 0.10848, Sensitive_Acc : 15.900, Run Time : 16.68 sec
INFO:root:2024-04-27 10:58:07, Train, Epoch : 3, Step : 1650, Loss : 0.34477, Acc : 0.866, Sensitive_Loss : 0.09790, Sensitive_Acc : 17.800, Run Time : 17.26 sec
INFO:root:2024-04-27 10:58:24, Train, Epoch : 3, Step : 1660, Loss : 0.35566, Acc : 0.841, Sensitive_Loss : 0.12477, Sensitive_Acc : 16.400, Run Time : 17.03 sec
INFO:root:2024-04-27 10:58:42, Train, Epoch : 3, Step : 1670, Loss : 0.38243, Acc : 0.850, Sensitive_Loss : 0.12959, Sensitive_Acc : 16.500, Run Time : 18.08 sec
INFO:root:2024-04-27 10:59:01, Train, Epoch : 3, Step : 1680, Loss : 0.36777, Acc : 0.859, Sensitive_Loss : 0.10275, Sensitive_Acc : 16.100, Run Time : 18.98 sec
INFO:root:2024-04-27 10:59:18, Train, Epoch : 3, Step : 1690, Loss : 0.38477, Acc : 0.816, Sensitive_Loss : 0.14376, Sensitive_Acc : 17.000, Run Time : 16.81 sec
INFO:root:2024-04-27 10:59:34, Train, Epoch : 3, Step : 1700, Loss : 0.34478, Acc : 0.863, Sensitive_Loss : 0.11011, Sensitive_Acc : 16.800, Run Time : 15.82 sec
INFO:root:2024-04-27 11:03:38, Dev, Step : 1700, Loss : 0.40752, Acc : 0.822, Auc : 0.907, Sensitive_Loss : 0.12961, Sensitive_Acc : 16.893, Sensitive_Auc : 0.996, Mean auc: 0.907, Run Time : 244.29 sec
INFO:root:2024-04-27 11:03:39, Best, Step : 1700, Loss : 0.40752, Acc : 0.822, Auc : 0.907, Sensitive_Loss : 0.12961, Sensitive_Acc : 16.893, Sensitive_Auc : 0.996, Best Auc : 0.907
INFO:root:2024-04-27 11:03:52, Train, Epoch : 3, Step : 1710, Loss : 0.40268, Acc : 0.847, Sensitive_Loss : 0.11537, Sensitive_Acc : 15.900, Run Time : 258.12 sec
INFO:root:2024-04-27 11:04:10, Train, Epoch : 3, Step : 1720, Loss : 0.31689, Acc : 0.859, Sensitive_Loss : 0.09829, Sensitive_Acc : 16.200, Run Time : 18.36 sec
INFO:root:2024-04-27 11:04:27, Train, Epoch : 3, Step : 1730, Loss : 0.31894, Acc : 0.847, Sensitive_Loss : 0.08360, Sensitive_Acc : 17.400, Run Time : 16.86 sec
INFO:root:2024-04-27 11:04:44, Train, Epoch : 3, Step : 1740, Loss : 0.37756, Acc : 0.841, Sensitive_Loss : 0.10178, Sensitive_Acc : 16.600, Run Time : 17.14 sec
INFO:root:2024-04-27 11:05:01, Train, Epoch : 3, Step : 1750, Loss : 0.34672, Acc : 0.859, Sensitive_Loss : 0.12941, Sensitive_Acc : 17.000, Run Time : 16.63 sec
INFO:root:2024-04-27 11:05:19, Train, Epoch : 3, Step : 1760, Loss : 0.35039, Acc : 0.856, Sensitive_Loss : 0.10892, Sensitive_Acc : 15.800, Run Time : 17.78 sec
INFO:root:2024-04-27 11:05:37, Train, Epoch : 3, Step : 1770, Loss : 0.34216, Acc : 0.859, Sensitive_Loss : 0.09884, Sensitive_Acc : 15.600, Run Time : 17.98 sec
INFO:root:2024-04-27 11:05:55, Train, Epoch : 3, Step : 1780, Loss : 0.39255, Acc : 0.847, Sensitive_Loss : 0.10413, Sensitive_Acc : 15.600, Run Time : 18.46 sec
INFO:root:2024-04-27 11:06:12, Train, Epoch : 3, Step : 1790, Loss : 0.32999, Acc : 0.853, Sensitive_Loss : 0.10834, Sensitive_Acc : 17.500, Run Time : 16.51 sec
INFO:root:2024-04-27 11:06:29, Train, Epoch : 3, Step : 1800, Loss : 0.34203, Acc : 0.828, Sensitive_Loss : 0.08728, Sensitive_Acc : 15.800, Run Time : 16.97 sec
INFO:root:2024-04-27 11:10:34, Dev, Step : 1800, Loss : 0.43710, Acc : 0.806, Auc : 0.908, Sensitive_Loss : 0.14392, Sensitive_Acc : 16.950, Sensitive_Auc : 0.995, Mean auc: 0.908, Run Time : 245.18 sec
INFO:root:2024-04-27 11:10:34, Best, Step : 1800, Loss : 0.43710, Acc : 0.806, Auc : 0.908, Sensitive_Loss : 0.14392, Sensitive_Acc : 16.950, Sensitive_Auc : 0.995, Best Auc : 0.908
INFO:root:2024-04-27 11:10:48, Train, Epoch : 3, Step : 1810, Loss : 0.43354, Acc : 0.812, Sensitive_Loss : 0.09495, Sensitive_Acc : 15.500, Run Time : 259.75 sec
INFO:root:2024-04-27 11:11:06, Train, Epoch : 3, Step : 1820, Loss : 0.27874, Acc : 0.872, Sensitive_Loss : 0.13864, Sensitive_Acc : 16.500, Run Time : 17.62 sec
INFO:root:2024-04-27 11:11:22, Train, Epoch : 3, Step : 1830, Loss : 0.41746, Acc : 0.841, Sensitive_Loss : 0.13649, Sensitive_Acc : 16.100, Run Time : 15.73 sec
INFO:root:2024-04-27 11:11:40, Train, Epoch : 3, Step : 1840, Loss : 0.40512, Acc : 0.841, Sensitive_Loss : 0.08653, Sensitive_Acc : 15.300, Run Time : 17.86 sec
INFO:root:2024-04-27 11:11:57, Train, Epoch : 3, Step : 1850, Loss : 0.34063, Acc : 0.869, Sensitive_Loss : 0.08163, Sensitive_Acc : 16.400, Run Time : 17.64 sec
INFO:root:2024-04-27 11:12:15, Train, Epoch : 3, Step : 1860, Loss : 0.28203, Acc : 0.884, Sensitive_Loss : 0.09577, Sensitive_Acc : 15.600, Run Time : 18.04 sec
INFO:root:2024-04-27 11:12:34, Train, Epoch : 3, Step : 1870, Loss : 0.35248, Acc : 0.853, Sensitive_Loss : 0.11614, Sensitive_Acc : 16.500, Run Time : 18.79 sec
INFO:root:2024-04-27 11:16:49
INFO:root:y_pred: [0.04044567 0.95245117 0.03925848 ... 0.87856096 0.01014145 0.8325874 ]
INFO:root:y_true: [0. 1. 0. ... 1. 0. 1.]
INFO:root:sensitive_y_pred: [9.91297245e-01 5.59397340e-05 2.64878660e-01 1.06143882e-03
 9.99309540e-01 9.46779386e-04 9.99962926e-01 9.99782145e-01
 1.29219246e-04 9.24418390e-01 9.99080420e-01 9.99837756e-01
 9.91055965e-01 9.84175026e-01 8.95686261e-03 9.55539405e-01
 9.99787033e-01 1.88431237e-02 4.59755749e-01 9.49623227e-01
 9.99206841e-01 6.84136339e-03 9.99402046e-01 9.97891724e-01
 9.94395375e-01 9.98388648e-01 1.76639669e-03 9.98576403e-01
 9.96818542e-01 2.56554872e-01 1.08270289e-03 2.91496843e-01
 8.61803256e-03 5.02933785e-02 4.64243703e-02 2.12557707e-03
 3.19625884e-02 1.08938208e-02 9.99679446e-01 9.97408807e-01
 3.64477673e-05 5.73149700e-05 9.56126988e-01 2.01610965e-03
 9.99778569e-01 9.91900086e-01 9.98021245e-01 9.95682001e-01
 5.49653661e-04 9.95022058e-01 9.73369598e-01 1.54836746e-02
 6.43345833e-01 4.88139951e-04 2.02770554e-03 5.27756512e-02
 3.12971398e-02 2.70260358e-03 2.46307754e-04 1.07321665e-01
 6.63912529e-03 7.94919655e-02 5.15141450e-02 9.88335848e-01
 2.36959264e-01 9.99604762e-01 1.53099571e-03 9.99641657e-01
 9.97161150e-01 7.21724927e-02 9.67614830e-01 3.08998883e-01
 1.46812061e-02 8.34928080e-02 2.20418384e-04 6.72332710e-04
 2.92235613e-02 1.73890576e-01 3.29619716e-03 9.99891520e-01
 9.99283850e-01 2.38588126e-03 2.75651693e-01 3.99715407e-03
 8.25338781e-01 7.06391871e-01 2.17055529e-02 2.49466896e-02
 9.97927070e-01 9.99336898e-01 9.99945998e-01 3.27500701e-03
 3.92917497e-03 9.92535710e-01 5.53836226e-01 4.66281408e-03
 9.95994329e-01 9.99589384e-01 6.71834976e-04 1.60837963e-01
 9.88744855e-01 9.94032323e-01 9.97555077e-01 9.98470843e-01
 2.16388237e-03 1.94452330e-01 9.93588328e-01 9.97840643e-01
 9.90004957e-01 2.27564624e-06 9.93770778e-01 9.99064147e-01
 4.60839234e-02 9.99763787e-01 9.94547606e-01 9.99313474e-01
 6.13153994e-01 9.99626994e-01 2.67309267e-02 1.12043463e-01
 9.98971343e-01 9.99775708e-01 9.66782682e-05 9.94477868e-01
 9.99983788e-01 1.60537288e-01 9.79129970e-01 1.58246588e-02
 5.94349159e-03 9.80553627e-01 9.91790891e-01 7.72667537e-03
 2.05759960e-03 2.18870956e-02 9.90889728e-01 9.95549560e-01
 9.89277601e-01 5.41457720e-03 1.73315778e-02 9.42453206e-01]
INFO:root:sensitive_y_true: [1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.
 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.]
INFO:root:2024-04-27 11:16:49, Dev, Step : 1878, Loss : 0.40562, Acc : 0.824, Auc : 0.907, Sensitive_Loss : 0.11928, Sensitive_Acc : 16.979, Sensitive_Auc : 0.995, Mean auc: 0.907, Run Time : 242.88 sec
INFO:root:2024-04-27 11:16:57, Train, Epoch : 4, Step : 1880, Loss : 0.10465, Acc : 0.153, Sensitive_Loss : 0.01513, Sensitive_Acc : 2.700, Run Time : 6.52 sec
INFO:root:2024-04-27 11:17:14, Train, Epoch : 4, Step : 1890, Loss : 0.34302, Acc : 0.875, Sensitive_Loss : 0.11221, Sensitive_Acc : 15.300, Run Time : 17.73 sec
INFO:root:2024-04-27 11:17:32, Train, Epoch : 4, Step : 1900, Loss : 0.33316, Acc : 0.841, Sensitive_Loss : 0.11617, Sensitive_Acc : 16.700, Run Time : 18.09 sec
INFO:root:2024-04-27 11:21:37, Dev, Step : 1900, Loss : 0.40093, Acc : 0.830, Auc : 0.908, Sensitive_Loss : 0.11769, Sensitive_Acc : 16.979, Sensitive_Auc : 0.995, Mean auc: 0.908, Run Time : 244.43 sec
INFO:root:2024-04-27 11:21:50, Train, Epoch : 4, Step : 1910, Loss : 0.33462, Acc : 0.884, Sensitive_Loss : 0.11818, Sensitive_Acc : 15.900, Run Time : 257.22 sec
INFO:root:2024-04-27 11:22:08, Train, Epoch : 4, Step : 1920, Loss : 0.32340, Acc : 0.841, Sensitive_Loss : 0.12211, Sensitive_Acc : 15.300, Run Time : 18.17 sec
INFO:root:2024-04-27 11:22:25, Train, Epoch : 4, Step : 1930, Loss : 0.32829, Acc : 0.853, Sensitive_Loss : 0.09204, Sensitive_Acc : 17.000, Run Time : 16.79 sec
INFO:root:2024-04-27 11:22:41, Train, Epoch : 4, Step : 1940, Loss : 0.33454, Acc : 0.825, Sensitive_Loss : 0.08546, Sensitive_Acc : 16.700, Run Time : 16.01 sec
INFO:root:2024-04-27 11:22:59, Train, Epoch : 4, Step : 1950, Loss : 0.27929, Acc : 0.869, Sensitive_Loss : 0.08839, Sensitive_Acc : 17.500, Run Time : 18.40 sec
INFO:root:2024-04-27 11:23:16, Train, Epoch : 4, Step : 1960, Loss : 0.34979, Acc : 0.869, Sensitive_Loss : 0.10491, Sensitive_Acc : 14.600, Run Time : 16.58 sec
INFO:root:2024-04-27 11:23:33, Train, Epoch : 4, Step : 1970, Loss : 0.33405, Acc : 0.866, Sensitive_Loss : 0.11703, Sensitive_Acc : 16.500, Run Time : 17.13 sec
INFO:root:2024-04-27 11:23:51, Train, Epoch : 4, Step : 1980, Loss : 0.33170, Acc : 0.841, Sensitive_Loss : 0.07373, Sensitive_Acc : 15.600, Run Time : 17.86 sec
INFO:root:2024-04-27 11:24:08, Train, Epoch : 4, Step : 1990, Loss : 0.32235, Acc : 0.863, Sensitive_Loss : 0.08051, Sensitive_Acc : 16.400, Run Time : 17.79 sec
INFO:root:2024-04-27 11:24:29, Train, Epoch : 4, Step : 2000, Loss : 0.37911, Acc : 0.850, Sensitive_Loss : 0.11551, Sensitive_Acc : 14.400, Run Time : 20.31 sec
INFO:root:2024-04-27 11:28:33, Dev, Step : 2000, Loss : 0.41376, Acc : 0.819, Auc : 0.911, Sensitive_Loss : 0.13297, Sensitive_Acc : 16.950, Sensitive_Auc : 0.995, Mean auc: 0.911, Run Time : 244.80 sec
INFO:root:2024-04-27 11:28:34, Best, Step : 2000, Loss : 0.41376, Acc : 0.819, Auc : 0.911, Sensitive_Loss : 0.13297, Sensitive_Acc : 16.950, Sensitive_Auc : 0.995, Best Auc : 0.911
INFO:root:2024-04-27 11:28:47, Train, Epoch : 4, Step : 2010, Loss : 0.37185, Acc : 0.850, Sensitive_Loss : 0.10737, Sensitive_Acc : 17.700, Run Time : 258.05 sec
INFO:root:2024-04-27 11:29:04, Train, Epoch : 4, Step : 2020, Loss : 0.31911, Acc : 0.875, Sensitive_Loss : 0.10183, Sensitive_Acc : 15.900, Run Time : 17.56 sec
INFO:root:2024-04-27 11:29:22, Train, Epoch : 4, Step : 2030, Loss : 0.30283, Acc : 0.859, Sensitive_Loss : 0.12674, Sensitive_Acc : 17.500, Run Time : 17.87 sec
INFO:root:2024-04-27 11:29:39, Train, Epoch : 4, Step : 2040, Loss : 0.33786, Acc : 0.844, Sensitive_Loss : 0.09791, Sensitive_Acc : 15.300, Run Time : 16.61 sec
INFO:root:2024-04-27 11:29:56, Train, Epoch : 4, Step : 2050, Loss : 0.33690, Acc : 0.850, Sensitive_Loss : 0.11173, Sensitive_Acc : 16.100, Run Time : 17.57 sec
INFO:root:2024-04-27 11:30:13, Train, Epoch : 4, Step : 2060, Loss : 0.33405, Acc : 0.863, Sensitive_Loss : 0.12261, Sensitive_Acc : 17.000, Run Time : 16.66 sec
INFO:root:2024-04-27 11:30:30, Train, Epoch : 4, Step : 2070, Loss : 0.27715, Acc : 0.872, Sensitive_Loss : 0.10784, Sensitive_Acc : 16.500, Run Time : 17.16 sec
INFO:root:2024-04-27 11:30:49, Train, Epoch : 4, Step : 2080, Loss : 0.37869, Acc : 0.859, Sensitive_Loss : 0.10038, Sensitive_Acc : 16.400, Run Time : 18.45 sec
INFO:root:2024-04-27 11:31:07, Train, Epoch : 4, Step : 2090, Loss : 0.34705, Acc : 0.844, Sensitive_Loss : 0.09202, Sensitive_Acc : 16.300, Run Time : 18.24 sec
INFO:root:2024-04-27 11:31:25, Train, Epoch : 4, Step : 2100, Loss : 0.37910, Acc : 0.850, Sensitive_Loss : 0.09950, Sensitive_Acc : 17.200, Run Time : 17.84 sec
INFO:root:2024-04-27 11:35:29, Dev, Step : 2100, Loss : 0.40919, Acc : 0.822, Auc : 0.909, Sensitive_Loss : 0.11986, Sensitive_Acc : 16.950, Sensitive_Auc : 0.995, Mean auc: 0.909, Run Time : 244.25 sec
INFO:root:2024-04-27 11:35:41, Train, Epoch : 4, Step : 2110, Loss : 0.37545, Acc : 0.828, Sensitive_Loss : 0.11137, Sensitive_Acc : 16.000, Run Time : 256.11 sec
INFO:root:2024-04-27 11:35:58, Train, Epoch : 4, Step : 2120, Loss : 0.30650, Acc : 0.891, Sensitive_Loss : 0.10262, Sensitive_Acc : 16.100, Run Time : 17.69 sec
INFO:root:2024-04-27 11:36:17, Train, Epoch : 4, Step : 2130, Loss : 0.35350, Acc : 0.856, Sensitive_Loss : 0.09934, Sensitive_Acc : 16.400, Run Time : 18.25 sec
INFO:root:2024-04-27 11:36:35, Train, Epoch : 4, Step : 2140, Loss : 0.32712, Acc : 0.856, Sensitive_Loss : 0.13422, Sensitive_Acc : 16.000, Run Time : 18.32 sec
INFO:root:2024-04-27 11:36:52, Train, Epoch : 4, Step : 2150, Loss : 0.35378, Acc : 0.838, Sensitive_Loss : 0.13774, Sensitive_Acc : 16.800, Run Time : 17.30 sec
INFO:root:2024-04-27 11:37:09, Train, Epoch : 4, Step : 2160, Loss : 0.31415, Acc : 0.856, Sensitive_Loss : 0.11755, Sensitive_Acc : 14.800, Run Time : 16.95 sec
INFO:root:2024-04-27 11:37:26, Train, Epoch : 4, Step : 2170, Loss : 0.33482, Acc : 0.869, Sensitive_Loss : 0.10778, Sensitive_Acc : 16.900, Run Time : 16.76 sec
INFO:root:2024-04-27 11:37:43, Train, Epoch : 4, Step : 2180, Loss : 0.35427, Acc : 0.834, Sensitive_Loss : 0.09548, Sensitive_Acc : 15.300, Run Time : 17.03 sec
INFO:root:2024-04-27 11:38:01, Train, Epoch : 4, Step : 2190, Loss : 0.34815, Acc : 0.856, Sensitive_Loss : 0.08413, Sensitive_Acc : 16.800, Run Time : 17.61 sec
INFO:root:2024-04-27 11:38:18, Train, Epoch : 4, Step : 2200, Loss : 0.34363, Acc : 0.834, Sensitive_Loss : 0.09109, Sensitive_Acc : 15.000, Run Time : 17.65 sec
INFO:root:2024-04-27 11:42:24, Dev, Step : 2200, Loss : 0.40881, Acc : 0.822, Auc : 0.910, Sensitive_Loss : 0.12189, Sensitive_Acc : 16.950, Sensitive_Auc : 0.995, Mean auc: 0.910, Run Time : 245.71 sec
INFO:root:2024-04-27 11:42:36, Train, Epoch : 4, Step : 2210, Loss : 0.29547, Acc : 0.887, Sensitive_Loss : 0.09642, Sensitive_Acc : 16.500, Run Time : 257.70 sec
INFO:root:2024-04-27 11:42:53, Train, Epoch : 4, Step : 2220, Loss : 0.37591, Acc : 0.838, Sensitive_Loss : 0.10179, Sensitive_Acc : 17.600, Run Time : 17.34 sec
INFO:root:2024-04-27 11:43:11, Train, Epoch : 4, Step : 2230, Loss : 0.39543, Acc : 0.834, Sensitive_Loss : 0.10553, Sensitive_Acc : 16.300, Run Time : 17.64 sec
INFO:root:2024-04-27 11:43:28, Train, Epoch : 4, Step : 2240, Loss : 0.29510, Acc : 0.881, Sensitive_Loss : 0.11409, Sensitive_Acc : 16.800, Run Time : 16.96 sec
INFO:root:2024-04-27 11:43:44, Train, Epoch : 4, Step : 2250, Loss : 0.30488, Acc : 0.875, Sensitive_Loss : 0.07634, Sensitive_Acc : 15.800, Run Time : 16.23 sec
INFO:root:2024-04-27 11:44:02, Train, Epoch : 4, Step : 2260, Loss : 0.34300, Acc : 0.856, Sensitive_Loss : 0.08969, Sensitive_Acc : 15.300, Run Time : 18.10 sec
INFO:root:2024-04-27 11:44:20, Train, Epoch : 4, Step : 2270, Loss : 0.31495, Acc : 0.831, Sensitive_Loss : 0.10157, Sensitive_Acc : 15.600, Run Time : 17.77 sec
INFO:root:2024-04-27 11:44:38, Train, Epoch : 4, Step : 2280, Loss : 0.38376, Acc : 0.819, Sensitive_Loss : 0.10423, Sensitive_Acc : 16.200, Run Time : 17.71 sec
INFO:root:2024-04-27 11:44:55, Train, Epoch : 4, Step : 2290, Loss : 0.34743, Acc : 0.822, Sensitive_Loss : 0.08280, Sensitive_Acc : 15.300, Run Time : 17.31 sec
INFO:root:2024-04-27 11:45:11, Train, Epoch : 4, Step : 2300, Loss : 0.33679, Acc : 0.856, Sensitive_Loss : 0.10855, Sensitive_Acc : 14.900, Run Time : 16.14 sec
INFO:root:2024-04-27 11:49:19, Dev, Step : 2300, Loss : 0.42760, Acc : 0.814, Auc : 0.909, Sensitive_Loss : 0.13113, Sensitive_Acc : 16.950, Sensitive_Auc : 0.995, Mean auc: 0.909, Run Time : 247.64 sec
INFO:root:2024-04-27 11:49:31, Train, Epoch : 4, Step : 2310, Loss : 0.32572, Acc : 0.863, Sensitive_Loss : 0.07576, Sensitive_Acc : 16.000, Run Time : 260.10 sec
INFO:root:2024-04-27 11:49:49, Train, Epoch : 4, Step : 2320, Loss : 0.33329, Acc : 0.841, Sensitive_Loss : 0.12153, Sensitive_Acc : 16.700, Run Time : 17.88 sec
INFO:root:2024-04-27 11:50:07, Train, Epoch : 4, Step : 2330, Loss : 0.37691, Acc : 0.847, Sensitive_Loss : 0.11122, Sensitive_Acc : 16.800, Run Time : 18.14 sec
INFO:root:2024-04-27 11:50:24, Train, Epoch : 4, Step : 2340, Loss : 0.33319, Acc : 0.847, Sensitive_Loss : 0.08718, Sensitive_Acc : 16.000, Run Time : 16.68 sec
INFO:root:2024-04-27 11:50:41, Train, Epoch : 4, Step : 2350, Loss : 0.35083, Acc : 0.853, Sensitive_Loss : 0.08427, Sensitive_Acc : 19.100, Run Time : 17.18 sec
INFO:root:2024-04-27 11:50:58, Train, Epoch : 4, Step : 2360, Loss : 0.30453, Acc : 0.844, Sensitive_Loss : 0.09906, Sensitive_Acc : 16.300, Run Time : 16.30 sec
INFO:root:2024-04-27 11:51:16, Train, Epoch : 4, Step : 2370, Loss : 0.36236, Acc : 0.825, Sensitive_Loss : 0.09649, Sensitive_Acc : 15.900, Run Time : 18.34 sec
INFO:root:2024-04-27 11:51:33, Train, Epoch : 4, Step : 2380, Loss : 0.32258, Acc : 0.878, Sensitive_Loss : 0.07491, Sensitive_Acc : 16.100, Run Time : 17.58 sec
INFO:root:2024-04-27 11:51:51, Train, Epoch : 4, Step : 2390, Loss : 0.33818, Acc : 0.853, Sensitive_Loss : 0.12791, Sensitive_Acc : 16.200, Run Time : 17.33 sec
INFO:root:2024-04-27 11:52:08, Train, Epoch : 4, Step : 2400, Loss : 0.30609, Acc : 0.878, Sensitive_Loss : 0.10349, Sensitive_Acc : 16.600, Run Time : 17.48 sec
INFO:root:2024-04-27 11:56:12, Dev, Step : 2400, Loss : 0.41248, Acc : 0.821, Auc : 0.910, Sensitive_Loss : 0.12287, Sensitive_Acc : 16.950, Sensitive_Auc : 0.996, Mean auc: 0.910, Run Time : 244.04 sec
INFO:root:2024-04-27 11:56:25, Train, Epoch : 4, Step : 2410, Loss : 0.38425, Acc : 0.847, Sensitive_Loss : 0.08930, Sensitive_Acc : 17.100, Run Time : 256.72 sec
INFO:root:2024-04-27 11:56:42, Train, Epoch : 4, Step : 2420, Loss : 0.29129, Acc : 0.881, Sensitive_Loss : 0.07885, Sensitive_Acc : 14.500, Run Time : 17.35 sec
INFO:root:2024-04-27 11:57:01, Train, Epoch : 4, Step : 2430, Loss : 0.33863, Acc : 0.875, Sensitive_Loss : 0.10154, Sensitive_Acc : 17.100, Run Time : 18.27 sec
INFO:root:2024-04-27 11:57:19, Train, Epoch : 4, Step : 2440, Loss : 0.32845, Acc : 0.838, Sensitive_Loss : 0.08841, Sensitive_Acc : 17.000, Run Time : 18.64 sec
INFO:root:2024-04-27 11:57:36, Train, Epoch : 4, Step : 2450, Loss : 0.29998, Acc : 0.853, Sensitive_Loss : 0.10511, Sensitive_Acc : 16.700, Run Time : 16.59 sec
INFO:root:2024-04-27 11:57:53, Train, Epoch : 4, Step : 2460, Loss : 0.36958, Acc : 0.819, Sensitive_Loss : 0.09788, Sensitive_Acc : 16.000, Run Time : 17.61 sec
INFO:root:2024-04-27 11:58:12, Train, Epoch : 4, Step : 2470, Loss : 0.25589, Acc : 0.891, Sensitive_Loss : 0.08010, Sensitive_Acc : 15.300, Run Time : 18.24 sec
INFO:root:2024-04-27 11:58:30, Train, Epoch : 4, Step : 2480, Loss : 0.33695, Acc : 0.825, Sensitive_Loss : 0.10875, Sensitive_Acc : 15.900, Run Time : 17.92 sec
INFO:root:2024-04-27 11:58:47, Train, Epoch : 4, Step : 2490, Loss : 0.37542, Acc : 0.844, Sensitive_Loss : 0.10180, Sensitive_Acc : 17.200, Run Time : 17.35 sec
INFO:root:2024-04-27 11:59:04, Train, Epoch : 4, Step : 2500, Loss : 0.39618, Acc : 0.838, Sensitive_Loss : 0.14496, Sensitive_Acc : 17.600, Run Time : 17.32 sec
INFO:root:2024-04-27 12:03:08, Dev, Step : 2500, Loss : 0.43152, Acc : 0.812, Auc : 0.909, Sensitive_Loss : 0.14613, Sensitive_Acc : 16.907, Sensitive_Auc : 0.996, Mean auc: 0.909, Run Time : 243.59 sec
INFO:root:2024-04-27 12:07:11
INFO:root:y_pred: [0.03557324 0.93691003 0.02654659 ... 0.85636085 0.00603326 0.81154686]
INFO:root:y_true: [0. 1. 0. ... 1. 0. 1.]
INFO:root:sensitive_y_pred: [9.92734790e-01 1.04852072e-04 3.37375879e-01 2.65489705e-03
 9.99629378e-01 1.03221380e-03 9.99974728e-01 9.99912024e-01
 1.39439158e-04 9.44175243e-01 9.99668717e-01 9.99925494e-01
 9.97215986e-01 9.93308663e-01 2.38425247e-02 9.66681302e-01
 9.99862075e-01 3.06443460e-02 7.32620060e-01 9.54948664e-01
 9.99466479e-01 1.62900556e-02 9.99536753e-01 9.98404443e-01
 9.97894704e-01 9.99084234e-01 9.29515576e-04 9.99079943e-01
 9.96730685e-01 2.86124110e-01 2.14837771e-03 3.48936528e-01
 5.46227582e-03 9.85986963e-02 7.99772218e-02 5.07780816e-03
 6.84190989e-02 2.44436879e-02 9.99825776e-01 9.98789847e-01
 1.17113050e-05 3.95188654e-05 9.70467865e-01 3.03775002e-03
 9.99825895e-01 9.94816720e-01 9.98887241e-01 9.96982753e-01
 1.05241465e-03 9.97848153e-01 9.55076516e-01 3.60370353e-02
 6.63464963e-01 1.72326027e-03 1.44264882e-03 1.01588801e-01
 4.67027985e-02 3.76920961e-03 2.33226107e-04 1.05592854e-01
 7.29159312e-03 9.50056538e-02 5.15503325e-02 9.93773818e-01
 5.66780388e-01 9.99773443e-01 1.69611000e-03 9.99829531e-01
 9.98075247e-01 1.05738372e-01 9.71544862e-01 3.82594913e-01
 1.75194275e-02 5.40484637e-02 1.85777593e-04 1.82653673e-03
 3.35644670e-02 1.76079601e-01 2.27102288e-03 9.99926567e-01
 9.99313474e-01 5.76970028e-03 2.62167960e-01 2.79777381e-03
 8.83718371e-01 7.30145514e-01 3.54179367e-02 1.57113168e-02
 9.96313274e-01 9.99855876e-01 9.99977350e-01 3.15719959e-03
 5.66429785e-03 9.92893159e-01 6.74301326e-01 3.26819951e-03
 9.98486280e-01 9.99758780e-01 6.11880678e-04 1.43235326e-01
 9.91561711e-01 9.95038331e-01 9.98907685e-01 9.98660445e-01
 1.63504784e-03 7.93769136e-02 9.96357501e-01 9.98797774e-01
 9.94777918e-01 3.92245192e-06 9.97119665e-01 9.99368727e-01
 5.77119552e-02 9.99749720e-01 9.97238994e-01 9.99814332e-01
 8.02239895e-01 9.99849916e-01 1.04611129e-01 7.33654946e-02
 9.99560416e-01 9.99901891e-01 1.12445661e-04 9.97340143e-01
 9.99991179e-01 1.93748698e-01 9.86651182e-01 2.33688019e-02
 6.15057861e-03 9.75324154e-01 9.98403132e-01 1.12303924e-02
 1.26552384e-03 5.89679182e-02 9.95253563e-01 9.96937275e-01
 9.97302651e-01 4.05165646e-03 1.09030688e-02 9.85842764e-01]
INFO:root:sensitive_y_true: [1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.
 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.]
INFO:root:2024-04-27 12:07:11, Dev, Step : 2504, Loss : 0.42091, Acc : 0.816, Auc : 0.909, Sensitive_Loss : 0.12928, Sensitive_Acc : 16.907, Sensitive_Auc : 0.996, Mean auc: 0.909, Run Time : 241.28 sec
INFO:root:2024-04-27 12:07:28, Train, Epoch : 5, Step : 2510, Loss : 0.20758, Acc : 0.512, Sensitive_Loss : 0.04507, Sensitive_Acc : 9.400, Run Time : 15.68 sec
INFO:root:2024-04-27 12:07:45, Train, Epoch : 5, Step : 2520, Loss : 0.32944, Acc : 0.875, Sensitive_Loss : 0.11052, Sensitive_Acc : 17.000, Run Time : 16.70 sec
INFO:root:2024-04-27 12:08:03, Train, Epoch : 5, Step : 2530, Loss : 0.30994, Acc : 0.872, Sensitive_Loss : 0.09090, Sensitive_Acc : 18.100, Run Time : 18.34 sec
INFO:root:2024-04-27 12:08:20, Train, Epoch : 5, Step : 2540, Loss : 0.33067, Acc : 0.822, Sensitive_Loss : 0.10650, Sensitive_Acc : 16.700, Run Time : 17.40 sec
INFO:root:2024-04-27 12:08:39, Train, Epoch : 5, Step : 2550, Loss : 0.34150, Acc : 0.859, Sensitive_Loss : 0.09684, Sensitive_Acc : 18.200, Run Time : 18.47 sec
INFO:root:2024-04-27 12:08:56, Train, Epoch : 5, Step : 2560, Loss : 0.27106, Acc : 0.872, Sensitive_Loss : 0.11871, Sensitive_Acc : 15.800, Run Time : 16.87 sec
INFO:root:2024-04-27 12:09:14, Train, Epoch : 5, Step : 2570, Loss : 0.33961, Acc : 0.869, Sensitive_Loss : 0.08158, Sensitive_Acc : 15.000, Run Time : 18.15 sec
INFO:root:2024-04-27 12:09:31, Train, Epoch : 5, Step : 2580, Loss : 0.35217, Acc : 0.850, Sensitive_Loss : 0.12187, Sensitive_Acc : 15.500, Run Time : 16.75 sec
INFO:root:2024-04-27 12:09:48, Train, Epoch : 5, Step : 2590, Loss : 0.31490, Acc : 0.866, Sensitive_Loss : 0.09281, Sensitive_Acc : 16.300, Run Time : 16.94 sec
INFO:root:2024-04-27 12:10:06, Train, Epoch : 5, Step : 2600, Loss : 0.29738, Acc : 0.872, Sensitive_Loss : 0.07890, Sensitive_Acc : 16.800, Run Time : 18.43 sec
INFO:root:2024-04-27 12:14:11, Dev, Step : 2600, Loss : 0.42012, Acc : 0.818, Auc : 0.909, Sensitive_Loss : 0.12734, Sensitive_Acc : 16.950, Sensitive_Auc : 0.996, Mean auc: 0.909, Run Time : 245.28 sec
INFO:root:2024-04-27 12:14:25, Train, Epoch : 5, Step : 2610, Loss : 0.30798, Acc : 0.853, Sensitive_Loss : 0.12219, Sensitive_Acc : 16.100, Run Time : 259.26 sec
INFO:root:2024-04-27 12:14:43, Train, Epoch : 5, Step : 2620, Loss : 0.31488, Acc : 0.872, Sensitive_Loss : 0.15762, Sensitive_Acc : 15.600, Run Time : 17.76 sec
INFO:root:2024-04-27 12:15:01, Train, Epoch : 5, Step : 2630, Loss : 0.31648, Acc : 0.853, Sensitive_Loss : 0.12711, Sensitive_Acc : 15.600, Run Time : 17.72 sec
INFO:root:2024-04-27 12:15:19, Train, Epoch : 5, Step : 2640, Loss : 0.32005, Acc : 0.853, Sensitive_Loss : 0.08550, Sensitive_Acc : 15.600, Run Time : 17.97 sec
INFO:root:2024-04-27 12:15:37, Train, Epoch : 5, Step : 2650, Loss : 0.32924, Acc : 0.859, Sensitive_Loss : 0.11964, Sensitive_Acc : 15.900, Run Time : 17.73 sec
INFO:root:2024-04-27 12:15:53, Train, Epoch : 5, Step : 2660, Loss : 0.32823, Acc : 0.847, Sensitive_Loss : 0.10239, Sensitive_Acc : 15.400, Run Time : 16.89 sec
INFO:root:2024-04-27 12:16:12, Train, Epoch : 5, Step : 2670, Loss : 0.27802, Acc : 0.887, Sensitive_Loss : 0.07996, Sensitive_Acc : 17.300, Run Time : 18.96 sec
INFO:root:2024-04-27 12:16:29, Train, Epoch : 5, Step : 2680, Loss : 0.30651, Acc : 0.863, Sensitive_Loss : 0.08583, Sensitive_Acc : 15.900, Run Time : 16.62 sec
INFO:root:2024-04-27 12:16:45, Train, Epoch : 5, Step : 2690, Loss : 0.33681, Acc : 0.856, Sensitive_Loss : 0.08706, Sensitive_Acc : 16.700, Run Time : 16.30 sec
INFO:root:2024-04-27 12:17:05, Train, Epoch : 5, Step : 2700, Loss : 0.28432, Acc : 0.894, Sensitive_Loss : 0.08160, Sensitive_Acc : 16.400, Run Time : 19.29 sec
INFO:root:2024-04-27 12:21:07, Dev, Step : 2700, Loss : 0.40437, Acc : 0.823, Auc : 0.909, Sensitive_Loss : 0.12744, Sensitive_Acc : 16.950, Sensitive_Auc : 0.996, Mean auc: 0.909, Run Time : 242.81 sec
INFO:root:2024-04-27 12:21:20, Train, Epoch : 5, Step : 2710, Loss : 0.34691, Acc : 0.872, Sensitive_Loss : 0.09712, Sensitive_Acc : 18.200, Run Time : 255.50 sec
INFO:root:2024-04-27 12:21:39, Train, Epoch : 5, Step : 2720, Loss : 0.34171, Acc : 0.834, Sensitive_Loss : 0.14276, Sensitive_Acc : 16.700, Run Time : 18.86 sec
INFO:root:2024-04-27 12:21:57, Train, Epoch : 5, Step : 2730, Loss : 0.29341, Acc : 0.875, Sensitive_Loss : 0.08189, Sensitive_Acc : 16.300, Run Time : 18.29 sec
INFO:root:2024-04-27 12:22:15, Train, Epoch : 5, Step : 2740, Loss : 0.29080, Acc : 0.869, Sensitive_Loss : 0.08362, Sensitive_Acc : 15.300, Run Time : 18.16 sec
INFO:root:2024-04-27 12:22:33, Train, Epoch : 5, Step : 2750, Loss : 0.26470, Acc : 0.875, Sensitive_Loss : 0.09397, Sensitive_Acc : 16.800, Run Time : 17.56 sec
INFO:root:2024-04-27 12:22:51, Train, Epoch : 5, Step : 2760, Loss : 0.31744, Acc : 0.844, Sensitive_Loss : 0.05731, Sensitive_Acc : 15.400, Run Time : 17.89 sec
INFO:root:2024-04-27 12:23:08, Train, Epoch : 5, Step : 2770, Loss : 0.32371, Acc : 0.866, Sensitive_Loss : 0.09065, Sensitive_Acc : 16.600, Run Time : 17.44 sec
INFO:root:2024-04-27 12:23:25, Train, Epoch : 5, Step : 2780, Loss : 0.32901, Acc : 0.828, Sensitive_Loss : 0.08084, Sensitive_Acc : 16.300, Run Time : 16.70 sec
INFO:root:2024-04-27 12:23:44, Train, Epoch : 5, Step : 2790, Loss : 0.27800, Acc : 0.900, Sensitive_Loss : 0.09610, Sensitive_Acc : 16.200, Run Time : 19.00 sec
INFO:root:2024-04-27 12:24:02, Train, Epoch : 5, Step : 2800, Loss : 0.34688, Acc : 0.841, Sensitive_Loss : 0.11500, Sensitive_Acc : 15.300, Run Time : 17.99 sec
INFO:root:2024-04-27 12:28:18, Dev, Step : 2800, Loss : 0.40121, Acc : 0.829, Auc : 0.909, Sensitive_Loss : 0.10780, Sensitive_Acc : 16.864, Sensitive_Auc : 0.996, Mean auc: 0.909, Run Time : 256.22 sec
INFO:root:2024-04-27 12:28:36, Train, Epoch : 5, Step : 2810, Loss : 0.34831, Acc : 0.863, Sensitive_Loss : 0.09323, Sensitive_Acc : 16.900, Run Time : 274.13 sec
INFO:root:2024-04-27 12:28:57, Train, Epoch : 5, Step : 2820, Loss : 0.32094, Acc : 0.863, Sensitive_Loss : 0.10091, Sensitive_Acc : 16.600, Run Time : 21.08 sec
INFO:root:2024-04-27 12:29:13, Train, Epoch : 5, Step : 2830, Loss : 0.29829, Acc : 0.891, Sensitive_Loss : 0.10518, Sensitive_Acc : 16.400, Run Time : 15.32 sec
INFO:root:2024-04-27 12:29:36, Train, Epoch : 5, Step : 2840, Loss : 0.37291, Acc : 0.884, Sensitive_Loss : 0.10060, Sensitive_Acc : 16.200, Run Time : 23.23 sec
INFO:root:2024-04-27 12:29:55, Train, Epoch : 5, Step : 2850, Loss : 0.33001, Acc : 0.850, Sensitive_Loss : 0.06731, Sensitive_Acc : 17.900, Run Time : 19.00 sec
INFO:root:2024-04-27 12:30:10, Train, Epoch : 5, Step : 2860, Loss : 0.30345, Acc : 0.872, Sensitive_Loss : 0.11801, Sensitive_Acc : 15.500, Run Time : 15.54 sec
INFO:root:2024-04-27 12:30:28, Train, Epoch : 5, Step : 2870, Loss : 0.37308, Acc : 0.866, Sensitive_Loss : 0.09491, Sensitive_Acc : 15.800, Run Time : 17.87 sec
INFO:root:2024-04-27 12:30:45, Train, Epoch : 5, Step : 2880, Loss : 0.35679, Acc : 0.881, Sensitive_Loss : 0.07311, Sensitive_Acc : 15.000, Run Time : 17.30 sec
INFO:root:2024-04-27 12:31:03, Train, Epoch : 5, Step : 2890, Loss : 0.29988, Acc : 0.878, Sensitive_Loss : 0.11467, Sensitive_Acc : 17.200, Run Time : 17.31 sec
INFO:root:2024-04-27 12:31:21, Train, Epoch : 5, Step : 2900, Loss : 0.24972, Acc : 0.897, Sensitive_Loss : 0.08565, Sensitive_Acc : 15.400, Run Time : 18.47 sec
INFO:root:2024-04-27 12:35:25, Dev, Step : 2900, Loss : 0.40521, Acc : 0.828, Auc : 0.910, Sensitive_Loss : 0.11617, Sensitive_Acc : 16.921, Sensitive_Auc : 0.996, Mean auc: 0.910, Run Time : 244.21 sec
INFO:root:2024-04-27 12:35:37, Train, Epoch : 5, Step : 2910, Loss : 0.26279, Acc : 0.903, Sensitive_Loss : 0.07496, Sensitive_Acc : 15.000, Run Time : 256.21 sec
INFO:root:2024-04-27 12:35:56, Train, Epoch : 5, Step : 2920, Loss : 0.25762, Acc : 0.850, Sensitive_Loss : 0.11032, Sensitive_Acc : 16.400, Run Time : 18.12 sec
INFO:root:2024-04-27 12:36:11, Train, Epoch : 5, Step : 2930, Loss : 0.37004, Acc : 0.828, Sensitive_Loss : 0.12954, Sensitive_Acc : 14.600, Run Time : 15.48 sec
INFO:root:2024-04-27 12:36:27, Train, Epoch : 5, Step : 2940, Loss : 0.35202, Acc : 0.844, Sensitive_Loss : 0.09169, Sensitive_Acc : 17.000, Run Time : 15.90 sec
INFO:root:2024-04-27 12:36:44, Train, Epoch : 5, Step : 2950, Loss : 0.33015, Acc : 0.866, Sensitive_Loss : 0.07652, Sensitive_Acc : 15.100, Run Time : 16.72 sec
INFO:root:2024-04-27 12:36:59, Train, Epoch : 5, Step : 2960, Loss : 0.34404, Acc : 0.856, Sensitive_Loss : 0.09845, Sensitive_Acc : 15.700, Run Time : 15.61 sec
INFO:root:2024-04-27 12:37:16, Train, Epoch : 5, Step : 2970, Loss : 0.31986, Acc : 0.863, Sensitive_Loss : 0.07599, Sensitive_Acc : 16.100, Run Time : 16.67 sec
INFO:root:2024-04-27 12:37:32, Train, Epoch : 5, Step : 2980, Loss : 0.32919, Acc : 0.869, Sensitive_Loss : 0.08681, Sensitive_Acc : 15.800, Run Time : 16.55 sec
INFO:root:2024-04-27 12:37:49, Train, Epoch : 5, Step : 2990, Loss : 0.32749, Acc : 0.859, Sensitive_Loss : 0.09465, Sensitive_Acc : 16.300, Run Time : 16.43 sec
INFO:root:2024-04-27 12:38:05, Train, Epoch : 5, Step : 3000, Loss : 0.32270, Acc : 0.863, Sensitive_Loss : 0.09220, Sensitive_Acc : 14.700, Run Time : 15.96 sec
INFO:root:2024-04-27 12:42:09, Dev, Step : 3000, Loss : 0.40074, Acc : 0.830, Auc : 0.909, Sensitive_Loss : 0.11176, Sensitive_Acc : 16.893, Sensitive_Auc : 0.997, Mean auc: 0.909, Run Time : 244.33 sec
INFO:root:2024-04-27 12:42:23, Train, Epoch : 5, Step : 3010, Loss : 0.35368, Acc : 0.847, Sensitive_Loss : 0.09614, Sensitive_Acc : 17.200, Run Time : 258.53 sec
INFO:root:2024-04-27 12:42:40, Train, Epoch : 5, Step : 3020, Loss : 0.36283, Acc : 0.856, Sensitive_Loss : 0.07825, Sensitive_Acc : 16.400, Run Time : 16.65 sec
INFO:root:2024-04-27 12:42:58, Train, Epoch : 5, Step : 3030, Loss : 0.29970, Acc : 0.859, Sensitive_Loss : 0.09249, Sensitive_Acc : 16.400, Run Time : 17.86 sec
INFO:root:2024-04-27 12:43:16, Train, Epoch : 5, Step : 3040, Loss : 0.32897, Acc : 0.847, Sensitive_Loss : 0.08443, Sensitive_Acc : 14.700, Run Time : 18.47 sec
INFO:root:2024-04-27 12:43:35, Train, Epoch : 5, Step : 3050, Loss : 0.34891, Acc : 0.847, Sensitive_Loss : 0.11013, Sensitive_Acc : 15.900, Run Time : 18.46 sec
INFO:root:2024-04-27 12:43:52, Train, Epoch : 5, Step : 3060, Loss : 0.33700, Acc : 0.825, Sensitive_Loss : 0.04481, Sensitive_Acc : 16.300, Run Time : 16.91 sec
INFO:root:2024-04-27 12:44:10, Train, Epoch : 5, Step : 3070, Loss : 0.31081, Acc : 0.881, Sensitive_Loss : 0.10831, Sensitive_Acc : 17.600, Run Time : 18.45 sec
INFO:root:2024-04-27 12:44:26, Train, Epoch : 5, Step : 3080, Loss : 0.34544, Acc : 0.853, Sensitive_Loss : 0.11840, Sensitive_Acc : 15.900, Run Time : 15.51 sec
INFO:root:2024-04-27 12:44:44, Train, Epoch : 5, Step : 3090, Loss : 0.29047, Acc : 0.891, Sensitive_Loss : 0.09543, Sensitive_Acc : 15.700, Run Time : 18.53 sec
INFO:root:2024-04-27 12:45:02, Train, Epoch : 5, Step : 3100, Loss : 0.31739, Acc : 0.869, Sensitive_Loss : 0.09572, Sensitive_Acc : 15.600, Run Time : 17.56 sec
INFO:root:2024-04-27 12:49:08, Dev, Step : 3100, Loss : 0.40436, Acc : 0.829, Auc : 0.911, Sensitive_Loss : 0.12096, Sensitive_Acc : 16.950, Sensitive_Auc : 0.996, Mean auc: 0.911, Run Time : 246.24 sec
INFO:root:2024-04-27 12:49:22, Train, Epoch : 5, Step : 3110, Loss : 0.29839, Acc : 0.853, Sensitive_Loss : 0.09847, Sensitive_Acc : 16.600, Run Time : 260.48 sec
INFO:root:2024-04-27 12:49:39, Train, Epoch : 5, Step : 3120, Loss : 0.33210, Acc : 0.869, Sensitive_Loss : 0.10058, Sensitive_Acc : 16.700, Run Time : 16.95 sec
INFO:root:2024-04-27 12:49:55, Train, Epoch : 5, Step : 3130, Loss : 0.30650, Acc : 0.872, Sensitive_Loss : 0.06697, Sensitive_Acc : 15.200, Run Time : 15.84 sec
INFO:root:2024-04-27 12:53:58
INFO:root:y_pred: [0.07431474 0.96685946 0.02986019 ... 0.96500134 0.0061964  0.86987156]
INFO:root:y_true: [0. 1. 0. ... 1. 0. 1.]
INFO:root:sensitive_y_pred: [9.81230676e-01 4.81753123e-05 1.01312637e-01 6.74364332e-04
 9.99319196e-01 3.93268798e-04 9.99932885e-01 9.99907851e-01
 5.05017670e-05 9.03077006e-01 9.99446332e-01 9.99837995e-01
 9.95347083e-01 9.94492054e-01 7.85791781e-03 9.29557025e-01
 9.99763906e-01 9.02365521e-03 4.62349981e-01 9.23861504e-01
 9.98660803e-01 5.25346352e-03 9.99101162e-01 9.98800874e-01
 9.95506525e-01 9.98591125e-01 1.85380166e-04 9.98377919e-01
 9.97248232e-01 1.52750820e-01 4.59611358e-04 5.22105955e-02
 1.77447742e-03 3.09920143e-02 7.02176765e-02 1.56990474e-03
 2.06626598e-02 6.96812337e-03 9.99792635e-01 9.97674048e-01
 1.93235019e-06 1.18983953e-05 9.15119946e-01 1.07239722e-03
 9.99395490e-01 9.91589963e-01 9.98653531e-01 9.88161623e-01
 4.17087082e-04 9.96783257e-01 8.63445342e-01 2.58746520e-02
 4.68731701e-01 1.00554712e-03 3.37583944e-04 4.28944305e-02
 1.48912473e-02 1.07983372e-03 5.14636522e-05 4.31671813e-02
 3.94710852e-03 5.67353554e-02 1.19832875e-02 9.80966926e-01
 2.36614794e-01 9.99580085e-01 2.27640127e-03 9.99657154e-01
 9.96103048e-01 7.13800415e-02 8.88553858e-01 1.44389331e-01
 5.40933385e-03 1.47690168e-02 6.56093835e-05 6.20840234e-04
 1.56626999e-02 1.17435217e-01 1.20184256e-03 9.99912739e-01
 9.98496532e-01 1.09097175e-03 6.61917478e-02 2.02999939e-03
 6.64649308e-01 7.79713452e-01 7.10866833e-03 7.00649573e-03
 9.92879689e-01 9.99641895e-01 9.99971986e-01 1.69329683e-03
 2.09029042e-03 9.78425324e-01 4.98567760e-01 1.88985269e-03
 9.95671988e-01 9.99336779e-01 1.79786293e-04 2.15707831e-02
 9.85599756e-01 9.91819620e-01 9.98132765e-01 9.97071505e-01
 2.52981437e-04 2.06055567e-02 9.93801296e-01 9.99265015e-01
 9.92780745e-01 1.28221609e-06 9.92918193e-01 9.98504519e-01
 1.81604270e-02 9.99491215e-01 9.96032655e-01 9.99651790e-01
 5.21611869e-01 9.99834776e-01 1.82881393e-02 3.22883762e-02
 9.99043167e-01 9.99810755e-01 6.05932437e-05 9.96341407e-01
 9.99991775e-01 6.49088100e-02 9.80979621e-01 1.07171806e-02
 2.72980193e-03 8.91939580e-01 9.94746208e-01 4.29584365e-03
 1.57110032e-03 9.95401107e-03 9.92608964e-01 9.91070032e-01
 9.88743424e-01 1.84275489e-03 4.30229353e-03 9.63346779e-01]
INFO:root:sensitive_y_true: [1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.
 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.]
INFO:root:2024-04-27 12:53:58, Dev, Step : 3130, Loss : 0.39930, Acc : 0.830, Auc : 0.910, Sensitive_Loss : 0.10473, Sensitive_Acc : 16.893, Sensitive_Auc : 0.997, Mean auc: 0.910, Run Time : 242.97 sec
INFO:root:2024-04-27 12:54:21, Train, Epoch : 6, Step : 3140, Loss : 0.27514, Acc : 0.872, Sensitive_Loss : 0.09423, Sensitive_Acc : 15.500, Run Time : 21.37 sec
INFO:root:2024-04-27 12:54:39, Train, Epoch : 6, Step : 3150, Loss : 0.26639, Acc : 0.878, Sensitive_Loss : 0.07994, Sensitive_Acc : 16.300, Run Time : 18.65 sec
INFO:root:2024-04-27 12:54:58, Train, Epoch : 6, Step : 3160, Loss : 0.33156, Acc : 0.869, Sensitive_Loss : 0.10848, Sensitive_Acc : 16.000, Run Time : 18.48 sec
INFO:root:2024-04-27 12:55:16, Train, Epoch : 6, Step : 3170, Loss : 0.29790, Acc : 0.878, Sensitive_Loss : 0.08712, Sensitive_Acc : 17.700, Run Time : 17.91 sec
INFO:root:2024-04-27 12:55:34, Train, Epoch : 6, Step : 3180, Loss : 0.36341, Acc : 0.838, Sensitive_Loss : 0.10910, Sensitive_Acc : 15.200, Run Time : 18.03 sec
INFO:root:2024-04-27 12:55:51, Train, Epoch : 6, Step : 3190, Loss : 0.33721, Acc : 0.875, Sensitive_Loss : 0.09894, Sensitive_Acc : 15.200, Run Time : 17.56 sec
INFO:root:2024-04-27 12:56:10, Train, Epoch : 6, Step : 3200, Loss : 0.30651, Acc : 0.859, Sensitive_Loss : 0.10021, Sensitive_Acc : 16.600, Run Time : 18.24 sec
INFO:root:2024-04-27 13:00:13, Dev, Step : 3200, Loss : 0.41339, Acc : 0.824, Auc : 0.908, Sensitive_Loss : 0.11950, Sensitive_Acc : 16.950, Sensitive_Auc : 0.997, Mean auc: 0.908, Run Time : 243.08 sec
INFO:root:2024-04-27 13:00:25, Train, Epoch : 6, Step : 3210, Loss : 0.26841, Acc : 0.894, Sensitive_Loss : 0.08711, Sensitive_Acc : 16.500, Run Time : 255.92 sec
INFO:root:2024-04-27 13:00:45, Train, Epoch : 6, Step : 3220, Loss : 0.33116, Acc : 0.806, Sensitive_Loss : 0.11900, Sensitive_Acc : 16.100, Run Time : 19.49 sec
INFO:root:2024-04-27 13:01:02, Train, Epoch : 6, Step : 3230, Loss : 0.34160, Acc : 0.875, Sensitive_Loss : 0.10172, Sensitive_Acc : 17.500, Run Time : 17.24 sec
INFO:root:2024-04-27 13:01:20, Train, Epoch : 6, Step : 3240, Loss : 0.33780, Acc : 0.850, Sensitive_Loss : 0.09213, Sensitive_Acc : 15.400, Run Time : 17.60 sec
INFO:root:2024-04-27 13:01:38, Train, Epoch : 6, Step : 3250, Loss : 0.28246, Acc : 0.838, Sensitive_Loss : 0.08505, Sensitive_Acc : 15.500, Run Time : 18.67 sec
INFO:root:2024-04-27 13:01:56, Train, Epoch : 6, Step : 3260, Loss : 0.29933, Acc : 0.900, Sensitive_Loss : 0.08179, Sensitive_Acc : 15.900, Run Time : 17.82 sec
INFO:root:2024-04-27 13:02:13, Train, Epoch : 6, Step : 3270, Loss : 0.28852, Acc : 0.863, Sensitive_Loss : 0.09763, Sensitive_Acc : 16.800, Run Time : 16.99 sec
INFO:root:2024-04-27 13:02:31, Train, Epoch : 6, Step : 3280, Loss : 0.33404, Acc : 0.859, Sensitive_Loss : 0.10077, Sensitive_Acc : 15.500, Run Time : 18.03 sec
INFO:root:2024-04-27 13:02:49, Train, Epoch : 6, Step : 3290, Loss : 0.26178, Acc : 0.887, Sensitive_Loss : 0.07788, Sensitive_Acc : 17.200, Run Time : 18.21 sec
INFO:root:2024-04-27 13:03:07, Train, Epoch : 6, Step : 3300, Loss : 0.28776, Acc : 0.884, Sensitive_Loss : 0.07631, Sensitive_Acc : 16.300, Run Time : 17.52 sec
INFO:root:2024-04-27 13:07:11, Dev, Step : 3300, Loss : 0.40570, Acc : 0.823, Auc : 0.910, Sensitive_Loss : 0.11707, Sensitive_Acc : 16.950, Sensitive_Auc : 0.997, Mean auc: 0.910, Run Time : 243.85 sec
INFO:root:2024-04-27 13:07:24, Train, Epoch : 6, Step : 3310, Loss : 0.30438, Acc : 0.850, Sensitive_Loss : 0.12739, Sensitive_Acc : 15.800, Run Time : 257.45 sec
INFO:root:2024-04-27 13:07:43, Train, Epoch : 6, Step : 3320, Loss : 0.34540, Acc : 0.838, Sensitive_Loss : 0.08660, Sensitive_Acc : 15.300, Run Time : 18.06 sec
INFO:root:2024-04-27 13:08:00, Train, Epoch : 6, Step : 3330, Loss : 0.25201, Acc : 0.891, Sensitive_Loss : 0.09299, Sensitive_Acc : 18.000, Run Time : 17.81 sec
INFO:root:2024-04-27 13:08:18, Train, Epoch : 6, Step : 3340, Loss : 0.28854, Acc : 0.897, Sensitive_Loss : 0.07346, Sensitive_Acc : 15.700, Run Time : 17.29 sec
INFO:root:2024-04-27 13:08:35, Train, Epoch : 6, Step : 3350, Loss : 0.31639, Acc : 0.853, Sensitive_Loss : 0.08203, Sensitive_Acc : 15.500, Run Time : 17.51 sec
INFO:root:2024-04-27 13:08:52, Train, Epoch : 6, Step : 3360, Loss : 0.32880, Acc : 0.872, Sensitive_Loss : 0.09346, Sensitive_Acc : 15.900, Run Time : 16.62 sec
INFO:root:2024-04-27 13:09:10, Train, Epoch : 6, Step : 3370, Loss : 0.34728, Acc : 0.863, Sensitive_Loss : 0.12366, Sensitive_Acc : 15.000, Run Time : 18.12 sec
INFO:root:2024-04-27 13:09:28, Train, Epoch : 6, Step : 3380, Loss : 0.28601, Acc : 0.850, Sensitive_Loss : 0.09575, Sensitive_Acc : 16.800, Run Time : 17.76 sec
INFO:root:2024-04-27 13:09:45, Train, Epoch : 6, Step : 3390, Loss : 0.34940, Acc : 0.856, Sensitive_Loss : 0.08024, Sensitive_Acc : 16.700, Run Time : 16.98 sec
INFO:root:2024-04-27 13:10:04, Train, Epoch : 6, Step : 3400, Loss : 0.28959, Acc : 0.881, Sensitive_Loss : 0.11273, Sensitive_Acc : 16.100, Run Time : 19.08 sec
INFO:root:2024-04-27 13:14:08, Dev, Step : 3400, Loss : 0.43478, Acc : 0.815, Auc : 0.908, Sensitive_Loss : 0.12599, Sensitive_Acc : 16.950, Sensitive_Auc : 0.996, Mean auc: 0.908, Run Time : 244.51 sec
INFO:root:2024-04-27 13:14:21, Train, Epoch : 6, Step : 3410, Loss : 0.30136, Acc : 0.859, Sensitive_Loss : 0.06278, Sensitive_Acc : 17.300, Run Time : 257.28 sec
INFO:root:2024-04-27 13:14:40, Train, Epoch : 6, Step : 3420, Loss : 0.27572, Acc : 0.881, Sensitive_Loss : 0.09405, Sensitive_Acc : 15.900, Run Time : 19.38 sec
INFO:root:2024-04-27 13:14:58, Train, Epoch : 6, Step : 3430, Loss : 0.27021, Acc : 0.878, Sensitive_Loss : 0.08537, Sensitive_Acc : 17.000, Run Time : 17.26 sec
INFO:root:2024-04-27 13:15:16, Train, Epoch : 6, Step : 3440, Loss : 0.24155, Acc : 0.866, Sensitive_Loss : 0.10985, Sensitive_Acc : 15.800, Run Time : 18.12 sec
INFO:root:2024-04-27 13:15:33, Train, Epoch : 6, Step : 3450, Loss : 0.25639, Acc : 0.891, Sensitive_Loss : 0.10146, Sensitive_Acc : 16.000, Run Time : 17.23 sec
INFO:root:2024-04-27 13:15:50, Train, Epoch : 6, Step : 3460, Loss : 0.26983, Acc : 0.875, Sensitive_Loss : 0.11538, Sensitive_Acc : 16.600, Run Time : 17.36 sec
INFO:root:2024-04-27 13:16:08, Train, Epoch : 6, Step : 3470, Loss : 0.29501, Acc : 0.878, Sensitive_Loss : 0.07717, Sensitive_Acc : 15.300, Run Time : 17.74 sec
INFO:root:2024-04-27 13:16:27, Train, Epoch : 6, Step : 3480, Loss : 0.31885, Acc : 0.878, Sensitive_Loss : 0.11097, Sensitive_Acc : 16.000, Run Time : 18.62 sec
INFO:root:2024-04-27 13:16:44, Train, Epoch : 6, Step : 3490, Loss : 0.32205, Acc : 0.878, Sensitive_Loss : 0.08666, Sensitive_Acc : 15.800, Run Time : 17.53 sec
INFO:root:2024-04-27 13:17:02, Train, Epoch : 6, Step : 3500, Loss : 0.28685, Acc : 0.878, Sensitive_Loss : 0.07519, Sensitive_Acc : 16.700, Run Time : 17.71 sec
INFO:root:2024-04-27 13:21:05, Dev, Step : 3500, Loss : 0.41325, Acc : 0.826, Auc : 0.909, Sensitive_Loss : 0.12336, Sensitive_Acc : 16.950, Sensitive_Auc : 0.995, Mean auc: 0.909, Run Time : 242.69 sec
INFO:root:2024-04-27 13:21:18, Train, Epoch : 6, Step : 3510, Loss : 0.33379, Acc : 0.859, Sensitive_Loss : 0.06531, Sensitive_Acc : 15.100, Run Time : 256.37 sec
INFO:root:2024-04-27 13:21:36, Train, Epoch : 6, Step : 3520, Loss : 0.28129, Acc : 0.884, Sensitive_Loss : 0.07963, Sensitive_Acc : 17.300, Run Time : 17.94 sec
INFO:root:2024-04-27 13:21:54, Train, Epoch : 6, Step : 3530, Loss : 0.27317, Acc : 0.881, Sensitive_Loss : 0.06836, Sensitive_Acc : 17.300, Run Time : 18.15 sec
INFO:root:2024-04-27 13:22:12, Train, Epoch : 6, Step : 3540, Loss : 0.30934, Acc : 0.866, Sensitive_Loss : 0.12450, Sensitive_Acc : 17.100, Run Time : 18.12 sec
INFO:root:2024-04-27 13:22:31, Train, Epoch : 6, Step : 3550, Loss : 0.26513, Acc : 0.875, Sensitive_Loss : 0.10673, Sensitive_Acc : 15.400, Run Time : 18.07 sec
INFO:root:2024-04-27 13:22:48, Train, Epoch : 6, Step : 3560, Loss : 0.24364, Acc : 0.906, Sensitive_Loss : 0.10025, Sensitive_Acc : 16.500, Run Time : 17.74 sec
INFO:root:2024-04-27 13:23:06, Train, Epoch : 6, Step : 3570, Loss : 0.28834, Acc : 0.847, Sensitive_Loss : 0.06379, Sensitive_Acc : 16.100, Run Time : 17.50 sec
INFO:root:2024-04-27 13:23:23, Train, Epoch : 6, Step : 3580, Loss : 0.31202, Acc : 0.869, Sensitive_Loss : 0.15349, Sensitive_Acc : 15.800, Run Time : 16.71 sec
INFO:root:2024-04-27 13:23:41, Train, Epoch : 6, Step : 3590, Loss : 0.31308, Acc : 0.856, Sensitive_Loss : 0.10309, Sensitive_Acc : 16.700, Run Time : 18.25 sec
INFO:root:2024-04-27 13:23:59, Train, Epoch : 6, Step : 3600, Loss : 0.27207, Acc : 0.897, Sensitive_Loss : 0.11594, Sensitive_Acc : 15.900, Run Time : 18.54 sec
INFO:root:2024-04-27 13:28:03, Dev, Step : 3600, Loss : 0.43610, Acc : 0.815, Auc : 0.906, Sensitive_Loss : 0.11453, Sensitive_Acc : 16.921, Sensitive_Auc : 0.996, Mean auc: 0.906, Run Time : 243.22 sec
INFO:root:2024-04-27 13:28:16, Train, Epoch : 6, Step : 3610, Loss : 0.33417, Acc : 0.872, Sensitive_Loss : 0.10491, Sensitive_Acc : 16.400, Run Time : 256.81 sec
INFO:root:2024-04-27 13:28:34, Train, Epoch : 6, Step : 3620, Loss : 0.31080, Acc : 0.866, Sensitive_Loss : 0.08690, Sensitive_Acc : 17.000, Run Time : 17.77 sec
INFO:root:2024-04-27 13:28:52, Train, Epoch : 6, Step : 3630, Loss : 0.27757, Acc : 0.894, Sensitive_Loss : 0.09331, Sensitive_Acc : 15.500, Run Time : 18.34 sec
INFO:root:2024-04-27 13:29:09, Train, Epoch : 6, Step : 3640, Loss : 0.31530, Acc : 0.878, Sensitive_Loss : 0.11344, Sensitive_Acc : 17.000, Run Time : 16.93 sec
INFO:root:2024-04-27 13:29:27, Train, Epoch : 6, Step : 3650, Loss : 0.27156, Acc : 0.869, Sensitive_Loss : 0.08588, Sensitive_Acc : 18.100, Run Time : 18.09 sec
INFO:root:2024-04-27 13:29:44, Train, Epoch : 6, Step : 3660, Loss : 0.28978, Acc : 0.853, Sensitive_Loss : 0.12162, Sensitive_Acc : 15.700, Run Time : 17.13 sec
INFO:root:2024-04-27 13:30:03, Train, Epoch : 6, Step : 3670, Loss : 0.22606, Acc : 0.909, Sensitive_Loss : 0.06354, Sensitive_Acc : 16.200, Run Time : 18.39 sec
INFO:root:2024-04-27 13:30:20, Train, Epoch : 6, Step : 3680, Loss : 0.31023, Acc : 0.891, Sensitive_Loss : 0.07401, Sensitive_Acc : 15.600, Run Time : 17.62 sec
INFO:root:2024-04-27 13:30:39, Train, Epoch : 6, Step : 3690, Loss : 0.33569, Acc : 0.853, Sensitive_Loss : 0.09766, Sensitive_Acc : 16.900, Run Time : 18.19 sec
INFO:root:2024-04-27 13:30:55, Train, Epoch : 6, Step : 3700, Loss : 0.31732, Acc : 0.838, Sensitive_Loss : 0.07359, Sensitive_Acc : 17.600, Run Time : 16.71 sec
INFO:root:2024-04-27 13:35:00, Dev, Step : 3700, Loss : 0.46686, Acc : 0.805, Auc : 0.906, Sensitive_Loss : 0.12386, Sensitive_Acc : 16.950, Sensitive_Auc : 0.996, Mean auc: 0.906, Run Time : 244.77 sec
INFO:root:2024-04-27 13:35:14, Train, Epoch : 6, Step : 3710, Loss : 0.30951, Acc : 0.869, Sensitive_Loss : 0.08376, Sensitive_Acc : 16.300, Run Time : 258.61 sec
INFO:root:2024-04-27 13:35:31, Train, Epoch : 6, Step : 3720, Loss : 0.30360, Acc : 0.866, Sensitive_Loss : 0.06988, Sensitive_Acc : 16.300, Run Time : 17.00 sec
INFO:root:2024-04-27 13:35:49, Train, Epoch : 6, Step : 3730, Loss : 0.27124, Acc : 0.887, Sensitive_Loss : 0.07244, Sensitive_Acc : 16.900, Run Time : 18.00 sec
INFO:root:2024-04-27 13:36:07, Train, Epoch : 6, Step : 3740, Loss : 0.33018, Acc : 0.853, Sensitive_Loss : 0.08397, Sensitive_Acc : 15.100, Run Time : 18.54 sec
INFO:root:2024-04-27 13:36:25, Train, Epoch : 6, Step : 3750, Loss : 0.29962, Acc : 0.853, Sensitive_Loss : 0.07067, Sensitive_Acc : 17.400, Run Time : 17.27 sec
INFO:root:2024-04-27 13:40:36
INFO:root:y_pred: [0.0506534  0.9417134  0.01363042 ... 0.9525259  0.0031475  0.9132573 ]
INFO:root:y_true: [0. 1. 0. ... 1. 0. 1.]
INFO:root:sensitive_y_pred: [9.92639899e-01 1.75951311e-04 2.57031113e-01 8.87377013e-04
 9.99784648e-01 8.83841305e-04 9.99973059e-01 9.99950409e-01
 2.80954118e-04 9.67147529e-01 9.99858022e-01 9.99925137e-01
 9.97806847e-01 9.98339534e-01 1.16604716e-02 9.79754865e-01
 9.99886513e-01 3.21807303e-02 7.17269421e-01 9.41737652e-01
 9.99208033e-01 1.16097704e-02 9.99448478e-01 9.99219060e-01
 9.98751163e-01 9.99323130e-01 9.18624981e-04 9.99270618e-01
 9.97169912e-01 3.66325200e-01 6.83901773e-04 1.24822184e-01
 2.55220127e-03 6.08718395e-02 1.29754260e-01 2.75307964e-03
 3.42990085e-02 1.71841718e-02 9.99918938e-01 9.99026775e-01
 6.46316630e-06 7.69001927e-05 9.72497523e-01 2.60250689e-03
 9.99769390e-01 9.95340824e-01 9.99257028e-01 9.97412384e-01
 2.44946009e-03 9.98724043e-01 8.52116227e-01 3.74178253e-02
 6.94469929e-01 2.40847073e-03 1.44650892e-03 6.70183003e-02
 3.44018824e-02 5.52291796e-03 1.87640791e-04 8.38463083e-02
 1.28070628e-02 1.56038687e-01 3.36836651e-02 9.90515113e-01
 3.65606844e-01 9.99854326e-01 2.59564049e-03 9.99912977e-01
 9.99009252e-01 9.51744318e-02 9.39649880e-01 5.29314399e-01
 7.45647121e-03 9.42930281e-02 7.48907114e-05 1.13193423e-03
 3.37517820e-02 2.45141938e-01 1.19691587e-03 9.99978781e-01
 9.99317884e-01 3.72411031e-03 2.83724576e-01 3.22815939e-03
 7.78415740e-01 9.28893030e-01 2.41463315e-02 1.39364125e-02
 9.97829378e-01 9.99920607e-01 9.99985695e-01 4.46065050e-03
 5.27141755e-03 9.94518220e-01 6.17835760e-01 9.34466254e-03
 9.99104321e-01 9.99788940e-01 5.30824880e-04 3.77358831e-02
 9.90466475e-01 9.95355368e-01 9.98894155e-01 9.99363005e-01
 4.62433381e-04 9.96082649e-02 9.97827590e-01 9.99816954e-01
 9.98146653e-01 7.07817026e-06 9.97803032e-01 9.99595106e-01
 2.40852591e-02 9.99848247e-01 9.97165382e-01 9.99792635e-01
 7.77438223e-01 9.99912024e-01 4.62006927e-02 7.50503764e-02
 9.99651194e-01 9.99937296e-01 1.41547745e-04 9.99043882e-01
 9.99997973e-01 1.99812397e-01 9.87142324e-01 3.23787257e-02
 1.78506952e-02 9.66708362e-01 9.97308254e-01 1.08873798e-02
 2.72547128e-03 2.72516105e-02 9.95490968e-01 9.96695161e-01
 9.95347440e-01 4.26776009e-03 6.97715674e-03 9.91676927e-01]
INFO:root:sensitive_y_true: [1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.
 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.]
INFO:root:2024-04-27 13:40:36, Dev, Step : 3756, Loss : 0.44307, Acc : 0.813, Auc : 0.907, Sensitive_Loss : 0.12811, Sensitive_Acc : 16.921, Sensitive_Auc : 0.997, Mean auc: 0.907, Run Time : 241.95 sec
INFO:root:2024-04-27 13:40:48, Train, Epoch : 7, Step : 3760, Loss : 0.09650, Acc : 0.353, Sensitive_Loss : 0.02444, Sensitive_Acc : 5.700, Run Time : 11.33 sec
INFO:root:2024-04-27 13:41:06, Train, Epoch : 7, Step : 3770, Loss : 0.23207, Acc : 0.863, Sensitive_Loss : 0.15289, Sensitive_Acc : 18.300, Run Time : 17.80 sec
INFO:root:2024-04-27 13:41:25, Train, Epoch : 7, Step : 3780, Loss : 0.26596, Acc : 0.897, Sensitive_Loss : 0.07860, Sensitive_Acc : 16.500, Run Time : 19.28 sec
INFO:root:2024-04-27 13:41:41, Train, Epoch : 7, Step : 3790, Loss : 0.27263, Acc : 0.875, Sensitive_Loss : 0.08941, Sensitive_Acc : 15.100, Run Time : 15.61 sec
INFO:root:2024-04-27 13:42:00, Train, Epoch : 7, Step : 3800, Loss : 0.25193, Acc : 0.881, Sensitive_Loss : 0.11301, Sensitive_Acc : 17.400, Run Time : 19.20 sec
INFO:root:2024-04-27 13:46:03, Dev, Step : 3800, Loss : 0.43911, Acc : 0.817, Auc : 0.909, Sensitive_Loss : 0.11975, Sensitive_Acc : 16.893, Sensitive_Auc : 0.997, Mean auc: 0.909, Run Time : 243.19 sec
INFO:root:2024-04-27 13:46:18, Train, Epoch : 7, Step : 3810, Loss : 0.27060, Acc : 0.897, Sensitive_Loss : 0.12283, Sensitive_Acc : 16.800, Run Time : 257.65 sec
INFO:root:2024-04-27 13:46:35, Train, Epoch : 7, Step : 3820, Loss : 0.24406, Acc : 0.891, Sensitive_Loss : 0.08013, Sensitive_Acc : 16.700, Run Time : 17.54 sec
INFO:root:2024-04-27 13:46:54, Train, Epoch : 7, Step : 3830, Loss : 0.26913, Acc : 0.884, Sensitive_Loss : 0.08448, Sensitive_Acc : 16.500, Run Time : 18.07 sec
INFO:root:2024-04-27 13:47:12, Train, Epoch : 7, Step : 3840, Loss : 0.27345, Acc : 0.875, Sensitive_Loss : 0.09181, Sensitive_Acc : 16.000, Run Time : 18.50 sec
INFO:root:2024-04-27 13:47:30, Train, Epoch : 7, Step : 3850, Loss : 0.27730, Acc : 0.884, Sensitive_Loss : 0.09847, Sensitive_Acc : 15.900, Run Time : 17.80 sec
INFO:root:2024-04-27 13:47:47, Train, Epoch : 7, Step : 3860, Loss : 0.28552, Acc : 0.863, Sensitive_Loss : 0.09016, Sensitive_Acc : 15.900, Run Time : 17.14 sec
INFO:root:2024-04-27 13:48:05, Train, Epoch : 7, Step : 3870, Loss : 0.30438, Acc : 0.884, Sensitive_Loss : 0.07767, Sensitive_Acc : 16.800, Run Time : 18.03 sec
INFO:root:2024-04-27 13:48:22, Train, Epoch : 7, Step : 3880, Loss : 0.23708, Acc : 0.903, Sensitive_Loss : 0.07960, Sensitive_Acc : 16.400, Run Time : 17.42 sec
INFO:root:2024-04-27 13:48:40, Train, Epoch : 7, Step : 3890, Loss : 0.30481, Acc : 0.878, Sensitive_Loss : 0.10268, Sensitive_Acc : 15.300, Run Time : 17.36 sec
INFO:root:2024-04-27 13:48:56, Train, Epoch : 7, Step : 3900, Loss : 0.28711, Acc : 0.875, Sensitive_Loss : 0.07498, Sensitive_Acc : 15.600, Run Time : 16.44 sec
INFO:root:2024-04-27 13:53:01, Dev, Step : 3900, Loss : 0.42689, Acc : 0.819, Auc : 0.907, Sensitive_Loss : 0.11022, Sensitive_Acc : 16.921, Sensitive_Auc : 0.998, Mean auc: 0.907, Run Time : 244.66 sec
INFO:root:2024-04-27 13:53:15, Train, Epoch : 7, Step : 3910, Loss : 0.28142, Acc : 0.894, Sensitive_Loss : 0.10320, Sensitive_Acc : 16.900, Run Time : 258.49 sec
INFO:root:2024-04-27 13:53:32, Train, Epoch : 7, Step : 3920, Loss : 0.25701, Acc : 0.900, Sensitive_Loss : 0.06746, Sensitive_Acc : 15.800, Run Time : 17.22 sec
INFO:root:2024-04-27 13:53:50, Train, Epoch : 7, Step : 3930, Loss : 0.26089, Acc : 0.891, Sensitive_Loss : 0.09278, Sensitive_Acc : 16.800, Run Time : 18.49 sec
INFO:root:2024-04-27 13:54:08, Train, Epoch : 7, Step : 3940, Loss : 0.27867, Acc : 0.891, Sensitive_Loss : 0.06350, Sensitive_Acc : 17.600, Run Time : 17.76 sec
INFO:root:2024-04-27 13:54:25, Train, Epoch : 7, Step : 3950, Loss : 0.29275, Acc : 0.891, Sensitive_Loss : 0.07246, Sensitive_Acc : 16.100, Run Time : 16.96 sec
INFO:root:2024-04-27 13:54:43, Train, Epoch : 7, Step : 3960, Loss : 0.28103, Acc : 0.872, Sensitive_Loss : 0.11749, Sensitive_Acc : 16.400, Run Time : 18.11 sec
INFO:root:2024-04-27 13:55:01, Train, Epoch : 7, Step : 3970, Loss : 0.25655, Acc : 0.869, Sensitive_Loss : 0.09185, Sensitive_Acc : 16.800, Run Time : 17.52 sec
INFO:root:2024-04-27 13:55:19, Train, Epoch : 7, Step : 3980, Loss : 0.25090, Acc : 0.906, Sensitive_Loss : 0.08463, Sensitive_Acc : 17.800, Run Time : 18.18 sec
INFO:root:2024-04-27 13:55:35, Train, Epoch : 7, Step : 3990, Loss : 0.29704, Acc : 0.869, Sensitive_Loss : 0.10591, Sensitive_Acc : 16.700, Run Time : 16.13 sec
INFO:root:2024-04-27 13:55:54, Train, Epoch : 7, Step : 4000, Loss : 0.29038, Acc : 0.872, Sensitive_Loss : 0.09254, Sensitive_Acc : 16.100, Run Time : 18.55 sec
INFO:root:2024-04-27 13:59:58, Dev, Step : 4000, Loss : 0.44317, Acc : 0.817, Auc : 0.906, Sensitive_Loss : 0.13061, Sensitive_Acc : 16.950, Sensitive_Auc : 0.996, Mean auc: 0.906, Run Time : 243.98 sec
INFO:root:2024-04-27 14:00:11, Train, Epoch : 7, Step : 4010, Loss : 0.32828, Acc : 0.878, Sensitive_Loss : 0.08174, Sensitive_Acc : 17.100, Run Time : 256.84 sec
INFO:root:2024-04-27 14:00:30, Train, Epoch : 7, Step : 4020, Loss : 0.38459, Acc : 0.859, Sensitive_Loss : 0.05573, Sensitive_Acc : 16.500, Run Time : 19.14 sec
INFO:root:2024-04-27 14:00:48, Train, Epoch : 7, Step : 4030, Loss : 0.27897, Acc : 0.887, Sensitive_Loss : 0.08886, Sensitive_Acc : 16.200, Run Time : 17.97 sec
INFO:root:2024-04-27 14:01:05, Train, Epoch : 7, Step : 4040, Loss : 0.33436, Acc : 0.863, Sensitive_Loss : 0.11129, Sensitive_Acc : 15.900, Run Time : 17.51 sec
INFO:root:2024-04-27 14:01:23, Train, Epoch : 7, Step : 4050, Loss : 0.28570, Acc : 0.891, Sensitive_Loss : 0.06585, Sensitive_Acc : 16.100, Run Time : 17.77 sec
INFO:root:2024-04-27 14:01:40, Train, Epoch : 7, Step : 4060, Loss : 0.30071, Acc : 0.887, Sensitive_Loss : 0.08193, Sensitive_Acc : 17.300, Run Time : 17.23 sec
INFO:root:2024-04-27 14:01:58, Train, Epoch : 7, Step : 4070, Loss : 0.29019, Acc : 0.869, Sensitive_Loss : 0.08903, Sensitive_Acc : 15.900, Run Time : 18.21 sec
INFO:root:2024-04-27 14:02:15, Train, Epoch : 7, Step : 4080, Loss : 0.25481, Acc : 0.891, Sensitive_Loss : 0.11009, Sensitive_Acc : 17.300, Run Time : 16.62 sec
INFO:root:2024-04-27 14:02:35, Train, Epoch : 7, Step : 4090, Loss : 0.25570, Acc : 0.909, Sensitive_Loss : 0.06558, Sensitive_Acc : 17.000, Run Time : 19.74 sec
INFO:root:2024-04-27 14:02:51, Train, Epoch : 7, Step : 4100, Loss : 0.28690, Acc : 0.881, Sensitive_Loss : 0.07782, Sensitive_Acc : 17.200, Run Time : 15.91 sec
INFO:root:2024-04-27 14:06:56, Dev, Step : 4100, Loss : 0.42365, Acc : 0.822, Auc : 0.906, Sensitive_Loss : 0.11490, Sensitive_Acc : 16.921, Sensitive_Auc : 0.996, Mean auc: 0.906, Run Time : 245.60 sec
INFO:root:2024-04-27 14:07:09, Train, Epoch : 7, Step : 4110, Loss : 0.24364, Acc : 0.900, Sensitive_Loss : 0.07835, Sensitive_Acc : 16.400, Run Time : 258.32 sec
INFO:root:2024-04-27 14:07:28, Train, Epoch : 7, Step : 4120, Loss : 0.30453, Acc : 0.878, Sensitive_Loss : 0.09993, Sensitive_Acc : 16.000, Run Time : 18.85 sec
INFO:root:2024-04-27 14:07:47, Train, Epoch : 7, Step : 4130, Loss : 0.27397, Acc : 0.875, Sensitive_Loss : 0.06850, Sensitive_Acc : 15.400, Run Time : 18.68 sec
INFO:root:2024-04-27 14:08:04, Train, Epoch : 7, Step : 4140, Loss : 0.27665, Acc : 0.872, Sensitive_Loss : 0.07327, Sensitive_Acc : 16.900, Run Time : 17.66 sec
INFO:root:2024-04-27 14:08:21, Train, Epoch : 7, Step : 4150, Loss : 0.27753, Acc : 0.891, Sensitive_Loss : 0.07851, Sensitive_Acc : 18.200, Run Time : 17.06 sec
INFO:root:2024-04-27 14:08:37, Train, Epoch : 7, Step : 4160, Loss : 0.30975, Acc : 0.859, Sensitive_Loss : 0.07039, Sensitive_Acc : 17.000, Run Time : 16.17 sec
INFO:root:2024-04-27 14:08:56, Train, Epoch : 7, Step : 4170, Loss : 0.26293, Acc : 0.887, Sensitive_Loss : 0.07260, Sensitive_Acc : 17.200, Run Time : 18.95 sec
INFO:root:2024-04-27 14:09:13, Train, Epoch : 7, Step : 4180, Loss : 0.27527, Acc : 0.887, Sensitive_Loss : 0.06898, Sensitive_Acc : 15.600, Run Time : 16.47 sec
INFO:root:2024-04-27 14:09:33, Train, Epoch : 7, Step : 4190, Loss : 0.31056, Acc : 0.903, Sensitive_Loss : 0.13897, Sensitive_Acc : 15.500, Run Time : 19.76 sec
INFO:root:2024-04-27 14:09:50, Train, Epoch : 7, Step : 4200, Loss : 0.24128, Acc : 0.891, Sensitive_Loss : 0.08650, Sensitive_Acc : 17.400, Run Time : 17.87 sec
INFO:root:2024-04-27 14:13:53, Dev, Step : 4200, Loss : 0.41835, Acc : 0.819, Auc : 0.906, Sensitive_Loss : 0.12340, Sensitive_Acc : 16.950, Sensitive_Auc : 0.995, Mean auc: 0.906, Run Time : 243.04 sec
INFO:root:2024-04-27 14:14:08, Train, Epoch : 7, Step : 4210, Loss : 0.26268, Acc : 0.878, Sensitive_Loss : 0.08296, Sensitive_Acc : 16.100, Run Time : 257.51 sec
INFO:root:2024-04-27 14:14:26, Train, Epoch : 7, Step : 4220, Loss : 0.27519, Acc : 0.881, Sensitive_Loss : 0.08208, Sensitive_Acc : 14.800, Run Time : 17.79 sec
INFO:root:2024-04-27 14:14:44, Train, Epoch : 7, Step : 4230, Loss : 0.34801, Acc : 0.875, Sensitive_Loss : 0.11145, Sensitive_Acc : 14.600, Run Time : 18.26 sec
INFO:root:2024-04-27 14:15:02, Train, Epoch : 7, Step : 4240, Loss : 0.32972, Acc : 0.872, Sensitive_Loss : 0.09220, Sensitive_Acc : 16.300, Run Time : 17.72 sec
INFO:root:2024-04-27 14:15:19, Train, Epoch : 7, Step : 4250, Loss : 0.23167, Acc : 0.916, Sensitive_Loss : 0.05730, Sensitive_Acc : 17.500, Run Time : 17.36 sec
INFO:root:2024-04-27 14:15:36, Train, Epoch : 7, Step : 4260, Loss : 0.27386, Acc : 0.875, Sensitive_Loss : 0.10659, Sensitive_Acc : 18.100, Run Time : 17.12 sec
INFO:root:2024-04-27 14:15:55, Train, Epoch : 7, Step : 4270, Loss : 0.25103, Acc : 0.912, Sensitive_Loss : 0.09252, Sensitive_Acc : 14.600, Run Time : 18.83 sec
INFO:root:2024-04-27 14:16:11, Train, Epoch : 7, Step : 4280, Loss : 0.29692, Acc : 0.875, Sensitive_Loss : 0.06474, Sensitive_Acc : 17.300, Run Time : 15.97 sec
INFO:root:2024-04-27 14:16:30, Train, Epoch : 7, Step : 4290, Loss : 0.27211, Acc : 0.878, Sensitive_Loss : 0.10974, Sensitive_Acc : 15.700, Run Time : 18.88 sec
INFO:root:2024-04-27 14:16:48, Train, Epoch : 7, Step : 4300, Loss : 0.28084, Acc : 0.869, Sensitive_Loss : 0.09380, Sensitive_Acc : 18.600, Run Time : 18.00 sec
INFO:root:2024-04-27 14:20:52, Dev, Step : 4300, Loss : 0.45666, Acc : 0.814, Auc : 0.905, Sensitive_Loss : 0.12876, Sensitive_Acc : 16.921, Sensitive_Auc : 0.996, Mean auc: 0.905, Run Time : 244.01 sec
INFO:root:2024-04-27 14:21:05, Train, Epoch : 7, Step : 4310, Loss : 0.30013, Acc : 0.878, Sensitive_Loss : 0.09761, Sensitive_Acc : 18.200, Run Time : 256.94 sec
INFO:root:2024-04-27 14:21:24, Train, Epoch : 7, Step : 4320, Loss : 0.24725, Acc : 0.894, Sensitive_Loss : 0.06970, Sensitive_Acc : 17.200, Run Time : 19.58 sec
INFO:root:2024-04-27 14:21:42, Train, Epoch : 7, Step : 4330, Loss : 0.25256, Acc : 0.875, Sensitive_Loss : 0.08487, Sensitive_Acc : 16.400, Run Time : 17.14 sec
INFO:root:2024-04-27 14:22:00, Train, Epoch : 7, Step : 4340, Loss : 0.31612, Acc : 0.869, Sensitive_Loss : 0.10591, Sensitive_Acc : 18.400, Run Time : 18.20 sec
INFO:root:2024-04-27 14:22:16, Train, Epoch : 7, Step : 4350, Loss : 0.29570, Acc : 0.884, Sensitive_Loss : 0.10226, Sensitive_Acc : 14.300, Run Time : 16.60 sec
INFO:root:2024-04-27 14:22:34, Train, Epoch : 7, Step : 4360, Loss : 0.31930, Acc : 0.863, Sensitive_Loss : 0.12696, Sensitive_Acc : 17.600, Run Time : 17.39 sec
INFO:root:2024-04-27 14:22:53, Train, Epoch : 7, Step : 4370, Loss : 0.30286, Acc : 0.866, Sensitive_Loss : 0.12240, Sensitive_Acc : 16.600, Run Time : 19.22 sec
INFO:root:2024-04-27 14:23:10, Train, Epoch : 7, Step : 4380, Loss : 0.30285, Acc : 0.869, Sensitive_Loss : 0.09392, Sensitive_Acc : 18.100, Run Time : 17.06 sec
INFO:root:2024-04-27 14:27:21
INFO:root:y_pred: [0.0921668  0.98445594 0.02792505 ... 0.9541021  0.0011873  0.94321626]
INFO:root:y_true: [0. 1. 0. ... 1. 0. 1.]
INFO:root:sensitive_y_pred: [9.80534852e-01 1.27351959e-04 9.55604464e-02 6.24016044e-04
 9.99493480e-01 3.32829775e-04 9.99967456e-01 9.99854445e-01
 3.59862752e-05 9.37330782e-01 9.99953032e-01 9.99777615e-01
 9.94641900e-01 9.92571414e-01 3.79361399e-03 9.52481449e-01
 9.99764860e-01 1.77994873e-02 3.76084387e-01 9.44569588e-01
 9.98960972e-01 7.09042000e-03 9.98936117e-01 9.97220755e-01
 9.98418808e-01 9.99153018e-01 3.23871238e-04 9.97458875e-01
 9.81799722e-01 6.67218715e-02 3.37219361e-04 8.28943700e-02
 1.00839394e-03 7.46765137e-02 2.06330586e-02 2.45887483e-03
 1.09282834e-02 9.34447255e-03 9.99838352e-01 9.98476803e-01
 3.78387767e-06 2.05813976e-05 9.52510357e-01 1.91670074e-03
 9.99811947e-01 9.95163798e-01 9.98025894e-01 9.95943725e-01
 5.95129328e-04 9.95787680e-01 7.44294465e-01 9.75294039e-03
 4.34191823e-01 7.34295347e-04 6.85899111e-04 7.12132752e-02
 2.95765828e-02 4.14441852e-03 4.81091993e-05 3.36004905e-02
 7.21724937e-03 1.18792899e-01 8.06445070e-03 9.87041235e-01
 2.52210170e-01 9.99692440e-01 7.77477457e-04 9.99857306e-01
 9.97824907e-01 1.32749677e-02 9.06275153e-01 2.44918689e-01
 2.19727913e-03 2.69253813e-02 1.12776615e-05 7.06767139e-04
 1.24671245e-02 5.44366352e-02 1.21667006e-04 9.99951243e-01
 9.98228967e-01 1.95125851e-03 1.62190706e-01 1.56200211e-03
 4.91752207e-01 9.25823927e-01 1.20081706e-02 2.54599634e-03
 9.93000388e-01 9.99838710e-01 9.99980450e-01 4.02225007e-04
 2.48562871e-03 9.80163991e-01 4.18697178e-01 1.96171016e-03
 9.98901010e-01 9.99418616e-01 4.78706177e-04 1.72225554e-02
 9.50450122e-01 9.86671031e-01 9.98818457e-01 9.97984529e-01
 4.07809799e-04 3.92240845e-02 9.89815950e-01 9.99158025e-01
 9.95016396e-01 2.10849043e-06 9.90966320e-01 9.98762608e-01
 1.13203423e-02 9.99872565e-01 9.90146458e-01 9.99531507e-01
 4.10086751e-01 9.99719083e-01 1.34124393e-02 4.46122475e-02
 9.99557674e-01 9.99815404e-01 7.85926459e-05 9.99065816e-01
 9.99995828e-01 8.74667615e-02 9.54840183e-01 9.70531348e-03
 5.80814388e-03 8.98831666e-01 9.96192336e-01 3.42739769e-03
 4.19300777e-04 1.07498225e-02 9.94256794e-01 9.96543944e-01
 9.92442608e-01 6.12753152e-04 4.21793060e-03 9.92926538e-01]
INFO:root:sensitive_y_true: [1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.
 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.]
INFO:root:2024-04-27 14:27:21, Dev, Step : 4382, Loss : 0.42393, Acc : 0.825, Auc : 0.905, Sensitive_Loss : 0.10245, Sensitive_Acc : 16.764, Sensitive_Auc : 0.995, Mean auc: 0.905, Run Time : 249.82 sec
INFO:root:2024-04-27 14:27:45, Train, Epoch : 8, Step : 4390, Loss : 0.19949, Acc : 0.703, Sensitive_Loss : 0.04938, Sensitive_Acc : 13.400, Run Time : 21.44 sec
INFO:root:2024-04-27 14:28:06, Train, Epoch : 8, Step : 4400, Loss : 0.23558, Acc : 0.919, Sensitive_Loss : 0.04605, Sensitive_Acc : 17.200, Run Time : 21.30 sec
INFO:root:2024-04-27 14:32:14, Dev, Step : 4400, Loss : 0.43628, Acc : 0.823, Auc : 0.904, Sensitive_Loss : 0.11482, Sensitive_Acc : 16.950, Sensitive_Auc : 0.996, Mean auc: 0.904, Run Time : 248.12 sec
INFO:root:2024-04-27 14:32:27, Train, Epoch : 8, Step : 4410, Loss : 0.26396, Acc : 0.869, Sensitive_Loss : 0.05358, Sensitive_Acc : 15.200, Run Time : 261.33 sec
INFO:root:2024-04-27 14:32:46, Train, Epoch : 8, Step : 4420, Loss : 0.23502, Acc : 0.912, Sensitive_Loss : 0.08713, Sensitive_Acc : 18.000, Run Time : 19.09 sec
INFO:root:2024-04-27 14:33:05, Train, Epoch : 8, Step : 4430, Loss : 0.28460, Acc : 0.887, Sensitive_Loss : 0.06000, Sensitive_Acc : 15.800, Run Time : 18.39 sec
INFO:root:2024-04-27 14:33:23, Train, Epoch : 8, Step : 4440, Loss : 0.23025, Acc : 0.922, Sensitive_Loss : 0.11149, Sensitive_Acc : 16.800, Run Time : 17.72 sec
INFO:root:2024-04-27 14:33:41, Train, Epoch : 8, Step : 4450, Loss : 0.25212, Acc : 0.894, Sensitive_Loss : 0.08126, Sensitive_Acc : 15.800, Run Time : 18.14 sec
INFO:root:2024-04-27 14:33:59, Train, Epoch : 8, Step : 4460, Loss : 0.26665, Acc : 0.884, Sensitive_Loss : 0.08560, Sensitive_Acc : 15.400, Run Time : 18.56 sec
INFO:root:2024-04-27 14:34:17, Train, Epoch : 8, Step : 4470, Loss : 0.29237, Acc : 0.866, Sensitive_Loss : 0.09564, Sensitive_Acc : 14.600, Run Time : 18.19 sec
INFO:root:2024-04-27 14:34:35, Train, Epoch : 8, Step : 4480, Loss : 0.25447, Acc : 0.878, Sensitive_Loss : 0.08482, Sensitive_Acc : 17.300, Run Time : 17.58 sec
INFO:root:2024-04-27 14:34:53, Train, Epoch : 8, Step : 4490, Loss : 0.27317, Acc : 0.884, Sensitive_Loss : 0.09860, Sensitive_Acc : 17.400, Run Time : 17.69 sec
INFO:root:2024-04-27 14:35:11, Train, Epoch : 8, Step : 4500, Loss : 0.27209, Acc : 0.900, Sensitive_Loss : 0.10502, Sensitive_Acc : 16.800, Run Time : 18.14 sec
INFO:root:2024-04-27 14:39:15, Dev, Step : 4500, Loss : 0.44819, Acc : 0.818, Auc : 0.902, Sensitive_Loss : 0.12263, Sensitive_Acc : 16.879, Sensitive_Auc : 0.996, Mean auc: 0.902, Run Time : 243.81 sec
INFO:root:2024-04-27 14:39:28, Train, Epoch : 8, Step : 4510, Loss : 0.24595, Acc : 0.881, Sensitive_Loss : 0.10632, Sensitive_Acc : 16.000, Run Time : 257.15 sec
INFO:root:2024-04-27 14:39:47, Train, Epoch : 8, Step : 4520, Loss : 0.27298, Acc : 0.891, Sensitive_Loss : 0.08382, Sensitive_Acc : 16.500, Run Time : 19.24 sec
INFO:root:2024-04-27 14:40:04, Train, Epoch : 8, Step : 4530, Loss : 0.24399, Acc : 0.916, Sensitive_Loss : 0.07745, Sensitive_Acc : 17.100, Run Time : 16.73 sec
INFO:root:2024-04-27 14:40:22, Train, Epoch : 8, Step : 4540, Loss : 0.31388, Acc : 0.869, Sensitive_Loss : 0.11073, Sensitive_Acc : 16.800, Run Time : 18.37 sec
INFO:root:2024-04-27 14:40:40, Train, Epoch : 8, Step : 4550, Loss : 0.26708, Acc : 0.891, Sensitive_Loss : 0.11491, Sensitive_Acc : 15.500, Run Time : 17.68 sec
INFO:root:2024-04-27 14:40:58, Train, Epoch : 8, Step : 4560, Loss : 0.25805, Acc : 0.891, Sensitive_Loss : 0.07126, Sensitive_Acc : 17.100, Run Time : 18.02 sec
INFO:root:2024-04-27 14:41:16, Train, Epoch : 8, Step : 4570, Loss : 0.20421, Acc : 0.919, Sensitive_Loss : 0.06884, Sensitive_Acc : 17.500, Run Time : 17.86 sec
INFO:root:2024-04-27 14:41:32, Train, Epoch : 8, Step : 4580, Loss : 0.26236, Acc : 0.884, Sensitive_Loss : 0.08121, Sensitive_Acc : 15.400, Run Time : 15.69 sec
INFO:root:2024-04-27 14:41:51, Train, Epoch : 8, Step : 4590, Loss : 0.27241, Acc : 0.884, Sensitive_Loss : 0.10598, Sensitive_Acc : 15.900, Run Time : 19.66 sec
INFO:root:2024-04-27 14:42:09, Train, Epoch : 8, Step : 4600, Loss : 0.20153, Acc : 0.891, Sensitive_Loss : 0.12348, Sensitive_Acc : 18.100, Run Time : 17.64 sec
INFO:root:2024-04-27 14:46:13, Dev, Step : 4600, Loss : 0.46306, Acc : 0.814, Auc : 0.901, Sensitive_Loss : 0.12907, Sensitive_Acc : 16.921, Sensitive_Auc : 0.995, Mean auc: 0.901, Run Time : 244.52 sec
INFO:root:2024-04-27 14:46:27, Train, Epoch : 8, Step : 4610, Loss : 0.24225, Acc : 0.872, Sensitive_Loss : 0.13096, Sensitive_Acc : 16.600, Run Time : 257.94 sec
INFO:root:2024-04-27 14:46:45, Train, Epoch : 8, Step : 4620, Loss : 0.27174, Acc : 0.884, Sensitive_Loss : 0.07684, Sensitive_Acc : 17.100, Run Time : 18.15 sec
INFO:root:2024-04-27 14:47:03, Train, Epoch : 8, Step : 4630, Loss : 0.30573, Acc : 0.878, Sensitive_Loss : 0.07079, Sensitive_Acc : 15.000, Run Time : 17.96 sec
INFO:root:2024-04-27 14:47:21, Train, Epoch : 8, Step : 4640, Loss : 0.26936, Acc : 0.897, Sensitive_Loss : 0.07814, Sensitive_Acc : 16.000, Run Time : 17.95 sec
INFO:root:2024-04-27 14:47:38, Train, Epoch : 8, Step : 4650, Loss : 0.21495, Acc : 0.922, Sensitive_Loss : 0.07497, Sensitive_Acc : 15.800, Run Time : 17.07 sec
INFO:root:2024-04-27 14:47:56, Train, Epoch : 8, Step : 4660, Loss : 0.26784, Acc : 0.891, Sensitive_Loss : 0.06415, Sensitive_Acc : 15.500, Run Time : 18.08 sec
INFO:root:2024-04-27 14:48:14, Train, Epoch : 8, Step : 4670, Loss : 0.26136, Acc : 0.903, Sensitive_Loss : 0.09657, Sensitive_Acc : 17.000, Run Time : 17.98 sec
INFO:root:2024-04-27 14:48:32, Train, Epoch : 8, Step : 4680, Loss : 0.20590, Acc : 0.925, Sensitive_Loss : 0.08986, Sensitive_Acc : 16.800, Run Time : 17.83 sec
INFO:root:2024-04-27 14:48:49, Train, Epoch : 8, Step : 4690, Loss : 0.22023, Acc : 0.887, Sensitive_Loss : 0.08231, Sensitive_Acc : 15.400, Run Time : 16.90 sec
INFO:root:2024-04-27 14:49:07, Train, Epoch : 8, Step : 4700, Loss : 0.19500, Acc : 0.925, Sensitive_Loss : 0.07574, Sensitive_Acc : 15.100, Run Time : 17.99 sec
INFO:root:2024-04-27 14:53:10, Dev, Step : 4700, Loss : 0.48086, Acc : 0.810, Auc : 0.903, Sensitive_Loss : 0.12222, Sensitive_Acc : 16.921, Sensitive_Auc : 0.993, Mean auc: 0.903, Run Time : 243.35 sec
INFO:root:2024-04-27 14:53:24, Train, Epoch : 8, Step : 4710, Loss : 0.33341, Acc : 0.866, Sensitive_Loss : 0.06921, Sensitive_Acc : 17.800, Run Time : 256.90 sec
INFO:root:2024-04-27 14:53:42, Train, Epoch : 8, Step : 4720, Loss : 0.25623, Acc : 0.872, Sensitive_Loss : 0.11322, Sensitive_Acc : 17.300, Run Time : 18.05 sec
INFO:root:2024-04-27 14:54:00, Train, Epoch : 8, Step : 4730, Loss : 0.24676, Acc : 0.866, Sensitive_Loss : 0.08044, Sensitive_Acc : 16.300, Run Time : 18.27 sec
INFO:root:2024-04-27 14:54:18, Train, Epoch : 8, Step : 4740, Loss : 0.20137, Acc : 0.912, Sensitive_Loss : 0.08633, Sensitive_Acc : 15.600, Run Time : 17.89 sec
INFO:root:2024-04-27 14:54:35, Train, Epoch : 8, Step : 4750, Loss : 0.29671, Acc : 0.869, Sensitive_Loss : 0.11946, Sensitive_Acc : 16.300, Run Time : 17.33 sec
INFO:root:2024-04-27 14:54:53, Train, Epoch : 8, Step : 4760, Loss : 0.27516, Acc : 0.866, Sensitive_Loss : 0.07963, Sensitive_Acc : 15.100, Run Time : 17.65 sec
INFO:root:2024-04-27 14:55:09, Train, Epoch : 8, Step : 4770, Loss : 0.22291, Acc : 0.887, Sensitive_Loss : 0.08569, Sensitive_Acc : 15.800, Run Time : 15.82 sec
INFO:root:2024-04-27 14:55:30, Train, Epoch : 8, Step : 4780, Loss : 0.22009, Acc : 0.891, Sensitive_Loss : 0.11876, Sensitive_Acc : 17.400, Run Time : 20.88 sec
INFO:root:2024-04-27 14:55:47, Train, Epoch : 8, Step : 4790, Loss : 0.25641, Acc : 0.875, Sensitive_Loss : 0.10123, Sensitive_Acc : 15.500, Run Time : 17.65 sec
INFO:root:2024-04-27 14:56:04, Train, Epoch : 8, Step : 4800, Loss : 0.31749, Acc : 0.884, Sensitive_Loss : 0.08973, Sensitive_Acc : 16.400, Run Time : 17.07 sec
INFO:root:2024-04-27 15:00:09, Dev, Step : 4800, Loss : 0.46139, Acc : 0.812, Auc : 0.904, Sensitive_Loss : 0.11730, Sensitive_Acc : 16.921, Sensitive_Auc : 0.996, Mean auc: 0.904, Run Time : 244.40 sec
INFO:root:2024-04-27 15:00:22, Train, Epoch : 8, Step : 4810, Loss : 0.32135, Acc : 0.847, Sensitive_Loss : 0.10218, Sensitive_Acc : 17.400, Run Time : 257.72 sec
INFO:root:2024-04-27 15:00:41, Train, Epoch : 8, Step : 4820, Loss : 0.23973, Acc : 0.869, Sensitive_Loss : 0.06979, Sensitive_Acc : 17.000, Run Time : 18.77 sec
INFO:root:2024-04-27 15:00:57, Train, Epoch : 8, Step : 4830, Loss : 0.23380, Acc : 0.887, Sensitive_Loss : 0.09220, Sensitive_Acc : 17.000, Run Time : 16.10 sec
INFO:root:2024-04-27 15:01:16, Train, Epoch : 8, Step : 4840, Loss : 0.24459, Acc : 0.894, Sensitive_Loss : 0.08108, Sensitive_Acc : 16.300, Run Time : 18.99 sec
INFO:root:2024-04-27 15:01:32, Train, Epoch : 8, Step : 4850, Loss : 0.25325, Acc : 0.884, Sensitive_Loss : 0.06596, Sensitive_Acc : 17.600, Run Time : 16.27 sec
INFO:root:2024-04-27 15:01:51, Train, Epoch : 8, Step : 4860, Loss : 0.27199, Acc : 0.884, Sensitive_Loss : 0.10512, Sensitive_Acc : 16.600, Run Time : 18.81 sec
INFO:root:2024-04-27 15:02:09, Train, Epoch : 8, Step : 4870, Loss : 0.26825, Acc : 0.884, Sensitive_Loss : 0.04673, Sensitive_Acc : 16.200, Run Time : 17.97 sec
INFO:root:2024-04-27 15:02:26, Train, Epoch : 8, Step : 4880, Loss : 0.25436, Acc : 0.897, Sensitive_Loss : 0.08292, Sensitive_Acc : 15.600, Run Time : 17.14 sec
INFO:root:2024-04-27 15:02:44, Train, Epoch : 8, Step : 4890, Loss : 0.25863, Acc : 0.878, Sensitive_Loss : 0.12768, Sensitive_Acc : 16.300, Run Time : 18.35 sec
INFO:root:2024-04-27 15:03:02, Train, Epoch : 8, Step : 4900, Loss : 0.26616, Acc : 0.863, Sensitive_Loss : 0.08165, Sensitive_Acc : 17.600, Run Time : 17.75 sec
INFO:root:2024-04-27 15:07:08, Dev, Step : 4900, Loss : 0.44247, Acc : 0.819, Auc : 0.904, Sensitive_Loss : 0.12193, Sensitive_Acc : 16.893, Sensitive_Auc : 0.996, Mean auc: 0.904, Run Time : 246.16 sec
INFO:root:2024-04-27 15:07:21, Train, Epoch : 8, Step : 4910, Loss : 0.22773, Acc : 0.909, Sensitive_Loss : 0.09341, Sensitive_Acc : 15.400, Run Time : 258.46 sec
INFO:root:2024-04-27 15:07:39, Train, Epoch : 8, Step : 4920, Loss : 0.27924, Acc : 0.875, Sensitive_Loss : 0.06539, Sensitive_Acc : 15.700, Run Time : 18.55 sec
INFO:root:2024-04-27 15:07:57, Train, Epoch : 8, Step : 4930, Loss : 0.21050, Acc : 0.903, Sensitive_Loss : 0.07824, Sensitive_Acc : 15.100, Run Time : 17.68 sec
INFO:root:2024-04-27 15:08:15, Train, Epoch : 8, Step : 4940, Loss : 0.24439, Acc : 0.916, Sensitive_Loss : 0.09894, Sensitive_Acc : 16.000, Run Time : 18.10 sec
INFO:root:2024-04-27 15:08:34, Train, Epoch : 8, Step : 4950, Loss : 0.26586, Acc : 0.891, Sensitive_Loss : 0.06993, Sensitive_Acc : 16.500, Run Time : 18.85 sec
INFO:root:2024-04-27 15:08:51, Train, Epoch : 8, Step : 4960, Loss : 0.28936, Acc : 0.878, Sensitive_Loss : 0.09437, Sensitive_Acc : 15.100, Run Time : 17.02 sec
INFO:root:2024-04-27 15:09:08, Train, Epoch : 8, Step : 4970, Loss : 0.21660, Acc : 0.894, Sensitive_Loss : 0.10871, Sensitive_Acc : 16.800, Run Time : 16.68 sec
INFO:root:2024-04-27 15:09:27, Train, Epoch : 8, Step : 4980, Loss : 0.27308, Acc : 0.878, Sensitive_Loss : 0.08087, Sensitive_Acc : 17.400, Run Time : 19.72 sec
INFO:root:2024-04-27 15:09:45, Train, Epoch : 8, Step : 4990, Loss : 0.27441, Acc : 0.881, Sensitive_Loss : 0.09880, Sensitive_Acc : 15.400, Run Time : 17.35 sec
INFO:root:2024-04-27 15:10:01, Train, Epoch : 8, Step : 5000, Loss : 0.24027, Acc : 0.919, Sensitive_Loss : 0.09906, Sensitive_Acc : 15.600, Run Time : 16.77 sec
INFO:root:2024-04-27 15:14:08, Dev, Step : 5000, Loss : 0.46869, Acc : 0.811, Auc : 0.901, Sensitive_Loss : 0.11583, Sensitive_Acc : 16.821, Sensitive_Auc : 0.996, Mean auc: 0.901, Run Time : 246.22 sec
INFO:root:2024-04-27 15:18:19
INFO:root:y_pred: [4.2679053e-02 9.7614509e-01 1.4092153e-02 ... 9.5391548e-01 3.5001172e-04
 9.6851784e-01]
INFO:root:y_true: [0. 1. 0. ... 1. 0. 1.]
INFO:root:sensitive_y_pred: [9.85001087e-01 1.21778314e-04 1.90136760e-01 9.58270859e-04
 9.99816716e-01 4.13581118e-04 9.99977112e-01 9.99949932e-01
 5.59162145e-05 9.27185178e-01 9.99928355e-01 9.99923587e-01
 9.98665214e-01 9.94919717e-01 5.52781438e-03 9.85221207e-01
 9.99861598e-01 1.97544955e-02 7.57321894e-01 9.44565713e-01
 9.98852491e-01 4.90981853e-03 9.99431789e-01 9.98905778e-01
 9.98713017e-01 9.99601185e-01 7.18958909e-04 9.99267042e-01
 9.94235337e-01 2.69432873e-01 1.42915384e-03 2.48431683e-01
 2.63221725e-03 1.63971946e-01 2.50732135e-02 3.54440766e-03
 3.80911976e-02 1.49233863e-02 9.99916434e-01 9.99304533e-01
 2.93364883e-06 3.10085670e-05 9.69567716e-01 2.93690874e-03
 9.99869943e-01 9.97008860e-01 9.99329925e-01 9.98417377e-01
 1.51977176e-03 9.94882703e-01 8.59716415e-01 1.57836955e-02
 5.29081106e-01 3.80857894e-03 1.23216084e-03 1.32222101e-01
 4.55004834e-02 5.19465096e-03 2.26467208e-04 7.13654160e-02
 8.72768089e-03 1.58164516e-01 1.08738579e-02 9.87647653e-01
 3.06353688e-01 9.99778569e-01 8.64577363e-04 9.99931097e-01
 9.98786986e-01 2.98842173e-02 8.79754782e-01 5.33850074e-01
 1.90394884e-03 5.48041537e-02 4.90585444e-05 7.24580896e-04
 1.66181345e-02 1.01610661e-01 1.23376100e-04 9.99978304e-01
 9.99039471e-01 1.38239108e-03 1.74197778e-01 1.40839827e-03
 6.30651772e-01 9.52490330e-01 1.20288320e-02 7.42171658e-03
 9.94499087e-01 9.99951363e-01 9.99990821e-01 4.50617255e-04
 3.61398840e-03 9.93166149e-01 7.33299077e-01 2.37009162e-03
 9.99123037e-01 9.99728739e-01 9.94024682e-04 3.22434045e-02
 9.87754166e-01 9.93022919e-01 9.99391556e-01 9.99341309e-01
 3.79227800e-04 8.50019604e-02 9.94239211e-01 9.99757111e-01
 9.96351719e-01 2.94282290e-06 9.94272590e-01 9.98981774e-01
 1.70693267e-02 9.99937534e-01 9.95279074e-01 9.99701023e-01
 4.68026310e-01 9.99698639e-01 2.52259634e-02 2.89237835e-02
 9.99763429e-01 9.99953270e-01 8.89038129e-05 9.99622107e-01
 9.99997735e-01 1.20453179e-01 9.83607829e-01 3.35237160e-02
 1.01273283e-02 9.62345958e-01 9.98951674e-01 4.10614675e-03
 1.01216405e-03 1.79868713e-02 9.94475424e-01 9.99273837e-01
 9.95311201e-01 4.33233392e-04 3.21999472e-03 9.94640410e-01]
INFO:root:sensitive_y_true: [1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.
 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.]
INFO:root:2024-04-27 15:18:19, Dev, Step : 5008, Loss : 0.44758, Acc : 0.818, Auc : 0.903, Sensitive_Loss : 0.11246, Sensitive_Acc : 16.821, Sensitive_Auc : 0.996, Mean auc: 0.903, Run Time : 243.22 sec
INFO:root:2024-04-27 15:18:28, Train, Epoch : 9, Step : 5010, Loss : 0.05042, Acc : 0.178, Sensitive_Loss : 0.02166, Sensitive_Acc : 3.200, Run Time : 7.90 sec
INFO:root:2024-04-27 15:18:45, Train, Epoch : 9, Step : 5020, Loss : 0.26361, Acc : 0.872, Sensitive_Loss : 0.10899, Sensitive_Acc : 15.900, Run Time : 16.83 sec
INFO:root:2024-04-27 15:19:03, Train, Epoch : 9, Step : 5030, Loss : 0.19272, Acc : 0.894, Sensitive_Loss : 0.11431, Sensitive_Acc : 16.200, Run Time : 18.85 sec
INFO:root:2024-04-27 15:19:21, Train, Epoch : 9, Step : 5040, Loss : 0.23553, Acc : 0.894, Sensitive_Loss : 0.07149, Sensitive_Acc : 17.400, Run Time : 17.32 sec
INFO:root:2024-04-27 15:19:39, Train, Epoch : 9, Step : 5050, Loss : 0.23697, Acc : 0.909, Sensitive_Loss : 0.06967, Sensitive_Acc : 15.400, Run Time : 18.43 sec
INFO:root:2024-04-27 15:19:56, Train, Epoch : 9, Step : 5060, Loss : 0.25079, Acc : 0.887, Sensitive_Loss : 0.08279, Sensitive_Acc : 15.900, Run Time : 17.36 sec
INFO:root:2024-04-27 15:20:16, Train, Epoch : 9, Step : 5070, Loss : 0.18942, Acc : 0.947, Sensitive_Loss : 0.08499, Sensitive_Acc : 16.700, Run Time : 19.09 sec
INFO:root:2024-04-27 15:20:32, Train, Epoch : 9, Step : 5080, Loss : 0.21772, Acc : 0.897, Sensitive_Loss : 0.06001, Sensitive_Acc : 16.300, Run Time : 16.72 sec
INFO:root:2024-04-27 15:20:50, Train, Epoch : 9, Step : 5090, Loss : 0.30693, Acc : 0.872, Sensitive_Loss : 0.05696, Sensitive_Acc : 16.600, Run Time : 17.81 sec
INFO:root:2024-04-27 15:21:08, Train, Epoch : 9, Step : 5100, Loss : 0.22961, Acc : 0.894, Sensitive_Loss : 0.07474, Sensitive_Acc : 16.000, Run Time : 17.61 sec
INFO:root:2024-04-27 15:25:11, Dev, Step : 5100, Loss : 0.44872, Acc : 0.822, Auc : 0.902, Sensitive_Loss : 0.11338, Sensitive_Acc : 16.793, Sensitive_Auc : 0.997, Mean auc: 0.902, Run Time : 243.59 sec
INFO:root:2024-04-27 15:25:25, Train, Epoch : 9, Step : 5110, Loss : 0.27687, Acc : 0.872, Sensitive_Loss : 0.09395, Sensitive_Acc : 15.400, Run Time : 257.33 sec
INFO:root:2024-04-27 15:25:43, Train, Epoch : 9, Step : 5120, Loss : 0.27385, Acc : 0.866, Sensitive_Loss : 0.06525, Sensitive_Acc : 17.000, Run Time : 17.77 sec
INFO:root:2024-04-27 15:26:01, Train, Epoch : 9, Step : 5130, Loss : 0.21667, Acc : 0.903, Sensitive_Loss : 0.08783, Sensitive_Acc : 17.000, Run Time : 18.23 sec
INFO:root:2024-04-27 15:26:18, Train, Epoch : 9, Step : 5140, Loss : 0.21811, Acc : 0.894, Sensitive_Loss : 0.09113, Sensitive_Acc : 15.600, Run Time : 16.72 sec
INFO:root:2024-04-27 15:26:36, Train, Epoch : 9, Step : 5150, Loss : 0.19753, Acc : 0.919, Sensitive_Loss : 0.09152, Sensitive_Acc : 16.900, Run Time : 17.86 sec
INFO:root:2024-04-27 15:26:53, Train, Epoch : 9, Step : 5160, Loss : 0.23050, Acc : 0.869, Sensitive_Loss : 0.08449, Sensitive_Acc : 16.600, Run Time : 17.74 sec
INFO:root:2024-04-27 15:27:12, Train, Epoch : 9, Step : 5170, Loss : 0.21191, Acc : 0.891, Sensitive_Loss : 0.11558, Sensitive_Acc : 15.600, Run Time : 18.23 sec
INFO:root:2024-04-27 15:27:29, Train, Epoch : 9, Step : 5180, Loss : 0.23925, Acc : 0.900, Sensitive_Loss : 0.09480, Sensitive_Acc : 15.800, Run Time : 17.67 sec
INFO:root:2024-04-27 15:27:47, Train, Epoch : 9, Step : 5190, Loss : 0.19334, Acc : 0.925, Sensitive_Loss : 0.08684, Sensitive_Acc : 16.600, Run Time : 17.92 sec
INFO:root:2024-04-27 15:28:05, Train, Epoch : 9, Step : 5200, Loss : 0.23336, Acc : 0.919, Sensitive_Loss : 0.04916, Sensitive_Acc : 17.200, Run Time : 17.81 sec
INFO:root:2024-04-27 15:32:09, Dev, Step : 5200, Loss : 0.48161, Acc : 0.808, Auc : 0.899, Sensitive_Loss : 0.13419, Sensitive_Acc : 16.879, Sensitive_Auc : 0.996, Mean auc: 0.899, Run Time : 243.88 sec
INFO:root:2024-04-27 15:32:23, Train, Epoch : 9, Step : 5210, Loss : 0.22386, Acc : 0.891, Sensitive_Loss : 0.06664, Sensitive_Acc : 16.700, Run Time : 258.32 sec
INFO:root:2024-04-27 15:32:42, Train, Epoch : 9, Step : 5220, Loss : 0.18986, Acc : 0.903, Sensitive_Loss : 0.07960, Sensitive_Acc : 16.400, Run Time : 18.29 sec
INFO:root:2024-04-27 15:33:00, Train, Epoch : 9, Step : 5230, Loss : 0.23740, Acc : 0.887, Sensitive_Loss : 0.10873, Sensitive_Acc : 16.000, Run Time : 17.85 sec
INFO:root:2024-04-27 15:33:17, Train, Epoch : 9, Step : 5240, Loss : 0.20756, Acc : 0.925, Sensitive_Loss : 0.06781, Sensitive_Acc : 17.100, Run Time : 17.66 sec
INFO:root:2024-04-27 15:33:34, Train, Epoch : 9, Step : 5250, Loss : 0.22879, Acc : 0.906, Sensitive_Loss : 0.08670, Sensitive_Acc : 16.800, Run Time : 17.13 sec
INFO:root:2024-04-27 15:33:53, Train, Epoch : 9, Step : 5260, Loss : 0.21057, Acc : 0.903, Sensitive_Loss : 0.12346, Sensitive_Acc : 17.300, Run Time : 18.42 sec
INFO:root:2024-04-27 15:34:11, Train, Epoch : 9, Step : 5270, Loss : 0.23089, Acc : 0.919, Sensitive_Loss : 0.09097, Sensitive_Acc : 16.400, Run Time : 17.93 sec
INFO:root:2024-04-27 15:34:28, Train, Epoch : 9, Step : 5280, Loss : 0.31962, Acc : 0.881, Sensitive_Loss : 0.06789, Sensitive_Acc : 16.300, Run Time : 17.49 sec
INFO:root:2024-04-27 15:34:45, Train, Epoch : 9, Step : 5290, Loss : 0.27958, Acc : 0.872, Sensitive_Loss : 0.08140, Sensitive_Acc : 16.500, Run Time : 16.46 sec
INFO:root:2024-04-27 15:35:04, Train, Epoch : 9, Step : 5300, Loss : 0.25855, Acc : 0.891, Sensitive_Loss : 0.10406, Sensitive_Acc : 15.500, Run Time : 19.21 sec
INFO:root:2024-04-27 15:39:08, Dev, Step : 5300, Loss : 0.48450, Acc : 0.811, Auc : 0.899, Sensitive_Loss : 0.13148, Sensitive_Acc : 16.821, Sensitive_Auc : 0.996, Mean auc: 0.899, Run Time : 243.63 sec
INFO:root:2024-04-27 15:39:21, Train, Epoch : 9, Step : 5310, Loss : 0.26450, Acc : 0.878, Sensitive_Loss : 0.10022, Sensitive_Acc : 17.400, Run Time : 257.33 sec
INFO:root:2024-04-27 15:39:39, Train, Epoch : 9, Step : 5320, Loss : 0.24568, Acc : 0.897, Sensitive_Loss : 0.07654, Sensitive_Acc : 16.000, Run Time : 18.30 sec
INFO:root:2024-04-27 15:39:56, Train, Epoch : 9, Step : 5330, Loss : 0.22736, Acc : 0.922, Sensitive_Loss : 0.12846, Sensitive_Acc : 16.100, Run Time : 16.63 sec
INFO:root:2024-04-27 15:40:13, Train, Epoch : 9, Step : 5340, Loss : 0.18504, Acc : 0.941, Sensitive_Loss : 0.10566, Sensitive_Acc : 17.100, Run Time : 17.12 sec
INFO:root:2024-04-27 15:40:31, Train, Epoch : 9, Step : 5350, Loss : 0.26580, Acc : 0.875, Sensitive_Loss : 0.11072, Sensitive_Acc : 16.400, Run Time : 17.64 sec
INFO:root:2024-04-27 15:40:48, Train, Epoch : 9, Step : 5360, Loss : 0.25740, Acc : 0.869, Sensitive_Loss : 0.09498, Sensitive_Acc : 17.100, Run Time : 17.10 sec
INFO:root:2024-04-27 15:41:06, Train, Epoch : 9, Step : 5370, Loss : 0.21333, Acc : 0.881, Sensitive_Loss : 0.08191, Sensitive_Acc : 16.200, Run Time : 18.43 sec
INFO:root:2024-04-27 15:41:24, Train, Epoch : 9, Step : 5380, Loss : 0.27234, Acc : 0.903, Sensitive_Loss : 0.09829, Sensitive_Acc : 16.900, Run Time : 17.76 sec
INFO:root:2024-04-27 15:41:43, Train, Epoch : 9, Step : 5390, Loss : 0.24212, Acc : 0.900, Sensitive_Loss : 0.09359, Sensitive_Acc : 16.600, Run Time : 18.55 sec
INFO:root:2024-04-27 15:42:01, Train, Epoch : 9, Step : 5400, Loss : 0.20410, Acc : 0.912, Sensitive_Loss : 0.07054, Sensitive_Acc : 15.900, Run Time : 18.32 sec
INFO:root:2024-04-27 15:46:06, Dev, Step : 5400, Loss : 0.49964, Acc : 0.809, Auc : 0.899, Sensitive_Loss : 0.12170, Sensitive_Acc : 16.893, Sensitive_Auc : 0.997, Mean auc: 0.899, Run Time : 244.98 sec
INFO:root:2024-04-27 15:46:19, Train, Epoch : 9, Step : 5410, Loss : 0.24357, Acc : 0.909, Sensitive_Loss : 0.08263, Sensitive_Acc : 17.400, Run Time : 258.23 sec
INFO:root:2024-04-27 15:46:37, Train, Epoch : 9, Step : 5420, Loss : 0.26194, Acc : 0.894, Sensitive_Loss : 0.05448, Sensitive_Acc : 17.500, Run Time : 17.42 sec
INFO:root:2024-04-27 15:46:54, Train, Epoch : 9, Step : 5430, Loss : 0.21810, Acc : 0.912, Sensitive_Loss : 0.07389, Sensitive_Acc : 17.500, Run Time : 17.44 sec
INFO:root:2024-04-27 15:47:12, Train, Epoch : 9, Step : 5440, Loss : 0.25549, Acc : 0.912, Sensitive_Loss : 0.11094, Sensitive_Acc : 17.200, Run Time : 18.03 sec
INFO:root:2024-04-27 15:47:29, Train, Epoch : 9, Step : 5450, Loss : 0.20965, Acc : 0.938, Sensitive_Loss : 0.09220, Sensitive_Acc : 18.800, Run Time : 17.12 sec
INFO:root:2024-04-27 15:47:46, Train, Epoch : 9, Step : 5460, Loss : 0.19855, Acc : 0.919, Sensitive_Loss : 0.07919, Sensitive_Acc : 15.900, Run Time : 16.49 sec
INFO:root:2024-04-27 15:48:04, Train, Epoch : 9, Step : 5470, Loss : 0.26588, Acc : 0.863, Sensitive_Loss : 0.08835, Sensitive_Acc : 16.400, Run Time : 18.39 sec
INFO:root:2024-04-27 15:48:23, Train, Epoch : 9, Step : 5480, Loss : 0.21825, Acc : 0.928, Sensitive_Loss : 0.07704, Sensitive_Acc : 15.000, Run Time : 18.35 sec
INFO:root:2024-04-27 15:48:39, Train, Epoch : 9, Step : 5490, Loss : 0.21175, Acc : 0.897, Sensitive_Loss : 0.04959, Sensitive_Acc : 15.200, Run Time : 16.64 sec
INFO:root:2024-04-27 15:48:57, Train, Epoch : 9, Step : 5500, Loss : 0.23649, Acc : 0.887, Sensitive_Loss : 0.08231, Sensitive_Acc : 16.500, Run Time : 17.52 sec
INFO:root:2024-04-27 15:53:04, Dev, Step : 5500, Loss : 0.53833, Acc : 0.796, Auc : 0.901, Sensitive_Loss : 0.14148, Sensitive_Acc : 16.879, Sensitive_Auc : 0.995, Mean auc: 0.901, Run Time : 247.54 sec
INFO:root:2024-04-27 15:53:17, Train, Epoch : 9, Step : 5510, Loss : 0.31190, Acc : 0.869, Sensitive_Loss : 0.09056, Sensitive_Acc : 17.000, Run Time : 260.20 sec
INFO:root:2024-04-27 15:53:34, Train, Epoch : 9, Step : 5520, Loss : 0.23513, Acc : 0.869, Sensitive_Loss : 0.11817, Sensitive_Acc : 16.500, Run Time : 17.44 sec
INFO:root:2024-04-27 15:53:52, Train, Epoch : 9, Step : 5530, Loss : 0.24411, Acc : 0.894, Sensitive_Loss : 0.10847, Sensitive_Acc : 17.000, Run Time : 17.29 sec
INFO:root:2024-04-27 15:54:09, Train, Epoch : 9, Step : 5540, Loss : 0.20496, Acc : 0.903, Sensitive_Loss : 0.09234, Sensitive_Acc : 17.900, Run Time : 17.10 sec
INFO:root:2024-04-27 15:54:28, Train, Epoch : 9, Step : 5550, Loss : 0.29056, Acc : 0.884, Sensitive_Loss : 0.10910, Sensitive_Acc : 14.200, Run Time : 19.04 sec
INFO:root:2024-04-27 15:54:45, Train, Epoch : 9, Step : 5560, Loss : 0.21142, Acc : 0.909, Sensitive_Loss : 0.07276, Sensitive_Acc : 15.300, Run Time : 17.08 sec
INFO:root:2024-04-27 15:55:02, Train, Epoch : 9, Step : 5570, Loss : 0.29635, Acc : 0.878, Sensitive_Loss : 0.10101, Sensitive_Acc : 15.600, Run Time : 16.81 sec
INFO:root:2024-04-27 15:55:22, Train, Epoch : 9, Step : 5580, Loss : 0.26064, Acc : 0.866, Sensitive_Loss : 0.10068, Sensitive_Acc : 17.400, Run Time : 20.16 sec
INFO:root:2024-04-27 15:55:40, Train, Epoch : 9, Step : 5590, Loss : 0.27632, Acc : 0.878, Sensitive_Loss : 0.07422, Sensitive_Acc : 14.100, Run Time : 18.00 sec
INFO:root:2024-04-27 15:55:57, Train, Epoch : 9, Step : 5600, Loss : 0.20577, Acc : 0.903, Sensitive_Loss : 0.10501, Sensitive_Acc : 16.400, Run Time : 16.78 sec
INFO:root:2024-04-27 16:00:21, Dev, Step : 5600, Loss : 0.46796, Acc : 0.813, Auc : 0.901, Sensitive_Loss : 0.12858, Sensitive_Acc : 16.921, Sensitive_Auc : 0.994, Mean auc: 0.901, Run Time : 264.62 sec
INFO:root:2024-04-27 16:00:33, Train, Epoch : 9, Step : 5610, Loss : 0.21578, Acc : 0.900, Sensitive_Loss : 0.06310, Sensitive_Acc : 14.400, Run Time : 276.37 sec
INFO:root:2024-04-27 16:00:49, Train, Epoch : 9, Step : 5620, Loss : 0.28631, Acc : 0.881, Sensitive_Loss : 0.08607, Sensitive_Acc : 15.700, Run Time : 16.22 sec
INFO:root:2024-04-27 16:01:05, Train, Epoch : 9, Step : 5630, Loss : 0.22213, Acc : 0.919, Sensitive_Loss : 0.06290, Sensitive_Acc : 16.600, Run Time : 15.58 sec
INFO:root:2024-04-27 16:05:13
INFO:root:y_pred: [6.4144589e-02 9.9647325e-01 9.2969555e-03 ... 9.5607358e-01 1.9553519e-04
 9.5404679e-01]
INFO:root:y_true: [0. 1. 0. ... 1. 0. 1.]
INFO:root:sensitive_y_pred: [9.92159784e-01 2.06940342e-04 1.71666682e-01 2.39967392e-03
 9.99819100e-01 3.84165905e-04 9.99985337e-01 9.99972820e-01
 1.08791362e-04 9.38762605e-01 9.99917865e-01 9.99944925e-01
 9.99411464e-01 9.98778403e-01 1.12729864e-02 9.87966001e-01
 9.99900222e-01 5.88245317e-02 6.91719174e-01 9.55501437e-01
 9.99128520e-01 8.73508118e-03 9.99419570e-01 9.99596655e-01
 9.99263108e-01 9.99680519e-01 7.72493251e-04 9.99706089e-01
 9.97630000e-01 3.08209866e-01 1.95970479e-03 1.57914177e-01
 8.09812546e-03 2.17349559e-01 9.93623957e-02 5.78638259e-03
 3.55549566e-02 2.81736739e-02 9.99943018e-01 9.99635696e-01
 2.61213518e-06 1.96192868e-05 9.83096719e-01 5.10883378e-03
 9.99842405e-01 9.95544732e-01 9.99595702e-01 9.98672962e-01
 2.98624416e-03 9.98393238e-01 7.19837308e-01 2.01906916e-02
 5.02446890e-01 2.03566160e-03 1.50000781e-03 1.06704049e-01
 8.87382850e-02 6.82467269e-03 2.19702066e-04 9.14424062e-02
 1.05482396e-02 2.02160582e-01 2.27055103e-02 9.95273411e-01
 4.38035160e-01 9.99904752e-01 7.16324989e-03 9.99912143e-01
 9.98973489e-01 6.96836784e-02 9.66585398e-01 5.68479359e-01
 2.67934008e-03 2.04045735e-02 7.67415986e-05 9.14054457e-04
 5.34353629e-02 1.99164286e-01 2.09324920e-04 9.99985456e-01
 9.98945057e-01 3.68376961e-03 1.79549277e-01 1.78738520e-03
 6.36025608e-01 9.62914646e-01 2.30523907e-02 7.30365934e-03
 9.97856915e-01 9.99977112e-01 9.99996305e-01 5.46329073e-04
 6.76353043e-03 9.93866861e-01 6.67774260e-01 5.76056028e-03
 9.99653220e-01 9.99913931e-01 5.86834154e-04 2.27091461e-02
 9.82133567e-01 9.90846694e-01 9.99264657e-01 9.99561369e-01
 6.74578070e-04 8.62976462e-02 9.98387098e-01 9.99842405e-01
 9.98706579e-01 1.03488055e-05 9.96562183e-01 9.99365270e-01
 2.08653491e-02 9.99882579e-01 9.98183787e-01 9.99903321e-01
 6.13612473e-01 9.99956131e-01 2.91017629e-02 6.12038262e-02
 9.99838352e-01 9.99984741e-01 1.64950587e-04 9.99642491e-01
 9.99998808e-01 1.72880054e-01 9.94656682e-01 1.88409369e-02
 1.26704006e-02 8.57858002e-01 9.99130547e-01 5.18105691e-03
 2.59928824e-03 1.54641261e-02 9.94316041e-01 9.99056160e-01
 9.97410595e-01 1.16043293e-03 5.34350658e-03 9.83376205e-01]
INFO:root:sensitive_y_true: [1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.
 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.]
INFO:root:2024-04-27 16:05:13, Dev, Step : 5634, Loss : 0.46084, Acc : 0.816, Auc : 0.900, Sensitive_Loss : 0.12045, Sensitive_Acc : 16.921, Sensitive_Auc : 0.996, Mean auc: 0.900, Run Time : 242.67 sec
INFO:root:2024-04-27 16:05:29, Train, Epoch : 10, Step : 5640, Loss : 0.14113, Acc : 0.506, Sensitive_Loss : 0.06021, Sensitive_Acc : 9.300, Run Time : 14.27 sec
INFO:root:2024-04-27 16:05:48, Train, Epoch : 10, Step : 5650, Loss : 0.22098, Acc : 0.900, Sensitive_Loss : 0.06930, Sensitive_Acc : 16.100, Run Time : 18.86 sec
INFO:root:2024-04-27 16:06:05, Train, Epoch : 10, Step : 5660, Loss : 0.20178, Acc : 0.903, Sensitive_Loss : 0.07788, Sensitive_Acc : 15.600, Run Time : 17.15 sec
INFO:root:2024-04-27 16:06:23, Train, Epoch : 10, Step : 5670, Loss : 0.19464, Acc : 0.909, Sensitive_Loss : 0.10504, Sensitive_Acc : 16.200, Run Time : 18.04 sec
INFO:root:2024-04-27 16:06:41, Train, Epoch : 10, Step : 5680, Loss : 0.19324, Acc : 0.922, Sensitive_Loss : 0.06793, Sensitive_Acc : 17.100, Run Time : 17.93 sec
INFO:root:2024-04-27 16:06:58, Train, Epoch : 10, Step : 5690, Loss : 0.19611, Acc : 0.922, Sensitive_Loss : 0.08485, Sensitive_Acc : 18.100, Run Time : 17.76 sec
INFO:root:2024-04-27 16:07:14, Train, Epoch : 10, Step : 5700, Loss : 0.26573, Acc : 0.881, Sensitive_Loss : 0.07273, Sensitive_Acc : 17.100, Run Time : 15.81 sec
INFO:root:2024-04-27 16:11:20, Dev, Step : 5700, Loss : 0.46224, Acc : 0.819, Auc : 0.899, Sensitive_Loss : 0.11554, Sensitive_Acc : 16.821, Sensitive_Auc : 0.996, Mean auc: 0.899, Run Time : 245.46 sec
INFO:root:2024-04-27 16:11:33, Train, Epoch : 10, Step : 5710, Loss : 0.20685, Acc : 0.919, Sensitive_Loss : 0.05744, Sensitive_Acc : 15.200, Run Time : 258.36 sec
INFO:root:2024-04-27 16:11:50, Train, Epoch : 10, Step : 5720, Loss : 0.19371, Acc : 0.922, Sensitive_Loss : 0.06291, Sensitive_Acc : 15.800, Run Time : 17.81 sec
INFO:root:2024-04-27 16:12:08, Train, Epoch : 10, Step : 5730, Loss : 0.27425, Acc : 0.906, Sensitive_Loss : 0.05682, Sensitive_Acc : 16.200, Run Time : 17.23 sec
INFO:root:2024-04-27 16:12:27, Train, Epoch : 10, Step : 5740, Loss : 0.23731, Acc : 0.906, Sensitive_Loss : 0.06822, Sensitive_Acc : 15.800, Run Time : 19.00 sec
INFO:root:2024-04-27 16:12:45, Train, Epoch : 10, Step : 5750, Loss : 0.21918, Acc : 0.922, Sensitive_Loss : 0.09478, Sensitive_Acc : 16.200, Run Time : 18.05 sec
INFO:root:2024-04-27 16:13:02, Train, Epoch : 10, Step : 5760, Loss : 0.20121, Acc : 0.909, Sensitive_Loss : 0.08242, Sensitive_Acc : 15.500, Run Time : 17.54 sec
INFO:root:2024-04-27 16:13:20, Train, Epoch : 10, Step : 5770, Loss : 0.23335, Acc : 0.916, Sensitive_Loss : 0.05787, Sensitive_Acc : 16.000, Run Time : 17.55 sec
INFO:root:2024-04-27 16:13:37, Train, Epoch : 10, Step : 5780, Loss : 0.15718, Acc : 0.950, Sensitive_Loss : 0.07773, Sensitive_Acc : 16.200, Run Time : 17.23 sec
INFO:root:2024-04-27 16:13:53, Train, Epoch : 10, Step : 5790, Loss : 0.22677, Acc : 0.916, Sensitive_Loss : 0.07673, Sensitive_Acc : 15.800, Run Time : 16.12 sec
INFO:root:2024-04-27 16:14:11, Train, Epoch : 10, Step : 5800, Loss : 0.20501, Acc : 0.903, Sensitive_Loss : 0.13028, Sensitive_Acc : 16.300, Run Time : 17.70 sec
INFO:root:2024-04-27 16:18:17, Dev, Step : 5800, Loss : 0.49415, Acc : 0.809, Auc : 0.898, Sensitive_Loss : 0.13040, Sensitive_Acc : 16.921, Sensitive_Auc : 0.997, Mean auc: 0.898, Run Time : 246.45 sec
INFO:root:2024-04-27 16:18:30, Train, Epoch : 10, Step : 5810, Loss : 0.23120, Acc : 0.881, Sensitive_Loss : 0.08530, Sensitive_Acc : 15.900, Run Time : 258.62 sec
INFO:root:2024-04-27 16:18:47, Train, Epoch : 10, Step : 5820, Loss : 0.22625, Acc : 0.916, Sensitive_Loss : 0.07946, Sensitive_Acc : 16.200, Run Time : 17.76 sec
INFO:root:2024-04-27 16:19:07, Train, Epoch : 10, Step : 5830, Loss : 0.20905, Acc : 0.912, Sensitive_Loss : 0.04940, Sensitive_Acc : 16.400, Run Time : 19.58 sec
INFO:root:2024-04-27 16:19:25, Train, Epoch : 10, Step : 5840, Loss : 0.20107, Acc : 0.909, Sensitive_Loss : 0.06617, Sensitive_Acc : 14.900, Run Time : 18.01 sec
INFO:root:2024-04-27 16:19:42, Train, Epoch : 10, Step : 5850, Loss : 0.17089, Acc : 0.931, Sensitive_Loss : 0.09592, Sensitive_Acc : 16.800, Run Time : 17.54 sec
INFO:root:2024-04-27 16:20:00, Train, Epoch : 10, Step : 5860, Loss : 0.21255, Acc : 0.900, Sensitive_Loss : 0.10646, Sensitive_Acc : 17.600, Run Time : 17.16 sec
INFO:root:2024-04-27 16:20:18, Train, Epoch : 10, Step : 5870, Loss : 0.24961, Acc : 0.903, Sensitive_Loss : 0.09068, Sensitive_Acc : 16.400, Run Time : 18.07 sec
INFO:root:2024-04-27 16:20:35, Train, Epoch : 10, Step : 5880, Loss : 0.22011, Acc : 0.922, Sensitive_Loss : 0.12192, Sensitive_Acc : 18.300, Run Time : 17.15 sec
INFO:root:2024-04-27 16:20:52, Train, Epoch : 10, Step : 5890, Loss : 0.22803, Acc : 0.894, Sensitive_Loss : 0.12505, Sensitive_Acc : 15.400, Run Time : 17.16 sec
INFO:root:2024-04-27 16:21:09, Train, Epoch : 10, Step : 5900, Loss : 0.22998, Acc : 0.881, Sensitive_Loss : 0.09471, Sensitive_Acc : 14.900, Run Time : 17.43 sec
INFO:root:2024-04-27 16:25:14, Dev, Step : 5900, Loss : 0.48584, Acc : 0.815, Auc : 0.900, Sensitive_Loss : 0.12900, Sensitive_Acc : 16.821, Sensitive_Auc : 0.995, Mean auc: 0.900, Run Time : 244.17 sec
INFO:root:2024-04-27 16:25:27, Train, Epoch : 10, Step : 5910, Loss : 0.21578, Acc : 0.900, Sensitive_Loss : 0.07984, Sensitive_Acc : 14.900, Run Time : 257.32 sec
INFO:root:2024-04-27 16:25:44, Train, Epoch : 10, Step : 5920, Loss : 0.20884, Acc : 0.934, Sensitive_Loss : 0.06731, Sensitive_Acc : 15.300, Run Time : 16.94 sec
INFO:root:2024-04-27 16:26:03, Train, Epoch : 10, Step : 5930, Loss : 0.23874, Acc : 0.884, Sensitive_Loss : 0.07176, Sensitive_Acc : 16.400, Run Time : 19.03 sec
INFO:root:2024-04-27 16:26:21, Train, Epoch : 10, Step : 5940, Loss : 0.22027, Acc : 0.919, Sensitive_Loss : 0.08228, Sensitive_Acc : 17.300, Run Time : 18.19 sec
INFO:root:2024-04-27 16:26:41, Train, Epoch : 10, Step : 5950, Loss : 0.22313, Acc : 0.922, Sensitive_Loss : 0.08167, Sensitive_Acc : 15.700, Run Time : 19.78 sec
INFO:root:2024-04-27 16:27:05, Train, Epoch : 10, Step : 5960, Loss : 0.20562, Acc : 0.916, Sensitive_Loss : 0.07025, Sensitive_Acc : 16.600, Run Time : 24.02 sec
INFO:root:2024-04-27 16:27:29, Train, Epoch : 10, Step : 5970, Loss : 0.18457, Acc : 0.934, Sensitive_Loss : 0.12618, Sensitive_Acc : 15.300, Run Time : 24.03 sec
INFO:root:2024-04-27 16:27:52, Train, Epoch : 10, Step : 5980, Loss : 0.19268, Acc : 0.884, Sensitive_Loss : 0.08653, Sensitive_Acc : 17.800, Run Time : 23.81 sec
INFO:root:2024-04-27 16:28:09, Train, Epoch : 10, Step : 5990, Loss : 0.25497, Acc : 0.875, Sensitive_Loss : 0.12342, Sensitive_Acc : 14.900, Run Time : 16.65 sec
INFO:root:2024-04-27 16:28:32, Train, Epoch : 10, Step : 6000, Loss : 0.21892, Acc : 0.916, Sensitive_Loss : 0.10503, Sensitive_Acc : 17.300, Run Time : 23.01 sec
INFO:root:2024-04-27 16:32:38, Dev, Step : 6000, Loss : 0.48598, Acc : 0.816, Auc : 0.898, Sensitive_Loss : 0.12868, Sensitive_Acc : 16.821, Sensitive_Auc : 0.996, Mean auc: 0.898, Run Time : 245.86 sec
INFO:root:2024-04-27 16:32:51, Train, Epoch : 10, Step : 6010, Loss : 0.24901, Acc : 0.900, Sensitive_Loss : 0.10865, Sensitive_Acc : 17.800, Run Time : 258.51 sec
INFO:root:2024-04-27 16:33:08, Train, Epoch : 10, Step : 6020, Loss : 0.20842, Acc : 0.912, Sensitive_Loss : 0.08531, Sensitive_Acc : 16.900, Run Time : 17.26 sec
INFO:root:2024-04-27 16:33:26, Train, Epoch : 10, Step : 6030, Loss : 0.23444, Acc : 0.906, Sensitive_Loss : 0.05419, Sensitive_Acc : 15.500, Run Time : 17.82 sec
INFO:root:2024-04-27 16:33:43, Train, Epoch : 10, Step : 6040, Loss : 0.25356, Acc : 0.906, Sensitive_Loss : 0.09380, Sensitive_Acc : 14.900, Run Time : 17.42 sec
INFO:root:2024-04-27 16:34:02, Train, Epoch : 10, Step : 6050, Loss : 0.20150, Acc : 0.925, Sensitive_Loss : 0.06934, Sensitive_Acc : 17.300, Run Time : 18.49 sec
INFO:root:2024-04-27 16:34:18, Train, Epoch : 10, Step : 6060, Loss : 0.23959, Acc : 0.887, Sensitive_Loss : 0.06974, Sensitive_Acc : 16.200, Run Time : 16.17 sec
INFO:root:2024-04-27 16:34:36, Train, Epoch : 10, Step : 6070, Loss : 0.18823, Acc : 0.912, Sensitive_Loss : 0.09190, Sensitive_Acc : 17.600, Run Time : 18.21 sec
INFO:root:2024-04-27 16:34:54, Train, Epoch : 10, Step : 6080, Loss : 0.20565, Acc : 0.903, Sensitive_Loss : 0.11025, Sensitive_Acc : 17.800, Run Time : 17.79 sec
INFO:root:2024-04-27 16:35:10, Train, Epoch : 10, Step : 6090, Loss : 0.23494, Acc : 0.909, Sensitive_Loss : 0.09488, Sensitive_Acc : 18.600, Run Time : 16.09 sec
INFO:root:2024-04-27 16:35:28, Train, Epoch : 10, Step : 6100, Loss : 0.18688, Acc : 0.931, Sensitive_Loss : 0.07006, Sensitive_Acc : 17.000, Run Time : 18.14 sec
INFO:root:2024-04-27 16:39:32, Dev, Step : 6100, Loss : 0.48186, Acc : 0.814, Auc : 0.900, Sensitive_Loss : 0.11651, Sensitive_Acc : 16.764, Sensitive_Auc : 0.996, Mean auc: 0.900, Run Time : 243.76 sec
INFO:root:2024-04-27 16:39:44, Train, Epoch : 10, Step : 6110, Loss : 0.21829, Acc : 0.909, Sensitive_Loss : 0.05473, Sensitive_Acc : 16.400, Run Time : 256.25 sec
INFO:root:2024-04-27 16:40:03, Train, Epoch : 10, Step : 6120, Loss : 0.23855, Acc : 0.912, Sensitive_Loss : 0.08258, Sensitive_Acc : 16.200, Run Time : 18.57 sec
INFO:root:2024-04-27 16:40:21, Train, Epoch : 10, Step : 6130, Loss : 0.20039, Acc : 0.916, Sensitive_Loss : 0.11996, Sensitive_Acc : 17.700, Run Time : 18.27 sec
INFO:root:2024-04-27 16:40:39, Train, Epoch : 10, Step : 6140, Loss : 0.22479, Acc : 0.906, Sensitive_Loss : 0.06854, Sensitive_Acc : 16.700, Run Time : 18.23 sec
INFO:root:2024-04-27 16:40:57, Train, Epoch : 10, Step : 6150, Loss : 0.26140, Acc : 0.891, Sensitive_Loss : 0.08007, Sensitive_Acc : 17.700, Run Time : 17.61 sec
INFO:root:2024-04-27 16:41:13, Train, Epoch : 10, Step : 6160, Loss : 0.24056, Acc : 0.906, Sensitive_Loss : 0.08120, Sensitive_Acc : 17.100, Run Time : 16.28 sec
INFO:root:2024-04-27 16:41:30, Train, Epoch : 10, Step : 6170, Loss : 0.24930, Acc : 0.906, Sensitive_Loss : 0.05378, Sensitive_Acc : 17.500, Run Time : 16.96 sec
INFO:root:2024-04-27 16:41:47, Train, Epoch : 10, Step : 6180, Loss : 0.21059, Acc : 0.906, Sensitive_Loss : 0.06639, Sensitive_Acc : 16.100, Run Time : 16.52 sec
INFO:root:2024-04-27 16:42:07, Train, Epoch : 10, Step : 6190, Loss : 0.22866, Acc : 0.891, Sensitive_Loss : 0.07766, Sensitive_Acc : 16.000, Run Time : 20.24 sec
INFO:root:2024-04-27 16:42:24, Train, Epoch : 10, Step : 6200, Loss : 0.25281, Acc : 0.897, Sensitive_Loss : 0.10010, Sensitive_Acc : 17.600, Run Time : 17.21 sec
INFO:root:2024-04-27 16:46:29, Dev, Step : 6200, Loss : 0.49874, Acc : 0.810, Auc : 0.897, Sensitive_Loss : 0.13473, Sensitive_Acc : 16.921, Sensitive_Auc : 0.996, Mean auc: 0.897, Run Time : 244.52 sec
INFO:root:2024-04-27 16:46:42, Train, Epoch : 10, Step : 6210, Loss : 0.19844, Acc : 0.925, Sensitive_Loss : 0.08878, Sensitive_Acc : 16.100, Run Time : 258.06 sec
INFO:root:2024-04-27 16:47:01, Train, Epoch : 10, Step : 6220, Loss : 0.19724, Acc : 0.916, Sensitive_Loss : 0.05906, Sensitive_Acc : 16.800, Run Time : 18.40 sec
INFO:root:2024-04-27 16:47:18, Train, Epoch : 10, Step : 6230, Loss : 0.25227, Acc : 0.887, Sensitive_Loss : 0.09465, Sensitive_Acc : 17.400, Run Time : 17.53 sec
INFO:root:2024-04-27 16:47:36, Train, Epoch : 10, Step : 6240, Loss : 0.21080, Acc : 0.903, Sensitive_Loss : 0.09546, Sensitive_Acc : 16.300, Run Time : 17.44 sec
INFO:root:2024-04-27 16:47:52, Train, Epoch : 10, Step : 6250, Loss : 0.18595, Acc : 0.931, Sensitive_Loss : 0.07954, Sensitive_Acc : 17.500, Run Time : 16.47 sec
INFO:root:2024-04-27 16:48:09, Train, Epoch : 10, Step : 6260, Loss : 0.17507, Acc : 0.938, Sensitive_Loss : 0.07857, Sensitive_Acc : 16.700, Run Time : 16.48 sec
INFO:root:2024-04-27 16:52:10
INFO:root:y_pred: [1.2065568e-01 9.8895895e-01 7.7967383e-03 ... 9.6764553e-01 1.6224108e-04
 9.8799276e-01]
INFO:root:y_true: [0. 1. 0. ... 1. 0. 1.]
INFO:root:sensitive_y_pred: [9.88654256e-01 2.18394227e-04 2.39842370e-01 2.98309815e-03
 9.99887705e-01 9.14905628e-04 9.99954343e-01 9.99978065e-01
 6.31997173e-05 9.67326403e-01 9.99931931e-01 9.99917030e-01
 9.98958111e-01 9.98204112e-01 7.33976206e-03 9.91738379e-01
 9.99840856e-01 6.95187896e-02 7.18747556e-01 9.54909325e-01
 9.98846412e-01 1.19067673e-02 9.99360740e-01 9.99458730e-01
 9.99195516e-01 9.99665380e-01 6.67689194e-04 9.99653339e-01
 9.95801508e-01 3.37313682e-01 4.82762977e-03 1.56138375e-01
 4.94882651e-03 1.91817790e-01 4.41053249e-02 1.11141233e-02
 2.53947638e-02 3.66341695e-02 9.99945879e-01 9.99192417e-01
 2.82024848e-06 2.36899614e-05 9.83190954e-01 1.04197981e-02
 9.99784052e-01 9.96603489e-01 9.99586642e-01 9.97877121e-01
 2.76480173e-03 9.97178197e-01 8.27395439e-01 1.68511290e-02
 6.11330450e-01 4.87039983e-03 3.30318813e-03 1.43940747e-01
 1.28807068e-01 1.06782112e-02 3.13894590e-04 1.05356671e-01
 3.14766727e-02 2.92152852e-01 2.57558990e-02 9.96745229e-01
 4.03729826e-01 9.99879837e-01 4.14980249e-03 9.99924660e-01
 9.98951912e-01 5.14182299e-02 9.42362428e-01 6.09077930e-01
 5.21613052e-03 5.10301106e-02 6.18072445e-05 1.23979361e-03
 5.05417027e-02 2.03683734e-01 1.05869723e-04 9.99979138e-01
 9.98660445e-01 5.45074744e-03 3.13871086e-01 2.71965796e-03
 5.56872487e-01 9.68220055e-01 1.16907014e-02 9.03879292e-03
 9.97936249e-01 9.99929070e-01 9.99995351e-01 7.88958801e-04
 1.06415860e-02 9.82689619e-01 6.14736557e-01 8.92475620e-03
 9.99328136e-01 9.99875903e-01 1.94042176e-03 3.83115597e-02
 9.84737694e-01 9.94903803e-01 9.98463869e-01 9.99475181e-01
 1.53591007e-03 5.29902317e-02 9.96151149e-01 9.99763191e-01
 9.97661710e-01 1.06533953e-05 9.96236622e-01 9.99351203e-01
 1.32189654e-02 9.99881506e-01 9.96666372e-01 9.99821246e-01
 3.24451298e-01 9.99927044e-01 2.84024384e-02 8.75545815e-02
 9.99787867e-01 9.99967217e-01 4.46341553e-04 9.99683499e-01
 9.99999404e-01 1.40413478e-01 9.95407999e-01 4.72913869e-02
 1.48884365e-02 9.39671397e-01 9.98538017e-01 1.38513325e-02
 2.53722724e-03 3.00634820e-02 9.94909704e-01 9.98904943e-01
 9.96967375e-01 4.59883781e-03 1.22679463e-02 9.91783619e-01]
INFO:root:sensitive_y_true: [1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.
 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.]
INFO:root:2024-04-27 16:52:10, Dev, Step : 6260, Loss : 0.48001, Acc : 0.814, Auc : 0.899, Sensitive_Loss : 0.12265, Sensitive_Acc : 16.821, Sensitive_Auc : 0.996, Mean auc: 0.899, Run Time : 241.76 sec
