Running on desktop18:
stdin: is not a tty
Activating chexpert environment...
/home/katkr/.conda/envs/chexpert/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'
2
Using the specified args:
Namespace(cfg_path='/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/config/config_katkr.json', device_ids='0', logtofile=False, num_workers=2, pre_train=None, resume=0, save_path='/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/logdirs/logdir-30k-2', verbose=True)
{
    "base_path": "/home/data_shares/purrlab/CheXpert/CheXpert-v1.0-small",
    "train_csv": "/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/biased_dataset_train.csv",
    "dev_csv": "/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/biased_dataset_val.csv",
    "pred_csv": "/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/predictions/Pred_Balanced_Sex_0_0.csv",
    "pred_model": "/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/logdirs/logdir-30k-2/Best_Balanced_Sex_0_01.ckpt",
    "backbone": "densenet121",
    "sensitive_attribute": "Sex",
    "lambda_val": 0.1,
    "num_heads": 2,
    "width": 512,
    "height": 512,
    "long_side": 512,
    "fix_ratio": true,
    "pixel_mean": 128.0,
    "pixel_std": 64.0,
    "use_pixel_std": true,
    "use_equalizeHist": true,
    "use_transforms_type": "Aug",
    "gaussian_blur": 3,
    "border_pad": "pixel_mean",
    "num_classes": [
        1
    ],
    "batch_weight": true,
    "batch_weight_sensitive": true,
    "enhance_index": [
        2,
        6
    ],
    "enhance_times": 1,
    "pos_weight": [
        1
    ],
    "sensitive_pos_weight": [
        1
    ],
    "train_batch_size": 32,
    "dev_batch_size": 32,
    "pretrained": true,
    "log_every": 10,
    "test_every": 100,
    "epoch": 10,
    "norm_type": "BatchNorm",
    "global_pool": "PCAM",
    "fc_bn": true,
    "attention_map": "FPA",
    "lse_gamma": 0.5,
    "fc_drop": 0,
    "optimizer": "Adam",
    "criterion": "BCE",
    "sensitive_criterion": "BCE",
    "lr": 0.0001,
    "lr_factor": 0.1,
    "lr_epochs": [
        2
    ],
    "momentum": 0.9,
    "weight_decay": 0.0,
    "best_target": "auc",
    "save_top_k": 3,
    "save_index": [
        0
    ]
}
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 256, 256]           9,408
       BatchNorm2d-2         [-1, 64, 256, 256]             128
              ReLU-3         [-1, 64, 256, 256]               0
         MaxPool2d-4         [-1, 64, 128, 128]               0
       BatchNorm2d-5         [-1, 64, 128, 128]             128
              ReLU-6         [-1, 64, 128, 128]               0
            Conv2d-7        [-1, 128, 128, 128]           8,192
       BatchNorm2d-8        [-1, 128, 128, 128]             256
              ReLU-9        [-1, 128, 128, 128]               0
           Conv2d-10         [-1, 32, 128, 128]          36,864
      BatchNorm2d-11         [-1, 96, 128, 128]             192
             ReLU-12         [-1, 96, 128, 128]               0
           Conv2d-13        [-1, 128, 128, 128]          12,288
      BatchNorm2d-14        [-1, 128, 128, 128]             256
             ReLU-15        [-1, 128, 128, 128]               0
           Conv2d-16         [-1, 32, 128, 128]          36,864
      BatchNorm2d-17        [-1, 128, 128, 128]             256
             ReLU-18        [-1, 128, 128, 128]               0
           Conv2d-19        [-1, 128, 128, 128]          16,384
      BatchNorm2d-20        [-1, 128, 128, 128]             256
             ReLU-21        [-1, 128, 128, 128]               0
           Conv2d-22         [-1, 32, 128, 128]          36,864
      BatchNorm2d-23        [-1, 160, 128, 128]             320
             ReLU-24        [-1, 160, 128, 128]               0
           Conv2d-25        [-1, 128, 128, 128]          20,480
      BatchNorm2d-26        [-1, 128, 128, 128]             256
             ReLU-27        [-1, 128, 128, 128]               0
           Conv2d-28         [-1, 32, 128, 128]          36,864
      BatchNorm2d-29        [-1, 192, 128, 128]             384
             ReLU-30        [-1, 192, 128, 128]               0
           Conv2d-31        [-1, 128, 128, 128]          24,576
      BatchNorm2d-32        [-1, 128, 128, 128]             256
             ReLU-33        [-1, 128, 128, 128]               0
           Conv2d-34         [-1, 32, 128, 128]          36,864
      BatchNorm2d-35        [-1, 224, 128, 128]             448
             ReLU-36        [-1, 224, 128, 128]               0
           Conv2d-37        [-1, 128, 128, 128]          28,672
      BatchNorm2d-38        [-1, 128, 128, 128]             256
             ReLU-39        [-1, 128, 128, 128]               0
           Conv2d-40         [-1, 32, 128, 128]          36,864
      BatchNorm2d-41        [-1, 256, 128, 128]             512
             ReLU-42        [-1, 256, 128, 128]               0
           Conv2d-43        [-1, 128, 128, 128]          32,768
        AvgPool2d-44          [-1, 128, 64, 64]               0
      BatchNorm2d-45          [-1, 128, 64, 64]             256
             ReLU-46          [-1, 128, 64, 64]               0
           Conv2d-47          [-1, 128, 64, 64]          16,384
      BatchNorm2d-48          [-1, 128, 64, 64]             256
             ReLU-49          [-1, 128, 64, 64]               0
           Conv2d-50           [-1, 32, 64, 64]          36,864
      BatchNorm2d-51          [-1, 160, 64, 64]             320
             ReLU-52          [-1, 160, 64, 64]               0
           Conv2d-53          [-1, 128, 64, 64]          20,480
      BatchNorm2d-54          [-1, 128, 64, 64]             256
             ReLU-55          [-1, 128, 64, 64]               0
           Conv2d-56           [-1, 32, 64, 64]          36,864
      BatchNorm2d-57          [-1, 192, 64, 64]             384
             ReLU-58          [-1, 192, 64, 64]               0
           Conv2d-59          [-1, 128, 64, 64]          24,576
      BatchNorm2d-60          [-1, 128, 64, 64]             256
             ReLU-61          [-1, 128, 64, 64]               0
           Conv2d-62           [-1, 32, 64, 64]          36,864
      BatchNorm2d-63          [-1, 224, 64, 64]             448
             ReLU-64          [-1, 224, 64, 64]               0
           Conv2d-65          [-1, 128, 64, 64]          28,672
      BatchNorm2d-66          [-1, 128, 64, 64]             256
             ReLU-67          [-1, 128, 64, 64]               0
           Conv2d-68           [-1, 32, 64, 64]          36,864
      BatchNorm2d-69          [-1, 256, 64, 64]             512
             ReLU-70          [-1, 256, 64, 64]               0
           Conv2d-71          [-1, 128, 64, 64]          32,768
      BatchNorm2d-72          [-1, 128, 64, 64]             256
             ReLU-73          [-1, 128, 64, 64]               0
           Conv2d-74           [-1, 32, 64, 64]          36,864
      BatchNorm2d-75          [-1, 288, 64, 64]             576
             ReLU-76          [-1, 288, 64, 64]               0
           Conv2d-77          [-1, 128, 64, 64]          36,864
      BatchNorm2d-78          [-1, 128, 64, 64]             256
             ReLU-79          [-1, 128, 64, 64]               0
           Conv2d-80           [-1, 32, 64, 64]          36,864
      BatchNorm2d-81          [-1, 320, 64, 64]             640
             ReLU-82          [-1, 320, 64, 64]               0
           Conv2d-83          [-1, 128, 64, 64]          40,960
      BatchNorm2d-84          [-1, 128, 64, 64]             256
             ReLU-85          [-1, 128, 64, 64]               0
           Conv2d-86           [-1, 32, 64, 64]          36,864
      BatchNorm2d-87          [-1, 352, 64, 64]             704
             ReLU-88          [-1, 352, 64, 64]               0
           Conv2d-89          [-1, 128, 64, 64]          45,056
      BatchNorm2d-90          [-1, 128, 64, 64]             256
             ReLU-91          [-1, 128, 64, 64]               0
           Conv2d-92           [-1, 32, 64, 64]          36,864
      BatchNorm2d-93          [-1, 384, 64, 64]             768
             ReLU-94          [-1, 384, 64, 64]               0
           Conv2d-95          [-1, 128, 64, 64]          49,152
      BatchNorm2d-96          [-1, 128, 64, 64]             256
             ReLU-97          [-1, 128, 64, 64]               0
           Conv2d-98           [-1, 32, 64, 64]          36,864
      BatchNorm2d-99          [-1, 416, 64, 64]             832
            ReLU-100          [-1, 416, 64, 64]               0
          Conv2d-101          [-1, 128, 64, 64]          53,248
     BatchNorm2d-102          [-1, 128, 64, 64]             256
            ReLU-103          [-1, 128, 64, 64]               0
          Conv2d-104           [-1, 32, 64, 64]          36,864
     BatchNorm2d-105          [-1, 448, 64, 64]             896
            ReLU-106          [-1, 448, 64, 64]               0
          Conv2d-107          [-1, 128, 64, 64]          57,344
     BatchNorm2d-108          [-1, 128, 64, 64]             256
            ReLU-109          [-1, 128, 64, 64]               0
          Conv2d-110           [-1, 32, 64, 64]          36,864
     BatchNorm2d-111          [-1, 480, 64, 64]             960
            ReLU-112          [-1, 480, 64, 64]               0
          Conv2d-113          [-1, 128, 64, 64]          61,440
     BatchNorm2d-114          [-1, 128, 64, 64]             256
            ReLU-115          [-1, 128, 64, 64]               0
          Conv2d-116           [-1, 32, 64, 64]          36,864
     BatchNorm2d-117          [-1, 512, 64, 64]           1,024
            ReLU-118          [-1, 512, 64, 64]               0
          Conv2d-119          [-1, 256, 64, 64]         131,072
       AvgPool2d-120          [-1, 256, 32, 32]               0
     BatchNorm2d-121          [-1, 256, 32, 32]             512
            ReLU-122          [-1, 256, 32, 32]               0
          Conv2d-123          [-1, 128, 32, 32]          32,768
     BatchNorm2d-124          [-1, 128, 32, 32]             256
            ReLU-125          [-1, 128, 32, 32]               0
          Conv2d-126           [-1, 32, 32, 32]          36,864
     BatchNorm2d-127          [-1, 288, 32, 32]             576
            ReLU-128          [-1, 288, 32, 32]               0
          Conv2d-129          [-1, 128, 32, 32]          36,864
     BatchNorm2d-130          [-1, 128, 32, 32]             256
            ReLU-131          [-1, 128, 32, 32]               0
          Conv2d-132           [-1, 32, 32, 32]          36,864
     BatchNorm2d-133          [-1, 320, 32, 32]             640
            ReLU-134          [-1, 320, 32, 32]               0
          Conv2d-135          [-1, 128, 32, 32]          40,960
     BatchNorm2d-136          [-1, 128, 32, 32]             256
            ReLU-137          [-1, 128, 32, 32]               0
          Conv2d-138           [-1, 32, 32, 32]          36,864
     BatchNorm2d-139          [-1, 352, 32, 32]             704
            ReLU-140          [-1, 352, 32, 32]               0
          Conv2d-141          [-1, 128, 32, 32]          45,056
     BatchNorm2d-142          [-1, 128, 32, 32]             256
            ReLU-143          [-1, 128, 32, 32]               0
          Conv2d-144           [-1, 32, 32, 32]          36,864
     BatchNorm2d-145          [-1, 384, 32, 32]             768
            ReLU-146          [-1, 384, 32, 32]               0
          Conv2d-147          [-1, 128, 32, 32]          49,152
     BatchNorm2d-148          [-1, 128, 32, 32]             256
            ReLU-149          [-1, 128, 32, 32]               0
          Conv2d-150           [-1, 32, 32, 32]          36,864
     BatchNorm2d-151          [-1, 416, 32, 32]             832
            ReLU-152          [-1, 416, 32, 32]               0
          Conv2d-153          [-1, 128, 32, 32]          53,248
     BatchNorm2d-154          [-1, 128, 32, 32]             256
            ReLU-155          [-1, 128, 32, 32]               0
          Conv2d-156           [-1, 32, 32, 32]          36,864
     BatchNorm2d-157          [-1, 448, 32, 32]             896
            ReLU-158          [-1, 448, 32, 32]               0
          Conv2d-159          [-1, 128, 32, 32]          57,344
     BatchNorm2d-160          [-1, 128, 32, 32]             256
            ReLU-161          [-1, 128, 32, 32]               0
          Conv2d-162           [-1, 32, 32, 32]          36,864
     BatchNorm2d-163          [-1, 480, 32, 32]             960
            ReLU-164          [-1, 480, 32, 32]               0
          Conv2d-165          [-1, 128, 32, 32]          61,440
     BatchNorm2d-166          [-1, 128, 32, 32]             256
            ReLU-167          [-1, 128, 32, 32]               0
          Conv2d-168           [-1, 32, 32, 32]          36,864
     BatchNorm2d-169          [-1, 512, 32, 32]           1,024
            ReLU-170          [-1, 512, 32, 32]               0
          Conv2d-171          [-1, 128, 32, 32]          65,536
     BatchNorm2d-172          [-1, 128, 32, 32]             256
            ReLU-173          [-1, 128, 32, 32]               0
          Conv2d-174           [-1, 32, 32, 32]          36,864
     BatchNorm2d-175          [-1, 544, 32, 32]           1,088
            ReLU-176          [-1, 544, 32, 32]               0
          Conv2d-177          [-1, 128, 32, 32]          69,632
     BatchNorm2d-178          [-1, 128, 32, 32]             256
            ReLU-179          [-1, 128, 32, 32]               0
          Conv2d-180           [-1, 32, 32, 32]          36,864
     BatchNorm2d-181          [-1, 576, 32, 32]           1,152
            ReLU-182          [-1, 576, 32, 32]               0
          Conv2d-183          [-1, 128, 32, 32]          73,728
     BatchNorm2d-184          [-1, 128, 32, 32]             256
            ReLU-185          [-1, 128, 32, 32]               0
          Conv2d-186           [-1, 32, 32, 32]          36,864
     BatchNorm2d-187          [-1, 608, 32, 32]           1,216
            ReLU-188          [-1, 608, 32, 32]               0
          Conv2d-189          [-1, 128, 32, 32]          77,824
     BatchNorm2d-190          [-1, 128, 32, 32]             256
            ReLU-191          [-1, 128, 32, 32]               0
          Conv2d-192           [-1, 32, 32, 32]          36,864
     BatchNorm2d-193          [-1, 640, 32, 32]           1,280
            ReLU-194          [-1, 640, 32, 32]               0
          Conv2d-195          [-1, 128, 32, 32]          81,920
     BatchNorm2d-196          [-1, 128, 32, 32]             256
            ReLU-197          [-1, 128, 32, 32]               0
          Conv2d-198           [-1, 32, 32, 32]          36,864
     BatchNorm2d-199          [-1, 672, 32, 32]           1,344
            ReLU-200          [-1, 672, 32, 32]               0
          Conv2d-201          [-1, 128, 32, 32]          86,016
     BatchNorm2d-202          [-1, 128, 32, 32]             256
            ReLU-203          [-1, 128, 32, 32]               0
          Conv2d-204           [-1, 32, 32, 32]          36,864
     BatchNorm2d-205          [-1, 704, 32, 32]           1,408
            ReLU-206          [-1, 704, 32, 32]               0
          Conv2d-207          [-1, 128, 32, 32]          90,112
     BatchNorm2d-208          [-1, 128, 32, 32]             256
            ReLU-209          [-1, 128, 32, 32]               0
          Conv2d-210           [-1, 32, 32, 32]          36,864
     BatchNorm2d-211          [-1, 736, 32, 32]           1,472
            ReLU-212          [-1, 736, 32, 32]               0
          Conv2d-213          [-1, 128, 32, 32]          94,208
     BatchNorm2d-214          [-1, 128, 32, 32]             256
            ReLU-215          [-1, 128, 32, 32]               0
          Conv2d-216           [-1, 32, 32, 32]          36,864
     BatchNorm2d-217          [-1, 768, 32, 32]           1,536
            ReLU-218          [-1, 768, 32, 32]               0
          Conv2d-219          [-1, 128, 32, 32]          98,304
     BatchNorm2d-220          [-1, 128, 32, 32]             256
            ReLU-221          [-1, 128, 32, 32]               0
          Conv2d-222           [-1, 32, 32, 32]          36,864
     BatchNorm2d-223          [-1, 800, 32, 32]           1,600
            ReLU-224          [-1, 800, 32, 32]               0
          Conv2d-225          [-1, 128, 32, 32]         102,400
     BatchNorm2d-226          [-1, 128, 32, 32]             256
            ReLU-227          [-1, 128, 32, 32]               0
          Conv2d-228           [-1, 32, 32, 32]          36,864
     BatchNorm2d-229          [-1, 832, 32, 32]           1,664
            ReLU-230          [-1, 832, 32, 32]               0
          Conv2d-231          [-1, 128, 32, 32]         106,496
     BatchNorm2d-232          [-1, 128, 32, 32]             256
            ReLU-233          [-1, 128, 32, 32]               0
          Conv2d-234           [-1, 32, 32, 32]          36,864
     BatchNorm2d-235          [-1, 864, 32, 32]           1,728
            ReLU-236          [-1, 864, 32, 32]               0
          Conv2d-237          [-1, 128, 32, 32]         110,592
     BatchNorm2d-238          [-1, 128, 32, 32]             256
            ReLU-239          [-1, 128, 32, 32]               0
          Conv2d-240           [-1, 32, 32, 32]          36,864
     BatchNorm2d-241          [-1, 896, 32, 32]           1,792
            ReLU-242          [-1, 896, 32, 32]               0
          Conv2d-243          [-1, 128, 32, 32]         114,688
     BatchNorm2d-244          [-1, 128, 32, 32]             256
            ReLU-245          [-1, 128, 32, 32]               0
          Conv2d-246           [-1, 32, 32, 32]          36,864
     BatchNorm2d-247          [-1, 928, 32, 32]           1,856
            ReLU-248          [-1, 928, 32, 32]               0
          Conv2d-249          [-1, 128, 32, 32]         118,784
     BatchNorm2d-250          [-1, 128, 32, 32]             256
            ReLU-251          [-1, 128, 32, 32]               0
          Conv2d-252           [-1, 32, 32, 32]          36,864
     BatchNorm2d-253          [-1, 960, 32, 32]           1,920
            ReLU-254          [-1, 960, 32, 32]               0
          Conv2d-255          [-1, 128, 32, 32]         122,880
     BatchNorm2d-256          [-1, 128, 32, 32]             256
            ReLU-257          [-1, 128, 32, 32]               0
          Conv2d-258           [-1, 32, 32, 32]          36,864
     BatchNorm2d-259          [-1, 992, 32, 32]           1,984
            ReLU-260          [-1, 992, 32, 32]               0
          Conv2d-261          [-1, 128, 32, 32]         126,976
     BatchNorm2d-262          [-1, 128, 32, 32]             256
            ReLU-263          [-1, 128, 32, 32]               0
          Conv2d-264           [-1, 32, 32, 32]          36,864
     BatchNorm2d-265         [-1, 1024, 32, 32]           2,048
            ReLU-266         [-1, 1024, 32, 32]               0
          Conv2d-267          [-1, 512, 32, 32]         524,288
       AvgPool2d-268          [-1, 512, 16, 16]               0
     BatchNorm2d-269          [-1, 512, 16, 16]           1,024
            ReLU-270          [-1, 512, 16, 16]               0
          Conv2d-271          [-1, 128, 16, 16]          65,536
     BatchNorm2d-272          [-1, 128, 16, 16]             256
            ReLU-273          [-1, 128, 16, 16]               0
          Conv2d-274           [-1, 32, 16, 16]          36,864
     BatchNorm2d-275          [-1, 544, 16, 16]           1,088
            ReLU-276          [-1, 544, 16, 16]               0
          Conv2d-277          [-1, 128, 16, 16]          69,632
     BatchNorm2d-278          [-1, 128, 16, 16]             256
            ReLU-279          [-1, 128, 16, 16]               0
          Conv2d-280           [-1, 32, 16, 16]          36,864
     BatchNorm2d-281          [-1, 576, 16, 16]           1,152
            ReLU-282          [-1, 576, 16, 16]               0
          Conv2d-283          [-1, 128, 16, 16]          73,728
     BatchNorm2d-284          [-1, 128, 16, 16]             256
            ReLU-285          [-1, 128, 16, 16]               0
          Conv2d-286           [-1, 32, 16, 16]          36,864
     BatchNorm2d-287          [-1, 608, 16, 16]           1,216
            ReLU-288          [-1, 608, 16, 16]               0
          Conv2d-289          [-1, 128, 16, 16]          77,824
     BatchNorm2d-290          [-1, 128, 16, 16]             256
            ReLU-291          [-1, 128, 16, 16]               0
          Conv2d-292           [-1, 32, 16, 16]          36,864
     BatchNorm2d-293          [-1, 640, 16, 16]           1,280
            ReLU-294          [-1, 640, 16, 16]               0
          Conv2d-295          [-1, 128, 16, 16]          81,920
     BatchNorm2d-296          [-1, 128, 16, 16]             256
            ReLU-297          [-1, 128, 16, 16]               0
          Conv2d-298           [-1, 32, 16, 16]          36,864
     BatchNorm2d-299          [-1, 672, 16, 16]           1,344
            ReLU-300          [-1, 672, 16, 16]               0
          Conv2d-301          [-1, 128, 16, 16]          86,016
     BatchNorm2d-302          [-1, 128, 16, 16]             256
            ReLU-303          [-1, 128, 16, 16]               0
          Conv2d-304           [-1, 32, 16, 16]          36,864
     BatchNorm2d-305          [-1, 704, 16, 16]           1,408
            ReLU-306          [-1, 704, 16, 16]               0
          Conv2d-307          [-1, 128, 16, 16]          90,112
     BatchNorm2d-308          [-1, 128, 16, 16]             256
            ReLU-309          [-1, 128, 16, 16]               0
          Conv2d-310           [-1, 32, 16, 16]          36,864
     BatchNorm2d-311          [-1, 736, 16, 16]           1,472
            ReLU-312          [-1, 736, 16, 16]               0
          Conv2d-313          [-1, 128, 16, 16]          94,208
     BatchNorm2d-314          [-1, 128, 16, 16]             256
            ReLU-315          [-1, 128, 16, 16]               0
          Conv2d-316           [-1, 32, 16, 16]          36,864
     BatchNorm2d-317          [-1, 768, 16, 16]           1,536
            ReLU-318          [-1, 768, 16, 16]               0
          Conv2d-319          [-1, 128, 16, 16]          98,304
     BatchNorm2d-320          [-1, 128, 16, 16]             256
            ReLU-321          [-1, 128, 16, 16]               0
          Conv2d-322           [-1, 32, 16, 16]          36,864
     BatchNorm2d-323          [-1, 800, 16, 16]           1,600
            ReLU-324          [-1, 800, 16, 16]               0
          Conv2d-325          [-1, 128, 16, 16]         102,400
     BatchNorm2d-326          [-1, 128, 16, 16]             256
            ReLU-327          [-1, 128, 16, 16]               0
          Conv2d-328           [-1, 32, 16, 16]          36,864
     BatchNorm2d-329          [-1, 832, 16, 16]           1,664
            ReLU-330          [-1, 832, 16, 16]               0
          Conv2d-331          [-1, 128, 16, 16]         106,496
     BatchNorm2d-332          [-1, 128, 16, 16]             256
            ReLU-333          [-1, 128, 16, 16]               0
          Conv2d-334           [-1, 32, 16, 16]          36,864
     BatchNorm2d-335          [-1, 864, 16, 16]           1,728
            ReLU-336          [-1, 864, 16, 16]               0
          Conv2d-337          [-1, 128, 16, 16]         110,592
     BatchNorm2d-338          [-1, 128, 16, 16]             256
            ReLU-339          [-1, 128, 16, 16]               0
          Conv2d-340           [-1, 32, 16, 16]          36,864
     BatchNorm2d-341          [-1, 896, 16, 16]           1,792
            ReLU-342          [-1, 896, 16, 16]               0
          Conv2d-343          [-1, 128, 16, 16]         114,688
     BatchNorm2d-344          [-1, 128, 16, 16]             256
            ReLU-345          [-1, 128, 16, 16]               0
          Conv2d-346           [-1, 32, 16, 16]          36,864
     BatchNorm2d-347          [-1, 928, 16, 16]           1,856
            ReLU-348          [-1, 928, 16, 16]               0
          Conv2d-349          [-1, 128, 16, 16]         118,784
     BatchNorm2d-350          [-1, 128, 16, 16]             256
            ReLU-351          [-1, 128, 16, 16]               0
          Conv2d-352           [-1, 32, 16, 16]          36,864
     BatchNorm2d-353          [-1, 960, 16, 16]           1,920
            ReLU-354          [-1, 960, 16, 16]               0
          Conv2d-355          [-1, 128, 16, 16]         122,880
     BatchNorm2d-356          [-1, 128, 16, 16]             256
            ReLU-357          [-1, 128, 16, 16]               0
          Conv2d-358           [-1, 32, 16, 16]          36,864
     BatchNorm2d-359          [-1, 992, 16, 16]           1,984
            ReLU-360          [-1, 992, 16, 16]               0
          Conv2d-361          [-1, 128, 16, 16]         126,976
     BatchNorm2d-362          [-1, 128, 16, 16]             256
            ReLU-363          [-1, 128, 16, 16]               0
          Conv2d-364           [-1, 32, 16, 16]          36,864
     BatchNorm2d-365         [-1, 1024, 16, 16]           2,048
        DenseNet-366         [-1, 1024, 16, 16]               0
AdaptiveAvgPool2d-367           [-1, 1024, 1, 1]               0
          Conv2d-368           [-1, 1024, 1, 1]       1,049,600
     BatchNorm2d-369           [-1, 1024, 1, 1]           2,048
            ReLU-370           [-1, 1024, 1, 1]               0
  Conv2dNormRelu-371           [-1, 1024, 1, 1]               0
          Conv2d-372         [-1, 1024, 16, 16]       1,049,600
     BatchNorm2d-373         [-1, 1024, 16, 16]           2,048
            ReLU-374         [-1, 1024, 16, 16]               0
  Conv2dNormRelu-375         [-1, 1024, 16, 16]               0
          Conv2d-376              [-1, 1, 8, 8]          50,177
     BatchNorm2d-377              [-1, 1, 8, 8]               2
            ReLU-378              [-1, 1, 8, 8]               0
  Conv2dNormRelu-379              [-1, 1, 8, 8]               0
          Conv2d-380              [-1, 1, 4, 4]              26
     BatchNorm2d-381              [-1, 1, 4, 4]               2
            ReLU-382              [-1, 1, 4, 4]               0
  Conv2dNormRelu-383              [-1, 1, 4, 4]               0
          Conv2d-384              [-1, 1, 2, 2]              10
     BatchNorm2d-385              [-1, 1, 2, 2]               2
            ReLU-386              [-1, 1, 2, 2]               0
  Conv2dNormRelu-387              [-1, 1, 2, 2]               0
          Conv2d-388              [-1, 1, 2, 2]              10
     BatchNorm2d-389              [-1, 1, 2, 2]               2
            ReLU-390              [-1, 1, 2, 2]               0
  Conv2dNormRelu-391              [-1, 1, 2, 2]               0
          Conv2d-392              [-1, 1, 4, 4]              26
     BatchNorm2d-393              [-1, 1, 4, 4]               2
            ReLU-394              [-1, 1, 4, 4]               0
  Conv2dNormRelu-395              [-1, 1, 4, 4]               0
          Conv2d-396              [-1, 1, 8, 8]              50
     BatchNorm2d-397              [-1, 1, 8, 8]               2
            ReLU-398              [-1, 1, 8, 8]               0
  Conv2dNormRelu-399              [-1, 1, 8, 8]               0
       FPAModule-400         [-1, 1024, 16, 16]               0
    AttentionMap-401         [-1, 1024, 16, 16]               0
          Conv2d-402            [-1, 1, 16, 16]           1,025
        PcamPool-403           [-1, 1024, 1, 1]               0
      GlobalPool-404           [-1, 1024, 1, 1]               0
     BatchNorm2d-405           [-1, 1024, 1, 1]           2,048
          Conv2d-406              [-1, 1, 1, 1]           1,025
        PcamPool-407           [-1, 1024, 1, 1]               0
      GlobalPool-408           [-1, 1024, 1, 1]               0
          Linear-409                    [-1, 1]           1,025
================================================================
Total params: 9,112,586
Trainable params: 9,112,586
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 3.00
Forward/backward pass size (MB): 1551.09
Params size (MB): 34.76
Estimated Total Size (MB): 1588.85
----------------------------------------------------------------
INFO:root:2024-04-16 10:56:20, Train, Epoch : 1, Step : 10, Loss : 0.71281, Acc : 0.541, Sensitive_Loss : 1.10747, Sensitive_Acc : 18.700, Run Time : 24.04 sec
INFO:root:2024-04-16 10:56:41, Train, Epoch : 1, Step : 20, Loss : 0.74268, Acc : 0.553, Sensitive_Loss : 0.97338, Sensitive_Acc : 19.000, Run Time : 20.75 sec
INFO:root:2024-04-16 10:57:02, Train, Epoch : 1, Step : 30, Loss : 0.71003, Acc : 0.578, Sensitive_Loss : 0.97657, Sensitive_Acc : 16.200, Run Time : 21.04 sec
INFO:root:2024-04-16 10:57:18, Train, Epoch : 1, Step : 40, Loss : 0.68156, Acc : 0.581, Sensitive_Loss : 0.97119, Sensitive_Acc : 14.900, Run Time : 16.16 sec
INFO:root:2024-04-16 10:57:38, Train, Epoch : 1, Step : 50, Loss : 0.58302, Acc : 0.647, Sensitive_Loss : 0.93396, Sensitive_Acc : 17.200, Run Time : 20.41 sec
INFO:root:2024-04-16 10:57:57, Train, Epoch : 1, Step : 60, Loss : 0.61153, Acc : 0.625, Sensitive_Loss : 0.81191, Sensitive_Acc : 17.700, Run Time : 18.87 sec
INFO:root:2024-04-16 10:58:18, Train, Epoch : 1, Step : 70, Loss : 0.61605, Acc : 0.691, Sensitive_Loss : 0.77621, Sensitive_Acc : 19.000, Run Time : 20.94 sec
INFO:root:2024-04-16 10:58:36, Train, Epoch : 1, Step : 80, Loss : 0.59094, Acc : 0.656, Sensitive_Loss : 0.74795, Sensitive_Acc : 17.000, Run Time : 18.15 sec
INFO:root:2024-04-16 10:58:55, Train, Epoch : 1, Step : 90, Loss : 0.65842, Acc : 0.678, Sensitive_Loss : 0.72721, Sensitive_Acc : 19.900, Run Time : 18.52 sec
INFO:root:2024-04-16 10:59:16, Train, Epoch : 1, Step : 100, Loss : 0.72758, Acc : 0.625, Sensitive_Loss : 0.70269, Sensitive_Acc : 19.300, Run Time : 20.91 sec
INFO:root:2024-04-16 11:03:18, Dev, Step : 100, Loss : 0.75607, Acc : 0.615, Auc : 0.714, Sensitive_Loss : 0.94621, Sensitive_Acc : 12.774, Sensitive_Auc : 0.857, Mean auc: 0.714, Run Time : 242.59 sec
INFO:root:2024-04-16 11:03:19, Best, Step : 100, Loss : 0.75607, Acc : 0.615, Auc : 0.714, Sensitive_Loss : 0.94621, Sensitive_Acc : 12.774, Sensitive_Auc : 0.857, Best Auc : 0.714
INFO:root:2024-04-16 11:03:32, Train, Epoch : 1, Step : 110, Loss : 0.70747, Acc : 0.656, Sensitive_Loss : 0.67705, Sensitive_Acc : 19.900, Run Time : 255.88 sec
INFO:root:2024-04-16 11:03:50, Train, Epoch : 1, Step : 120, Loss : 0.60456, Acc : 0.650, Sensitive_Loss : 0.64169, Sensitive_Acc : 21.500, Run Time : 18.27 sec
INFO:root:2024-04-16 11:04:08, Train, Epoch : 1, Step : 130, Loss : 0.65108, Acc : 0.697, Sensitive_Loss : 0.54251, Sensitive_Acc : 21.500, Run Time : 17.94 sec
INFO:root:2024-04-16 11:04:26, Train, Epoch : 1, Step : 140, Loss : 0.63035, Acc : 0.694, Sensitive_Loss : 0.69973, Sensitive_Acc : 20.800, Run Time : 18.15 sec
INFO:root:2024-04-16 11:04:44, Train, Epoch : 1, Step : 150, Loss : 0.62416, Acc : 0.634, Sensitive_Loss : 0.59782, Sensitive_Acc : 24.000, Run Time : 18.21 sec
INFO:root:2024-04-16 11:05:02, Train, Epoch : 1, Step : 160, Loss : 0.63207, Acc : 0.691, Sensitive_Loss : 0.55873, Sensitive_Acc : 24.300, Run Time : 17.95 sec
INFO:root:2024-04-16 11:05:20, Train, Epoch : 1, Step : 170, Loss : 0.57022, Acc : 0.703, Sensitive_Loss : 0.56240, Sensitive_Acc : 18.100, Run Time : 18.21 sec
INFO:root:2024-04-16 11:05:40, Train, Epoch : 1, Step : 180, Loss : 0.60659, Acc : 0.722, Sensitive_Loss : 0.50173, Sensitive_Acc : 13.700, Run Time : 19.78 sec
INFO:root:2024-04-16 11:05:58, Train, Epoch : 1, Step : 190, Loss : 0.58073, Acc : 0.706, Sensitive_Loss : 0.48874, Sensitive_Acc : 21.900, Run Time : 17.74 sec
INFO:root:2024-04-16 11:06:17, Train, Epoch : 1, Step : 200, Loss : 0.63526, Acc : 0.684, Sensitive_Loss : 0.55831, Sensitive_Acc : 13.300, Run Time : 18.63 sec
INFO:root:2024-04-16 11:10:15, Dev, Step : 200, Loss : 0.71895, Acc : 0.652, Auc : 0.767, Sensitive_Loss : 0.67427, Sensitive_Acc : 16.323, Sensitive_Auc : 0.902, Mean auc: 0.767, Run Time : 238.24 sec
INFO:root:2024-04-16 11:10:16, Best, Step : 200, Loss : 0.71895, Acc : 0.652, Auc : 0.767, Sensitive_Loss : 0.67427, Sensitive_Acc : 16.323, Sensitive_Auc : 0.902, Best Auc : 0.767
INFO:root:2024-04-16 11:10:30, Train, Epoch : 1, Step : 210, Loss : 0.62067, Acc : 0.656, Sensitive_Loss : 0.41461, Sensitive_Acc : 19.800, Run Time : 253.53 sec
INFO:root:2024-04-16 11:10:50, Train, Epoch : 1, Step : 220, Loss : 0.58619, Acc : 0.694, Sensitive_Loss : 0.49535, Sensitive_Acc : 16.800, Run Time : 19.42 sec
INFO:root:2024-04-16 11:11:09, Train, Epoch : 1, Step : 230, Loss : 0.51604, Acc : 0.722, Sensitive_Loss : 0.48496, Sensitive_Acc : 25.000, Run Time : 18.94 sec
INFO:root:2024-04-16 11:11:27, Train, Epoch : 1, Step : 240, Loss : 0.57270, Acc : 0.725, Sensitive_Loss : 0.47807, Sensitive_Acc : 21.700, Run Time : 18.63 sec
INFO:root:2024-04-16 11:11:45, Train, Epoch : 1, Step : 250, Loss : 0.59400, Acc : 0.675, Sensitive_Loss : 0.33002, Sensitive_Acc : 19.100, Run Time : 17.97 sec
INFO:root:2024-04-16 11:12:02, Train, Epoch : 1, Step : 260, Loss : 0.64963, Acc : 0.675, Sensitive_Loss : 0.41053, Sensitive_Acc : 20.500, Run Time : 16.69 sec
INFO:root:2024-04-16 11:12:22, Train, Epoch : 1, Step : 270, Loss : 0.63808, Acc : 0.662, Sensitive_Loss : 0.41338, Sensitive_Acc : 25.100, Run Time : 19.72 sec
INFO:root:2024-04-16 11:12:39, Train, Epoch : 1, Step : 280, Loss : 0.64929, Acc : 0.681, Sensitive_Loss : 0.46421, Sensitive_Acc : 20.000, Run Time : 17.86 sec
INFO:root:2024-04-16 11:12:56, Train, Epoch : 1, Step : 290, Loss : 0.59662, Acc : 0.700, Sensitive_Loss : 0.46925, Sensitive_Acc : 21.600, Run Time : 16.82 sec
INFO:root:2024-04-16 11:13:14, Train, Epoch : 1, Step : 300, Loss : 0.53783, Acc : 0.719, Sensitive_Loss : 0.41414, Sensitive_Acc : 19.000, Run Time : 17.63 sec
INFO:root:2024-04-16 11:17:05, Dev, Step : 300, Loss : 0.63647, Acc : 0.708, Auc : 0.786, Sensitive_Loss : 0.37932, Sensitive_Acc : 19.992, Sensitive_Auc : 0.935, Mean auc: 0.786, Run Time : 231.33 sec
INFO:root:2024-04-16 11:17:06, Best, Step : 300, Loss : 0.63647, Acc : 0.708, Auc : 0.786, Sensitive_Loss : 0.37932, Sensitive_Acc : 19.992, Sensitive_Auc : 0.935, Best Auc : 0.786
INFO:root:2024-04-16 11:17:19, Train, Epoch : 1, Step : 310, Loss : 0.57123, Acc : 0.709, Sensitive_Loss : 0.36706, Sensitive_Acc : 24.400, Run Time : 244.79 sec
INFO:root:2024-04-16 11:17:37, Train, Epoch : 1, Step : 320, Loss : 0.56072, Acc : 0.725, Sensitive_Loss : 0.39914, Sensitive_Acc : 22.600, Run Time : 18.23 sec
INFO:root:2024-04-16 11:17:54, Train, Epoch : 1, Step : 330, Loss : 0.57391, Acc : 0.709, Sensitive_Loss : 0.34062, Sensitive_Acc : 26.000, Run Time : 16.73 sec
INFO:root:2024-04-16 11:18:12, Train, Epoch : 1, Step : 340, Loss : 0.56750, Acc : 0.700, Sensitive_Loss : 0.34546, Sensitive_Acc : 20.000, Run Time : 17.95 sec
INFO:root:2024-04-16 11:18:28, Train, Epoch : 1, Step : 350, Loss : 0.54871, Acc : 0.709, Sensitive_Loss : 0.36498, Sensitive_Acc : 19.500, Run Time : 16.30 sec
INFO:root:2024-04-16 11:18:45, Train, Epoch : 1, Step : 360, Loss : 0.58234, Acc : 0.700, Sensitive_Loss : 0.37907, Sensitive_Acc : 18.200, Run Time : 17.09 sec
INFO:root:2024-04-16 11:19:03, Train, Epoch : 1, Step : 370, Loss : 0.58197, Acc : 0.734, Sensitive_Loss : 0.36684, Sensitive_Acc : 20.200, Run Time : 18.29 sec
INFO:root:2024-04-16 11:19:20, Train, Epoch : 1, Step : 380, Loss : 0.54183, Acc : 0.694, Sensitive_Loss : 0.31694, Sensitive_Acc : 19.300, Run Time : 17.04 sec
INFO:root:2024-04-16 11:19:38, Train, Epoch : 1, Step : 390, Loss : 0.62779, Acc : 0.744, Sensitive_Loss : 0.43218, Sensitive_Acc : 22.600, Run Time : 17.36 sec
INFO:root:2024-04-16 11:19:55, Train, Epoch : 1, Step : 400, Loss : 0.57131, Acc : 0.716, Sensitive_Loss : 0.38105, Sensitive_Acc : 20.800, Run Time : 17.80 sec
INFO:root:2024-04-16 11:23:53, Dev, Step : 400, Loss : 0.58645, Acc : 0.722, Auc : 0.790, Sensitive_Loss : 0.38291, Sensitive_Acc : 19.211, Sensitive_Auc : 0.960, Mean auc: 0.790, Run Time : 237.63 sec
INFO:root:2024-04-16 11:23:54, Best, Step : 400, Loss : 0.58645, Acc : 0.722, Auc : 0.790, Sensitive_Loss : 0.38291, Sensitive_Acc : 19.211, Sensitive_Auc : 0.960, Best Auc : 0.790
INFO:root:2024-04-16 11:24:06, Train, Epoch : 1, Step : 410, Loss : 0.52092, Acc : 0.716, Sensitive_Loss : 0.41233, Sensitive_Acc : 23.900, Run Time : 250.22 sec
INFO:root:2024-04-16 11:24:23, Train, Epoch : 1, Step : 420, Loss : 0.59717, Acc : 0.722, Sensitive_Loss : 0.33209, Sensitive_Acc : 17.800, Run Time : 17.03 sec
INFO:root:2024-04-16 11:24:41, Train, Epoch : 1, Step : 430, Loss : 0.58348, Acc : 0.697, Sensitive_Loss : 0.31332, Sensitive_Acc : 21.100, Run Time : 18.38 sec
INFO:root:2024-04-16 11:24:58, Train, Epoch : 1, Step : 440, Loss : 0.50822, Acc : 0.734, Sensitive_Loss : 0.30082, Sensitive_Acc : 21.300, Run Time : 17.17 sec
INFO:root:2024-04-16 11:25:16, Train, Epoch : 1, Step : 450, Loss : 0.60413, Acc : 0.722, Sensitive_Loss : 0.39304, Sensitive_Acc : 16.800, Run Time : 17.51 sec
INFO:root:2024-04-16 11:25:33, Train, Epoch : 1, Step : 460, Loss : 0.57028, Acc : 0.722, Sensitive_Loss : 0.32445, Sensitive_Acc : 25.100, Run Time : 17.39 sec
INFO:root:2024-04-16 11:25:50, Train, Epoch : 1, Step : 470, Loss : 0.56928, Acc : 0.703, Sensitive_Loss : 0.32133, Sensitive_Acc : 19.500, Run Time : 17.22 sec
INFO:root:2024-04-16 11:26:09, Train, Epoch : 1, Step : 480, Loss : 0.64590, Acc : 0.694, Sensitive_Loss : 0.27722, Sensitive_Acc : 19.400, Run Time : 18.69 sec
INFO:root:2024-04-16 11:26:28, Train, Epoch : 1, Step : 490, Loss : 0.60705, Acc : 0.650, Sensitive_Loss : 0.35704, Sensitive_Acc : 23.900, Run Time : 18.86 sec
INFO:root:2024-04-16 11:26:47, Train, Epoch : 1, Step : 500, Loss : 0.63666, Acc : 0.709, Sensitive_Loss : 0.33525, Sensitive_Acc : 19.900, Run Time : 19.00 sec
INFO:root:2024-04-16 11:30:42, Dev, Step : 500, Loss : 0.60219, Acc : 0.697, Auc : 0.796, Sensitive_Loss : 0.31034, Sensitive_Acc : 21.030, Sensitive_Auc : 0.971, Mean auc: 0.796, Run Time : 234.64 sec
INFO:root:2024-04-16 11:30:43, Best, Step : 500, Loss : 0.60219, Acc : 0.697, Auc : 0.796, Sensitive_Loss : 0.31034, Sensitive_Acc : 21.030, Sensitive_Auc : 0.971, Best Auc : 0.796
INFO:root:2024-04-16 11:30:55, Train, Epoch : 1, Step : 510, Loss : 0.60717, Acc : 0.659, Sensitive_Loss : 0.30414, Sensitive_Acc : 15.800, Run Time : 248.17 sec
INFO:root:2024-04-16 11:31:13, Train, Epoch : 1, Step : 520, Loss : 0.57959, Acc : 0.719, Sensitive_Loss : 0.41392, Sensitive_Acc : 16.300, Run Time : 18.12 sec
INFO:root:2024-04-16 11:31:30, Train, Epoch : 1, Step : 530, Loss : 0.65848, Acc : 0.694, Sensitive_Loss : 0.33788, Sensitive_Acc : 19.900, Run Time : 17.14 sec
INFO:root:2024-04-16 11:31:48, Train, Epoch : 1, Step : 540, Loss : 0.58802, Acc : 0.738, Sensitive_Loss : 0.32642, Sensitive_Acc : 19.000, Run Time : 18.03 sec
INFO:root:2024-04-16 11:32:07, Train, Epoch : 1, Step : 550, Loss : 0.55322, Acc : 0.709, Sensitive_Loss : 0.27628, Sensitive_Acc : 18.900, Run Time : 18.08 sec
INFO:root:2024-04-16 11:32:27, Train, Epoch : 1, Step : 560, Loss : 0.60233, Acc : 0.719, Sensitive_Loss : 0.32617, Sensitive_Acc : 19.700, Run Time : 20.71 sec
INFO:root:2024-04-16 11:32:45, Train, Epoch : 1, Step : 570, Loss : 0.49567, Acc : 0.734, Sensitive_Loss : 0.35231, Sensitive_Acc : 21.600, Run Time : 17.47 sec
INFO:root:2024-04-16 11:33:05, Train, Epoch : 1, Step : 580, Loss : 0.53389, Acc : 0.747, Sensitive_Loss : 0.36923, Sensitive_Acc : 19.300, Run Time : 19.82 sec
INFO:root:2024-04-16 11:33:25, Train, Epoch : 1, Step : 590, Loss : 0.61000, Acc : 0.719, Sensitive_Loss : 0.37294, Sensitive_Acc : 26.500, Run Time : 20.29 sec
INFO:root:2024-04-16 11:33:42, Train, Epoch : 1, Step : 600, Loss : 0.60286, Acc : 0.688, Sensitive_Loss : 0.33051, Sensitive_Acc : 21.400, Run Time : 16.82 sec
INFO:root:2024-04-16 11:37:45, Dev, Step : 600, Loss : 0.59889, Acc : 0.725, Auc : 0.811, Sensitive_Loss : 0.26337, Sensitive_Acc : 21.120, Sensitive_Auc : 0.969, Mean auc: 0.811, Run Time : 243.23 sec
INFO:root:2024-04-16 11:37:46, Best, Step : 600, Loss : 0.59889, Acc : 0.725, Auc : 0.811, Sensitive_Loss : 0.26337, Sensitive_Acc : 21.120, Sensitive_Auc : 0.969, Best Auc : 0.811
INFO:root:2024-04-16 11:37:58, Train, Epoch : 1, Step : 610, Loss : 0.54566, Acc : 0.706, Sensitive_Loss : 0.23448, Sensitive_Acc : 21.900, Run Time : 256.63 sec
INFO:root:2024-04-16 11:38:15, Train, Epoch : 1, Step : 620, Loss : 0.53028, Acc : 0.725, Sensitive_Loss : 0.25695, Sensitive_Acc : 18.800, Run Time : 17.21 sec
INFO:root:2024-04-16 11:38:35, Train, Epoch : 1, Step : 630, Loss : 0.59304, Acc : 0.741, Sensitive_Loss : 0.23463, Sensitive_Acc : 23.200, Run Time : 19.40 sec
INFO:root:2024-04-16 11:42:46
INFO:root:y_pred: [0.21174578 0.1627872  0.58399683 ... 0.30924878 0.33980742 0.26455098]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [2.85326096e-04 2.75692344e-02 1.24581754e-01 6.67172819e-02
 4.65542562e-02 1.81630105e-02 3.90950358e-03 2.42285989e-02
 3.23809624e-01 9.89445031e-01 6.43104255e-01 2.57250946e-03
 1.13678977e-01 1.83484738e-03 9.98362601e-01 2.06399690e-02
 7.75520923e-03 9.93361950e-01 9.98025894e-01 4.98427451e-03
 9.74794626e-01 2.77910591e-03 6.05011582e-01 3.09610404e-02
 1.03042647e-01 4.76447552e-01 1.16030243e-03 2.17145607e-02
 1.12852280e-03 2.16648970e-02 3.68475825e-01 9.91415441e-01
 6.87844306e-02 9.07355011e-01 1.26402336e-03 2.24911910e-03
 3.83047312e-02 4.52526480e-01 2.92277694e-01 9.43447798e-02
 2.27530047e-01 9.14024830e-01 9.70507115e-02 5.42697422e-02
 9.80089664e-01 6.46640360e-01 8.89374018e-01 3.21363986e-01
 4.75759566e-01 9.95332658e-01 6.26078010e-01 9.95007277e-01
 9.86408234e-01 2.09478531e-02 1.14953935e-01 6.25515223e-01
 2.21514061e-01 1.53232459e-02 9.88743424e-01 2.69683916e-03
 1.89597509e-03 1.44956261e-03 1.19879171e-02 4.12010268e-04
 9.84721124e-01 4.26928550e-02 2.58278887e-04 8.52666050e-02
 6.99070767e-02 9.19543803e-01 9.98768985e-01 9.97426689e-01
 2.01830477e-03 2.79598176e-01 7.28848390e-04 6.62623465e-01
 1.21948510e-01 1.90439459e-04 5.84407337e-03 1.09160494e-03
 1.96944419e-02 1.43498387e-02 9.80966687e-01 9.92939711e-01
 1.45856692e-02 1.26536950e-01 1.10102221e-01 2.22423766e-02
 1.52954325e-01 2.14437377e-02 7.63241248e-03 8.70875835e-01
 3.75550968e-04 9.68286826e-04 3.41578573e-01 1.23203946e-02
 1.93277316e-03 2.08199471e-01 1.19635044e-02 8.17224383e-02
 1.40705397e-02 4.61940736e-01 1.15529425e-01 1.01356488e-02
 6.86757937e-02 4.38031275e-03 6.07091069e-01 5.17090380e-01
 4.89384145e-01 5.60741425e-01 2.45850242e-04 9.99476254e-01
 9.96911347e-01 3.28700495e-04 2.56136179e-01 6.57161534e-01
 3.20083290e-01 2.60937680e-03 8.72255936e-02 7.79714109e-03
 2.65933424e-02 6.00841377e-05 7.11181248e-03 8.69338750e-04
 3.23698781e-02 9.55570340e-01 2.02537072e-03 9.94370162e-01
 2.36665890e-01 2.09314093e-01 2.12864019e-02 1.73337013e-01
 2.74385908e-03]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-16 11:42:46, Dev, Step : 634, Loss : 0.57422, Acc : 0.725, Auc : 0.808, Sensitive_Loss : 0.27988, Sensitive_Acc : 20.489, Sensitive_Auc : 0.985, Mean auc: 0.808, Run Time : 245.00 sec
INFO:root:2024-04-16 11:43:00, Train, Epoch : 2, Step : 640, Loss : 0.36087, Acc : 0.431, Sensitive_Loss : 0.15221, Sensitive_Acc : 15.200, Run Time : 12.60 sec
INFO:root:2024-04-16 11:43:18, Train, Epoch : 2, Step : 650, Loss : 0.56869, Acc : 0.728, Sensitive_Loss : 0.25830, Sensitive_Acc : 23.800, Run Time : 18.51 sec
INFO:root:2024-04-16 11:43:35, Train, Epoch : 2, Step : 660, Loss : 0.59571, Acc : 0.731, Sensitive_Loss : 0.23985, Sensitive_Acc : 22.900, Run Time : 17.20 sec
INFO:root:2024-04-16 11:43:54, Train, Epoch : 2, Step : 670, Loss : 0.53722, Acc : 0.778, Sensitive_Loss : 0.31317, Sensitive_Acc : 19.800, Run Time : 18.84 sec
INFO:root:2024-04-16 11:44:11, Train, Epoch : 2, Step : 680, Loss : 0.43106, Acc : 0.800, Sensitive_Loss : 0.21732, Sensitive_Acc : 21.200, Run Time : 17.21 sec
INFO:root:2024-04-16 11:44:28, Train, Epoch : 2, Step : 690, Loss : 0.51692, Acc : 0.778, Sensitive_Loss : 0.25540, Sensitive_Acc : 24.700, Run Time : 16.64 sec
INFO:root:2024-04-16 11:44:47, Train, Epoch : 2, Step : 700, Loss : 0.60121, Acc : 0.734, Sensitive_Loss : 0.21822, Sensitive_Acc : 22.600, Run Time : 18.79 sec
INFO:root:2024-04-16 11:48:51, Dev, Step : 700, Loss : 0.67166, Acc : 0.684, Auc : 0.815, Sensitive_Loss : 0.26649, Sensitive_Acc : 21.511, Sensitive_Auc : 0.996, Mean auc: 0.815, Run Time : 243.68 sec
INFO:root:2024-04-16 11:48:51, Best, Step : 700, Loss : 0.67166, Acc : 0.684, Auc : 0.815, Sensitive_Loss : 0.26649, Sensitive_Acc : 21.511, Sensitive_Auc : 0.996, Best Auc : 0.815
INFO:root:2024-04-16 11:49:04, Train, Epoch : 2, Step : 710, Loss : 0.48997, Acc : 0.750, Sensitive_Loss : 0.27045, Sensitive_Acc : 23.500, Run Time : 257.01 sec
INFO:root:2024-04-16 11:49:22, Train, Epoch : 2, Step : 720, Loss : 0.51803, Acc : 0.766, Sensitive_Loss : 0.26450, Sensitive_Acc : 24.000, Run Time : 18.01 sec
INFO:root:2024-04-16 11:49:39, Train, Epoch : 2, Step : 730, Loss : 0.48717, Acc : 0.753, Sensitive_Loss : 0.21955, Sensitive_Acc : 20.600, Run Time : 16.96 sec
INFO:root:2024-04-16 11:49:57, Train, Epoch : 2, Step : 740, Loss : 0.50170, Acc : 0.781, Sensitive_Loss : 0.26552, Sensitive_Acc : 23.700, Run Time : 18.06 sec
INFO:root:2024-04-16 11:50:14, Train, Epoch : 2, Step : 750, Loss : 0.48806, Acc : 0.753, Sensitive_Loss : 0.28966, Sensitive_Acc : 27.100, Run Time : 17.50 sec
INFO:root:2024-04-16 11:50:37, Train, Epoch : 2, Step : 760, Loss : 0.52092, Acc : 0.769, Sensitive_Loss : 0.26969, Sensitive_Acc : 25.000, Run Time : 22.50 sec
INFO:root:2024-04-16 11:50:55, Train, Epoch : 2, Step : 770, Loss : 0.54090, Acc : 0.753, Sensitive_Loss : 0.42053, Sensitive_Acc : 18.500, Run Time : 17.73 sec
INFO:root:2024-04-16 11:51:18, Train, Epoch : 2, Step : 780, Loss : 0.58096, Acc : 0.747, Sensitive_Loss : 0.24746, Sensitive_Acc : 19.500, Run Time : 22.95 sec
INFO:root:2024-04-16 11:51:37, Train, Epoch : 2, Step : 790, Loss : 0.53317, Acc : 0.722, Sensitive_Loss : 0.35641, Sensitive_Acc : 20.500, Run Time : 19.80 sec
INFO:root:2024-04-16 11:51:54, Train, Epoch : 2, Step : 800, Loss : 0.55618, Acc : 0.725, Sensitive_Loss : 0.32035, Sensitive_Acc : 18.600, Run Time : 16.89 sec
INFO:root:2024-04-16 11:55:52, Dev, Step : 800, Loss : 0.57870, Acc : 0.743, Auc : 0.811, Sensitive_Loss : 0.41619, Sensitive_Acc : 19.150, Sensitive_Auc : 0.990, Mean auc: 0.811, Run Time : 238.13 sec
INFO:root:2024-04-16 11:56:06, Train, Epoch : 2, Step : 810, Loss : 0.53719, Acc : 0.775, Sensitive_Loss : 0.24949, Sensitive_Acc : 19.600, Run Time : 251.58 sec
INFO:root:2024-04-16 11:56:25, Train, Epoch : 2, Step : 820, Loss : 0.55073, Acc : 0.756, Sensitive_Loss : 0.27710, Sensitive_Acc : 21.800, Run Time : 18.84 sec
INFO:root:2024-04-16 11:56:43, Train, Epoch : 2, Step : 830, Loss : 0.47078, Acc : 0.769, Sensitive_Loss : 0.24891, Sensitive_Acc : 24.200, Run Time : 18.47 sec
INFO:root:2024-04-16 11:57:00, Train, Epoch : 2, Step : 840, Loss : 0.58355, Acc : 0.728, Sensitive_Loss : 0.27695, Sensitive_Acc : 18.100, Run Time : 16.91 sec
INFO:root:2024-04-16 11:57:19, Train, Epoch : 2, Step : 850, Loss : 0.55021, Acc : 0.772, Sensitive_Loss : 0.28976, Sensitive_Acc : 23.800, Run Time : 18.64 sec
INFO:root:2024-04-16 11:57:38, Train, Epoch : 2, Step : 860, Loss : 0.49291, Acc : 0.734, Sensitive_Loss : 0.32850, Sensitive_Acc : 20.400, Run Time : 19.55 sec
INFO:root:2024-04-16 11:58:01, Train, Epoch : 2, Step : 870, Loss : 0.51335, Acc : 0.756, Sensitive_Loss : 0.22000, Sensitive_Acc : 20.000, Run Time : 22.87 sec
INFO:root:2024-04-16 11:58:17, Train, Epoch : 2, Step : 880, Loss : 0.53828, Acc : 0.753, Sensitive_Loss : 0.25343, Sensitive_Acc : 21.700, Run Time : 16.23 sec
INFO:root:2024-04-16 11:58:35, Train, Epoch : 2, Step : 890, Loss : 0.53389, Acc : 0.744, Sensitive_Loss : 0.19302, Sensitive_Acc : 17.600, Run Time : 17.85 sec
INFO:root:2024-04-16 11:58:52, Train, Epoch : 2, Step : 900, Loss : 0.55123, Acc : 0.734, Sensitive_Loss : 0.25970, Sensitive_Acc : 22.100, Run Time : 17.19 sec
INFO:root:2024-04-16 12:02:57, Dev, Step : 900, Loss : 0.60279, Acc : 0.731, Auc : 0.814, Sensitive_Loss : 0.26257, Sensitive_Acc : 21.632, Sensitive_Auc : 0.994, Mean auc: 0.814, Run Time : 244.39 sec
INFO:root:2024-04-16 12:03:11, Train, Epoch : 2, Step : 910, Loss : 0.53926, Acc : 0.713, Sensitive_Loss : 0.25760, Sensitive_Acc : 19.600, Run Time : 258.47 sec
INFO:root:2024-04-16 12:03:28, Train, Epoch : 2, Step : 920, Loss : 0.53009, Acc : 0.734, Sensitive_Loss : 0.31147, Sensitive_Acc : 22.200, Run Time : 17.49 sec
INFO:root:2024-04-16 12:03:46, Train, Epoch : 2, Step : 930, Loss : 0.50913, Acc : 0.772, Sensitive_Loss : 0.21439, Sensitive_Acc : 21.200, Run Time : 17.21 sec
INFO:root:2024-04-16 12:04:05, Train, Epoch : 2, Step : 940, Loss : 0.54387, Acc : 0.759, Sensitive_Loss : 0.23490, Sensitive_Acc : 20.400, Run Time : 19.38 sec
INFO:root:2024-04-16 12:04:22, Train, Epoch : 2, Step : 950, Loss : 0.65532, Acc : 0.697, Sensitive_Loss : 0.19218, Sensitive_Acc : 23.600, Run Time : 17.50 sec
INFO:root:2024-04-16 12:04:41, Train, Epoch : 2, Step : 960, Loss : 0.53105, Acc : 0.750, Sensitive_Loss : 0.24535, Sensitive_Acc : 21.100, Run Time : 18.56 sec
INFO:root:2024-04-16 12:04:59, Train, Epoch : 2, Step : 970, Loss : 0.55463, Acc : 0.750, Sensitive_Loss : 0.21603, Sensitive_Acc : 25.700, Run Time : 18.04 sec
INFO:root:2024-04-16 12:05:16, Train, Epoch : 2, Step : 980, Loss : 0.54006, Acc : 0.709, Sensitive_Loss : 0.24499, Sensitive_Acc : 22.100, Run Time : 16.75 sec
INFO:root:2024-04-16 12:05:33, Train, Epoch : 2, Step : 990, Loss : 0.55117, Acc : 0.731, Sensitive_Loss : 0.16511, Sensitive_Acc : 15.900, Run Time : 17.57 sec
INFO:root:2024-04-16 12:05:50, Train, Epoch : 2, Step : 1000, Loss : 0.52331, Acc : 0.759, Sensitive_Loss : 0.33591, Sensitive_Acc : 17.900, Run Time : 16.24 sec
INFO:root:2024-04-16 12:09:55, Dev, Step : 1000, Loss : 0.54819, Acc : 0.740, Auc : 0.821, Sensitive_Loss : 0.31207, Sensitive_Acc : 22.203, Sensitive_Auc : 0.977, Mean auc: 0.821, Run Time : 245.91 sec
INFO:root:2024-04-16 12:09:57, Best, Step : 1000, Loss : 0.54819, Acc : 0.740, Auc : 0.821, Sensitive_Loss : 0.31207, Sensitive_Acc : 22.203, Sensitive_Auc : 0.977, Best Auc : 0.821
INFO:root:2024-04-16 12:10:10, Train, Epoch : 2, Step : 1010, Loss : 0.62560, Acc : 0.731, Sensitive_Loss : 0.27237, Sensitive_Acc : 20.000, Run Time : 259.96 sec
INFO:root:2024-04-16 12:10:27, Train, Epoch : 2, Step : 1020, Loss : 0.50631, Acc : 0.734, Sensitive_Loss : 0.20001, Sensitive_Acc : 20.000, Run Time : 17.72 sec
INFO:root:2024-04-16 12:10:45, Train, Epoch : 2, Step : 1030, Loss : 0.51560, Acc : 0.759, Sensitive_Loss : 0.23421, Sensitive_Acc : 17.300, Run Time : 17.71 sec
INFO:root:2024-04-16 12:11:04, Train, Epoch : 2, Step : 1040, Loss : 0.56664, Acc : 0.728, Sensitive_Loss : 0.24287, Sensitive_Acc : 17.800, Run Time : 18.84 sec
INFO:root:2024-04-16 12:11:20, Train, Epoch : 2, Step : 1050, Loss : 0.56083, Acc : 0.750, Sensitive_Loss : 0.26006, Sensitive_Acc : 20.700, Run Time : 16.35 sec
INFO:root:2024-04-16 12:11:39, Train, Epoch : 2, Step : 1060, Loss : 0.45594, Acc : 0.747, Sensitive_Loss : 0.24765, Sensitive_Acc : 22.800, Run Time : 19.19 sec
INFO:root:2024-04-16 12:11:56, Train, Epoch : 2, Step : 1070, Loss : 0.49702, Acc : 0.772, Sensitive_Loss : 0.30531, Sensitive_Acc : 24.400, Run Time : 16.72 sec
INFO:root:2024-04-16 12:12:15, Train, Epoch : 2, Step : 1080, Loss : 0.62625, Acc : 0.706, Sensitive_Loss : 0.22495, Sensitive_Acc : 18.000, Run Time : 18.74 sec
INFO:root:2024-04-16 12:12:33, Train, Epoch : 2, Step : 1090, Loss : 0.51779, Acc : 0.753, Sensitive_Loss : 0.12250, Sensitive_Acc : 25.400, Run Time : 17.74 sec
INFO:root:2024-04-16 12:12:52, Train, Epoch : 2, Step : 1100, Loss : 0.52452, Acc : 0.762, Sensitive_Loss : 0.15597, Sensitive_Acc : 20.000, Run Time : 19.22 sec
INFO:root:2024-04-16 12:16:51, Dev, Step : 1100, Loss : 0.64326, Acc : 0.711, Auc : 0.828, Sensitive_Loss : 0.21988, Sensitive_Acc : 21.872, Sensitive_Auc : 0.985, Mean auc: 0.828, Run Time : 239.14 sec
INFO:root:2024-04-16 12:16:52, Best, Step : 1100, Loss : 0.64326, Acc : 0.711, Auc : 0.828, Sensitive_Loss : 0.21988, Sensitive_Acc : 21.872, Sensitive_Auc : 0.985, Best Auc : 0.828
INFO:root:2024-04-16 12:17:04, Train, Epoch : 2, Step : 1110, Loss : 0.54805, Acc : 0.734, Sensitive_Loss : 0.19552, Sensitive_Acc : 20.700, Run Time : 252.36 sec
INFO:root:2024-04-16 12:17:22, Train, Epoch : 2, Step : 1120, Loss : 0.44953, Acc : 0.753, Sensitive_Loss : 0.20597, Sensitive_Acc : 21.400, Run Time : 17.66 sec
INFO:root:2024-04-16 12:17:39, Train, Epoch : 2, Step : 1130, Loss : 0.52883, Acc : 0.731, Sensitive_Loss : 0.15170, Sensitive_Acc : 17.200, Run Time : 17.06 sec
INFO:root:2024-04-16 12:17:58, Train, Epoch : 2, Step : 1140, Loss : 0.51285, Acc : 0.778, Sensitive_Loss : 0.21180, Sensitive_Acc : 21.800, Run Time : 18.49 sec
INFO:root:2024-04-16 12:18:14, Train, Epoch : 2, Step : 1150, Loss : 0.50805, Acc : 0.791, Sensitive_Loss : 0.22586, Sensitive_Acc : 18.800, Run Time : 16.75 sec
INFO:root:2024-04-16 12:18:31, Train, Epoch : 2, Step : 1160, Loss : 0.50154, Acc : 0.731, Sensitive_Loss : 0.19416, Sensitive_Acc : 24.400, Run Time : 17.02 sec
INFO:root:2024-04-16 12:18:53, Train, Epoch : 2, Step : 1170, Loss : 0.44611, Acc : 0.812, Sensitive_Loss : 0.20170, Sensitive_Acc : 22.300, Run Time : 22.01 sec
INFO:root:2024-04-16 12:19:11, Train, Epoch : 2, Step : 1180, Loss : 0.52558, Acc : 0.766, Sensitive_Loss : 0.23538, Sensitive_Acc : 20.800, Run Time : 17.86 sec
INFO:root:2024-04-16 12:19:29, Train, Epoch : 2, Step : 1190, Loss : 0.56837, Acc : 0.722, Sensitive_Loss : 0.16314, Sensitive_Acc : 21.500, Run Time : 17.96 sec
INFO:root:2024-04-16 12:19:48, Train, Epoch : 2, Step : 1200, Loss : 0.57316, Acc : 0.700, Sensitive_Loss : 0.16557, Sensitive_Acc : 25.900, Run Time : 18.67 sec
INFO:root:2024-04-16 12:23:50, Dev, Step : 1200, Loss : 0.56370, Acc : 0.734, Auc : 0.809, Sensitive_Loss : 0.29228, Sensitive_Acc : 21.105, Sensitive_Auc : 0.979, Mean auc: 0.809, Run Time : 242.04 sec
INFO:root:2024-04-16 12:24:03, Train, Epoch : 2, Step : 1210, Loss : 0.50351, Acc : 0.778, Sensitive_Loss : 0.16050, Sensitive_Acc : 22.900, Run Time : 255.10 sec
INFO:root:2024-04-16 12:24:20, Train, Epoch : 2, Step : 1220, Loss : 0.53022, Acc : 0.759, Sensitive_Loss : 0.19985, Sensitive_Acc : 23.000, Run Time : 17.58 sec
INFO:root:2024-04-16 12:24:40, Train, Epoch : 2, Step : 1230, Loss : 0.56716, Acc : 0.719, Sensitive_Loss : 0.19457, Sensitive_Acc : 19.600, Run Time : 19.22 sec
INFO:root:2024-04-16 12:25:03, Train, Epoch : 2, Step : 1240, Loss : 0.54307, Acc : 0.728, Sensitive_Loss : 0.18552, Sensitive_Acc : 15.400, Run Time : 22.92 sec
INFO:root:2024-04-16 12:25:25, Train, Epoch : 2, Step : 1250, Loss : 0.53377, Acc : 0.725, Sensitive_Loss : 0.14502, Sensitive_Acc : 23.700, Run Time : 22.17 sec
INFO:root:2024-04-16 12:25:44, Train, Epoch : 2, Step : 1260, Loss : 0.44184, Acc : 0.753, Sensitive_Loss : 0.23232, Sensitive_Acc : 18.700, Run Time : 19.02 sec
INFO:root:2024-04-16 12:29:51
INFO:root:y_pred: [0.15855505 0.02217717 0.16299023 ... 0.40242404 0.13329211 0.14286608]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [4.4488353e-03 3.0027747e-02 2.6716986e-01 2.4392363e-01 2.8118262e-01
 2.8065918e-03 2.5104424e-01 1.4868986e-02 1.6789450e-01 9.9998546e-01
 5.1358753e-01 2.2189345e-03 1.4029058e-03 4.8510204e-03 9.9976236e-01
 4.4551957e-01 4.3092656e-01 9.9980730e-01 9.9995065e-01 1.4784780e-03
 9.5823735e-01 1.0442376e-02 1.2476010e-02 6.5151908e-02 8.1893873e-01
 4.3108840e-02 1.0092859e-03 1.3115573e-02 2.1695069e-03 3.3338614e-02
 1.6890474e-01 9.9768388e-01 7.3788166e-02 9.5924366e-01 7.0203268e-03
 2.0589646e-04 3.8346837e-03 4.0107825e-01 9.0559047e-01 2.7168632e-01
 6.8627395e-02 9.9518859e-01 8.5250139e-02 2.5030255e-01 9.7384024e-01
 2.2459555e-01 8.8452071e-01 6.2839156e-01 3.3136159e-01 9.9903893e-01
 9.3660522e-01 9.9957854e-01 9.9905020e-01 1.5606857e-03 7.7372271e-01
 2.6413187e-02 2.3042090e-02 3.5856473e-01 9.9960774e-01 5.3893346e-02
 1.6112614e-04 1.6681603e-03 9.5337667e-03 6.4206199e-04 9.9955767e-01
 7.3580825e-01 4.6108628e-04 8.9137965e-01 1.7709867e-03 9.9015421e-01
 9.9988067e-01 9.9980420e-01 2.2473834e-02 7.5378972e-01 2.5519875e-03
 8.7654358e-01 1.2903988e-01 3.1022044e-04 3.8068409e-03 1.8640947e-02
 2.7469596e-02 3.9787445e-02 9.9826860e-01 9.9782467e-01 1.7429383e-02
 4.3022358e-01 7.8753108e-01 1.9129744e-03 1.2211249e-02 4.8811142e-03
 4.3414542e-03 2.9620150e-01 3.2184838e-04 3.1585642e-04 5.4559344e-01
 3.0724466e-02 1.0678356e-03 6.0577530e-01 5.6683101e-02 1.1585208e-01
 1.7553436e-03 5.1550761e-02 2.7678180e-01 4.4579385e-03 9.2517566e-03
 5.9979358e-03 2.8914690e-02 2.6827642e-01 4.9177003e-01 1.9568210e-02
 1.0792130e-03 9.9999464e-01 9.9844849e-01 6.4616627e-04 8.9597011e-01
 8.5384913e-02 1.7390961e-02 1.5229117e-03 2.8484881e-01 2.3519723e-02
 8.2296364e-02 1.3869352e-04 4.6762362e-02 4.9933774e-04 2.3878384e-02
 9.6361327e-01 6.7664929e-05 9.9663347e-01 3.8670659e-02 3.2396862e-01
 6.4708680e-02 2.6913303e-01 2.6535423e-04]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-16 12:29:51, Dev, Step : 1268, Loss : 0.53657, Acc : 0.755, Auc : 0.832, Sensitive_Loss : 0.36134, Sensitive_Acc : 20.173, Sensitive_Auc : 0.994, Mean auc: 0.832, Run Time : 235.46 sec
INFO:root:2024-04-16 12:29:52, Best, Step : 1268, Loss : 0.53657, Acc : 0.755,Auc : 0.832, Best Auc : 0.832, Sensitive_Loss : 0.36134, Sensitive_Acc : 20.173, Sensitive_Auc : 0.994
INFO:root:2024-04-16 12:29:59, Train, Epoch : 3, Step : 1270, Loss : 0.09089, Acc : 0.144, Sensitive_Loss : 0.04479, Sensitive_Acc : 3.200, Run Time : 5.80 sec
INFO:root:2024-04-16 12:30:16, Train, Epoch : 3, Step : 1280, Loss : 0.49456, Acc : 0.803, Sensitive_Loss : 0.17520, Sensitive_Acc : 19.900, Run Time : 17.32 sec
INFO:root:2024-04-16 12:30:36, Train, Epoch : 3, Step : 1290, Loss : 0.50146, Acc : 0.772, Sensitive_Loss : 0.19075, Sensitive_Acc : 23.100, Run Time : 19.27 sec
INFO:root:2024-04-16 12:30:54, Train, Epoch : 3, Step : 1300, Loss : 0.43120, Acc : 0.784, Sensitive_Loss : 0.19812, Sensitive_Acc : 25.300, Run Time : 18.24 sec
INFO:root:2024-04-16 12:34:54, Dev, Step : 1300, Loss : 0.52910, Acc : 0.765, Auc : 0.841, Sensitive_Loss : 0.24992, Sensitive_Acc : 21.165, Sensitive_Auc : 0.994, Mean auc: 0.841, Run Time : 240.39 sec
INFO:root:2024-04-16 12:34:55, Best, Step : 1300, Loss : 0.52910, Acc : 0.765, Auc : 0.841, Sensitive_Loss : 0.24992, Sensitive_Acc : 21.165, Sensitive_Auc : 0.994, Best Auc : 0.841
INFO:root:2024-04-16 12:35:08, Train, Epoch : 3, Step : 1310, Loss : 0.47068, Acc : 0.731, Sensitive_Loss : 0.22988, Sensitive_Acc : 25.100, Run Time : 254.18 sec
INFO:root:2024-04-16 12:35:26, Train, Epoch : 3, Step : 1320, Loss : 0.41863, Acc : 0.787, Sensitive_Loss : 0.15809, Sensitive_Acc : 22.300, Run Time : 18.50 sec
INFO:root:2024-04-16 12:35:44, Train, Epoch : 3, Step : 1330, Loss : 0.46433, Acc : 0.787, Sensitive_Loss : 0.19550, Sensitive_Acc : 20.100, Run Time : 17.68 sec
INFO:root:2024-04-16 12:36:02, Train, Epoch : 3, Step : 1340, Loss : 0.46854, Acc : 0.759, Sensitive_Loss : 0.14447, Sensitive_Acc : 24.200, Run Time : 18.09 sec
INFO:root:2024-04-16 12:36:19, Train, Epoch : 3, Step : 1350, Loss : 0.55386, Acc : 0.775, Sensitive_Loss : 0.14862, Sensitive_Acc : 21.600, Run Time : 16.66 sec
INFO:root:2024-04-16 12:36:38, Train, Epoch : 3, Step : 1360, Loss : 0.42118, Acc : 0.834, Sensitive_Loss : 0.12966, Sensitive_Acc : 16.600, Run Time : 19.22 sec
INFO:root:2024-04-16 12:36:55, Train, Epoch : 3, Step : 1370, Loss : 0.51118, Acc : 0.787, Sensitive_Loss : 0.20209, Sensitive_Acc : 27.000, Run Time : 17.25 sec
INFO:root:2024-04-16 12:37:12, Train, Epoch : 3, Step : 1380, Loss : 0.43166, Acc : 0.794, Sensitive_Loss : 0.20442, Sensitive_Acc : 21.000, Run Time : 17.02 sec
INFO:root:2024-04-16 12:37:31, Train, Epoch : 3, Step : 1390, Loss : 0.41225, Acc : 0.838, Sensitive_Loss : 0.15000, Sensitive_Acc : 21.700, Run Time : 18.38 sec
INFO:root:2024-04-16 12:37:49, Train, Epoch : 3, Step : 1400, Loss : 0.46506, Acc : 0.825, Sensitive_Loss : 0.21168, Sensitive_Acc : 21.300, Run Time : 18.45 sec
INFO:root:2024-04-16 12:41:51, Dev, Step : 1400, Loss : 0.51453, Acc : 0.769, Auc : 0.847, Sensitive_Loss : 0.26085, Sensitive_Acc : 20.955, Sensitive_Auc : 0.995, Mean auc: 0.847, Run Time : 241.63 sec
INFO:root:2024-04-16 12:41:52, Best, Step : 1400, Loss : 0.51453, Acc : 0.769, Auc : 0.847, Sensitive_Loss : 0.26085, Sensitive_Acc : 20.955, Sensitive_Auc : 0.995, Best Auc : 0.847
INFO:root:2024-04-16 12:42:06, Train, Epoch : 3, Step : 1410, Loss : 0.43623, Acc : 0.803, Sensitive_Loss : 0.16279, Sensitive_Acc : 20.700, Run Time : 256.51 sec
INFO:root:2024-04-16 12:42:25, Train, Epoch : 3, Step : 1420, Loss : 0.50378, Acc : 0.778, Sensitive_Loss : 0.18783, Sensitive_Acc : 23.500, Run Time : 19.33 sec
INFO:root:2024-04-16 12:42:43, Train, Epoch : 3, Step : 1430, Loss : 0.42303, Acc : 0.806, Sensitive_Loss : 0.17359, Sensitive_Acc : 21.100, Run Time : 18.16 sec
INFO:root:2024-04-16 12:43:00, Train, Epoch : 3, Step : 1440, Loss : 0.39796, Acc : 0.825, Sensitive_Loss : 0.14399, Sensitive_Acc : 20.100, Run Time : 16.77 sec
INFO:root:2024-04-16 12:43:18, Train, Epoch : 3, Step : 1450, Loss : 0.44852, Acc : 0.781, Sensitive_Loss : 0.13917, Sensitive_Acc : 18.100, Run Time : 18.30 sec
INFO:root:2024-04-16 12:43:34, Train, Epoch : 3, Step : 1460, Loss : 0.44026, Acc : 0.838, Sensitive_Loss : 0.17196, Sensitive_Acc : 18.300, Run Time : 15.23 sec
INFO:root:2024-04-16 12:43:52, Train, Epoch : 3, Step : 1470, Loss : 0.51921, Acc : 0.766, Sensitive_Loss : 0.14252, Sensitive_Acc : 23.500, Run Time : 18.45 sec
INFO:root:2024-04-16 12:44:11, Train, Epoch : 3, Step : 1480, Loss : 0.39807, Acc : 0.816, Sensitive_Loss : 0.14470, Sensitive_Acc : 23.100, Run Time : 19.43 sec
INFO:root:2024-04-16 12:44:29, Train, Epoch : 3, Step : 1490, Loss : 0.45364, Acc : 0.794, Sensitive_Loss : 0.13454, Sensitive_Acc : 20.000, Run Time : 18.08 sec
INFO:root:2024-04-16 12:44:47, Train, Epoch : 3, Step : 1500, Loss : 0.43250, Acc : 0.791, Sensitive_Loss : 0.13550, Sensitive_Acc : 26.500, Run Time : 17.90 sec
INFO:root:2024-04-16 12:48:49, Dev, Step : 1500, Loss : 0.52836, Acc : 0.766, Auc : 0.849, Sensitive_Loss : 0.25021, Sensitive_Acc : 20.789, Sensitive_Auc : 0.992, Mean auc: 0.849, Run Time : 241.97 sec
INFO:root:2024-04-16 12:48:50, Best, Step : 1500, Loss : 0.52836, Acc : 0.766, Auc : 0.849, Sensitive_Loss : 0.25021, Sensitive_Acc : 20.789, Sensitive_Auc : 0.992, Best Auc : 0.849
INFO:root:2024-04-16 12:49:02, Train, Epoch : 3, Step : 1510, Loss : 0.49262, Acc : 0.797, Sensitive_Loss : 0.19278, Sensitive_Acc : 21.800, Run Time : 255.09 sec
INFO:root:2024-04-16 12:49:21, Train, Epoch : 3, Step : 1520, Loss : 0.47447, Acc : 0.822, Sensitive_Loss : 0.09122, Sensitive_Acc : 19.700, Run Time : 18.12 sec
INFO:root:2024-04-16 12:49:38, Train, Epoch : 3, Step : 1530, Loss : 0.44029, Acc : 0.809, Sensitive_Loss : 0.17990, Sensitive_Acc : 23.300, Run Time : 17.50 sec
INFO:root:2024-04-16 12:49:56, Train, Epoch : 3, Step : 1540, Loss : 0.45096, Acc : 0.794, Sensitive_Loss : 0.14818, Sensitive_Acc : 22.100, Run Time : 18.38 sec
INFO:root:2024-04-16 12:50:13, Train, Epoch : 3, Step : 1550, Loss : 0.39308, Acc : 0.838, Sensitive_Loss : 0.15667, Sensitive_Acc : 25.800, Run Time : 16.14 sec
INFO:root:2024-04-16 12:50:31, Train, Epoch : 3, Step : 1560, Loss : 0.47230, Acc : 0.769, Sensitive_Loss : 0.11392, Sensitive_Acc : 20.300, Run Time : 18.37 sec
INFO:root:2024-04-16 12:50:50, Train, Epoch : 3, Step : 1570, Loss : 0.47227, Acc : 0.812, Sensitive_Loss : 0.17025, Sensitive_Acc : 20.500, Run Time : 18.83 sec
INFO:root:2024-04-16 12:51:07, Train, Epoch : 3, Step : 1580, Loss : 0.42446, Acc : 0.769, Sensitive_Loss : 0.17233, Sensitive_Acc : 25.000, Run Time : 17.20 sec
INFO:root:2024-04-16 12:51:26, Train, Epoch : 3, Step : 1590, Loss : 0.48143, Acc : 0.766, Sensitive_Loss : 0.12602, Sensitive_Acc : 24.200, Run Time : 18.59 sec
INFO:root:2024-04-16 12:51:43, Train, Epoch : 3, Step : 1600, Loss : 0.40059, Acc : 0.819, Sensitive_Loss : 0.11308, Sensitive_Acc : 17.000, Run Time : 17.40 sec
INFO:root:2024-04-16 12:55:47, Dev, Step : 1600, Loss : 0.52510, Acc : 0.766, Auc : 0.847, Sensitive_Loss : 0.25557, Sensitive_Acc : 20.789, Sensitive_Auc : 0.991, Mean auc: 0.847, Run Time : 243.71 sec
INFO:root:2024-04-16 12:55:59, Train, Epoch : 3, Step : 1610, Loss : 0.39713, Acc : 0.831, Sensitive_Loss : 0.14742, Sensitive_Acc : 26.600, Run Time : 256.26 sec
INFO:root:2024-04-16 12:56:17, Train, Epoch : 3, Step : 1620, Loss : 0.42797, Acc : 0.816, Sensitive_Loss : 0.22994, Sensitive_Acc : 24.500, Run Time : 17.25 sec
INFO:root:2024-04-16 12:56:34, Train, Epoch : 3, Step : 1630, Loss : 0.48149, Acc : 0.772, Sensitive_Loss : 0.09977, Sensitive_Acc : 21.200, Run Time : 17.94 sec
INFO:root:2024-04-16 12:56:53, Train, Epoch : 3, Step : 1640, Loss : 0.54407, Acc : 0.766, Sensitive_Loss : 0.13484, Sensitive_Acc : 19.500, Run Time : 18.22 sec
INFO:root:2024-04-16 12:57:11, Train, Epoch : 3, Step : 1650, Loss : 0.47610, Acc : 0.797, Sensitive_Loss : 0.14471, Sensitive_Acc : 20.400, Run Time : 18.04 sec
INFO:root:2024-04-16 12:57:29, Train, Epoch : 3, Step : 1660, Loss : 0.39248, Acc : 0.831, Sensitive_Loss : 0.17800, Sensitive_Acc : 18.100, Run Time : 17.88 sec
INFO:root:2024-04-16 12:57:44, Train, Epoch : 3, Step : 1670, Loss : 0.43445, Acc : 0.809, Sensitive_Loss : 0.14671, Sensitive_Acc : 22.200, Run Time : 15.45 sec
INFO:root:2024-04-16 12:58:02, Train, Epoch : 3, Step : 1680, Loss : 0.35883, Acc : 0.844, Sensitive_Loss : 0.13063, Sensitive_Acc : 24.200, Run Time : 18.14 sec
INFO:root:2024-04-16 12:58:21, Train, Epoch : 3, Step : 1690, Loss : 0.45509, Acc : 0.800, Sensitive_Loss : 0.10446, Sensitive_Acc : 20.300, Run Time : 18.57 sec
INFO:root:2024-04-16 12:58:39, Train, Epoch : 3, Step : 1700, Loss : 0.40930, Acc : 0.816, Sensitive_Loss : 0.13321, Sensitive_Acc : 21.600, Run Time : 17.75 sec
INFO:root:2024-04-16 13:02:39, Dev, Step : 1700, Loss : 0.52611, Acc : 0.770, Auc : 0.850, Sensitive_Loss : 0.22203, Sensitive_Acc : 21.180, Sensitive_Auc : 0.994, Mean auc: 0.850, Run Time : 240.77 sec
INFO:root:2024-04-16 13:02:40, Best, Step : 1700, Loss : 0.52611, Acc : 0.770, Auc : 0.850, Sensitive_Loss : 0.22203, Sensitive_Acc : 21.180, Sensitive_Auc : 0.994, Best Auc : 0.850
INFO:root:2024-04-16 13:02:52, Train, Epoch : 3, Step : 1710, Loss : 0.47481, Acc : 0.797, Sensitive_Loss : 0.15259, Sensitive_Acc : 24.500, Run Time : 253.63 sec
INFO:root:2024-04-16 13:03:10, Train, Epoch : 3, Step : 1720, Loss : 0.45959, Acc : 0.787, Sensitive_Loss : 0.11112, Sensitive_Acc : 24.300, Run Time : 17.73 sec
INFO:root:2024-04-16 13:03:26, Train, Epoch : 3, Step : 1730, Loss : 0.37943, Acc : 0.847, Sensitive_Loss : 0.17524, Sensitive_Acc : 22.500, Run Time : 16.60 sec
INFO:root:2024-04-16 13:03:44, Train, Epoch : 3, Step : 1740, Loss : 0.40967, Acc : 0.784, Sensitive_Loss : 0.16496, Sensitive_Acc : 18.000, Run Time : 17.80 sec
INFO:root:2024-04-16 13:04:02, Train, Epoch : 3, Step : 1750, Loss : 0.39456, Acc : 0.834, Sensitive_Loss : 0.19341, Sensitive_Acc : 24.500, Run Time : 17.74 sec
INFO:root:2024-04-16 13:04:22, Train, Epoch : 3, Step : 1760, Loss : 0.44449, Acc : 0.828, Sensitive_Loss : 0.15306, Sensitive_Acc : 19.700, Run Time : 20.37 sec
INFO:root:2024-04-16 13:04:40, Train, Epoch : 3, Step : 1770, Loss : 0.43557, Acc : 0.791, Sensitive_Loss : 0.14858, Sensitive_Acc : 18.300, Run Time : 17.79 sec
INFO:root:2024-04-16 13:04:59, Train, Epoch : 3, Step : 1780, Loss : 0.46010, Acc : 0.794, Sensitive_Loss : 0.13085, Sensitive_Acc : 19.500, Run Time : 18.89 sec
INFO:root:2024-04-16 13:05:20, Train, Epoch : 3, Step : 1790, Loss : 0.45647, Acc : 0.797, Sensitive_Loss : 0.17531, Sensitive_Acc : 20.000, Run Time : 21.31 sec
INFO:root:2024-04-16 13:05:40, Train, Epoch : 3, Step : 1800, Loss : 0.42634, Acc : 0.816, Sensitive_Loss : 0.14505, Sensitive_Acc : 20.800, Run Time : 19.32 sec
INFO:root:2024-04-16 13:09:31, Dev, Step : 1800, Loss : 0.51562, Acc : 0.772, Auc : 0.851, Sensitive_Loss : 0.21485, Sensitive_Acc : 21.316, Sensitive_Auc : 0.993, Mean auc: 0.851, Run Time : 231.69 sec
INFO:root:2024-04-16 13:09:34, Best, Step : 1800, Loss : 0.51562, Acc : 0.772, Auc : 0.851, Sensitive_Loss : 0.21485, Sensitive_Acc : 21.316, Sensitive_Auc : 0.993, Best Auc : 0.851
INFO:root:2024-04-16 13:09:47, Train, Epoch : 3, Step : 1810, Loss : 0.39416, Acc : 0.800, Sensitive_Loss : 0.15587, Sensitive_Acc : 21.100, Run Time : 247.13 sec
INFO:root:2024-04-16 13:10:05, Train, Epoch : 3, Step : 1820, Loss : 0.45620, Acc : 0.775, Sensitive_Loss : 0.28193, Sensitive_Acc : 22.400, Run Time : 18.18 sec
INFO:root:2024-04-16 13:10:22, Train, Epoch : 3, Step : 1830, Loss : 0.41508, Acc : 0.825, Sensitive_Loss : 0.18346, Sensitive_Acc : 20.400, Run Time : 17.14 sec
INFO:root:2024-04-16 13:10:42, Train, Epoch : 3, Step : 1840, Loss : 0.53104, Acc : 0.784, Sensitive_Loss : 0.15861, Sensitive_Acc : 17.800, Run Time : 19.37 sec
INFO:root:2024-04-16 13:11:01, Train, Epoch : 3, Step : 1850, Loss : 0.41779, Acc : 0.809, Sensitive_Loss : 0.20118, Sensitive_Acc : 19.200, Run Time : 19.50 sec
INFO:root:2024-04-16 13:11:19, Train, Epoch : 3, Step : 1860, Loss : 0.44613, Acc : 0.803, Sensitive_Loss : 0.09407, Sensitive_Acc : 21.200, Run Time : 17.68 sec
INFO:root:2024-04-16 13:11:36, Train, Epoch : 3, Step : 1870, Loss : 0.48498, Acc : 0.775, Sensitive_Loss : 0.11445, Sensitive_Acc : 24.500, Run Time : 17.75 sec
INFO:root:2024-04-16 13:11:57, Train, Epoch : 3, Step : 1880, Loss : 0.41986, Acc : 0.787, Sensitive_Loss : 0.17821, Sensitive_Acc : 19.900, Run Time : 20.13 sec
INFO:root:2024-04-16 13:12:16, Train, Epoch : 3, Step : 1890, Loss : 0.43990, Acc : 0.781, Sensitive_Loss : 0.13273, Sensitive_Acc : 20.700, Run Time : 18.95 sec
INFO:root:2024-04-16 13:12:33, Train, Epoch : 3, Step : 1900, Loss : 0.48771, Acc : 0.778, Sensitive_Loss : 0.15192, Sensitive_Acc : 22.400, Run Time : 16.98 sec
INFO:root:2024-04-16 13:16:19, Dev, Step : 1900, Loss : 0.53252, Acc : 0.770, Auc : 0.853, Sensitive_Loss : 0.23033, Sensitive_Acc : 21.090, Sensitive_Auc : 0.994, Mean auc: 0.853, Run Time : 226.21 sec
INFO:root:2024-04-16 13:16:20, Best, Step : 1900, Loss : 0.53252, Acc : 0.770, Auc : 0.853, Sensitive_Loss : 0.23033, Sensitive_Acc : 21.090, Sensitive_Auc : 0.994, Best Auc : 0.853
INFO:root:2024-04-16 13:20:21
INFO:root:y_pred: [0.19358121 0.00976042 0.05918625 ... 0.09058298 0.08052506 0.0726283 ]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [3.49260110e-04 1.43716182e-03 1.01462994e-02 1.52367175e-01
 3.18344794e-02 1.47063157e-03 4.19525942e-03 4.47103847e-03
 1.53134495e-01 9.99941587e-01 2.65382260e-01 1.10909995e-03
 4.73086257e-03 5.89022355e-04 9.99465883e-01 4.60419655e-02
 3.45555507e-02 9.99696970e-01 9.99899745e-01 2.88932957e-03
 9.98458862e-01 7.19408132e-03 8.14788137e-03 2.56356900e-03
 3.47342014e-01 2.67943054e-01 1.21594043e-04 1.01271924e-03
 8.39941611e-04 5.48741873e-03 1.45322621e-01 9.86991763e-01
 1.91339944e-02 9.09626245e-01 1.62892719e-03 7.03545928e-04
 1.17164915e-02 7.00089633e-02 7.53386915e-01 1.47278696e-01
 4.30900902e-02 9.93534684e-01 1.65739860e-02 7.38600716e-02
 9.99207079e-01 4.82918732e-02 5.48203826e-01 7.23426461e-01
 1.36140317e-01 9.97850180e-01 9.86309052e-01 9.99899387e-01
 9.98343468e-01 5.69717307e-03 6.56013787e-01 1.63803160e-01
 1.35150366e-02 1.25805587e-02 9.98833358e-01 2.84643448e-03
 1.04000886e-04 1.92427239e-03 1.23557437e-03 9.14752382e-05
 9.99285519e-01 4.29212183e-01 4.82225354e-04 6.18329227e-01
 2.51355860e-02 9.95022893e-01 9.99983549e-01 9.99894857e-01
 2.02582008e-03 5.97253203e-01 9.50782967e-04 6.99238122e-01
 1.35607067e-02 4.09524546e-05 2.83615640e-03 1.02714477e-02
 4.61311191e-02 6.99253927e-04 9.99441564e-01 9.97101843e-01
 1.22152530e-02 4.70037878e-01 1.17200471e-01 3.16597754e-03
 4.98554036e-02 1.76928379e-02 9.06762725e-04 1.24511771e-01
 3.65645072e-04 1.14125112e-04 2.91922875e-02 1.06514702e-02
 1.45908829e-03 2.72319794e-01 4.24847426e-03 3.37299891e-03
 7.32661271e-03 2.05180403e-02 2.67550826e-01 4.66146180e-03
 6.46849535e-03 5.00721857e-04 4.36668210e-02 1.16840646e-01
 1.87529027e-01 8.23038165e-03 3.29027185e-04 9.99992132e-01
 9.99760807e-01 5.82947105e-05 2.90169865e-01 4.89545278e-02
 5.28931106e-03 1.38307991e-03 3.12008448e-02 1.55604107e-03
 8.97789933e-03 2.60256405e-04 1.09091960e-01 2.22840477e-04
 2.15866556e-03 9.63172376e-01 2.41386719e-04 9.95722890e-01
 4.80387621e-02 3.49641033e-02 2.69088219e-03 8.02112073e-02
 1.06172709e-04]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-16 13:20:21, Dev, Step : 1902, Loss : 0.52744, Acc : 0.769, Auc : 0.853, Sensitive_Loss : 0.23717, Sensitive_Acc : 21.090, Sensitive_Auc : 0.995, Mean auc: 0.853, Run Time : 240.38 sec
INFO:root:2024-04-16 13:20:40, Train, Epoch : 4, Step : 1910, Loss : 0.32750, Acc : 0.644, Sensitive_Loss : 0.17218, Sensitive_Acc : 18.500, Run Time : 17.48 sec
INFO:root:2024-04-16 13:20:58, Train, Epoch : 4, Step : 1920, Loss : 0.40371, Acc : 0.816, Sensitive_Loss : 0.17998, Sensitive_Acc : 20.400, Run Time : 18.43 sec
INFO:root:2024-04-16 13:21:16, Train, Epoch : 4, Step : 1930, Loss : 0.45102, Acc : 0.781, Sensitive_Loss : 0.21556, Sensitive_Acc : 23.100, Run Time : 17.94 sec
INFO:root:2024-04-16 13:21:35, Train, Epoch : 4, Step : 1940, Loss : 0.39605, Acc : 0.800, Sensitive_Loss : 0.13132, Sensitive_Acc : 22.600, Run Time : 18.93 sec
INFO:root:2024-04-16 13:21:53, Train, Epoch : 4, Step : 1950, Loss : 0.42448, Acc : 0.834, Sensitive_Loss : 0.14914, Sensitive_Acc : 22.500, Run Time : 17.55 sec
INFO:root:2024-04-16 13:22:10, Train, Epoch : 4, Step : 1960, Loss : 0.44953, Acc : 0.831, Sensitive_Loss : 0.16957, Sensitive_Acc : 21.500, Run Time : 17.77 sec
INFO:root:2024-04-16 13:22:30, Train, Epoch : 4, Step : 1970, Loss : 0.44888, Acc : 0.825, Sensitive_Loss : 0.07652, Sensitive_Acc : 15.600, Run Time : 19.80 sec
INFO:root:2024-04-16 13:22:50, Train, Epoch : 4, Step : 1980, Loss : 0.40509, Acc : 0.825, Sensitive_Loss : 0.18235, Sensitive_Acc : 19.100, Run Time : 19.35 sec
INFO:root:2024-04-16 13:23:08, Train, Epoch : 4, Step : 1990, Loss : 0.40309, Acc : 0.825, Sensitive_Loss : 0.14623, Sensitive_Acc : 20.400, Run Time : 18.09 sec
INFO:root:2024-04-16 13:23:25, Train, Epoch : 4, Step : 2000, Loss : 0.38705, Acc : 0.828, Sensitive_Loss : 0.15661, Sensitive_Acc : 13.700, Run Time : 16.86 sec
INFO:root:2024-04-16 13:27:27, Dev, Step : 2000, Loss : 0.52062, Acc : 0.773, Auc : 0.851, Sensitive_Loss : 0.22379, Sensitive_Acc : 21.406, Sensitive_Auc : 0.996, Mean auc: 0.851, Run Time : 242.83 sec
INFO:root:2024-04-16 13:27:40, Train, Epoch : 4, Step : 2010, Loss : 0.48731, Acc : 0.784, Sensitive_Loss : 0.13180, Sensitive_Acc : 20.900, Run Time : 255.50 sec
INFO:root:2024-04-16 13:27:57, Train, Epoch : 4, Step : 2020, Loss : 0.39023, Acc : 0.825, Sensitive_Loss : 0.07758, Sensitive_Acc : 17.200, Run Time : 17.27 sec
INFO:root:2024-04-16 13:28:17, Train, Epoch : 4, Step : 2030, Loss : 0.39818, Acc : 0.822, Sensitive_Loss : 0.10439, Sensitive_Acc : 22.700, Run Time : 19.88 sec
INFO:root:2024-04-16 13:28:35, Train, Epoch : 4, Step : 2040, Loss : 0.40109, Acc : 0.812, Sensitive_Loss : 0.13530, Sensitive_Acc : 21.600, Run Time : 18.12 sec
INFO:root:2024-04-16 13:28:54, Train, Epoch : 4, Step : 2050, Loss : 0.43813, Acc : 0.787, Sensitive_Loss : 0.20704, Sensitive_Acc : 25.500, Run Time : 18.41 sec
INFO:root:2024-04-16 13:29:14, Train, Epoch : 4, Step : 2060, Loss : 0.40779, Acc : 0.834, Sensitive_Loss : 0.12680, Sensitive_Acc : 23.100, Run Time : 19.91 sec
INFO:root:2024-04-16 13:29:32, Train, Epoch : 4, Step : 2070, Loss : 0.38764, Acc : 0.819, Sensitive_Loss : 0.14982, Sensitive_Acc : 21.100, Run Time : 18.64 sec
INFO:root:2024-04-16 13:29:49, Train, Epoch : 4, Step : 2080, Loss : 0.37175, Acc : 0.844, Sensitive_Loss : 0.16720, Sensitive_Acc : 21.800, Run Time : 16.62 sec
INFO:root:2024-04-16 13:30:06, Train, Epoch : 4, Step : 2090, Loss : 0.42280, Acc : 0.828, Sensitive_Loss : 0.17118, Sensitive_Acc : 25.600, Run Time : 17.23 sec
INFO:root:2024-04-16 13:30:23, Train, Epoch : 4, Step : 2100, Loss : 0.39208, Acc : 0.800, Sensitive_Loss : 0.13311, Sensitive_Acc : 25.200, Run Time : 16.47 sec
INFO:root:2024-04-16 13:34:23, Dev, Step : 2100, Loss : 0.51796, Acc : 0.774, Auc : 0.855, Sensitive_Loss : 0.20605, Sensitive_Acc : 21.541, Sensitive_Auc : 0.995, Mean auc: 0.855, Run Time : 240.60 sec
INFO:root:2024-04-16 13:34:24, Best, Step : 2100, Loss : 0.51796, Acc : 0.774, Auc : 0.855, Sensitive_Loss : 0.20605, Sensitive_Acc : 21.541, Sensitive_Auc : 0.995, Best Auc : 0.855
INFO:root:2024-04-16 13:34:37, Train, Epoch : 4, Step : 2110, Loss : 0.42890, Acc : 0.800, Sensitive_Loss : 0.12518, Sensitive_Acc : 24.800, Run Time : 254.41 sec
INFO:root:2024-04-16 13:34:55, Train, Epoch : 4, Step : 2120, Loss : 0.40330, Acc : 0.800, Sensitive_Loss : 0.08428, Sensitive_Acc : 20.100, Run Time : 17.67 sec
INFO:root:2024-04-16 13:35:13, Train, Epoch : 4, Step : 2130, Loss : 0.34072, Acc : 0.825, Sensitive_Loss : 0.20240, Sensitive_Acc : 21.700, Run Time : 17.88 sec
INFO:root:2024-04-16 13:35:32, Train, Epoch : 4, Step : 2140, Loss : 0.44446, Acc : 0.784, Sensitive_Loss : 0.17503, Sensitive_Acc : 18.000, Run Time : 19.24 sec
INFO:root:2024-04-16 13:35:50, Train, Epoch : 4, Step : 2150, Loss : 0.45220, Acc : 0.787, Sensitive_Loss : 0.08870, Sensitive_Acc : 19.800, Run Time : 18.06 sec
INFO:root:2024-04-16 13:36:09, Train, Epoch : 4, Step : 2160, Loss : 0.45203, Acc : 0.806, Sensitive_Loss : 0.20168, Sensitive_Acc : 18.000, Run Time : 18.92 sec
INFO:root:2024-04-16 13:36:26, Train, Epoch : 4, Step : 2170, Loss : 0.37705, Acc : 0.841, Sensitive_Loss : 0.15288, Sensitive_Acc : 23.600, Run Time : 17.14 sec
INFO:root:2024-04-16 13:36:44, Train, Epoch : 4, Step : 2180, Loss : 0.41164, Acc : 0.806, Sensitive_Loss : 0.15427, Sensitive_Acc : 26.100, Run Time : 17.77 sec
INFO:root:2024-04-16 13:37:01, Train, Epoch : 4, Step : 2190, Loss : 0.46957, Acc : 0.803, Sensitive_Loss : 0.13782, Sensitive_Acc : 19.300, Run Time : 17.61 sec
INFO:root:2024-04-16 13:37:20, Train, Epoch : 4, Step : 2200, Loss : 0.45232, Acc : 0.791, Sensitive_Loss : 0.11535, Sensitive_Acc : 24.600, Run Time : 19.07 sec
INFO:root:2024-04-16 13:41:22, Dev, Step : 2200, Loss : 0.54998, Acc : 0.762, Auc : 0.854, Sensitive_Loss : 0.20609, Sensitive_Acc : 21.406, Sensitive_Auc : 0.995, Mean auc: 0.854, Run Time : 241.47 sec
INFO:root:2024-04-16 13:41:34, Train, Epoch : 4, Step : 2210, Loss : 0.41764, Acc : 0.825, Sensitive_Loss : 0.14163, Sensitive_Acc : 20.400, Run Time : 253.85 sec
INFO:root:2024-04-16 13:41:52, Train, Epoch : 4, Step : 2220, Loss : 0.48691, Acc : 0.772, Sensitive_Loss : 0.18970, Sensitive_Acc : 23.300, Run Time : 18.22 sec
INFO:root:2024-04-16 13:42:09, Train, Epoch : 4, Step : 2230, Loss : 0.41975, Acc : 0.803, Sensitive_Loss : 0.11399, Sensitive_Acc : 21.600, Run Time : 16.76 sec
INFO:root:2024-04-16 13:42:30, Train, Epoch : 4, Step : 2240, Loss : 0.43877, Acc : 0.797, Sensitive_Loss : 0.12825, Sensitive_Acc : 21.000, Run Time : 20.76 sec
INFO:root:2024-04-16 13:42:49, Train, Epoch : 4, Step : 2250, Loss : 0.38860, Acc : 0.834, Sensitive_Loss : 0.09867, Sensitive_Acc : 21.600, Run Time : 19.33 sec
INFO:root:2024-04-16 13:43:08, Train, Epoch : 4, Step : 2260, Loss : 0.48827, Acc : 0.794, Sensitive_Loss : 0.11876, Sensitive_Acc : 22.100, Run Time : 18.19 sec
INFO:root:2024-04-16 13:43:25, Train, Epoch : 4, Step : 2270, Loss : 0.42912, Acc : 0.794, Sensitive_Loss : 0.07035, Sensitive_Acc : 19.900, Run Time : 17.40 sec
INFO:root:2024-04-16 13:43:45, Train, Epoch : 4, Step : 2280, Loss : 0.41617, Acc : 0.800, Sensitive_Loss : 0.08189, Sensitive_Acc : 24.000, Run Time : 19.86 sec
INFO:root:2024-04-16 13:44:03, Train, Epoch : 4, Step : 2290, Loss : 0.44685, Acc : 0.825, Sensitive_Loss : 0.10657, Sensitive_Acc : 22.500, Run Time : 17.71 sec
INFO:root:2024-04-16 13:44:19, Train, Epoch : 4, Step : 2300, Loss : 0.40418, Acc : 0.822, Sensitive_Loss : 0.10605, Sensitive_Acc : 23.700, Run Time : 16.44 sec
INFO:root:2024-04-16 13:48:15, Dev, Step : 2300, Loss : 0.50755, Acc : 0.782, Auc : 0.858, Sensitive_Loss : 0.18738, Sensitive_Acc : 21.541, Sensitive_Auc : 0.996, Mean auc: 0.858, Run Time : 236.42 sec
INFO:root:2024-04-16 13:48:16, Best, Step : 2300, Loss : 0.50755, Acc : 0.782, Auc : 0.858, Sensitive_Loss : 0.18738, Sensitive_Acc : 21.541, Sensitive_Auc : 0.996, Best Auc : 0.858
INFO:root:2024-04-16 13:48:29, Train, Epoch : 4, Step : 2310, Loss : 0.42684, Acc : 0.816, Sensitive_Loss : 0.18318, Sensitive_Acc : 17.800, Run Time : 249.78 sec
INFO:root:2024-04-16 13:48:46, Train, Epoch : 4, Step : 2320, Loss : 0.38767, Acc : 0.809, Sensitive_Loss : 0.15063, Sensitive_Acc : 21.700, Run Time : 17.74 sec
INFO:root:2024-04-16 13:49:06, Train, Epoch : 4, Step : 2330, Loss : 0.43027, Acc : 0.831, Sensitive_Loss : 0.11925, Sensitive_Acc : 19.100, Run Time : 19.23 sec
INFO:root:2024-04-16 13:49:26, Train, Epoch : 4, Step : 2340, Loss : 0.49106, Acc : 0.819, Sensitive_Loss : 0.15114, Sensitive_Acc : 24.900, Run Time : 20.29 sec
INFO:root:2024-04-16 13:49:44, Train, Epoch : 4, Step : 2350, Loss : 0.41935, Acc : 0.794, Sensitive_Loss : 0.10311, Sensitive_Acc : 24.600, Run Time : 17.59 sec
INFO:root:2024-04-16 13:50:01, Train, Epoch : 4, Step : 2360, Loss : 0.42797, Acc : 0.797, Sensitive_Loss : 0.09426, Sensitive_Acc : 19.100, Run Time : 17.31 sec
INFO:root:2024-04-16 13:50:19, Train, Epoch : 4, Step : 2370, Loss : 0.43651, Acc : 0.819, Sensitive_Loss : 0.10991, Sensitive_Acc : 22.900, Run Time : 18.14 sec
INFO:root:2024-04-16 13:50:36, Train, Epoch : 4, Step : 2380, Loss : 0.36277, Acc : 0.831, Sensitive_Loss : 0.13088, Sensitive_Acc : 21.800, Run Time : 17.46 sec
INFO:root:2024-04-16 13:50:55, Train, Epoch : 4, Step : 2390, Loss : 0.36550, Acc : 0.850, Sensitive_Loss : 0.14810, Sensitive_Acc : 21.600, Run Time : 18.15 sec
INFO:root:2024-04-16 13:51:13, Train, Epoch : 4, Step : 2400, Loss : 0.43491, Acc : 0.825, Sensitive_Loss : 0.12385, Sensitive_Acc : 20.800, Run Time : 18.16 sec
INFO:root:2024-04-16 13:55:06, Dev, Step : 2400, Loss : 0.51746, Acc : 0.775, Auc : 0.854, Sensitive_Loss : 0.21692, Sensitive_Acc : 21.361, Sensitive_Auc : 0.994, Mean auc: 0.854, Run Time : 233.62 sec
INFO:root:2024-04-16 13:55:20, Train, Epoch : 4, Step : 2410, Loss : 0.42420, Acc : 0.775, Sensitive_Loss : 0.14994, Sensitive_Acc : 20.200, Run Time : 247.53 sec
INFO:root:2024-04-16 13:55:37, Train, Epoch : 4, Step : 2420, Loss : 0.41443, Acc : 0.784, Sensitive_Loss : 0.10162, Sensitive_Acc : 22.600, Run Time : 16.28 sec
INFO:root:2024-04-16 13:55:55, Train, Epoch : 4, Step : 2430, Loss : 0.48797, Acc : 0.778, Sensitive_Loss : 0.10778, Sensitive_Acc : 22.400, Run Time : 18.83 sec
INFO:root:2024-04-16 13:56:13, Train, Epoch : 4, Step : 2440, Loss : 0.42768, Acc : 0.816, Sensitive_Loss : 0.14108, Sensitive_Acc : 19.500, Run Time : 17.64 sec
INFO:root:2024-04-16 13:56:31, Train, Epoch : 4, Step : 2450, Loss : 0.44541, Acc : 0.797, Sensitive_Loss : 0.11155, Sensitive_Acc : 24.700, Run Time : 18.23 sec
INFO:root:2024-04-16 13:56:49, Train, Epoch : 4, Step : 2460, Loss : 0.45732, Acc : 0.816, Sensitive_Loss : 0.10583, Sensitive_Acc : 17.200, Run Time : 17.70 sec
INFO:root:2024-04-16 13:57:06, Train, Epoch : 4, Step : 2470, Loss : 0.46954, Acc : 0.791, Sensitive_Loss : 0.14585, Sensitive_Acc : 22.300, Run Time : 17.40 sec
INFO:root:2024-04-16 13:57:27, Train, Epoch : 4, Step : 2480, Loss : 0.41996, Acc : 0.791, Sensitive_Loss : 0.09132, Sensitive_Acc : 18.600, Run Time : 20.65 sec
INFO:root:2024-04-16 13:57:46, Train, Epoch : 4, Step : 2490, Loss : 0.43596, Acc : 0.797, Sensitive_Loss : 0.14070, Sensitive_Acc : 22.900, Run Time : 19.11 sec
INFO:root:2024-04-16 13:58:04, Train, Epoch : 4, Step : 2500, Loss : 0.36608, Acc : 0.841, Sensitive_Loss : 0.11717, Sensitive_Acc : 23.300, Run Time : 18.03 sec
INFO:root:2024-04-16 14:01:59, Dev, Step : 2500, Loss : 0.54415, Acc : 0.766, Auc : 0.854, Sensitive_Loss : 0.18020, Sensitive_Acc : 21.752, Sensitive_Auc : 0.995, Mean auc: 0.854, Run Time : 234.51 sec
INFO:root:2024-04-16 14:02:11, Train, Epoch : 4, Step : 2510, Loss : 0.42699, Acc : 0.828, Sensitive_Loss : 0.08546, Sensitive_Acc : 22.100, Run Time : 246.52 sec
INFO:root:2024-04-16 14:02:29, Train, Epoch : 4, Step : 2520, Loss : 0.37071, Acc : 0.812, Sensitive_Loss : 0.12781, Sensitive_Acc : 23.200, Run Time : 18.52 sec
INFO:root:2024-04-16 14:02:46, Train, Epoch : 4, Step : 2530, Loss : 0.44708, Acc : 0.803, Sensitive_Loss : 0.08883, Sensitive_Acc : 21.500, Run Time : 17.01 sec
INFO:root:2024-04-16 14:06:50
INFO:root:y_pred: [0.3112477  0.00734703 0.05554414 ... 0.10508519 0.07486124 0.05755416]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [1.52567809e-05 5.42408263e-04 4.51159338e-03 4.32486050e-02
 8.61640740e-03 3.99949611e-04 2.60052009e-04 1.32121984e-03
 4.68581058e-02 9.99904633e-01 1.62625298e-01 4.59438568e-04
 7.97874178e-04 2.70588265e-04 9.98361528e-01 1.37814041e-02
 1.33039923e-02 9.99345958e-01 9.99769628e-01 1.38275395e-03
 9.88489568e-01 8.64422414e-04 3.47668212e-03 6.16837235e-04
 1.41669378e-01 1.03693374e-01 3.60349004e-05 3.88067798e-04
 1.07400294e-03 2.68197525e-03 1.61471382e-01 9.76890862e-01
 5.50650060e-03 9.10524428e-01 1.60936499e-04 1.07679785e-04
 2.31693755e-03 7.13042095e-02 6.94419146e-01 5.59902675e-02
 3.43850553e-02 9.73643005e-01 1.31952129e-02 1.51022114e-02
 9.95300174e-01 1.17599349e-02 3.48311812e-01 4.08064574e-01
 3.33435163e-02 9.95229602e-01 9.51222122e-01 9.99790967e-01
 9.97190654e-01 8.67248862e-04 1.39406309e-01 6.01898618e-02
 3.08560999e-03 2.07016454e-03 9.96014714e-01 1.17817975e-03
 4.26220577e-05 1.74360105e-03 7.11373694e-04 1.25357456e-05
 9.98548687e-01 2.89530098e-01 1.46147839e-04 1.67533487e-01
 8.42528977e-03 9.86174464e-01 9.99939442e-01 9.99830008e-01
 3.48699308e-04 3.65903407e-01 7.63334858e-04 5.82320631e-01
 5.24135726e-03 2.23333773e-05 6.39011734e-04 1.67301053e-03
 1.92525331e-02 2.35581043e-04 9.98379588e-01 9.95092988e-01
 3.88660608e-03 1.15519598e-01 2.94609629e-02 6.60548452e-04
 2.19382215e-02 6.62069349e-03 3.86193191e-04 5.13663441e-02
 1.61994365e-04 4.74207300e-05 7.02941697e-03 2.30459240e-03
 5.12194878e-04 1.37967601e-01 1.71118032e-03 1.61581906e-03
 2.49927631e-03 7.18543539e-03 1.71498075e-01 1.23446679e-03
 5.10491803e-03 2.51744437e-04 1.91450324e-02 5.53814620e-02
 1.37322009e-01 3.89926881e-03 2.09649661e-04 9.99976754e-01
 9.99097824e-01 1.80566076e-05 1.75083324e-01 2.78289709e-02
 1.93857495e-03 5.47610805e-04 1.26862414e-02 1.55574922e-03
 2.67996080e-03 2.99591557e-05 1.43544460e-02 4.72640240e-05
 6.27847447e-04 9.25316215e-01 7.43526689e-05 9.92437184e-01
 2.07443181e-02 8.79198592e-03 3.74603958e-04 3.64465415e-02
 4.86147073e-05]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-16 14:06:50, Dev, Step : 2536, Loss : 0.53138, Acc : 0.773, Auc : 0.856, Sensitive_Loss : 0.18316, Sensitive_Acc : 21.752, Sensitive_Auc : 0.994, Mean auc: 0.856, Run Time : 234.88 sec
INFO:root:2024-04-16 14:07:03, Train, Epoch : 5, Step : 2540, Loss : 0.11880, Acc : 0.353, Sensitive_Loss : 0.04264, Sensitive_Acc : 8.600, Run Time : 10.02 sec
INFO:root:2024-04-16 14:07:22, Train, Epoch : 5, Step : 2550, Loss : 0.36388, Acc : 0.822, Sensitive_Loss : 0.10590, Sensitive_Acc : 22.200, Run Time : 18.99 sec
INFO:root:2024-04-16 14:07:41, Train, Epoch : 5, Step : 2560, Loss : 0.40433, Acc : 0.816, Sensitive_Loss : 0.12134, Sensitive_Acc : 22.100, Run Time : 19.71 sec
INFO:root:2024-04-16 14:07:58, Train, Epoch : 5, Step : 2570, Loss : 0.42049, Acc : 0.819, Sensitive_Loss : 0.14240, Sensitive_Acc : 24.700, Run Time : 16.76 sec
INFO:root:2024-04-16 14:08:16, Train, Epoch : 5, Step : 2580, Loss : 0.38536, Acc : 0.850, Sensitive_Loss : 0.09763, Sensitive_Acc : 17.900, Run Time : 17.83 sec
INFO:root:2024-04-16 14:08:34, Train, Epoch : 5, Step : 2590, Loss : 0.42443, Acc : 0.844, Sensitive_Loss : 0.13540, Sensitive_Acc : 22.500, Run Time : 17.84 sec
INFO:root:2024-04-16 14:08:51, Train, Epoch : 5, Step : 2600, Loss : 0.38394, Acc : 0.816, Sensitive_Loss : 0.16132, Sensitive_Acc : 22.800, Run Time : 17.17 sec
INFO:root:2024-04-16 14:12:48, Dev, Step : 2600, Loss : 0.52538, Acc : 0.771, Auc : 0.854, Sensitive_Loss : 0.20846, Sensitive_Acc : 21.541, Sensitive_Auc : 0.995, Mean auc: 0.854, Run Time : 237.05 sec
INFO:root:2024-04-16 14:13:01, Train, Epoch : 5, Step : 2610, Loss : 0.44139, Acc : 0.800, Sensitive_Loss : 0.06909, Sensitive_Acc : 20.500, Run Time : 250.03 sec
INFO:root:2024-04-16 14:13:18, Train, Epoch : 5, Step : 2620, Loss : 0.35066, Acc : 0.850, Sensitive_Loss : 0.10401, Sensitive_Acc : 20.500, Run Time : 17.39 sec
INFO:root:2024-04-16 14:13:37, Train, Epoch : 5, Step : 2630, Loss : 0.39085, Acc : 0.816, Sensitive_Loss : 0.18559, Sensitive_Acc : 21.200, Run Time : 18.27 sec
INFO:root:2024-04-16 14:13:55, Train, Epoch : 5, Step : 2640, Loss : 0.41360, Acc : 0.803, Sensitive_Loss : 0.11746, Sensitive_Acc : 23.800, Run Time : 18.10 sec
INFO:root:2024-04-16 14:14:11, Train, Epoch : 5, Step : 2650, Loss : 0.37974, Acc : 0.809, Sensitive_Loss : 0.15358, Sensitive_Acc : 22.400, Run Time : 15.90 sec
INFO:root:2024-04-16 14:14:29, Train, Epoch : 5, Step : 2660, Loss : 0.38653, Acc : 0.838, Sensitive_Loss : 0.12900, Sensitive_Acc : 18.700, Run Time : 18.20 sec
INFO:root:2024-04-16 14:14:47, Train, Epoch : 5, Step : 2670, Loss : 0.37952, Acc : 0.856, Sensitive_Loss : 0.08479, Sensitive_Acc : 22.800, Run Time : 17.93 sec
INFO:root:2024-04-16 14:15:04, Train, Epoch : 5, Step : 2680, Loss : 0.44433, Acc : 0.806, Sensitive_Loss : 0.12111, Sensitive_Acc : 24.000, Run Time : 17.67 sec
INFO:root:2024-04-16 14:15:23, Train, Epoch : 5, Step : 2690, Loss : 0.34949, Acc : 0.844, Sensitive_Loss : 0.12454, Sensitive_Acc : 20.200, Run Time : 18.98 sec
INFO:root:2024-04-16 14:15:41, Train, Epoch : 5, Step : 2700, Loss : 0.42060, Acc : 0.803, Sensitive_Loss : 0.14771, Sensitive_Acc : 24.200, Run Time : 17.49 sec
INFO:root:2024-04-16 14:19:36, Dev, Step : 2700, Loss : 0.53285, Acc : 0.774, Auc : 0.855, Sensitive_Loss : 0.21025, Sensitive_Acc : 21.376, Sensitive_Auc : 0.994, Mean auc: 0.855, Run Time : 235.38 sec
INFO:root:2024-04-16 14:19:48, Train, Epoch : 5, Step : 2710, Loss : 0.47323, Acc : 0.800, Sensitive_Loss : 0.14052, Sensitive_Acc : 18.400, Run Time : 246.97 sec
INFO:root:2024-04-16 14:20:06, Train, Epoch : 5, Step : 2720, Loss : 0.37718, Acc : 0.847, Sensitive_Loss : 0.13322, Sensitive_Acc : 17.800, Run Time : 17.92 sec
INFO:root:2024-04-16 14:20:24, Train, Epoch : 5, Step : 2730, Loss : 0.39835, Acc : 0.834, Sensitive_Loss : 0.17015, Sensitive_Acc : 21.800, Run Time : 18.47 sec
INFO:root:2024-04-16 14:20:41, Train, Epoch : 5, Step : 2740, Loss : 0.35419, Acc : 0.828, Sensitive_Loss : 0.14263, Sensitive_Acc : 22.100, Run Time : 16.95 sec
INFO:root:2024-04-16 14:21:00, Train, Epoch : 5, Step : 2750, Loss : 0.39601, Acc : 0.806, Sensitive_Loss : 0.11521, Sensitive_Acc : 22.900, Run Time : 18.63 sec
INFO:root:2024-04-16 14:21:17, Train, Epoch : 5, Step : 2760, Loss : 0.34032, Acc : 0.844, Sensitive_Loss : 0.14755, Sensitive_Acc : 23.800, Run Time : 17.42 sec
INFO:root:2024-04-16 14:21:34, Train, Epoch : 5, Step : 2770, Loss : 0.38560, Acc : 0.816, Sensitive_Loss : 0.11051, Sensitive_Acc : 20.800, Run Time : 16.85 sec
INFO:root:2024-04-16 14:21:52, Train, Epoch : 5, Step : 2780, Loss : 0.44603, Acc : 0.844, Sensitive_Loss : 0.19033, Sensitive_Acc : 23.900, Run Time : 18.07 sec
INFO:root:2024-04-16 14:22:10, Train, Epoch : 5, Step : 2790, Loss : 0.41534, Acc : 0.841, Sensitive_Loss : 0.12488, Sensitive_Acc : 26.500, Run Time : 17.49 sec
INFO:root:2024-04-16 14:22:27, Train, Epoch : 5, Step : 2800, Loss : 0.44167, Acc : 0.794, Sensitive_Loss : 0.14294, Sensitive_Acc : 22.800, Run Time : 17.65 sec
INFO:root:2024-04-16 14:26:21, Dev, Step : 2800, Loss : 0.51651, Acc : 0.777, Auc : 0.856, Sensitive_Loss : 0.20597, Sensitive_Acc : 21.376, Sensitive_Auc : 0.998, Mean auc: 0.856, Run Time : 233.53 sec
INFO:root:2024-04-16 14:26:34, Train, Epoch : 5, Step : 2810, Loss : 0.43485, Acc : 0.806, Sensitive_Loss : 0.12473, Sensitive_Acc : 19.100, Run Time : 246.16 sec
INFO:root:2024-04-16 14:26:52, Train, Epoch : 5, Step : 2820, Loss : 0.43209, Acc : 0.812, Sensitive_Loss : 0.11023, Sensitive_Acc : 19.500, Run Time : 18.24 sec
INFO:root:2024-04-16 14:27:09, Train, Epoch : 5, Step : 2830, Loss : 0.40861, Acc : 0.819, Sensitive_Loss : 0.09749, Sensitive_Acc : 20.500, Run Time : 16.98 sec
INFO:root:2024-04-16 14:27:26, Train, Epoch : 5, Step : 2840, Loss : 0.41076, Acc : 0.797, Sensitive_Loss : 0.12692, Sensitive_Acc : 22.100, Run Time : 17.30 sec
INFO:root:2024-04-16 14:27:45, Train, Epoch : 5, Step : 2850, Loss : 0.53444, Acc : 0.762, Sensitive_Loss : 0.26191, Sensitive_Acc : 20.700, Run Time : 19.15 sec
INFO:root:2024-04-16 14:28:02, Train, Epoch : 5, Step : 2860, Loss : 0.37707, Acc : 0.847, Sensitive_Loss : 0.12524, Sensitive_Acc : 19.400, Run Time : 16.87 sec
INFO:root:2024-04-16 14:28:21, Train, Epoch : 5, Step : 2870, Loss : 0.40728, Acc : 0.828, Sensitive_Loss : 0.12222, Sensitive_Acc : 21.700, Run Time : 18.80 sec
INFO:root:2024-04-16 14:28:39, Train, Epoch : 5, Step : 2880, Loss : 0.36503, Acc : 0.822, Sensitive_Loss : 0.08245, Sensitive_Acc : 17.600, Run Time : 18.27 sec
INFO:root:2024-04-16 14:28:56, Train, Epoch : 5, Step : 2890, Loss : 0.48930, Acc : 0.791, Sensitive_Loss : 0.11208, Sensitive_Acc : 16.500, Run Time : 16.62 sec
INFO:root:2024-04-16 14:29:15, Train, Epoch : 5, Step : 2900, Loss : 0.37797, Acc : 0.831, Sensitive_Loss : 0.15692, Sensitive_Acc : 23.800, Run Time : 19.09 sec
INFO:root:2024-04-16 14:33:10, Dev, Step : 2900, Loss : 0.52507, Acc : 0.776, Auc : 0.853, Sensitive_Loss : 0.19435, Sensitive_Acc : 21.541, Sensitive_Auc : 0.997, Mean auc: 0.853, Run Time : 235.54 sec
INFO:root:2024-04-16 14:33:22, Train, Epoch : 5, Step : 2910, Loss : 0.37754, Acc : 0.841, Sensitive_Loss : 0.09558, Sensitive_Acc : 13.800, Run Time : 246.75 sec
INFO:root:2024-04-16 14:33:39, Train, Epoch : 5, Step : 2920, Loss : 0.42260, Acc : 0.828, Sensitive_Loss : 0.11417, Sensitive_Acc : 23.200, Run Time : 17.86 sec
INFO:root:2024-04-16 14:33:58, Train, Epoch : 5, Step : 2930, Loss : 0.37560, Acc : 0.822, Sensitive_Loss : 0.13041, Sensitive_Acc : 21.100, Run Time : 18.66 sec
INFO:root:2024-04-16 14:34:14, Train, Epoch : 5, Step : 2940, Loss : 0.33921, Acc : 0.863, Sensitive_Loss : 0.12787, Sensitive_Acc : 23.300, Run Time : 15.73 sec
INFO:root:2024-04-16 14:34:33, Train, Epoch : 5, Step : 2950, Loss : 0.36485, Acc : 0.834, Sensitive_Loss : 0.10481, Sensitive_Acc : 21.500, Run Time : 18.76 sec
INFO:root:2024-04-16 14:34:50, Train, Epoch : 5, Step : 2960, Loss : 0.39049, Acc : 0.822, Sensitive_Loss : 0.09635, Sensitive_Acc : 18.800, Run Time : 17.14 sec
INFO:root:2024-04-16 14:35:09, Train, Epoch : 5, Step : 2970, Loss : 0.47719, Acc : 0.800, Sensitive_Loss : 0.10263, Sensitive_Acc : 23.200, Run Time : 19.29 sec
INFO:root:2024-04-16 14:35:26, Train, Epoch : 5, Step : 2980, Loss : 0.32464, Acc : 0.834, Sensitive_Loss : 0.09690, Sensitive_Acc : 19.000, Run Time : 17.22 sec
INFO:root:2024-04-16 14:35:44, Train, Epoch : 5, Step : 2990, Loss : 0.44750, Acc : 0.816, Sensitive_Loss : 0.11782, Sensitive_Acc : 14.600, Run Time : 17.75 sec
INFO:root:2024-04-16 14:36:01, Train, Epoch : 5, Step : 3000, Loss : 0.44896, Acc : 0.812, Sensitive_Loss : 0.10866, Sensitive_Acc : 24.000, Run Time : 17.42 sec
INFO:root:2024-04-16 14:39:58, Dev, Step : 3000, Loss : 0.55903, Acc : 0.766, Auc : 0.848, Sensitive_Loss : 0.23257, Sensitive_Acc : 20.820, Sensitive_Auc : 0.997, Mean auc: 0.848, Run Time : 236.28 sec
INFO:root:2024-04-16 14:40:09, Train, Epoch : 5, Step : 3010, Loss : 0.42404, Acc : 0.809, Sensitive_Loss : 0.18476, Sensitive_Acc : 22.900, Run Time : 247.77 sec
INFO:root:2024-04-16 14:40:28, Train, Epoch : 5, Step : 3020, Loss : 0.39304, Acc : 0.838, Sensitive_Loss : 0.16216, Sensitive_Acc : 22.700, Run Time : 18.50 sec
INFO:root:2024-04-16 14:40:46, Train, Epoch : 5, Step : 3030, Loss : 0.40332, Acc : 0.803, Sensitive_Loss : 0.17155, Sensitive_Acc : 20.100, Run Time : 18.39 sec
INFO:root:2024-04-16 14:41:05, Train, Epoch : 5, Step : 3040, Loss : 0.39327, Acc : 0.838, Sensitive_Loss : 0.09514, Sensitive_Acc : 20.300, Run Time : 18.59 sec
INFO:root:2024-04-16 14:41:22, Train, Epoch : 5, Step : 3050, Loss : 0.36306, Acc : 0.847, Sensitive_Loss : 0.12866, Sensitive_Acc : 18.800, Run Time : 17.77 sec
INFO:root:2024-04-16 14:41:41, Train, Epoch : 5, Step : 3060, Loss : 0.39282, Acc : 0.838, Sensitive_Loss : 0.07431, Sensitive_Acc : 26.400, Run Time : 18.52 sec
INFO:root:2024-04-16 14:41:58, Train, Epoch : 5, Step : 3070, Loss : 0.41048, Acc : 0.800, Sensitive_Loss : 0.08209, Sensitive_Acc : 19.100, Run Time : 17.44 sec
INFO:root:2024-04-16 14:42:16, Train, Epoch : 5, Step : 3080, Loss : 0.39417, Acc : 0.831, Sensitive_Loss : 0.08434, Sensitive_Acc : 24.100, Run Time : 17.10 sec
INFO:root:2024-04-16 14:42:35, Train, Epoch : 5, Step : 3090, Loss : 0.42763, Acc : 0.791, Sensitive_Loss : 0.13842, Sensitive_Acc : 23.400, Run Time : 19.22 sec
INFO:root:2024-04-16 14:42:53, Train, Epoch : 5, Step : 3100, Loss : 0.39824, Acc : 0.800, Sensitive_Loss : 0.13295, Sensitive_Acc : 21.200, Run Time : 18.72 sec
INFO:root:2024-04-16 14:46:59, Dev, Step : 3100, Loss : 0.52419, Acc : 0.776, Auc : 0.854, Sensitive_Loss : 0.18812, Sensitive_Acc : 21.632, Sensitive_Auc : 0.996, Mean auc: 0.854, Run Time : 245.45 sec
INFO:root:2024-04-16 14:47:11, Train, Epoch : 5, Step : 3110, Loss : 0.39675, Acc : 0.847, Sensitive_Loss : 0.07203, Sensitive_Acc : 15.600, Run Time : 257.54 sec
INFO:root:2024-04-16 14:47:28, Train, Epoch : 5, Step : 3120, Loss : 0.38111, Acc : 0.866, Sensitive_Loss : 0.12805, Sensitive_Acc : 23.900, Run Time : 16.48 sec
INFO:root:2024-04-16 14:47:46, Train, Epoch : 5, Step : 3130, Loss : 0.34732, Acc : 0.847, Sensitive_Loss : 0.10418, Sensitive_Acc : 25.100, Run Time : 18.60 sec
INFO:root:2024-04-16 14:48:05, Train, Epoch : 5, Step : 3140, Loss : 0.43007, Acc : 0.803, Sensitive_Loss : 0.11645, Sensitive_Acc : 21.600, Run Time : 18.89 sec
INFO:root:2024-04-16 14:48:23, Train, Epoch : 5, Step : 3150, Loss : 0.35693, Acc : 0.856, Sensitive_Loss : 0.14307, Sensitive_Acc : 20.200, Run Time : 18.17 sec
INFO:root:2024-04-16 14:48:41, Train, Epoch : 5, Step : 3160, Loss : 0.38904, Acc : 0.844, Sensitive_Loss : 0.10879, Sensitive_Acc : 22.700, Run Time : 17.77 sec
INFO:root:2024-04-16 14:48:56, Train, Epoch : 5, Step : 3170, Loss : 0.36830, Acc : 0.866, Sensitive_Loss : 0.15871, Sensitive_Acc : 20.400, Run Time : 14.63 sec
INFO:root:2024-04-16 14:52:44
INFO:root:y_pred: [0.20630798 0.00311843 0.05329068 ... 0.10535163 0.09551997 0.0453012 ]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [3.55543525e-05 4.54722060e-04 5.16429031e-03 6.38983324e-02
 2.16657910e-02 2.82137858e-04 1.07771251e-03 1.43626239e-03
 4.82104234e-02 9.99948978e-01 1.64752796e-01 5.48257376e-04
 4.27238643e-04 3.76116572e-04 9.99110281e-01 3.32220681e-02
 3.93582657e-02 9.99669909e-01 9.99850273e-01 1.06216269e-03
 9.90551591e-01 1.31960516e-03 3.98502825e-03 6.74081966e-04
 1.27296016e-01 1.31665781e-01 4.61436721e-05 3.12059274e-04
 1.53530901e-03 1.15326997e-02 1.17111176e-01 9.86627400e-01
 5.49321948e-03 9.61867392e-01 8.06919415e-04 6.94925402e-05
 3.15181073e-03 1.46665007e-01 7.13759542e-01 2.78586652e-02
 6.07046969e-02 9.85383809e-01 1.42445704e-02 1.33684054e-02
 9.97329473e-01 1.46391680e-02 2.41921932e-01 6.04951143e-01
 6.13583401e-02 9.96644258e-01 9.85124826e-01 9.99900818e-01
 9.99610245e-01 5.53966209e-04 6.11321628e-02 6.36370555e-02
 4.81632818e-03 2.41627730e-03 9.96341169e-01 1.20181404e-03
 5.57859930e-05 3.25393397e-03 9.79745062e-04 1.75936802e-05
 9.99585450e-01 3.68389845e-01 1.96663023e-04 4.16271031e-01
 6.10545091e-03 9.89683747e-01 9.99977231e-01 9.99927640e-01
 4.16453986e-04 6.00520432e-01 1.98272453e-03 7.72677660e-01
 8.77545774e-03 2.29478701e-05 1.11002337e-04 3.03522684e-03
 3.91694419e-02 5.51751931e-04 9.99336779e-01 9.97264266e-01
 7.01129762e-03 1.89271271e-01 2.99153738e-02 3.96575982e-04
 1.30153736e-02 7.22340541e-03 1.12910022e-03 7.04903603e-02
 6.13868178e-04 4.03940394e-05 3.12035112e-03 2.36712815e-03
 7.52164167e-04 2.05896959e-01 1.27488666e-03 2.21299473e-03
 2.32688244e-03 9.84228402e-03 3.42554569e-01 4.29619430e-03
 3.39334016e-03 3.99633078e-04 3.31360102e-02 9.59423855e-02
 4.07193571e-01 3.98122612e-03 3.92330257e-04 9.99987245e-01
 9.99455273e-01 5.87012182e-05 3.59443396e-01 2.67554075e-02
 7.18608208e-04 2.80885259e-04 2.11150516e-02 8.95526027e-04
 2.36662710e-03 4.05536412e-05 2.05230471e-02 1.12022608e-04
 4.69915976e-04 9.21438575e-01 1.39669239e-04 9.94825482e-01
 2.72192303e-02 2.29786299e-02 1.76678586e-04 2.38462593e-02
 3.27849848e-05]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-16 14:52:44, Dev, Step : 3170, Loss : 0.53923, Acc : 0.773, Auc : 0.854, Sensitive_Loss : 0.19795, Sensitive_Acc : 21.541, Sensitive_Auc : 0.996, Mean auc: 0.854, Run Time : 227.89 sec
INFO:root:2024-04-16 14:53:05, Train, Epoch : 6, Step : 3180, Loss : 0.38776, Acc : 0.834, Sensitive_Loss : 0.11152, Sensitive_Acc : 23.100, Run Time : 19.32 sec
INFO:root:2024-04-16 14:53:24, Train, Epoch : 6, Step : 3190, Loss : 0.37902, Acc : 0.794, Sensitive_Loss : 0.12213, Sensitive_Acc : 18.700, Run Time : 18.85 sec
INFO:root:2024-04-16 14:53:42, Train, Epoch : 6, Step : 3200, Loss : 0.36637, Acc : 0.844, Sensitive_Loss : 0.14254, Sensitive_Acc : 24.100, Run Time : 18.69 sec
INFO:root:2024-04-16 14:57:35, Dev, Step : 3200, Loss : 0.52449, Acc : 0.780, Auc : 0.857, Sensitive_Loss : 0.19700, Sensitive_Acc : 21.541, Sensitive_Auc : 0.996, Mean auc: 0.857, Run Time : 232.34 sec
INFO:root:2024-04-16 14:57:48, Train, Epoch : 6, Step : 3210, Loss : 0.40662, Acc : 0.831, Sensitive_Loss : 0.08829, Sensitive_Acc : 23.600, Run Time : 245.40 sec
INFO:root:2024-04-16 14:58:05, Train, Epoch : 6, Step : 3220, Loss : 0.39833, Acc : 0.841, Sensitive_Loss : 0.11064, Sensitive_Acc : 19.700, Run Time : 16.99 sec
INFO:root:2024-04-16 14:58:23, Train, Epoch : 6, Step : 3230, Loss : 0.31973, Acc : 0.850, Sensitive_Loss : 0.07479, Sensitive_Acc : 23.900, Run Time : 18.62 sec
INFO:root:2024-04-16 14:58:41, Train, Epoch : 6, Step : 3240, Loss : 0.34308, Acc : 0.884, Sensitive_Loss : 0.16697, Sensitive_Acc : 21.700, Run Time : 17.87 sec
INFO:root:2024-04-16 14:58:58, Train, Epoch : 6, Step : 3250, Loss : 0.39987, Acc : 0.809, Sensitive_Loss : 0.08751, Sensitive_Acc : 24.800, Run Time : 16.93 sec
INFO:root:2024-04-16 14:59:17, Train, Epoch : 6, Step : 3260, Loss : 0.33481, Acc : 0.819, Sensitive_Loss : 0.10984, Sensitive_Acc : 22.600, Run Time : 18.45 sec
INFO:root:2024-04-16 14:59:33, Train, Epoch : 6, Step : 3270, Loss : 0.36068, Acc : 0.850, Sensitive_Loss : 0.11660, Sensitive_Acc : 20.200, Run Time : 16.20 sec
INFO:root:2024-04-16 14:59:50, Train, Epoch : 6, Step : 3280, Loss : 0.36805, Acc : 0.819, Sensitive_Loss : 0.09565, Sensitive_Acc : 21.200, Run Time : 17.05 sec
INFO:root:2024-04-16 15:00:08, Train, Epoch : 6, Step : 3290, Loss : 0.31682, Acc : 0.872, Sensitive_Loss : 0.13306, Sensitive_Acc : 26.100, Run Time : 18.52 sec
INFO:root:2024-04-16 15:00:26, Train, Epoch : 6, Step : 3300, Loss : 0.36047, Acc : 0.834, Sensitive_Loss : 0.12281, Sensitive_Acc : 15.700, Run Time : 18.15 sec
INFO:root:2024-04-16 15:04:20, Dev, Step : 3300, Loss : 0.53804, Acc : 0.777, Auc : 0.853, Sensitive_Loss : 0.19087, Sensitive_Acc : 21.556, Sensitive_Auc : 0.994, Mean auc: 0.853, Run Time : 233.43 sec
INFO:root:2024-04-16 15:04:33, Train, Epoch : 6, Step : 3310, Loss : 0.42613, Acc : 0.794, Sensitive_Loss : 0.13066, Sensitive_Acc : 17.700, Run Time : 246.15 sec
INFO:root:2024-04-16 15:04:50, Train, Epoch : 6, Step : 3320, Loss : 0.34059, Acc : 0.838, Sensitive_Loss : 0.16908, Sensitive_Acc : 26.100, Run Time : 17.82 sec
INFO:root:2024-04-16 15:05:08, Train, Epoch : 6, Step : 3330, Loss : 0.33847, Acc : 0.856, Sensitive_Loss : 0.17642, Sensitive_Acc : 24.300, Run Time : 17.42 sec
INFO:root:2024-04-16 15:05:25, Train, Epoch : 6, Step : 3340, Loss : 0.33707, Acc : 0.853, Sensitive_Loss : 0.09284, Sensitive_Acc : 21.000, Run Time : 16.71 sec
INFO:root:2024-04-16 15:05:43, Train, Epoch : 6, Step : 3350, Loss : 0.39307, Acc : 0.812, Sensitive_Loss : 0.10197, Sensitive_Acc : 21.900, Run Time : 18.07 sec
INFO:root:2024-04-16 15:06:01, Train, Epoch : 6, Step : 3360, Loss : 0.33237, Acc : 0.847, Sensitive_Loss : 0.09126, Sensitive_Acc : 17.200, Run Time : 18.15 sec
INFO:root:2024-04-16 15:06:19, Train, Epoch : 6, Step : 3370, Loss : 0.38800, Acc : 0.844, Sensitive_Loss : 0.09692, Sensitive_Acc : 24.300, Run Time : 18.44 sec
INFO:root:2024-04-16 15:06:37, Train, Epoch : 6, Step : 3380, Loss : 0.33248, Acc : 0.872, Sensitive_Loss : 0.11161, Sensitive_Acc : 24.500, Run Time : 18.08 sec
INFO:root:2024-04-16 15:06:55, Train, Epoch : 6, Step : 3390, Loss : 0.41245, Acc : 0.822, Sensitive_Loss : 0.12541, Sensitive_Acc : 18.500, Run Time : 17.69 sec
INFO:root:2024-04-16 15:07:10, Train, Epoch : 6, Step : 3400, Loss : 0.40095, Acc : 0.838, Sensitive_Loss : 0.05706, Sensitive_Acc : 20.300, Run Time : 15.23 sec
INFO:root:2024-04-16 15:11:04, Dev, Step : 3400, Loss : 0.54599, Acc : 0.772, Auc : 0.851, Sensitive_Loss : 0.19398, Sensitive_Acc : 21.541, Sensitive_Auc : 0.996, Mean auc: 0.851, Run Time : 234.25 sec
INFO:root:2024-04-16 15:11:17, Train, Epoch : 6, Step : 3410, Loss : 0.35970, Acc : 0.800, Sensitive_Loss : 0.20075, Sensitive_Acc : 20.700, Run Time : 246.80 sec
INFO:root:2024-04-16 15:11:35, Train, Epoch : 6, Step : 3420, Loss : 0.36246, Acc : 0.828, Sensitive_Loss : 0.07413, Sensitive_Acc : 24.500, Run Time : 18.15 sec
INFO:root:2024-04-16 15:11:54, Train, Epoch : 6, Step : 3430, Loss : 0.38578, Acc : 0.838, Sensitive_Loss : 0.13372, Sensitive_Acc : 20.800, Run Time : 19.33 sec
INFO:root:2024-04-16 15:12:12, Train, Epoch : 6, Step : 3440, Loss : 0.37634, Acc : 0.847, Sensitive_Loss : 0.09565, Sensitive_Acc : 24.100, Run Time : 17.24 sec
INFO:root:2024-04-16 15:12:29, Train, Epoch : 6, Step : 3450, Loss : 0.50680, Acc : 0.797, Sensitive_Loss : 0.11783, Sensitive_Acc : 22.100, Run Time : 17.45 sec
INFO:root:2024-04-16 15:12:47, Train, Epoch : 6, Step : 3460, Loss : 0.35002, Acc : 0.866, Sensitive_Loss : 0.11423, Sensitive_Acc : 23.000, Run Time : 17.65 sec
INFO:root:2024-04-16 15:13:04, Train, Epoch : 6, Step : 3470, Loss : 0.38258, Acc : 0.850, Sensitive_Loss : 0.11091, Sensitive_Acc : 17.000, Run Time : 17.41 sec
INFO:root:2024-04-16 15:13:23, Train, Epoch : 6, Step : 3480, Loss : 0.39067, Acc : 0.800, Sensitive_Loss : 0.08051, Sensitive_Acc : 17.700, Run Time : 18.56 sec
INFO:root:2024-04-16 15:13:41, Train, Epoch : 6, Step : 3490, Loss : 0.41795, Acc : 0.828, Sensitive_Loss : 0.08014, Sensitive_Acc : 22.200, Run Time : 18.13 sec
INFO:root:2024-04-16 15:13:58, Train, Epoch : 6, Step : 3500, Loss : 0.37785, Acc : 0.819, Sensitive_Loss : 0.14121, Sensitive_Acc : 21.800, Run Time : 17.35 sec
INFO:root:2024-04-16 15:17:54, Dev, Step : 3500, Loss : 0.55598, Acc : 0.767, Auc : 0.848, Sensitive_Loss : 0.19757, Sensitive_Acc : 21.541, Sensitive_Auc : 0.997, Mean auc: 0.848, Run Time : 235.66 sec
INFO:root:2024-04-16 15:18:07, Train, Epoch : 6, Step : 3510, Loss : 0.45485, Acc : 0.825, Sensitive_Loss : 0.12205, Sensitive_Acc : 25.800, Run Time : 248.26 sec
INFO:root:2024-04-16 15:18:24, Train, Epoch : 6, Step : 3520, Loss : 0.34450, Acc : 0.853, Sensitive_Loss : 0.11795, Sensitive_Acc : 23.600, Run Time : 17.26 sec
INFO:root:2024-04-16 15:18:42, Train, Epoch : 6, Step : 3530, Loss : 0.41899, Acc : 0.809, Sensitive_Loss : 0.16943, Sensitive_Acc : 21.600, Run Time : 17.89 sec
INFO:root:2024-04-16 15:19:00, Train, Epoch : 6, Step : 3540, Loss : 0.29850, Acc : 0.878, Sensitive_Loss : 0.09406, Sensitive_Acc : 17.700, Run Time : 17.92 sec
INFO:root:2024-04-16 15:19:20, Train, Epoch : 6, Step : 3550, Loss : 0.38757, Acc : 0.828, Sensitive_Loss : 0.14695, Sensitive_Acc : 22.200, Run Time : 19.94 sec
INFO:root:2024-04-16 15:19:39, Train, Epoch : 6, Step : 3560, Loss : 0.44454, Acc : 0.825, Sensitive_Loss : 0.09125, Sensitive_Acc : 21.000, Run Time : 19.16 sec
INFO:root:2024-04-16 15:19:59, Train, Epoch : 6, Step : 3570, Loss : 0.34234, Acc : 0.828, Sensitive_Loss : 0.10455, Sensitive_Acc : 22.500, Run Time : 20.53 sec
INFO:root:2024-04-16 15:20:18, Train, Epoch : 6, Step : 3580, Loss : 0.35417, Acc : 0.847, Sensitive_Loss : 0.06785, Sensitive_Acc : 25.200, Run Time : 19.10 sec
INFO:root:2024-04-16 15:20:36, Train, Epoch : 6, Step : 3590, Loss : 0.40687, Acc : 0.816, Sensitive_Loss : 0.11955, Sensitive_Acc : 25.500, Run Time : 17.15 sec
INFO:root:2024-04-16 15:20:53, Train, Epoch : 6, Step : 3600, Loss : 0.40055, Acc : 0.812, Sensitive_Loss : 0.13861, Sensitive_Acc : 23.500, Run Time : 17.43 sec
INFO:root:2024-04-16 15:24:48, Dev, Step : 3600, Loss : 0.54238, Acc : 0.772, Auc : 0.852, Sensitive_Loss : 0.19547, Sensitive_Acc : 21.541, Sensitive_Auc : 0.996, Mean auc: 0.852, Run Time : 235.30 sec
INFO:root:2024-04-16 15:25:00, Train, Epoch : 6, Step : 3610, Loss : 0.32524, Acc : 0.859, Sensitive_Loss : 0.13324, Sensitive_Acc : 23.700, Run Time : 247.39 sec
INFO:root:2024-04-16 15:25:19, Train, Epoch : 6, Step : 3620, Loss : 0.32640, Acc : 0.863, Sensitive_Loss : 0.06868, Sensitive_Acc : 15.800, Run Time : 18.62 sec
INFO:root:2024-04-16 15:25:35, Train, Epoch : 6, Step : 3630, Loss : 0.37010, Acc : 0.828, Sensitive_Loss : 0.15193, Sensitive_Acc : 21.900, Run Time : 16.54 sec
INFO:root:2024-04-16 15:25:53, Train, Epoch : 6, Step : 3640, Loss : 0.36340, Acc : 0.853, Sensitive_Loss : 0.28089, Sensitive_Acc : 20.500, Run Time : 17.98 sec
INFO:root:2024-04-16 15:26:11, Train, Epoch : 6, Step : 3650, Loss : 0.33143, Acc : 0.859, Sensitive_Loss : 0.10338, Sensitive_Acc : 27.000, Run Time : 17.67 sec
INFO:root:2024-04-16 15:26:28, Train, Epoch : 6, Step : 3660, Loss : 0.33821, Acc : 0.838, Sensitive_Loss : 0.12434, Sensitive_Acc : 23.600, Run Time : 16.74 sec
INFO:root:2024-04-16 15:26:46, Train, Epoch : 6, Step : 3670, Loss : 0.38470, Acc : 0.856, Sensitive_Loss : 0.09532, Sensitive_Acc : 22.000, Run Time : 17.67 sec
INFO:root:2024-04-16 15:27:04, Train, Epoch : 6, Step : 3680, Loss : 0.42060, Acc : 0.850, Sensitive_Loss : 0.16734, Sensitive_Acc : 21.500, Run Time : 18.18 sec
INFO:root:2024-04-16 15:27:21, Train, Epoch : 6, Step : 3690, Loss : 0.40755, Acc : 0.822, Sensitive_Loss : 0.09319, Sensitive_Acc : 22.600, Run Time : 16.95 sec
INFO:root:2024-04-16 15:27:38, Train, Epoch : 6, Step : 3700, Loss : 0.44524, Acc : 0.816, Sensitive_Loss : 0.13193, Sensitive_Acc : 25.400, Run Time : 17.57 sec
INFO:root:2024-04-16 15:31:32, Dev, Step : 3700, Loss : 0.55559, Acc : 0.765, Auc : 0.849, Sensitive_Loss : 0.17940, Sensitive_Acc : 21.541, Sensitive_Auc : 0.996, Mean auc: 0.849, Run Time : 233.98 sec
INFO:root:2024-04-16 15:31:47, Train, Epoch : 6, Step : 3710, Loss : 0.40266, Acc : 0.822, Sensitive_Loss : 0.14031, Sensitive_Acc : 23.200, Run Time : 248.42 sec
INFO:root:2024-04-16 15:32:08, Train, Epoch : 6, Step : 3720, Loss : 0.39606, Acc : 0.844, Sensitive_Loss : 0.13729, Sensitive_Acc : 23.300, Run Time : 21.81 sec
INFO:root:2024-04-16 15:32:26, Train, Epoch : 6, Step : 3730, Loss : 0.37989, Acc : 0.834, Sensitive_Loss : 0.11413, Sensitive_Acc : 22.000, Run Time : 17.34 sec
INFO:root:2024-04-16 15:32:42, Train, Epoch : 6, Step : 3740, Loss : 0.36167, Acc : 0.859, Sensitive_Loss : 0.10797, Sensitive_Acc : 23.900, Run Time : 15.90 sec
INFO:root:2024-04-16 15:33:00, Train, Epoch : 6, Step : 3750, Loss : 0.41166, Acc : 0.809, Sensitive_Loss : 0.10146, Sensitive_Acc : 24.400, Run Time : 18.12 sec
INFO:root:2024-04-16 15:33:17, Train, Epoch : 6, Step : 3760, Loss : 0.37776, Acc : 0.819, Sensitive_Loss : 0.09367, Sensitive_Acc : 20.000, Run Time : 17.20 sec
INFO:root:2024-04-16 15:33:34, Train, Epoch : 6, Step : 3770, Loss : 0.39280, Acc : 0.819, Sensitive_Loss : 0.09025, Sensitive_Acc : 20.300, Run Time : 17.19 sec
INFO:root:2024-04-16 15:33:52, Train, Epoch : 6, Step : 3780, Loss : 0.39891, Acc : 0.831, Sensitive_Loss : 0.07880, Sensitive_Acc : 21.500, Run Time : 17.69 sec
INFO:root:2024-04-16 15:34:10, Train, Epoch : 6, Step : 3790, Loss : 0.31227, Acc : 0.844, Sensitive_Loss : 0.14110, Sensitive_Acc : 23.300, Run Time : 18.54 sec
INFO:root:2024-04-16 15:34:29, Train, Epoch : 6, Step : 3800, Loss : 0.37480, Acc : 0.856, Sensitive_Loss : 0.09835, Sensitive_Acc : 21.000, Run Time : 18.07 sec
INFO:root:2024-04-16 15:38:27, Dev, Step : 3800, Loss : 0.53590, Acc : 0.776, Auc : 0.853, Sensitive_Loss : 0.18709, Sensitive_Acc : 21.541, Sensitive_Auc : 0.997, Mean auc: 0.853, Run Time : 238.29 sec
INFO:root:2024-04-16 15:42:17
INFO:root:y_pred: [0.21475156 0.00303457 0.06937709 ... 0.0469045  0.05630764 0.06810084]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [5.70172597e-05 5.50490688e-04 5.22191403e-03 4.64768670e-02
 1.08320303e-02 1.54181849e-04 1.72157690e-03 1.63692725e-03
 5.73224761e-02 9.99888897e-01 8.98067653e-02 5.05362579e-04
 2.86531838e-04 5.97296981e-04 9.97498930e-01 1.08274892e-02
 1.23251528e-02 9.99387622e-01 9.99865294e-01 1.17277226e-03
 9.90729511e-01 1.89815904e-03 1.06514269e-03 1.75147521e-04
 8.93421620e-02 1.87443137e-01 1.86225989e-05 1.94346343e-04
 5.95175312e-04 9.81981214e-03 8.90897587e-02 9.83853221e-01
 8.16904195e-03 9.42483068e-01 1.01371971e-03 3.53951145e-05
 7.03075854e-03 1.19472288e-01 7.26218879e-01 1.26379915e-02
 2.84607597e-02 9.68676984e-01 1.04062026e-02 8.17974750e-03
 9.99508619e-01 1.21223619e-02 2.31887236e-01 4.86102849e-01
 3.40927616e-02 9.92715657e-01 9.80242193e-01 9.99874473e-01
 9.99225259e-01 4.65886289e-04 8.09912458e-02 4.57360595e-02
 2.75479164e-03 2.40966701e-03 9.91700709e-01 8.32664024e-04
 2.69271313e-05 3.00934725e-03 1.89327425e-03 2.32601651e-05
 9.99256790e-01 2.68342406e-01 3.68373236e-04 4.41381127e-01
 5.68946917e-03 9.90563631e-01 9.99948144e-01 9.99921441e-01
 1.85133569e-04 5.96691608e-01 9.04342916e-04 5.22583306e-01
 7.48168956e-03 2.52286918e-05 7.42703996e-05 2.31625955e-03
 3.13233174e-02 2.76396808e-04 9.99050915e-01 9.94855165e-01
 2.80029327e-03 1.91461071e-01 1.82760805e-02 2.17012392e-04
 1.53551940e-02 1.20611740e-02 7.92188046e-04 7.74898231e-02
 5.59734122e-04 8.37187981e-05 1.73154776e-03 4.85120015e-03
 7.91660103e-04 2.79081017e-01 9.08112794e-04 3.26155033e-03
 4.77476598e-04 7.46608619e-03 2.78090507e-01 2.27811513e-03
 3.33760167e-03 3.67515284e-04 1.49005465e-02 7.91112408e-02
 3.53962004e-01 1.44281785e-03 1.97832676e-04 9.99975920e-01
 9.99473035e-01 2.84289854e-05 2.79083520e-01 1.67634543e-02
 2.32731210e-04 2.72897712e-04 1.07269771e-02 7.87118974e-04
 1.43049716e-03 4.47123202e-05 1.91729218e-02 7.57800735e-05
 4.66829370e-04 8.42711091e-01 8.78028150e-05 9.94224489e-01
 2.01101471e-02 1.31935421e-02 1.01691679e-04 1.84825379e-02
 1.82437325e-05]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-16 15:42:17, Dev, Step : 3804, Loss : 0.54745, Acc : 0.770, Auc : 0.853, Sensitive_Loss : 0.18106, Sensitive_Acc : 21.662, Sensitive_Auc : 0.997, Mean auc: 0.853, Run Time : 227.69 sec
INFO:root:2024-04-16 15:42:31, Train, Epoch : 7, Step : 3810, Loss : 0.15694, Acc : 0.512, Sensitive_Loss : 0.05427, Sensitive_Acc : 11.000, Run Time : 12.65 sec
INFO:root:2024-04-16 15:42:51, Train, Epoch : 7, Step : 3820, Loss : 0.35084, Acc : 0.828, Sensitive_Loss : 0.15290, Sensitive_Acc : 21.300, Run Time : 19.93 sec
INFO:root:2024-04-16 15:43:09, Train, Epoch : 7, Step : 3830, Loss : 0.33550, Acc : 0.875, Sensitive_Loss : 0.12246, Sensitive_Acc : 16.600, Run Time : 18.18 sec
INFO:root:2024-04-16 15:43:26, Train, Epoch : 7, Step : 3840, Loss : 0.33599, Acc : 0.853, Sensitive_Loss : 0.06338, Sensitive_Acc : 24.700, Run Time : 17.26 sec
INFO:root:2024-04-16 15:43:44, Train, Epoch : 7, Step : 3850, Loss : 0.36722, Acc : 0.838, Sensitive_Loss : 0.10950, Sensitive_Acc : 24.400, Run Time : 17.73 sec
INFO:root:2024-04-16 15:44:01, Train, Epoch : 7, Step : 3860, Loss : 0.32565, Acc : 0.869, Sensitive_Loss : 0.17726, Sensitive_Acc : 18.800, Run Time : 17.81 sec
INFO:root:2024-04-16 15:44:19, Train, Epoch : 7, Step : 3870, Loss : 0.35933, Acc : 0.838, Sensitive_Loss : 0.10323, Sensitive_Acc : 23.000, Run Time : 17.54 sec
INFO:root:2024-04-16 15:44:38, Train, Epoch : 7, Step : 3880, Loss : 0.36140, Acc : 0.847, Sensitive_Loss : 0.08006, Sensitive_Acc : 19.400, Run Time : 18.62 sec
INFO:root:2024-04-16 15:44:56, Train, Epoch : 7, Step : 3890, Loss : 0.42451, Acc : 0.819, Sensitive_Loss : 0.13474, Sensitive_Acc : 17.900, Run Time : 18.61 sec
INFO:root:2024-04-16 15:45:13, Train, Epoch : 7, Step : 3900, Loss : 0.31225, Acc : 0.869, Sensitive_Loss : 0.10870, Sensitive_Acc : 14.800, Run Time : 16.90 sec
INFO:root:2024-04-16 15:49:04, Dev, Step : 3900, Loss : 0.58216, Acc : 0.766, Auc : 0.847, Sensitive_Loss : 0.18110, Sensitive_Acc : 21.541, Sensitive_Auc : 0.996, Mean auc: 0.847, Run Time : 230.64 sec
INFO:root:2024-04-16 15:49:16, Train, Epoch : 7, Step : 3910, Loss : 0.31390, Acc : 0.869, Sensitive_Loss : 0.11963, Sensitive_Acc : 22.600, Run Time : 242.40 sec
INFO:root:2024-04-16 15:49:32, Train, Epoch : 7, Step : 3920, Loss : 0.32065, Acc : 0.847, Sensitive_Loss : 0.10367, Sensitive_Acc : 23.100, Run Time : 16.25 sec
INFO:root:2024-04-16 15:49:49, Train, Epoch : 7, Step : 3930, Loss : 0.33002, Acc : 0.856, Sensitive_Loss : 0.09250, Sensitive_Acc : 17.900, Run Time : 17.10 sec
INFO:root:2024-04-16 15:50:07, Train, Epoch : 7, Step : 3940, Loss : 0.36871, Acc : 0.831, Sensitive_Loss : 0.13986, Sensitive_Acc : 20.000, Run Time : 17.72 sec
INFO:root:2024-04-16 15:50:24, Train, Epoch : 7, Step : 3950, Loss : 0.43039, Acc : 0.828, Sensitive_Loss : 0.09626, Sensitive_Acc : 21.200, Run Time : 17.64 sec
INFO:root:2024-04-16 15:50:43, Train, Epoch : 7, Step : 3960, Loss : 0.33398, Acc : 0.866, Sensitive_Loss : 0.09628, Sensitive_Acc : 24.300, Run Time : 19.09 sec
INFO:root:2024-04-16 15:51:00, Train, Epoch : 7, Step : 3970, Loss : 0.35860, Acc : 0.834, Sensitive_Loss : 0.12185, Sensitive_Acc : 20.400, Run Time : 16.70 sec
INFO:root:2024-04-16 15:51:19, Train, Epoch : 7, Step : 3980, Loss : 0.39405, Acc : 0.825, Sensitive_Loss : 0.10660, Sensitive_Acc : 22.700, Run Time : 18.84 sec
INFO:root:2024-04-16 15:51:40, Train, Epoch : 7, Step : 3990, Loss : 0.32794, Acc : 0.875, Sensitive_Loss : 0.14478, Sensitive_Acc : 25.300, Run Time : 21.55 sec
INFO:root:2024-04-16 15:52:00, Train, Epoch : 7, Step : 4000, Loss : 0.42927, Acc : 0.831, Sensitive_Loss : 0.09205, Sensitive_Acc : 24.100, Run Time : 19.07 sec
INFO:root:2024-04-16 15:55:53, Dev, Step : 4000, Loss : 0.53736, Acc : 0.773, Auc : 0.851, Sensitive_Loss : 0.20084, Sensitive_Acc : 21.301, Sensitive_Auc : 0.997, Mean auc: 0.851, Run Time : 233.67 sec
INFO:root:2024-04-16 15:56:06, Train, Epoch : 7, Step : 4010, Loss : 0.35363, Acc : 0.831, Sensitive_Loss : 0.10028, Sensitive_Acc : 21.300, Run Time : 246.05 sec
INFO:root:2024-04-16 15:56:25, Train, Epoch : 7, Step : 4020, Loss : 0.35348, Acc : 0.863, Sensitive_Loss : 0.10225, Sensitive_Acc : 21.500, Run Time : 19.15 sec
INFO:root:2024-04-16 15:56:43, Train, Epoch : 7, Step : 4030, Loss : 0.36428, Acc : 0.875, Sensitive_Loss : 0.11160, Sensitive_Acc : 23.800, Run Time : 18.11 sec
INFO:root:2024-04-16 15:56:59, Train, Epoch : 7, Step : 4040, Loss : 0.34081, Acc : 0.831, Sensitive_Loss : 0.09279, Sensitive_Acc : 22.200, Run Time : 15.77 sec
INFO:root:2024-04-16 15:57:18, Train, Epoch : 7, Step : 4050, Loss : 0.37956, Acc : 0.812, Sensitive_Loss : 0.10958, Sensitive_Acc : 20.500, Run Time : 19.29 sec
INFO:root:2024-04-16 15:57:35, Train, Epoch : 7, Step : 4060, Loss : 0.33840, Acc : 0.856, Sensitive_Loss : 0.08914, Sensitive_Acc : 21.100, Run Time : 17.59 sec
INFO:root:2024-04-16 15:57:54, Train, Epoch : 7, Step : 4070, Loss : 0.33611, Acc : 0.872, Sensitive_Loss : 0.05124, Sensitive_Acc : 21.400, Run Time : 18.70 sec
INFO:root:2024-04-16 15:58:14, Train, Epoch : 7, Step : 4080, Loss : 0.37172, Acc : 0.819, Sensitive_Loss : 0.12670, Sensitive_Acc : 23.000, Run Time : 19.45 sec
INFO:root:2024-04-16 15:58:33, Train, Epoch : 7, Step : 4090, Loss : 0.31976, Acc : 0.856, Sensitive_Loss : 0.11196, Sensitive_Acc : 23.700, Run Time : 19.31 sec
INFO:root:2024-04-16 15:58:50, Train, Epoch : 7, Step : 4100, Loss : 0.35420, Acc : 0.850, Sensitive_Loss : 0.08743, Sensitive_Acc : 17.600, Run Time : 17.30 sec
INFO:root:2024-04-16 16:02:40, Dev, Step : 4100, Loss : 0.53818, Acc : 0.773, Auc : 0.849, Sensitive_Loss : 0.19739, Sensitive_Acc : 21.541, Sensitive_Auc : 0.997, Mean auc: 0.849, Run Time : 230.03 sec
INFO:root:2024-04-16 16:02:55, Train, Epoch : 7, Step : 4110, Loss : 0.37984, Acc : 0.812, Sensitive_Loss : 0.11333, Sensitive_Acc : 20.700, Run Time : 244.38 sec
INFO:root:2024-04-16 16:03:13, Train, Epoch : 7, Step : 4120, Loss : 0.40789, Acc : 0.828, Sensitive_Loss : 0.07709, Sensitive_Acc : 24.100, Run Time : 18.68 sec
INFO:root:2024-04-16 16:03:33, Train, Epoch : 7, Step : 4130, Loss : 0.35590, Acc : 0.838, Sensitive_Loss : 0.10453, Sensitive_Acc : 21.700, Run Time : 19.35 sec
INFO:root:2024-04-16 16:03:50, Train, Epoch : 7, Step : 4140, Loss : 0.37787, Acc : 0.828, Sensitive_Loss : 0.10369, Sensitive_Acc : 25.000, Run Time : 17.73 sec
INFO:root:2024-04-16 16:04:08, Train, Epoch : 7, Step : 4150, Loss : 0.33296, Acc : 0.844, Sensitive_Loss : 0.09409, Sensitive_Acc : 25.100, Run Time : 18.07 sec
INFO:root:2024-04-16 16:04:27, Train, Epoch : 7, Step : 4160, Loss : 0.35076, Acc : 0.825, Sensitive_Loss : 0.12054, Sensitive_Acc : 19.800, Run Time : 18.70 sec
INFO:root:2024-04-16 16:04:48, Train, Epoch : 7, Step : 4170, Loss : 0.34828, Acc : 0.869, Sensitive_Loss : 0.13220, Sensitive_Acc : 25.700, Run Time : 20.75 sec
INFO:root:2024-04-16 16:05:06, Train, Epoch : 7, Step : 4180, Loss : 0.35694, Acc : 0.872, Sensitive_Loss : 0.09102, Sensitive_Acc : 24.800, Run Time : 18.15 sec
INFO:root:2024-04-16 16:05:24, Train, Epoch : 7, Step : 4190, Loss : 0.38340, Acc : 0.809, Sensitive_Loss : 0.08027, Sensitive_Acc : 20.200, Run Time : 17.93 sec
INFO:root:2024-04-16 16:05:40, Train, Epoch : 7, Step : 4200, Loss : 0.35454, Acc : 0.800, Sensitive_Loss : 0.15557, Sensitive_Acc : 23.300, Run Time : 15.77 sec
INFO:root:2024-04-16 16:09:44, Dev, Step : 4200, Loss : 0.56218, Acc : 0.766, Auc : 0.847, Sensitive_Loss : 0.20953, Sensitive_Acc : 21.301, Sensitive_Auc : 0.997, Mean auc: 0.847, Run Time : 244.45 sec
INFO:root:2024-04-16 16:09:57, Train, Epoch : 7, Step : 4210, Loss : 0.34091, Acc : 0.850, Sensitive_Loss : 0.10012, Sensitive_Acc : 21.000, Run Time : 256.99 sec
INFO:root:2024-04-16 16:10:15, Train, Epoch : 7, Step : 4220, Loss : 0.35421, Acc : 0.847, Sensitive_Loss : 0.10718, Sensitive_Acc : 23.100, Run Time : 17.96 sec
INFO:root:2024-04-16 16:10:34, Train, Epoch : 7, Step : 4230, Loss : 0.37425, Acc : 0.844, Sensitive_Loss : 0.09189, Sensitive_Acc : 21.200, Run Time : 19.09 sec
INFO:root:2024-04-16 16:10:52, Train, Epoch : 7, Step : 4240, Loss : 0.33297, Acc : 0.847, Sensitive_Loss : 0.10061, Sensitive_Acc : 26.300, Run Time : 18.64 sec
INFO:root:2024-04-16 16:11:09, Train, Epoch : 7, Step : 4250, Loss : 0.34232, Acc : 0.831, Sensitive_Loss : 0.10599, Sensitive_Acc : 22.000, Run Time : 16.86 sec
INFO:root:2024-04-16 16:11:29, Train, Epoch : 7, Step : 4260, Loss : 0.40042, Acc : 0.812, Sensitive_Loss : 0.06859, Sensitive_Acc : 22.000, Run Time : 20.11 sec
INFO:root:2024-04-16 16:11:47, Train, Epoch : 7, Step : 4270, Loss : 0.35386, Acc : 0.872, Sensitive_Loss : 0.08523, Sensitive_Acc : 21.400, Run Time : 17.12 sec
INFO:root:2024-04-16 16:12:07, Train, Epoch : 7, Step : 4280, Loss : 0.36168, Acc : 0.838, Sensitive_Loss : 0.18076, Sensitive_Acc : 20.900, Run Time : 20.17 sec
INFO:root:2024-04-16 16:12:26, Train, Epoch : 7, Step : 4290, Loss : 0.36180, Acc : 0.850, Sensitive_Loss : 0.07818, Sensitive_Acc : 18.500, Run Time : 18.82 sec
INFO:root:2024-04-16 16:12:44, Train, Epoch : 7, Step : 4300, Loss : 0.41223, Acc : 0.828, Sensitive_Loss : 0.11552, Sensitive_Acc : 23.700, Run Time : 18.28 sec
INFO:root:2024-04-16 16:16:37, Dev, Step : 4300, Loss : 0.54661, Acc : 0.773, Auc : 0.851, Sensitive_Loss : 0.21801, Sensitive_Acc : 21.165, Sensitive_Auc : 0.996, Mean auc: 0.851, Run Time : 233.42 sec
INFO:root:2024-04-16 16:16:50, Train, Epoch : 7, Step : 4310, Loss : 0.36459, Acc : 0.866, Sensitive_Loss : 0.07908, Sensitive_Acc : 17.400, Run Time : 246.45 sec
INFO:root:2024-04-16 16:17:08, Train, Epoch : 7, Step : 4320, Loss : 0.39103, Acc : 0.819, Sensitive_Loss : 0.10465, Sensitive_Acc : 19.300, Run Time : 17.38 sec
INFO:root:2024-04-16 16:17:27, Train, Epoch : 7, Step : 4330, Loss : 0.35971, Acc : 0.844, Sensitive_Loss : 0.07344, Sensitive_Acc : 23.100, Run Time : 19.14 sec
INFO:root:2024-04-16 16:17:43, Train, Epoch : 7, Step : 4340, Loss : 0.32314, Acc : 0.847, Sensitive_Loss : 0.07879, Sensitive_Acc : 22.600, Run Time : 16.64 sec
INFO:root:2024-04-16 16:18:02, Train, Epoch : 7, Step : 4350, Loss : 0.33084, Acc : 0.822, Sensitive_Loss : 0.08981, Sensitive_Acc : 17.500, Run Time : 18.53 sec
INFO:root:2024-04-16 16:18:18, Train, Epoch : 7, Step : 4360, Loss : 0.31053, Acc : 0.878, Sensitive_Loss : 0.06911, Sensitive_Acc : 17.700, Run Time : 16.09 sec
INFO:root:2024-04-16 16:18:36, Train, Epoch : 7, Step : 4370, Loss : 0.36019, Acc : 0.803, Sensitive_Loss : 0.15572, Sensitive_Acc : 23.300, Run Time : 17.79 sec
INFO:root:2024-04-16 16:18:55, Train, Epoch : 7, Step : 4380, Loss : 0.35460, Acc : 0.866, Sensitive_Loss : 0.09744, Sensitive_Acc : 22.600, Run Time : 18.96 sec
INFO:root:2024-04-16 16:19:12, Train, Epoch : 7, Step : 4390, Loss : 0.32377, Acc : 0.853, Sensitive_Loss : 0.09982, Sensitive_Acc : 22.000, Run Time : 17.66 sec
INFO:root:2024-04-16 16:19:29, Train, Epoch : 7, Step : 4400, Loss : 0.33682, Acc : 0.850, Sensitive_Loss : 0.09167, Sensitive_Acc : 21.400, Run Time : 16.56 sec
INFO:root:2024-04-16 16:23:23, Dev, Step : 4400, Loss : 0.56594, Acc : 0.768, Auc : 0.849, Sensitive_Loss : 0.18352, Sensitive_Acc : 21.782, Sensitive_Auc : 0.996, Mean auc: 0.849, Run Time : 233.55 sec
INFO:root:2024-04-16 16:23:36, Train, Epoch : 7, Step : 4410, Loss : 0.38465, Acc : 0.844, Sensitive_Loss : 0.07151, Sensitive_Acc : 21.200, Run Time : 246.51 sec
INFO:root:2024-04-16 16:23:53, Train, Epoch : 7, Step : 4420, Loss : 0.39096, Acc : 0.838, Sensitive_Loss : 0.10154, Sensitive_Acc : 17.200, Run Time : 17.47 sec
INFO:root:2024-04-16 16:24:12, Train, Epoch : 7, Step : 4430, Loss : 0.32590, Acc : 0.863, Sensitive_Loss : 0.10758, Sensitive_Acc : 25.700, Run Time : 19.28 sec
INFO:root:2024-04-16 16:28:15
INFO:root:y_pred: [0.22090463 0.00438484 0.09248299 ... 0.11013126 0.08812023 0.08147596]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [2.24368068e-05 5.33042883e-04 5.43129211e-03 4.53005843e-02
 1.96765661e-02 2.43006391e-04 1.12256629e-03 1.70689460e-03
 2.59773079e-02 9.99964118e-01 1.68321550e-01 2.68246920e-04
 2.48082448e-04 6.38682686e-04 9.98892128e-01 1.12231513e-02
 4.06592377e-02 9.99742925e-01 9.99972820e-01 1.36389618e-03
 9.95204091e-01 1.21475023e-03 3.64685850e-03 1.75164372e-04
 5.64407147e-02 1.99760273e-01 2.09315313e-05 2.69907789e-04
 1.33061956e-03 5.62918093e-03 2.15619728e-01 9.87941325e-01
 8.82737245e-03 9.78736639e-01 4.30548476e-04 3.59912810e-05
 3.34702106e-03 1.23121835e-01 6.68622971e-01 8.19804985e-03
 6.01549670e-02 9.83204544e-01 1.17153032e-02 6.52854284e-03
 9.99925256e-01 9.49535985e-03 2.47812152e-01 6.84813678e-01
 7.13462308e-02 9.99382615e-01 9.97855008e-01 9.99933481e-01
 9.99907136e-01 5.50181721e-04 1.83311537e-01 7.04897940e-02
 1.10256963e-03 2.28445325e-03 9.89486217e-01 2.96846410e-04
 3.32536547e-05 3.49330832e-03 7.56455585e-04 9.08787297e-06
 9.99851704e-01 2.57074118e-01 6.96682371e-04 5.85299730e-01
 4.20083757e-03 9.92473602e-01 9.99976993e-01 9.99939322e-01
 2.47718941e-04 7.52605498e-01 1.16187299e-03 6.57401025e-01
 6.71029277e-03 1.56258193e-05 1.95837511e-05 2.14439770e-03
 5.95652275e-02 1.21218392e-04 9.99062240e-01 9.97140288e-01
 4.82141599e-03 1.60183549e-01 2.21892502e-02 4.91638901e-04
 1.29262581e-02 1.48140667e-02 1.31157727e-03 9.66511816e-02
 4.06500039e-04 8.98901271e-05 1.25855918e-03 3.76059441e-03
 5.28033765e-04 3.04123998e-01 4.16426396e-04 2.78177927e-03
 1.83194503e-03 1.74668878e-02 4.70945805e-01 4.74231830e-03
 2.29883799e-03 5.40376117e-04 2.53695231e-02 8.83667171e-02
 5.94013631e-01 2.56404816e-03 1.77326001e-04 9.99995589e-01
 9.99912262e-01 1.07099522e-05 5.37575543e-01 8.31633247e-03
 3.06304399e-04 2.00809358e-04 9.27078538e-03 5.05425269e-04
 1.59294868e-03 4.95719905e-05 2.78492421e-02 5.65871742e-05
 4.97623871e-04 9.08989906e-01 1.47552710e-04 9.98317719e-01
 3.83255146e-02 2.27058046e-02 8.19856723e-05 1.99578237e-02
 9.33218325e-06]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-16 16:28:15, Dev, Step : 4438, Loss : 0.53170, Acc : 0.779, Auc : 0.852, Sensitive_Loss : 0.20397, Sensitive_Acc : 21.165, Sensitive_Auc : 0.997, Mean auc: 0.852, Run Time : 228.35 sec
INFO:root:2024-04-16 16:28:22, Train, Epoch : 8, Step : 4440, Loss : 0.07359, Acc : 0.166, Sensitive_Loss : 0.00727, Sensitive_Acc : 3.300, Run Time : 5.73 sec
INFO:root:2024-04-16 16:28:40, Train, Epoch : 8, Step : 4450, Loss : 0.33635, Acc : 0.853, Sensitive_Loss : 0.09547, Sensitive_Acc : 21.100, Run Time : 18.63 sec
INFO:root:2024-04-16 16:28:59, Train, Epoch : 8, Step : 4460, Loss : 0.30247, Acc : 0.887, Sensitive_Loss : 0.09282, Sensitive_Acc : 17.100, Run Time : 18.39 sec
INFO:root:2024-04-16 16:29:15, Train, Epoch : 8, Step : 4470, Loss : 0.32510, Acc : 0.853, Sensitive_Loss : 0.07886, Sensitive_Acc : 17.400, Run Time : 16.53 sec
INFO:root:2024-04-16 16:29:32, Train, Epoch : 8, Step : 4480, Loss : 0.31528, Acc : 0.869, Sensitive_Loss : 0.12052, Sensitive_Acc : 19.900, Run Time : 16.87 sec
INFO:root:2024-04-16 16:29:49, Train, Epoch : 8, Step : 4490, Loss : 0.29447, Acc : 0.872, Sensitive_Loss : 0.08304, Sensitive_Acc : 17.000, Run Time : 17.38 sec
INFO:root:2024-04-16 16:30:07, Train, Epoch : 8, Step : 4500, Loss : 0.33964, Acc : 0.875, Sensitive_Loss : 0.08622, Sensitive_Acc : 24.200, Run Time : 17.88 sec
INFO:root:2024-04-16 16:34:13, Dev, Step : 4500, Loss : 0.55869, Acc : 0.769, Auc : 0.851, Sensitive_Loss : 0.21377, Sensitive_Acc : 21.000, Sensitive_Auc : 0.995, Mean auc: 0.851, Run Time : 245.67 sec
INFO:root:2024-04-16 16:34:27, Train, Epoch : 8, Step : 4510, Loss : 0.30405, Acc : 0.856, Sensitive_Loss : 0.09149, Sensitive_Acc : 20.300, Run Time : 259.29 sec
INFO:root:2024-04-16 16:34:43, Train, Epoch : 8, Step : 4520, Loss : 0.29850, Acc : 0.863, Sensitive_Loss : 0.08574, Sensitive_Acc : 22.000, Run Time : 16.04 sec
INFO:root:2024-04-16 16:35:01, Train, Epoch : 8, Step : 4530, Loss : 0.37864, Acc : 0.847, Sensitive_Loss : 0.11490, Sensitive_Acc : 19.000, Run Time : 18.37 sec
INFO:root:2024-04-16 16:35:19, Train, Epoch : 8, Step : 4540, Loss : 0.33367, Acc : 0.866, Sensitive_Loss : 0.08211, Sensitive_Acc : 21.100, Run Time : 17.88 sec
INFO:root:2024-04-16 16:35:37, Train, Epoch : 8, Step : 4550, Loss : 0.27172, Acc : 0.900, Sensitive_Loss : 0.10961, Sensitive_Acc : 18.300, Run Time : 17.84 sec
INFO:root:2024-04-16 16:35:54, Train, Epoch : 8, Step : 4560, Loss : 0.34397, Acc : 0.838, Sensitive_Loss : 0.07723, Sensitive_Acc : 19.800, Run Time : 17.47 sec
INFO:root:2024-04-16 16:36:11, Train, Epoch : 8, Step : 4570, Loss : 0.36983, Acc : 0.869, Sensitive_Loss : 0.11983, Sensitive_Acc : 21.100, Run Time : 16.48 sec
INFO:root:2024-04-16 16:36:29, Train, Epoch : 8, Step : 4580, Loss : 0.33839, Acc : 0.853, Sensitive_Loss : 0.11848, Sensitive_Acc : 20.000, Run Time : 18.31 sec
INFO:root:2024-04-16 16:36:46, Train, Epoch : 8, Step : 4590, Loss : 0.33720, Acc : 0.831, Sensitive_Loss : 0.10300, Sensitive_Acc : 19.600, Run Time : 16.60 sec
INFO:root:2024-04-16 16:37:03, Train, Epoch : 8, Step : 4600, Loss : 0.37705, Acc : 0.841, Sensitive_Loss : 0.07902, Sensitive_Acc : 22.700, Run Time : 17.67 sec
INFO:root:2024-04-16 16:40:55, Dev, Step : 4600, Loss : 0.56147, Acc : 0.769, Auc : 0.848, Sensitive_Loss : 0.20698, Sensitive_Acc : 21.045, Sensitive_Auc : 0.996, Mean auc: 0.848, Run Time : 232.14 sec
INFO:root:2024-04-16 16:41:08, Train, Epoch : 8, Step : 4610, Loss : 0.33396, Acc : 0.866, Sensitive_Loss : 0.09532, Sensitive_Acc : 21.800, Run Time : 244.52 sec
INFO:root:2024-04-16 16:41:26, Train, Epoch : 8, Step : 4620, Loss : 0.35165, Acc : 0.844, Sensitive_Loss : 0.09978, Sensitive_Acc : 16.900, Run Time : 17.70 sec
INFO:root:2024-04-16 16:41:43, Train, Epoch : 8, Step : 4630, Loss : 0.31423, Acc : 0.869, Sensitive_Loss : 0.10874, Sensitive_Acc : 23.900, Run Time : 17.53 sec
INFO:root:2024-04-16 16:42:01, Train, Epoch : 8, Step : 4640, Loss : 0.32632, Acc : 0.853, Sensitive_Loss : 0.11903, Sensitive_Acc : 24.700, Run Time : 17.88 sec
INFO:root:2024-04-16 16:42:18, Train, Epoch : 8, Step : 4650, Loss : 0.30531, Acc : 0.856, Sensitive_Loss : 0.15250, Sensitive_Acc : 26.200, Run Time : 16.66 sec
INFO:root:2024-04-16 16:42:37, Train, Epoch : 8, Step : 4660, Loss : 0.29175, Acc : 0.894, Sensitive_Loss : 0.10439, Sensitive_Acc : 24.500, Run Time : 18.99 sec
INFO:root:2024-04-16 16:42:54, Train, Epoch : 8, Step : 4670, Loss : 0.28016, Acc : 0.869, Sensitive_Loss : 0.07851, Sensitive_Acc : 21.500, Run Time : 16.95 sec
INFO:root:2024-04-16 16:43:12, Train, Epoch : 8, Step : 4680, Loss : 0.34117, Acc : 0.850, Sensitive_Loss : 0.06691, Sensitive_Acc : 22.300, Run Time : 18.13 sec
INFO:root:2024-04-16 16:43:29, Train, Epoch : 8, Step : 4690, Loss : 0.32318, Acc : 0.878, Sensitive_Loss : 0.08216, Sensitive_Acc : 23.000, Run Time : 16.92 sec
INFO:root:2024-04-16 16:43:45, Train, Epoch : 8, Step : 4700, Loss : 0.34072, Acc : 0.834, Sensitive_Loss : 0.12316, Sensitive_Acc : 23.900, Run Time : 16.84 sec
INFO:root:2024-04-16 16:47:37, Dev, Step : 4700, Loss : 0.57741, Acc : 0.765, Auc : 0.847, Sensitive_Loss : 0.19835, Sensitive_Acc : 21.286, Sensitive_Auc : 0.996, Mean auc: 0.847, Run Time : 231.61 sec
INFO:root:2024-04-16 16:47:51, Train, Epoch : 8, Step : 4710, Loss : 0.35214, Acc : 0.872, Sensitive_Loss : 0.14342, Sensitive_Acc : 20.900, Run Time : 245.32 sec
INFO:root:2024-04-16 16:48:07, Train, Epoch : 8, Step : 4720, Loss : 0.34271, Acc : 0.847, Sensitive_Loss : 0.11691, Sensitive_Acc : 22.300, Run Time : 16.42 sec
INFO:root:2024-04-16 16:48:24, Train, Epoch : 8, Step : 4730, Loss : 0.31190, Acc : 0.891, Sensitive_Loss : 0.10852, Sensitive_Acc : 21.000, Run Time : 16.42 sec
INFO:root:2024-04-16 16:48:41, Train, Epoch : 8, Step : 4740, Loss : 0.33021, Acc : 0.859, Sensitive_Loss : 0.11526, Sensitive_Acc : 24.800, Run Time : 17.36 sec
INFO:root:2024-04-16 16:48:58, Train, Epoch : 8, Step : 4750, Loss : 0.33755, Acc : 0.844, Sensitive_Loss : 0.09640, Sensitive_Acc : 23.300, Run Time : 17.33 sec
INFO:root:2024-04-16 16:49:16, Train, Epoch : 8, Step : 4760, Loss : 0.36334, Acc : 0.844, Sensitive_Loss : 0.11237, Sensitive_Acc : 18.900, Run Time : 18.00 sec
INFO:root:2024-04-16 16:49:34, Train, Epoch : 8, Step : 4770, Loss : 0.30876, Acc : 0.856, Sensitive_Loss : 0.17365, Sensitive_Acc : 24.000, Run Time : 17.28 sec
INFO:root:2024-04-16 16:49:52, Train, Epoch : 8, Step : 4780, Loss : 0.36238, Acc : 0.863, Sensitive_Loss : 0.08289, Sensitive_Acc : 18.100, Run Time : 18.12 sec
INFO:root:2024-04-16 16:50:09, Train, Epoch : 8, Step : 4790, Loss : 0.31745, Acc : 0.869, Sensitive_Loss : 0.09153, Sensitive_Acc : 24.100, Run Time : 17.77 sec
INFO:root:2024-04-16 16:50:25, Train, Epoch : 8, Step : 4800, Loss : 0.35974, Acc : 0.850, Sensitive_Loss : 0.11323, Sensitive_Acc : 21.800, Run Time : 15.95 sec
INFO:root:2024-04-16 16:54:18, Dev, Step : 4800, Loss : 0.61133, Acc : 0.763, Auc : 0.848, Sensitive_Loss : 0.20119, Sensitive_Acc : 21.301, Sensitive_Auc : 0.997, Mean auc: 0.848, Run Time : 232.89 sec
INFO:root:2024-04-16 16:54:30, Train, Epoch : 8, Step : 4810, Loss : 0.44012, Acc : 0.803, Sensitive_Loss : 0.09702, Sensitive_Acc : 18.000, Run Time : 245.00 sec
INFO:root:2024-04-16 16:54:49, Train, Epoch : 8, Step : 4820, Loss : 0.32244, Acc : 0.834, Sensitive_Loss : 0.07173, Sensitive_Acc : 24.400, Run Time : 18.65 sec
INFO:root:2024-04-16 16:55:07, Train, Epoch : 8, Step : 4830, Loss : 0.35554, Acc : 0.875, Sensitive_Loss : 0.08582, Sensitive_Acc : 23.100, Run Time : 18.31 sec
INFO:root:2024-04-16 16:55:23, Train, Epoch : 8, Step : 4840, Loss : 0.31000, Acc : 0.881, Sensitive_Loss : 0.09105, Sensitive_Acc : 20.800, Run Time : 15.72 sec
INFO:root:2024-04-16 16:55:41, Train, Epoch : 8, Step : 4850, Loss : 0.33231, Acc : 0.866, Sensitive_Loss : 0.12360, Sensitive_Acc : 22.200, Run Time : 17.81 sec
INFO:root:2024-04-16 16:55:58, Train, Epoch : 8, Step : 4860, Loss : 0.32327, Acc : 0.875, Sensitive_Loss : 0.07843, Sensitive_Acc : 20.400, Run Time : 17.33 sec
INFO:root:2024-04-16 16:56:16, Train, Epoch : 8, Step : 4870, Loss : 0.36903, Acc : 0.844, Sensitive_Loss : 0.09678, Sensitive_Acc : 21.200, Run Time : 17.45 sec
INFO:root:2024-04-16 16:56:33, Train, Epoch : 8, Step : 4880, Loss : 0.39456, Acc : 0.816, Sensitive_Loss : 0.08214, Sensitive_Acc : 24.200, Run Time : 17.19 sec
INFO:root:2024-04-16 16:56:50, Train, Epoch : 8, Step : 4890, Loss : 0.35039, Acc : 0.816, Sensitive_Loss : 0.07866, Sensitive_Acc : 18.200, Run Time : 17.40 sec
INFO:root:2024-04-16 16:57:10, Train, Epoch : 8, Step : 4900, Loss : 0.32080, Acc : 0.856, Sensitive_Loss : 0.08956, Sensitive_Acc : 19.600, Run Time : 19.52 sec
INFO:root:2024-04-16 17:01:02, Dev, Step : 4900, Loss : 0.55813, Acc : 0.773, Auc : 0.852, Sensitive_Loss : 0.19697, Sensitive_Acc : 21.286, Sensitive_Auc : 0.997, Mean auc: 0.852, Run Time : 232.01 sec
INFO:root:2024-04-16 17:01:14, Train, Epoch : 8, Step : 4910, Loss : 0.26579, Acc : 0.887, Sensitive_Loss : 0.15840, Sensitive_Acc : 19.300, Run Time : 244.00 sec
INFO:root:2024-04-16 17:01:32, Train, Epoch : 8, Step : 4920, Loss : 0.41796, Acc : 0.822, Sensitive_Loss : 0.09987, Sensitive_Acc : 19.700, Run Time : 18.16 sec
INFO:root:2024-04-16 17:01:49, Train, Epoch : 8, Step : 4930, Loss : 0.35667, Acc : 0.856, Sensitive_Loss : 0.11034, Sensitive_Acc : 21.600, Run Time : 17.49 sec
INFO:root:2024-04-16 17:02:06, Train, Epoch : 8, Step : 4940, Loss : 0.40342, Acc : 0.831, Sensitive_Loss : 0.09567, Sensitive_Acc : 21.800, Run Time : 16.63 sec
INFO:root:2024-04-16 17:02:24, Train, Epoch : 8, Step : 4950, Loss : 0.25645, Acc : 0.891, Sensitive_Loss : 0.08314, Sensitive_Acc : 18.900, Run Time : 18.31 sec
INFO:root:2024-04-16 17:02:42, Train, Epoch : 8, Step : 4960, Loss : 0.28026, Acc : 0.906, Sensitive_Loss : 0.08352, Sensitive_Acc : 22.300, Run Time : 17.37 sec
INFO:root:2024-04-16 17:02:58, Train, Epoch : 8, Step : 4970, Loss : 0.30559, Acc : 0.872, Sensitive_Loss : 0.11346, Sensitive_Acc : 21.200, Run Time : 16.62 sec
INFO:root:2024-04-16 17:03:17, Train, Epoch : 8, Step : 4980, Loss : 0.39651, Acc : 0.819, Sensitive_Loss : 0.09292, Sensitive_Acc : 16.200, Run Time : 18.63 sec
INFO:root:2024-04-16 17:03:33, Train, Epoch : 8, Step : 4990, Loss : 0.38083, Acc : 0.847, Sensitive_Loss : 0.09180, Sensitive_Acc : 20.400, Run Time : 15.60 sec
INFO:root:2024-04-16 17:03:51, Train, Epoch : 8, Step : 5000, Loss : 0.38634, Acc : 0.841, Sensitive_Loss : 0.08877, Sensitive_Acc : 22.200, Run Time : 18.38 sec
INFO:root:2024-04-16 17:07:44, Dev, Step : 5000, Loss : 0.57913, Acc : 0.766, Auc : 0.848, Sensitive_Loss : 0.18989, Sensitive_Acc : 21.406, Sensitive_Auc : 0.997, Mean auc: 0.848, Run Time : 232.96 sec
INFO:root:2024-04-16 17:07:57, Train, Epoch : 8, Step : 5010, Loss : 0.41569, Acc : 0.847, Sensitive_Loss : 0.11803, Sensitive_Acc : 21.900, Run Time : 246.08 sec
INFO:root:2024-04-16 17:08:15, Train, Epoch : 8, Step : 5020, Loss : 0.30781, Acc : 0.884, Sensitive_Loss : 0.07737, Sensitive_Acc : 20.200, Run Time : 17.70 sec
INFO:root:2024-04-16 17:08:32, Train, Epoch : 8, Step : 5030, Loss : 0.39963, Acc : 0.816, Sensitive_Loss : 0.10631, Sensitive_Acc : 21.000, Run Time : 17.53 sec
INFO:root:2024-04-16 17:08:51, Train, Epoch : 8, Step : 5040, Loss : 0.32644, Acc : 0.844, Sensitive_Loss : 0.12526, Sensitive_Acc : 23.000, Run Time : 18.46 sec
INFO:root:2024-04-16 17:09:07, Train, Epoch : 8, Step : 5050, Loss : 0.28582, Acc : 0.834, Sensitive_Loss : 0.09261, Sensitive_Acc : 16.300, Run Time : 16.48 sec
INFO:root:2024-04-16 17:09:25, Train, Epoch : 8, Step : 5060, Loss : 0.32832, Acc : 0.878, Sensitive_Loss : 0.09819, Sensitive_Acc : 19.500, Run Time : 18.09 sec
INFO:root:2024-04-16 17:09:42, Train, Epoch : 8, Step : 5070, Loss : 0.30552, Acc : 0.841, Sensitive_Loss : 0.11223, Sensitive_Acc : 19.800, Run Time : 16.64 sec
INFO:root:2024-04-16 17:13:34
INFO:root:y_pred: [0.12067781 0.00094883 0.07324915 ... 0.04868476 0.07944109 0.08539333]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [9.8090986e-06 4.0312347e-04 6.1981045e-03 5.0216671e-02 1.5139002e-02
 9.1961265e-05 1.3271050e-03 5.6300039e-04 1.6817013e-02 9.9985373e-01
 1.2746136e-01 2.7117142e-04 1.1851359e-04 8.3844946e-04 9.9865627e-01
 9.4952835e-03 2.9165262e-02 9.9972278e-01 9.9995387e-01 9.0853072e-04
 9.9356681e-01 1.1692785e-03 2.6591392e-03 6.5292791e-04 4.5063335e-02
 1.0708313e-01 1.3369798e-05 2.1171432e-04 1.6683945e-03 1.1226952e-02
 6.7007229e-02 9.9042821e-01 1.2346847e-02 9.6570665e-01 6.2152999e-04
 2.2724435e-05 1.8851606e-03 1.6414706e-01 6.3417870e-01 3.0870230e-03
 3.1240823e-02 9.7438681e-01 3.2048088e-03 3.6097155e-03 9.9991119e-01
 7.2987033e-03 2.1535261e-01 4.9847355e-01 1.4219588e-01 9.9790633e-01
 9.9886024e-01 9.9995089e-01 9.9992716e-01 4.9466784e-05 4.6604708e-02
 4.8774362e-02 1.4065953e-03 1.8457896e-03 9.8668110e-01 3.4044377e-04
 3.5610508e-05 1.2617200e-02 1.4262056e-03 1.3937827e-05 9.9975663e-01
 2.1164818e-01 8.7427726e-04 4.9993193e-01 3.1449534e-03 9.8191535e-01
 9.9997592e-01 9.9991333e-01 1.6021747e-04 7.3719138e-01 9.0086157e-04
 4.1924006e-01 2.4302283e-03 6.4689571e-06 1.0821509e-06 1.2356867e-03
 4.8647232e-02 2.7325805e-04 9.9972612e-01 9.9471456e-01 6.6402419e-03
 1.3108034e-01 1.3965792e-02 5.6838329e-05 2.8735157e-02 1.7013630e-02
 1.9595118e-03 6.8419576e-02 5.1665283e-04 3.4459052e-05 7.6450506e-04
 2.1905869e-03 9.3469495e-04 3.7257645e-01 3.3860395e-04 6.8065934e-03
 1.4562340e-04 7.4481615e-03 3.3109418e-01 5.6514344e-03 1.8811714e-03
 9.6085027e-04 1.1827752e-02 7.3754869e-02 2.8453258e-01 1.3757095e-03
 4.6901588e-04 9.9999225e-01 9.9981004e-01 2.3069628e-05 3.0877399e-01
 4.6034106e-03 4.1992793e-05 7.1769937e-05 6.8486962e-03 2.7884936e-04
 1.4000629e-03 9.5641379e-05 3.1094804e-02 4.5201141e-05 6.4553047e-04
 9.0927368e-01 6.9011119e-05 9.9514043e-01 6.8283775e-03 2.7613955e-02
 5.9525919e-05 1.1828427e-02 1.0779669e-06]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-16 17:13:34, Dev, Step : 5072, Loss : 0.55767, Acc : 0.771, Auc : 0.848, Sensitive_Loss : 0.19465, Sensitive_Acc : 21.782, Sensitive_Auc : 0.998, Mean auc: 0.848, Run Time : 230.29 sec
INFO:root:2024-04-16 17:13:53, Train, Epoch : 9, Step : 5080, Loss : 0.20342, Acc : 0.713, Sensitive_Loss : 0.13770, Sensitive_Acc : 15.500, Run Time : 17.34 sec
INFO:root:2024-04-16 17:14:11, Train, Epoch : 9, Step : 5090, Loss : 0.26531, Acc : 0.884, Sensitive_Loss : 0.06403, Sensitive_Acc : 21.200, Run Time : 18.36 sec
INFO:root:2024-04-16 17:14:28, Train, Epoch : 9, Step : 5100, Loss : 0.26796, Acc : 0.903, Sensitive_Loss : 0.07607, Sensitive_Acc : 20.600, Run Time : 16.82 sec
INFO:root:2024-04-16 17:18:20, Dev, Step : 5100, Loss : 0.55859, Acc : 0.770, Auc : 0.849, Sensitive_Loss : 0.18666, Sensitive_Acc : 21.662, Sensitive_Auc : 0.997, Mean auc: 0.849, Run Time : 231.62 sec
INFO:root:2024-04-16 17:18:33, Train, Epoch : 9, Step : 5110, Loss : 0.37204, Acc : 0.856, Sensitive_Loss : 0.13356, Sensitive_Acc : 24.900, Run Time : 245.19 sec
INFO:root:2024-04-16 17:18:51, Train, Epoch : 9, Step : 5120, Loss : 0.31800, Acc : 0.844, Sensitive_Loss : 0.11506, Sensitive_Acc : 25.300, Run Time : 17.36 sec
INFO:root:2024-04-16 17:19:08, Train, Epoch : 9, Step : 5130, Loss : 0.31820, Acc : 0.866, Sensitive_Loss : 0.11076, Sensitive_Acc : 17.900, Run Time : 17.37 sec
INFO:root:2024-04-16 17:19:25, Train, Epoch : 9, Step : 5140, Loss : 0.33525, Acc : 0.869, Sensitive_Loss : 0.11075, Sensitive_Acc : 18.200, Run Time : 16.87 sec
INFO:root:2024-04-16 17:19:44, Train, Epoch : 9, Step : 5150, Loss : 0.33306, Acc : 0.866, Sensitive_Loss : 0.09100, Sensitive_Acc : 24.800, Run Time : 19.14 sec
INFO:root:2024-04-16 17:20:01, Train, Epoch : 9, Step : 5160, Loss : 0.30360, Acc : 0.881, Sensitive_Loss : 0.07843, Sensitive_Acc : 22.600, Run Time : 17.41 sec
INFO:root:2024-04-16 17:20:20, Train, Epoch : 9, Step : 5170, Loss : 0.36872, Acc : 0.847, Sensitive_Loss : 0.10120, Sensitive_Acc : 20.800, Run Time : 18.45 sec
INFO:root:2024-04-16 17:20:37, Train, Epoch : 9, Step : 5180, Loss : 0.34005, Acc : 0.859, Sensitive_Loss : 0.10774, Sensitive_Acc : 18.200, Run Time : 17.50 sec
INFO:root:2024-04-16 17:20:55, Train, Epoch : 9, Step : 5190, Loss : 0.32717, Acc : 0.863, Sensitive_Loss : 0.08570, Sensitive_Acc : 20.600, Run Time : 17.21 sec
INFO:root:2024-04-16 17:21:11, Train, Epoch : 9, Step : 5200, Loss : 0.27650, Acc : 0.872, Sensitive_Loss : 0.12457, Sensitive_Acc : 23.700, Run Time : 16.84 sec
INFO:root:2024-04-16 17:25:05, Dev, Step : 5200, Loss : 0.57361, Acc : 0.769, Auc : 0.847, Sensitive_Loss : 0.19014, Sensitive_Acc : 21.782, Sensitive_Auc : 0.997, Mean auc: 0.847, Run Time : 233.32 sec
INFO:root:2024-04-16 17:25:18, Train, Epoch : 9, Step : 5210, Loss : 0.31098, Acc : 0.863, Sensitive_Loss : 0.10167, Sensitive_Acc : 24.200, Run Time : 246.10 sec
INFO:root:2024-04-16 17:25:35, Train, Epoch : 9, Step : 5220, Loss : 0.30029, Acc : 0.894, Sensitive_Loss : 0.08617, Sensitive_Acc : 21.800, Run Time : 17.49 sec
INFO:root:2024-04-16 17:25:53, Train, Epoch : 9, Step : 5230, Loss : 0.24253, Acc : 0.919, Sensitive_Loss : 0.08870, Sensitive_Acc : 26.000, Run Time : 18.33 sec
INFO:root:2024-04-16 17:26:12, Train, Epoch : 9, Step : 5240, Loss : 0.29167, Acc : 0.881, Sensitive_Loss : 0.07820, Sensitive_Acc : 23.200, Run Time : 18.93 sec
INFO:root:2024-04-16 17:26:29, Train, Epoch : 9, Step : 5250, Loss : 0.31161, Acc : 0.853, Sensitive_Loss : 0.07380, Sensitive_Acc : 20.400, Run Time : 16.78 sec
INFO:root:2024-04-16 17:26:47, Train, Epoch : 9, Step : 5260, Loss : 0.34426, Acc : 0.822, Sensitive_Loss : 0.06432, Sensitive_Acc : 22.500, Run Time : 17.86 sec
INFO:root:2024-04-16 17:27:05, Train, Epoch : 9, Step : 5270, Loss : 0.36820, Acc : 0.856, Sensitive_Loss : 0.10930, Sensitive_Acc : 17.100, Run Time : 18.02 sec
INFO:root:2024-04-16 17:27:22, Train, Epoch : 9, Step : 5280, Loss : 0.30355, Acc : 0.884, Sensitive_Loss : 0.08129, Sensitive_Acc : 21.200, Run Time : 16.83 sec
INFO:root:2024-04-16 17:27:41, Train, Epoch : 9, Step : 5290, Loss : 0.31761, Acc : 0.869, Sensitive_Loss : 0.10306, Sensitive_Acc : 25.300, Run Time : 18.80 sec
INFO:root:2024-04-16 17:27:58, Train, Epoch : 9, Step : 5300, Loss : 0.29908, Acc : 0.887, Sensitive_Loss : 0.11395, Sensitive_Acc : 23.100, Run Time : 17.81 sec
INFO:root:2024-04-16 17:31:50, Dev, Step : 5300, Loss : 0.58504, Acc : 0.765, Auc : 0.845, Sensitive_Loss : 0.21867, Sensitive_Acc : 21.195, Sensitive_Auc : 0.998, Mean auc: 0.845, Run Time : 231.77 sec
INFO:root:2024-04-16 17:32:04, Train, Epoch : 9, Step : 5310, Loss : 0.30437, Acc : 0.875, Sensitive_Loss : 0.10133, Sensitive_Acc : 23.400, Run Time : 245.59 sec
INFO:root:2024-04-16 17:32:22, Train, Epoch : 9, Step : 5320, Loss : 0.31171, Acc : 0.869, Sensitive_Loss : 0.09701, Sensitive_Acc : 23.000, Run Time : 18.37 sec
INFO:root:2024-04-16 17:32:39, Train, Epoch : 9, Step : 5330, Loss : 0.27158, Acc : 0.884, Sensitive_Loss : 0.05625, Sensitive_Acc : 24.100, Run Time : 16.98 sec
INFO:root:2024-04-16 17:32:57, Train, Epoch : 9, Step : 5340, Loss : 0.28279, Acc : 0.881, Sensitive_Loss : 0.11486, Sensitive_Acc : 20.000, Run Time : 17.30 sec
INFO:root:2024-04-16 17:33:14, Train, Epoch : 9, Step : 5350, Loss : 0.28082, Acc : 0.863, Sensitive_Loss : 0.08409, Sensitive_Acc : 22.000, Run Time : 17.70 sec
INFO:root:2024-04-16 17:33:32, Train, Epoch : 9, Step : 5360, Loss : 0.35993, Acc : 0.853, Sensitive_Loss : 0.09841, Sensitive_Acc : 23.700, Run Time : 17.81 sec
INFO:root:2024-04-16 17:33:49, Train, Epoch : 9, Step : 5370, Loss : 0.33428, Acc : 0.869, Sensitive_Loss : 0.12254, Sensitive_Acc : 21.700, Run Time : 16.81 sec
INFO:root:2024-04-16 17:34:07, Train, Epoch : 9, Step : 5380, Loss : 0.31220, Acc : 0.859, Sensitive_Loss : 0.13300, Sensitive_Acc : 20.100, Run Time : 17.84 sec
INFO:root:2024-04-16 17:34:25, Train, Epoch : 9, Step : 5390, Loss : 0.37486, Acc : 0.844, Sensitive_Loss : 0.09361, Sensitive_Acc : 18.200, Run Time : 17.85 sec
INFO:root:2024-04-16 17:34:43, Train, Epoch : 9, Step : 5400, Loss : 0.30473, Acc : 0.872, Sensitive_Loss : 0.10985, Sensitive_Acc : 24.400, Run Time : 18.84 sec
INFO:root:2024-04-16 17:38:35, Dev, Step : 5400, Loss : 0.58539, Acc : 0.765, Auc : 0.846, Sensitive_Loss : 0.20089, Sensitive_Acc : 21.316, Sensitive_Auc : 0.998, Mean auc: 0.846, Run Time : 231.60 sec
INFO:root:2024-04-16 17:38:49, Train, Epoch : 9, Step : 5410, Loss : 0.32060, Acc : 0.838, Sensitive_Loss : 0.07971, Sensitive_Acc : 18.800, Run Time : 245.13 sec
INFO:root:2024-04-16 17:39:07, Train, Epoch : 9, Step : 5420, Loss : 0.31473, Acc : 0.872, Sensitive_Loss : 0.10003, Sensitive_Acc : 24.100, Run Time : 18.43 sec
INFO:root:2024-04-16 17:39:25, Train, Epoch : 9, Step : 5430, Loss : 0.29684, Acc : 0.856, Sensitive_Loss : 0.08643, Sensitive_Acc : 24.100, Run Time : 17.50 sec
INFO:root:2024-04-16 17:39:43, Train, Epoch : 9, Step : 5440, Loss : 0.25750, Acc : 0.881, Sensitive_Loss : 0.18570, Sensitive_Acc : 16.400, Run Time : 18.38 sec
INFO:root:2024-04-16 17:39:59, Train, Epoch : 9, Step : 5450, Loss : 0.36079, Acc : 0.844, Sensitive_Loss : 0.09235, Sensitive_Acc : 22.200, Run Time : 16.15 sec
INFO:root:2024-04-16 17:40:18, Train, Epoch : 9, Step : 5460, Loss : 0.34103, Acc : 0.859, Sensitive_Loss : 0.07381, Sensitive_Acc : 22.300, Run Time : 19.08 sec
INFO:root:2024-04-16 17:40:36, Train, Epoch : 9, Step : 5470, Loss : 0.38690, Acc : 0.844, Sensitive_Loss : 0.12110, Sensitive_Acc : 21.600, Run Time : 17.44 sec
INFO:root:2024-04-16 17:40:54, Train, Epoch : 9, Step : 5480, Loss : 0.38985, Acc : 0.838, Sensitive_Loss : 0.06031, Sensitive_Acc : 20.000, Run Time : 17.95 sec
INFO:root:2024-04-16 17:41:10, Train, Epoch : 9, Step : 5490, Loss : 0.27566, Acc : 0.884, Sensitive_Loss : 0.10140, Sensitive_Acc : 22.500, Run Time : 16.26 sec
INFO:root:2024-04-16 17:41:30, Train, Epoch : 9, Step : 5500, Loss : 0.37352, Acc : 0.872, Sensitive_Loss : 0.07612, Sensitive_Acc : 18.800, Run Time : 20.22 sec
INFO:root:2024-04-16 17:45:32, Dev, Step : 5500, Loss : 0.57634, Acc : 0.769, Auc : 0.843, Sensitive_Loss : 0.20667, Sensitive_Acc : 21.075, Sensitive_Auc : 0.997, Mean auc: 0.843, Run Time : 242.38 sec
INFO:root:2024-04-16 17:45:47, Train, Epoch : 9, Step : 5510, Loss : 0.28273, Acc : 0.878, Sensitive_Loss : 0.10439, Sensitive_Acc : 24.000, Run Time : 257.45 sec
INFO:root:2024-04-16 17:46:05, Train, Epoch : 9, Step : 5520, Loss : 0.38142, Acc : 0.844, Sensitive_Loss : 0.08162, Sensitive_Acc : 20.800, Run Time : 17.76 sec
INFO:root:2024-04-16 17:46:23, Train, Epoch : 9, Step : 5530, Loss : 0.26681, Acc : 0.872, Sensitive_Loss : 0.08417, Sensitive_Acc : 18.400, Run Time : 17.97 sec
INFO:root:2024-04-16 17:46:42, Train, Epoch : 9, Step : 5540, Loss : 0.39490, Acc : 0.800, Sensitive_Loss : 0.06063, Sensitive_Acc : 20.800, Run Time : 18.91 sec
INFO:root:2024-04-16 17:46:59, Train, Epoch : 9, Step : 5550, Loss : 0.30588, Acc : 0.875, Sensitive_Loss : 0.08375, Sensitive_Acc : 19.300, Run Time : 16.65 sec
INFO:root:2024-04-16 17:47:16, Train, Epoch : 9, Step : 5560, Loss : 0.32583, Acc : 0.856, Sensitive_Loss : 0.06401, Sensitive_Acc : 18.400, Run Time : 16.73 sec
INFO:root:2024-04-16 17:47:34, Train, Epoch : 9, Step : 5570, Loss : 0.31936, Acc : 0.863, Sensitive_Loss : 0.09000, Sensitive_Acc : 19.100, Run Time : 18.02 sec
INFO:root:2024-04-16 17:47:52, Train, Epoch : 9, Step : 5580, Loss : 0.28981, Acc : 0.887, Sensitive_Loss : 0.08739, Sensitive_Acc : 24.600, Run Time : 18.60 sec
INFO:root:2024-04-16 17:48:10, Train, Epoch : 9, Step : 5590, Loss : 0.33557, Acc : 0.856, Sensitive_Loss : 0.12028, Sensitive_Acc : 18.800, Run Time : 17.56 sec
INFO:root:2024-04-16 17:48:30, Train, Epoch : 9, Step : 5600, Loss : 0.40026, Acc : 0.812, Sensitive_Loss : 0.06602, Sensitive_Acc : 20.500, Run Time : 20.23 sec
INFO:root:2024-04-16 17:52:21, Dev, Step : 5600, Loss : 0.59289, Acc : 0.766, Auc : 0.843, Sensitive_Loss : 0.19039, Sensitive_Acc : 21.677, Sensitive_Auc : 0.997, Mean auc: 0.843, Run Time : 230.85 sec
INFO:root:2024-04-16 17:52:34, Train, Epoch : 9, Step : 5610, Loss : 0.25406, Acc : 0.891, Sensitive_Loss : 0.05569, Sensitive_Acc : 24.900, Run Time : 244.53 sec
INFO:root:2024-04-16 17:52:52, Train, Epoch : 9, Step : 5620, Loss : 0.24017, Acc : 0.863, Sensitive_Loss : 0.13947, Sensitive_Acc : 21.400, Run Time : 17.76 sec
INFO:root:2024-04-16 17:53:09, Train, Epoch : 9, Step : 5630, Loss : 0.39814, Acc : 0.831, Sensitive_Loss : 0.09594, Sensitive_Acc : 23.700, Run Time : 17.07 sec
INFO:root:2024-04-16 17:53:28, Train, Epoch : 9, Step : 5640, Loss : 0.31901, Acc : 0.856, Sensitive_Loss : 0.10981, Sensitive_Acc : 25.000, Run Time : 18.30 sec
INFO:root:2024-04-16 17:53:46, Train, Epoch : 9, Step : 5650, Loss : 0.37643, Acc : 0.859, Sensitive_Loss : 0.11287, Sensitive_Acc : 24.000, Run Time : 18.01 sec
INFO:root:2024-04-16 17:54:02, Train, Epoch : 9, Step : 5660, Loss : 0.27300, Acc : 0.900, Sensitive_Loss : 0.12330, Sensitive_Acc : 24.000, Run Time : 16.33 sec
INFO:root:2024-04-16 17:54:20, Train, Epoch : 9, Step : 5670, Loss : 0.27259, Acc : 0.894, Sensitive_Loss : 0.08200, Sensitive_Acc : 23.400, Run Time : 18.56 sec
INFO:root:2024-04-16 17:54:40, Train, Epoch : 9, Step : 5680, Loss : 0.26329, Acc : 0.887, Sensitive_Loss : 0.08227, Sensitive_Acc : 22.300, Run Time : 19.51 sec
INFO:root:2024-04-16 17:54:56, Train, Epoch : 9, Step : 5690, Loss : 0.32611, Acc : 0.887, Sensitive_Loss : 0.07140, Sensitive_Acc : 22.000, Run Time : 16.23 sec
INFO:root:2024-04-16 17:55:15, Train, Epoch : 9, Step : 5700, Loss : 0.32994, Acc : 0.847, Sensitive_Loss : 0.12288, Sensitive_Acc : 24.500, Run Time : 18.56 sec
INFO:root:2024-04-16 17:59:06, Dev, Step : 5700, Loss : 0.56565, Acc : 0.772, Auc : 0.849, Sensitive_Loss : 0.22293, Sensitive_Acc : 21.180, Sensitive_Auc : 0.997, Mean auc: 0.849, Run Time : 231.00 sec
INFO:root:2024-04-16 18:03:00
INFO:root:y_pred: [0.23248537 0.00075261 0.10198425 ... 0.06221185 0.04382927 0.04188138]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [7.10288532e-06 3.10937001e-04 7.21016014e-03 4.17328961e-02
 9.69253108e-03 8.21376452e-05 1.03622733e-03 1.31187902e-03
 2.57815160e-02 9.99850392e-01 2.00386599e-01 2.46065290e-04
 5.46596566e-05 9.47456108e-04 9.98814344e-01 1.57802589e-02
 5.60419597e-02 9.99712765e-01 9.99932528e-01 6.19272352e-04
 9.93920565e-01 1.15745724e-03 2.48505524e-03 5.50824217e-04
 5.83413318e-02 6.98595941e-02 9.66780590e-06 1.36426432e-04
 1.36173831e-03 6.19624276e-03 1.55708864e-01 9.92928207e-01
 2.50660349e-02 9.81072426e-01 3.98358679e-04 3.22481028e-05
 3.58388014e-03 1.89406335e-01 8.13117206e-01 2.41510989e-03
 5.76324761e-02 9.74891841e-01 7.09368102e-03 5.56763308e-03
 9.99794185e-01 6.06409134e-03 3.13647121e-01 7.84532249e-01
 1.94887727e-01 9.99481380e-01 9.98599231e-01 9.99968410e-01
 9.99927163e-01 5.46305710e-05 9.14374962e-02 4.43837494e-02
 6.91116555e-04 2.04578904e-03 9.90986407e-01 4.49325104e-04
 4.51366577e-05 1.02274055e-02 8.40154884e-04 1.11701838e-05
 9.99638915e-01 2.79663414e-01 3.03620822e-04 4.51091051e-01
 7.68735586e-03 9.95812356e-01 9.99963284e-01 9.99899149e-01
 1.35500886e-04 7.62663066e-01 9.98836826e-04 4.12620038e-01
 1.86951715e-03 2.12359409e-05 4.04916000e-06 6.70121168e-04
 6.31227195e-02 2.58829823e-04 9.99730647e-01 9.96753037e-01
 5.10825450e-03 1.02629706e-01 1.66443363e-02 3.91895082e-05
 2.64025144e-02 1.33845480e-02 2.37297965e-03 6.68524727e-02
 5.06681332e-04 3.36661033e-05 6.73974981e-04 5.88432001e-03
 1.17734901e-03 3.27093869e-01 1.33497792e-03 3.85360769e-03
 3.14119447e-04 1.92895308e-02 4.70173776e-01 9.63343401e-03
 1.39455451e-03 1.67616585e-03 1.32394694e-02 7.31601268e-02
 4.20504212e-01 2.48915562e-03 1.96853842e-04 9.99991775e-01
 9.99854565e-01 1.27656513e-05 3.08598071e-01 6.49608159e-03
 9.53632480e-05 6.01209584e-04 8.67651030e-03 7.88560021e-04
 2.66960007e-03 1.63659497e-04 3.34734209e-02 3.69240115e-05
 7.37095135e-04 8.10880423e-01 6.80101075e-05 9.95803416e-01
 9.82722919e-03 2.77144127e-02 5.33130915e-05 2.18874179e-02
 2.58761861e-06]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-16 18:03:00, Dev, Step : 5706, Loss : 0.57491, Acc : 0.772, Auc : 0.849, Sensitive_Loss : 0.19973, Sensitive_Acc : 21.662, Sensitive_Auc : 0.997, Mean auc: 0.849, Run Time : 229.45 sec
INFO:root:2024-04-16 18:03:10, Train, Epoch : 10, Step : 5710, Loss : 0.12425, Acc : 0.347, Sensitive_Loss : 0.02581, Sensitive_Acc : 9.800, Run Time : 8.66 sec
INFO:root:2024-04-16 18:03:28, Train, Epoch : 10, Step : 5720, Loss : 0.26637, Acc : 0.891, Sensitive_Loss : 0.11433, Sensitive_Acc : 22.800, Run Time : 18.19 sec
INFO:root:2024-04-16 18:03:46, Train, Epoch : 10, Step : 5730, Loss : 0.33758, Acc : 0.853, Sensitive_Loss : 0.08985, Sensitive_Acc : 21.500, Run Time : 18.50 sec
INFO:root:2024-04-16 18:04:04, Train, Epoch : 10, Step : 5740, Loss : 0.28790, Acc : 0.891, Sensitive_Loss : 0.06763, Sensitive_Acc : 18.000, Run Time : 17.65 sec
INFO:root:2024-04-16 18:04:21, Train, Epoch : 10, Step : 5750, Loss : 0.28396, Acc : 0.875, Sensitive_Loss : 0.06274, Sensitive_Acc : 23.500, Run Time : 17.13 sec
INFO:root:2024-04-16 18:04:40, Train, Epoch : 10, Step : 5760, Loss : 0.26201, Acc : 0.900, Sensitive_Loss : 0.09790, Sensitive_Acc : 18.900, Run Time : 19.25 sec
INFO:root:2024-04-16 18:04:58, Train, Epoch : 10, Step : 5770, Loss : 0.29929, Acc : 0.872, Sensitive_Loss : 0.08143, Sensitive_Acc : 21.600, Run Time : 17.55 sec
INFO:root:2024-04-16 18:05:16, Train, Epoch : 10, Step : 5780, Loss : 0.28948, Acc : 0.853, Sensitive_Loss : 0.10633, Sensitive_Acc : 19.500, Run Time : 18.40 sec
INFO:root:2024-04-16 18:05:34, Train, Epoch : 10, Step : 5790, Loss : 0.27049, Acc : 0.900, Sensitive_Loss : 0.08598, Sensitive_Acc : 25.100, Run Time : 17.74 sec
INFO:root:2024-04-16 18:05:50, Train, Epoch : 10, Step : 5800, Loss : 0.25259, Acc : 0.884, Sensitive_Loss : 0.03739, Sensitive_Acc : 19.600, Run Time : 16.35 sec
INFO:root:2024-04-16 18:09:43, Dev, Step : 5800, Loss : 0.58190, Acc : 0.766, Auc : 0.846, Sensitive_Loss : 0.18913, Sensitive_Acc : 21.662, Sensitive_Auc : 0.997, Mean auc: 0.846, Run Time : 232.82 sec
INFO:root:2024-04-16 18:09:56, Train, Epoch : 10, Step : 5810, Loss : 0.24553, Acc : 0.909, Sensitive_Loss : 0.07268, Sensitive_Acc : 18.000, Run Time : 245.21 sec
INFO:root:2024-04-16 18:10:13, Train, Epoch : 10, Step : 5820, Loss : 0.34032, Acc : 0.859, Sensitive_Loss : 0.11679, Sensitive_Acc : 24.200, Run Time : 17.77 sec
INFO:root:2024-04-16 18:10:31, Train, Epoch : 10, Step : 5830, Loss : 0.23893, Acc : 0.900, Sensitive_Loss : 0.08797, Sensitive_Acc : 22.400, Run Time : 17.94 sec
INFO:root:2024-04-16 18:10:51, Train, Epoch : 10, Step : 5840, Loss : 0.27335, Acc : 0.866, Sensitive_Loss : 0.11055, Sensitive_Acc : 21.300, Run Time : 19.52 sec
INFO:root:2024-04-16 18:11:09, Train, Epoch : 10, Step : 5850, Loss : 0.28894, Acc : 0.878, Sensitive_Loss : 0.07769, Sensitive_Acc : 19.900, Run Time : 17.97 sec
INFO:root:2024-04-16 18:11:27, Train, Epoch : 10, Step : 5860, Loss : 0.28068, Acc : 0.863, Sensitive_Loss : 0.09499, Sensitive_Acc : 26.800, Run Time : 17.79 sec
INFO:root:2024-04-16 18:11:44, Train, Epoch : 10, Step : 5870, Loss : 0.31275, Acc : 0.872, Sensitive_Loss : 0.06064, Sensitive_Acc : 21.000, Run Time : 17.72 sec
INFO:root:2024-04-16 18:12:02, Train, Epoch : 10, Step : 5880, Loss : 0.26293, Acc : 0.894, Sensitive_Loss : 0.08522, Sensitive_Acc : 20.000, Run Time : 17.67 sec
INFO:root:2024-04-16 18:12:18, Train, Epoch : 10, Step : 5890, Loss : 0.23620, Acc : 0.900, Sensitive_Loss : 0.04996, Sensitive_Acc : 14.800, Run Time : 16.32 sec
INFO:root:2024-04-16 18:12:36, Train, Epoch : 10, Step : 5900, Loss : 0.30507, Acc : 0.884, Sensitive_Loss : 0.09155, Sensitive_Acc : 24.500, Run Time : 17.70 sec
INFO:root:2024-04-16 18:16:28, Dev, Step : 5900, Loss : 0.61266, Acc : 0.761, Auc : 0.839, Sensitive_Loss : 0.18807, Sensitive_Acc : 21.662, Sensitive_Auc : 0.998, Mean auc: 0.839, Run Time : 232.24 sec
INFO:root:2024-04-16 18:16:42, Train, Epoch : 10, Step : 5910, Loss : 0.28861, Acc : 0.887, Sensitive_Loss : 0.07688, Sensitive_Acc : 18.700, Run Time : 245.71 sec
INFO:root:2024-04-16 18:16:59, Train, Epoch : 10, Step : 5920, Loss : 0.29967, Acc : 0.863, Sensitive_Loss : 0.09029, Sensitive_Acc : 24.800, Run Time : 17.30 sec
INFO:root:2024-04-16 18:17:18, Train, Epoch : 10, Step : 5930, Loss : 0.28849, Acc : 0.900, Sensitive_Loss : 0.05918, Sensitive_Acc : 21.500, Run Time : 19.10 sec
INFO:root:2024-04-16 18:17:35, Train, Epoch : 10, Step : 5940, Loss : 0.27333, Acc : 0.903, Sensitive_Loss : 0.08952, Sensitive_Acc : 22.000, Run Time : 16.38 sec
INFO:root:2024-04-16 18:17:53, Train, Epoch : 10, Step : 5950, Loss : 0.29778, Acc : 0.863, Sensitive_Loss : 0.09014, Sensitive_Acc : 18.400, Run Time : 18.22 sec
INFO:root:2024-04-16 18:18:12, Train, Epoch : 10, Step : 5960, Loss : 0.27940, Acc : 0.887, Sensitive_Loss : 0.05878, Sensitive_Acc : 18.000, Run Time : 18.67 sec
INFO:root:2024-04-16 18:18:26, Train, Epoch : 10, Step : 5970, Loss : 0.33845, Acc : 0.844, Sensitive_Loss : 0.07612, Sensitive_Acc : 24.200, Run Time : 14.92 sec
INFO:root:2024-04-16 18:18:46, Train, Epoch : 10, Step : 5980, Loss : 0.34648, Acc : 0.850, Sensitive_Loss : 0.08043, Sensitive_Acc : 25.200, Run Time : 19.61 sec
INFO:root:2024-04-16 18:19:03, Train, Epoch : 10, Step : 5990, Loss : 0.31822, Acc : 0.834, Sensitive_Loss : 0.16339, Sensitive_Acc : 22.100, Run Time : 16.99 sec
INFO:root:2024-04-16 18:19:21, Train, Epoch : 10, Step : 6000, Loss : 0.31126, Acc : 0.841, Sensitive_Loss : 0.09869, Sensitive_Acc : 25.200, Run Time : 17.75 sec
INFO:root:2024-04-16 18:23:13, Dev, Step : 6000, Loss : 0.67483, Acc : 0.754, Auc : 0.840, Sensitive_Loss : 0.18808, Sensitive_Acc : 21.662, Sensitive_Auc : 0.998, Mean auc: 0.840, Run Time : 232.65 sec
INFO:root:2024-04-16 18:23:26, Train, Epoch : 10, Step : 6010, Loss : 0.28302, Acc : 0.884, Sensitive_Loss : 0.09208, Sensitive_Acc : 14.200, Run Time : 245.48 sec
INFO:root:2024-04-16 18:23:44, Train, Epoch : 10, Step : 6020, Loss : 0.25270, Acc : 0.897, Sensitive_Loss : 0.07560, Sensitive_Acc : 23.400, Run Time : 17.36 sec
INFO:root:2024-04-16 18:24:02, Train, Epoch : 10, Step : 6030, Loss : 0.26081, Acc : 0.900, Sensitive_Loss : 0.05281, Sensitive_Acc : 22.100, Run Time : 18.23 sec
INFO:root:2024-04-16 18:24:20, Train, Epoch : 10, Step : 6040, Loss : 0.22434, Acc : 0.916, Sensitive_Loss : 0.14975, Sensitive_Acc : 25.900, Run Time : 17.88 sec
INFO:root:2024-04-16 18:24:38, Train, Epoch : 10, Step : 6050, Loss : 0.25962, Acc : 0.884, Sensitive_Loss : 0.11341, Sensitive_Acc : 26.000, Run Time : 17.77 sec
INFO:root:2024-04-16 18:24:56, Train, Epoch : 10, Step : 6060, Loss : 0.28721, Acc : 0.869, Sensitive_Loss : 0.06269, Sensitive_Acc : 21.200, Run Time : 18.03 sec
INFO:root:2024-04-16 18:25:13, Train, Epoch : 10, Step : 6070, Loss : 0.29123, Acc : 0.881, Sensitive_Loss : 0.08898, Sensitive_Acc : 20.600, Run Time : 17.22 sec
INFO:root:2024-04-16 18:25:30, Train, Epoch : 10, Step : 6080, Loss : 0.27870, Acc : 0.863, Sensitive_Loss : 0.10762, Sensitive_Acc : 21.900, Run Time : 17.72 sec
INFO:root:2024-04-16 18:25:47, Train, Epoch : 10, Step : 6090, Loss : 0.26421, Acc : 0.878, Sensitive_Loss : 0.08665, Sensitive_Acc : 18.800, Run Time : 16.96 sec
INFO:root:2024-04-16 18:26:06, Train, Epoch : 10, Step : 6100, Loss : 0.23902, Acc : 0.903, Sensitive_Loss : 0.06651, Sensitive_Acc : 22.400, Run Time : 18.10 sec
INFO:root:2024-04-16 18:29:58, Dev, Step : 6100, Loss : 0.66601, Acc : 0.760, Auc : 0.842, Sensitive_Loss : 0.20068, Sensitive_Acc : 21.556, Sensitive_Auc : 0.998, Mean auc: 0.842, Run Time : 232.72 sec
INFO:root:2024-04-16 18:30:11, Train, Epoch : 10, Step : 6110, Loss : 0.25608, Acc : 0.897, Sensitive_Loss : 0.12501, Sensitive_Acc : 23.800, Run Time : 245.49 sec
INFO:root:2024-04-16 18:30:30, Train, Epoch : 10, Step : 6120, Loss : 0.31505, Acc : 0.847, Sensitive_Loss : 0.13821, Sensitive_Acc : 18.400, Run Time : 18.71 sec
INFO:root:2024-04-16 18:30:48, Train, Epoch : 10, Step : 6130, Loss : 0.26906, Acc : 0.863, Sensitive_Loss : 0.08336, Sensitive_Acc : 19.900, Run Time : 18.37 sec
INFO:root:2024-04-16 18:31:04, Train, Epoch : 10, Step : 6140, Loss : 0.30321, Acc : 0.863, Sensitive_Loss : 0.13592, Sensitive_Acc : 22.800, Run Time : 15.64 sec
INFO:root:2024-04-16 18:31:21, Train, Epoch : 10, Step : 6150, Loss : 0.32968, Acc : 0.894, Sensitive_Loss : 0.07651, Sensitive_Acc : 22.500, Run Time : 17.63 sec
INFO:root:2024-04-16 18:31:40, Train, Epoch : 10, Step : 6160, Loss : 0.29377, Acc : 0.863, Sensitive_Loss : 0.04265, Sensitive_Acc : 21.200, Run Time : 18.84 sec
INFO:root:2024-04-16 18:31:59, Train, Epoch : 10, Step : 6170, Loss : 0.31033, Acc : 0.887, Sensitive_Loss : 0.08263, Sensitive_Acc : 23.600, Run Time : 18.50 sec
INFO:root:2024-04-16 18:32:16, Train, Epoch : 10, Step : 6180, Loss : 0.27934, Acc : 0.881, Sensitive_Loss : 0.05095, Sensitive_Acc : 19.500, Run Time : 17.52 sec
INFO:root:2024-04-16 18:32:34, Train, Epoch : 10, Step : 6190, Loss : 0.32257, Acc : 0.878, Sensitive_Loss : 0.09897, Sensitive_Acc : 22.700, Run Time : 17.69 sec
INFO:root:2024-04-16 18:32:51, Train, Epoch : 10, Step : 6200, Loss : 0.27089, Acc : 0.891, Sensitive_Loss : 0.12853, Sensitive_Acc : 16.800, Run Time : 17.08 sec
INFO:root:2024-04-16 18:36:43, Dev, Step : 6200, Loss : 0.60265, Acc : 0.768, Auc : 0.842, Sensitive_Loss : 0.19085, Sensitive_Acc : 21.662, Sensitive_Auc : 0.997, Mean auc: 0.842, Run Time : 232.49 sec
INFO:root:2024-04-16 18:36:56, Train, Epoch : 10, Step : 6210, Loss : 0.28553, Acc : 0.878, Sensitive_Loss : 0.08697, Sensitive_Acc : 17.600, Run Time : 245.36 sec
INFO:root:2024-04-16 18:37:15, Train, Epoch : 10, Step : 6220, Loss : 0.28998, Acc : 0.878, Sensitive_Loss : 0.08112, Sensitive_Acc : 21.900, Run Time : 18.50 sec
INFO:root:2024-04-16 18:37:31, Train, Epoch : 10, Step : 6230, Loss : 0.33862, Acc : 0.872, Sensitive_Loss : 0.08702, Sensitive_Acc : 19.400, Run Time : 15.82 sec
INFO:root:2024-04-16 18:37:50, Train, Epoch : 10, Step : 6240, Loss : 0.25923, Acc : 0.894, Sensitive_Loss : 0.15216, Sensitive_Acc : 26.200, Run Time : 19.21 sec
INFO:root:2024-04-16 18:38:07, Train, Epoch : 10, Step : 6250, Loss : 0.31911, Acc : 0.891, Sensitive_Loss : 0.09378, Sensitive_Acc : 25.100, Run Time : 16.83 sec
INFO:root:2024-04-16 18:38:26, Train, Epoch : 10, Step : 6260, Loss : 0.27252, Acc : 0.872, Sensitive_Loss : 0.09960, Sensitive_Acc : 19.100, Run Time : 19.35 sec
INFO:root:2024-04-16 18:38:45, Train, Epoch : 10, Step : 6270, Loss : 0.26079, Acc : 0.887, Sensitive_Loss : 0.07592, Sensitive_Acc : 24.400, Run Time : 18.53 sec
INFO:root:2024-04-16 18:39:02, Train, Epoch : 10, Step : 6280, Loss : 0.32868, Acc : 0.866, Sensitive_Loss : 0.09025, Sensitive_Acc : 22.700, Run Time : 17.55 sec
INFO:root:2024-04-16 18:39:19, Train, Epoch : 10, Step : 6290, Loss : 0.32180, Acc : 0.853, Sensitive_Loss : 0.07940, Sensitive_Acc : 21.400, Run Time : 17.22 sec
INFO:root:2024-04-16 18:39:37, Train, Epoch : 10, Step : 6300, Loss : 0.34696, Acc : 0.847, Sensitive_Loss : 0.07745, Sensitive_Acc : 23.800, Run Time : 17.19 sec
INFO:root:2024-04-16 18:43:30, Dev, Step : 6300, Loss : 0.70711, Acc : 0.749, Auc : 0.839, Sensitive_Loss : 0.18362, Sensitive_Acc : 21.662, Sensitive_Auc : 0.998, Mean auc: 0.839, Run Time : 233.01 sec
INFO:root:2024-04-16 18:43:42, Train, Epoch : 10, Step : 6310, Loss : 0.32087, Acc : 0.897, Sensitive_Loss : 0.09451, Sensitive_Acc : 26.400, Run Time : 245.36 sec
INFO:root:2024-04-16 18:44:00, Train, Epoch : 10, Step : 6320, Loss : 0.29945, Acc : 0.878, Sensitive_Loss : 0.05320, Sensitive_Acc : 20.800, Run Time : 18.11 sec
INFO:root:2024-04-16 18:44:19, Train, Epoch : 10, Step : 6330, Loss : 0.28687, Acc : 0.875, Sensitive_Loss : 0.07314, Sensitive_Acc : 24.600, Run Time : 18.50 sec
INFO:root:2024-04-16 18:44:34, Train, Epoch : 10, Step : 6340, Loss : 0.30098, Acc : 0.866, Sensitive_Loss : 0.12466, Sensitive_Acc : 19.700, Run Time : 15.52 sec
INFO:root:2024-04-16 18:48:24
INFO:root:y_pred: [0.21991047 0.0011888  0.10084019 ... 0.04204882 0.06307175 0.04112494]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [1.1694341e-05 7.6655080e-05 7.4231988e-03 5.0781474e-02 5.2006794e-03
 3.0730022e-05 1.0512653e-03 8.4806510e-05 7.8257974e-03 9.9977463e-01
 1.2106451e-01 4.9543542e-05 3.9437396e-05 2.8312678e-04 9.9586272e-01
 1.0097958e-02 2.5210151e-02 9.9960178e-01 9.9997365e-01 7.2360691e-04
 9.9329054e-01 3.4958089e-04 1.0105536e-03 2.5401787e-05 1.4706419e-02
 2.7207213e-02 6.3917573e-06 9.5831456e-05 7.6951215e-04 4.2334143e-03
 1.0110661e-01 9.9313241e-01 3.3287799e-03 9.6652925e-01 8.8274297e-05
 8.9076893e-06 1.0610132e-03 1.0149089e-01 7.1707064e-01 1.0978470e-03
 3.7274826e-02 9.7093672e-01 4.7534201e-03 6.7851548e-03 9.9881220e-01
 4.2788563e-03 1.7693694e-01 4.5911279e-01 8.7276042e-02 9.9926227e-01
 9.9717891e-01 9.9990916e-01 9.9997413e-01 7.5043426e-06 3.6178832e-03
 5.6938928e-02 1.2657540e-03 9.9773589e-04 9.8598307e-01 3.6423233e-05
 2.7140750e-06 4.0600677e-03 2.3306697e-04 3.7320592e-06 9.9947649e-01
 3.0102792e-01 2.3784064e-04 2.4079831e-01 2.9541363e-03 9.9537009e-01
 9.9993253e-01 9.9963832e-01 4.9314600e-05 6.6134012e-01 3.7519119e-04
 2.2964166e-01 8.1127050e-04 4.0890694e-07 2.7291025e-08 4.7076942e-04
 1.2575247e-02 1.3058737e-04 9.9964595e-01 9.9649400e-01 3.2572239e-03
 2.6386553e-02 8.3688749e-03 8.6968648e-06 1.0296651e-02 8.5900156e-03
 1.4401863e-03 8.2546547e-03 2.2904939e-04 5.4257621e-06 3.2949995e-04
 1.5683830e-03 3.7685121e-04 4.6970436e-01 1.7589092e-04 2.3524426e-03
 1.9858599e-06 1.0630928e-02 3.5676068e-01 3.1287414e-03 8.6579082e-04
 6.3113606e-04 5.1004789e-03 2.9919127e-02 1.1204619e-01 8.4409001e-04
 6.8984606e-05 9.9998355e-01 9.9981433e-01 1.1153409e-05 1.6519852e-01
 7.7758980e-04 1.8427454e-06 8.2380968e-05 3.1590313e-03 4.2970487e-04
 3.5090381e-04 3.9738774e-05 1.3285021e-02 1.9036304e-05 1.4595983e-04
 6.9345599e-01 1.4553856e-05 9.8265302e-01 3.1475064e-03 1.8874211e-02
 7.2588323e-06 4.1327667e-03 1.2054891e-06]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-16 18:48:24, Dev, Step : 6340, Loss : 0.61924, Acc : 0.767, Auc : 0.843, Sensitive_Loss : 0.17577, Sensitive_Acc : 21.782, Sensitive_Auc : 0.999, Mean auc: 0.843, Run Time : 230.28 sec
