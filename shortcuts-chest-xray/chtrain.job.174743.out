Running on desktop22:
stdin: is not a tty
Activating chexpert environment...
/home/katkr/.conda/envs/chexpert/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'
1
Using the specified args:
Namespace(cfg_path='/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/config/config_katkr.json', device_ids='0', logtofile=False, num_workers=2, pre_train=None, resume=0, save_path='/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/logdirs/logdir-30k-2', verbose=True)
{
    "base_path": "/home/data_shares/purrlab/CheXpert/CheXpert-v1.0-small",
    "train_csv": "/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/biased_dataset_train.csv",
    "dev_csv": "/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/biased_dataset_val.csv",
    "pred_csv": "/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/predictions/Pred_Balanced_Sex_0_0.csv",
    "pred_model": "/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/logdirs/logdir-30k-2/Best_Balanced_Sex_0_01.ckpt",
    "backbone": "densenet121",
    "sensitive_attribute": "Sex",
    "lambda_val": 0.05,
    "num_heads": 2,
    "width": 512,
    "height": 512,
    "long_side": 512,
    "fix_ratio": true,
    "pixel_mean": 128.0,
    "pixel_std": 64.0,
    "use_pixel_std": true,
    "use_equalizeHist": true,
    "use_transforms_type": "Aug",
    "gaussian_blur": 3,
    "border_pad": "pixel_mean",
    "num_classes": [
        1
    ],
    "batch_weight": true,
    "batch_weight_sensitive": true,
    "enhance_index": [
        2,
        6
    ],
    "enhance_times": 1,
    "pos_weight": [
        1
    ],
    "sensitive_pos_weight": [
        1
    ],
    "train_batch_size": 32,
    "dev_batch_size": 32,
    "pretrained": true,
    "log_every": 10,
    "test_every": 100,
    "epoch": 10,
    "norm_type": "BatchNorm",
    "global_pool": "PCAM",
    "fc_bn": true,
    "attention_map": "FPA",
    "lse_gamma": 0.5,
    "fc_drop": 0,
    "optimizer": "Adam",
    "criterion": "BCE",
    "sensitive_criterion": "BCE",
    "lr": 0.0001,
    "lr_factor": 0.1,
    "lr_epochs": [
        2
    ],
    "momentum": 0.9,
    "weight_decay": 0.0,
    "best_target": "auc",
    "save_top_k": 3,
    "save_index": [
        0
    ]
}
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 256, 256]           9,408
       BatchNorm2d-2         [-1, 64, 256, 256]             128
              ReLU-3         [-1, 64, 256, 256]               0
         MaxPool2d-4         [-1, 64, 128, 128]               0
       BatchNorm2d-5         [-1, 64, 128, 128]             128
              ReLU-6         [-1, 64, 128, 128]               0
            Conv2d-7        [-1, 128, 128, 128]           8,192
       BatchNorm2d-8        [-1, 128, 128, 128]             256
              ReLU-9        [-1, 128, 128, 128]               0
           Conv2d-10         [-1, 32, 128, 128]          36,864
      BatchNorm2d-11         [-1, 96, 128, 128]             192
             ReLU-12         [-1, 96, 128, 128]               0
           Conv2d-13        [-1, 128, 128, 128]          12,288
      BatchNorm2d-14        [-1, 128, 128, 128]             256
             ReLU-15        [-1, 128, 128, 128]               0
           Conv2d-16         [-1, 32, 128, 128]          36,864
      BatchNorm2d-17        [-1, 128, 128, 128]             256
             ReLU-18        [-1, 128, 128, 128]               0
           Conv2d-19        [-1, 128, 128, 128]          16,384
      BatchNorm2d-20        [-1, 128, 128, 128]             256
             ReLU-21        [-1, 128, 128, 128]               0
           Conv2d-22         [-1, 32, 128, 128]          36,864
      BatchNorm2d-23        [-1, 160, 128, 128]             320
             ReLU-24        [-1, 160, 128, 128]               0
           Conv2d-25        [-1, 128, 128, 128]          20,480
      BatchNorm2d-26        [-1, 128, 128, 128]             256
             ReLU-27        [-1, 128, 128, 128]               0
           Conv2d-28         [-1, 32, 128, 128]          36,864
      BatchNorm2d-29        [-1, 192, 128, 128]             384
             ReLU-30        [-1, 192, 128, 128]               0
           Conv2d-31        [-1, 128, 128, 128]          24,576
      BatchNorm2d-32        [-1, 128, 128, 128]             256
             ReLU-33        [-1, 128, 128, 128]               0
           Conv2d-34         [-1, 32, 128, 128]          36,864
      BatchNorm2d-35        [-1, 224, 128, 128]             448
             ReLU-36        [-1, 224, 128, 128]               0
           Conv2d-37        [-1, 128, 128, 128]          28,672
      BatchNorm2d-38        [-1, 128, 128, 128]             256
             ReLU-39        [-1, 128, 128, 128]               0
           Conv2d-40         [-1, 32, 128, 128]          36,864
      BatchNorm2d-41        [-1, 256, 128, 128]             512
             ReLU-42        [-1, 256, 128, 128]               0
           Conv2d-43        [-1, 128, 128, 128]          32,768
        AvgPool2d-44          [-1, 128, 64, 64]               0
      BatchNorm2d-45          [-1, 128, 64, 64]             256
             ReLU-46          [-1, 128, 64, 64]               0
           Conv2d-47          [-1, 128, 64, 64]          16,384
      BatchNorm2d-48          [-1, 128, 64, 64]             256
             ReLU-49          [-1, 128, 64, 64]               0
           Conv2d-50           [-1, 32, 64, 64]          36,864
      BatchNorm2d-51          [-1, 160, 64, 64]             320
             ReLU-52          [-1, 160, 64, 64]               0
           Conv2d-53          [-1, 128, 64, 64]          20,480
      BatchNorm2d-54          [-1, 128, 64, 64]             256
             ReLU-55          [-1, 128, 64, 64]               0
           Conv2d-56           [-1, 32, 64, 64]          36,864
      BatchNorm2d-57          [-1, 192, 64, 64]             384
             ReLU-58          [-1, 192, 64, 64]               0
           Conv2d-59          [-1, 128, 64, 64]          24,576
      BatchNorm2d-60          [-1, 128, 64, 64]             256
             ReLU-61          [-1, 128, 64, 64]               0
           Conv2d-62           [-1, 32, 64, 64]          36,864
      BatchNorm2d-63          [-1, 224, 64, 64]             448
             ReLU-64          [-1, 224, 64, 64]               0
           Conv2d-65          [-1, 128, 64, 64]          28,672
      BatchNorm2d-66          [-1, 128, 64, 64]             256
             ReLU-67          [-1, 128, 64, 64]               0
           Conv2d-68           [-1, 32, 64, 64]          36,864
      BatchNorm2d-69          [-1, 256, 64, 64]             512
             ReLU-70          [-1, 256, 64, 64]               0
           Conv2d-71          [-1, 128, 64, 64]          32,768
      BatchNorm2d-72          [-1, 128, 64, 64]             256
             ReLU-73          [-1, 128, 64, 64]               0
           Conv2d-74           [-1, 32, 64, 64]          36,864
      BatchNorm2d-75          [-1, 288, 64, 64]             576
             ReLU-76          [-1, 288, 64, 64]               0
           Conv2d-77          [-1, 128, 64, 64]          36,864
      BatchNorm2d-78          [-1, 128, 64, 64]             256
             ReLU-79          [-1, 128, 64, 64]               0
           Conv2d-80           [-1, 32, 64, 64]          36,864
      BatchNorm2d-81          [-1, 320, 64, 64]             640
             ReLU-82          [-1, 320, 64, 64]               0
           Conv2d-83          [-1, 128, 64, 64]          40,960
      BatchNorm2d-84          [-1, 128, 64, 64]             256
             ReLU-85          [-1, 128, 64, 64]               0
           Conv2d-86           [-1, 32, 64, 64]          36,864
      BatchNorm2d-87          [-1, 352, 64, 64]             704
             ReLU-88          [-1, 352, 64, 64]               0
           Conv2d-89          [-1, 128, 64, 64]          45,056
      BatchNorm2d-90          [-1, 128, 64, 64]             256
             ReLU-91          [-1, 128, 64, 64]               0
           Conv2d-92           [-1, 32, 64, 64]          36,864
      BatchNorm2d-93          [-1, 384, 64, 64]             768
             ReLU-94          [-1, 384, 64, 64]               0
           Conv2d-95          [-1, 128, 64, 64]          49,152
      BatchNorm2d-96          [-1, 128, 64, 64]             256
             ReLU-97          [-1, 128, 64, 64]               0
           Conv2d-98           [-1, 32, 64, 64]          36,864
      BatchNorm2d-99          [-1, 416, 64, 64]             832
            ReLU-100          [-1, 416, 64, 64]               0
          Conv2d-101          [-1, 128, 64, 64]          53,248
     BatchNorm2d-102          [-1, 128, 64, 64]             256
            ReLU-103          [-1, 128, 64, 64]               0
          Conv2d-104           [-1, 32, 64, 64]          36,864
     BatchNorm2d-105          [-1, 448, 64, 64]             896
            ReLU-106          [-1, 448, 64, 64]               0
          Conv2d-107          [-1, 128, 64, 64]          57,344
     BatchNorm2d-108          [-1, 128, 64, 64]             256
            ReLU-109          [-1, 128, 64, 64]               0
          Conv2d-110           [-1, 32, 64, 64]          36,864
     BatchNorm2d-111          [-1, 480, 64, 64]             960
            ReLU-112          [-1, 480, 64, 64]               0
          Conv2d-113          [-1, 128, 64, 64]          61,440
     BatchNorm2d-114          [-1, 128, 64, 64]             256
            ReLU-115          [-1, 128, 64, 64]               0
          Conv2d-116           [-1, 32, 64, 64]          36,864
     BatchNorm2d-117          [-1, 512, 64, 64]           1,024
            ReLU-118          [-1, 512, 64, 64]               0
          Conv2d-119          [-1, 256, 64, 64]         131,072
       AvgPool2d-120          [-1, 256, 32, 32]               0
     BatchNorm2d-121          [-1, 256, 32, 32]             512
            ReLU-122          [-1, 256, 32, 32]               0
          Conv2d-123          [-1, 128, 32, 32]          32,768
     BatchNorm2d-124          [-1, 128, 32, 32]             256
            ReLU-125          [-1, 128, 32, 32]               0
          Conv2d-126           [-1, 32, 32, 32]          36,864
     BatchNorm2d-127          [-1, 288, 32, 32]             576
            ReLU-128          [-1, 288, 32, 32]               0
          Conv2d-129          [-1, 128, 32, 32]          36,864
     BatchNorm2d-130          [-1, 128, 32, 32]             256
            ReLU-131          [-1, 128, 32, 32]               0
          Conv2d-132           [-1, 32, 32, 32]          36,864
     BatchNorm2d-133          [-1, 320, 32, 32]             640
            ReLU-134          [-1, 320, 32, 32]               0
          Conv2d-135          [-1, 128, 32, 32]          40,960
     BatchNorm2d-136          [-1, 128, 32, 32]             256
            ReLU-137          [-1, 128, 32, 32]               0
          Conv2d-138           [-1, 32, 32, 32]          36,864
     BatchNorm2d-139          [-1, 352, 32, 32]             704
            ReLU-140          [-1, 352, 32, 32]               0
          Conv2d-141          [-1, 128, 32, 32]          45,056
     BatchNorm2d-142          [-1, 128, 32, 32]             256
            ReLU-143          [-1, 128, 32, 32]               0
          Conv2d-144           [-1, 32, 32, 32]          36,864
     BatchNorm2d-145          [-1, 384, 32, 32]             768
            ReLU-146          [-1, 384, 32, 32]               0
          Conv2d-147          [-1, 128, 32, 32]          49,152
     BatchNorm2d-148          [-1, 128, 32, 32]             256
            ReLU-149          [-1, 128, 32, 32]               0
          Conv2d-150           [-1, 32, 32, 32]          36,864
     BatchNorm2d-151          [-1, 416, 32, 32]             832
            ReLU-152          [-1, 416, 32, 32]               0
          Conv2d-153          [-1, 128, 32, 32]          53,248
     BatchNorm2d-154          [-1, 128, 32, 32]             256
            ReLU-155          [-1, 128, 32, 32]               0
          Conv2d-156           [-1, 32, 32, 32]          36,864
     BatchNorm2d-157          [-1, 448, 32, 32]             896
            ReLU-158          [-1, 448, 32, 32]               0
          Conv2d-159          [-1, 128, 32, 32]          57,344
     BatchNorm2d-160          [-1, 128, 32, 32]             256
            ReLU-161          [-1, 128, 32, 32]               0
          Conv2d-162           [-1, 32, 32, 32]          36,864
     BatchNorm2d-163          [-1, 480, 32, 32]             960
            ReLU-164          [-1, 480, 32, 32]               0
          Conv2d-165          [-1, 128, 32, 32]          61,440
     BatchNorm2d-166          [-1, 128, 32, 32]             256
            ReLU-167          [-1, 128, 32, 32]               0
          Conv2d-168           [-1, 32, 32, 32]          36,864
     BatchNorm2d-169          [-1, 512, 32, 32]           1,024
            ReLU-170          [-1, 512, 32, 32]               0
          Conv2d-171          [-1, 128, 32, 32]          65,536
     BatchNorm2d-172          [-1, 128, 32, 32]             256
            ReLU-173          [-1, 128, 32, 32]               0
          Conv2d-174           [-1, 32, 32, 32]          36,864
     BatchNorm2d-175          [-1, 544, 32, 32]           1,088
            ReLU-176          [-1, 544, 32, 32]               0
          Conv2d-177          [-1, 128, 32, 32]          69,632
     BatchNorm2d-178          [-1, 128, 32, 32]             256
            ReLU-179          [-1, 128, 32, 32]               0
          Conv2d-180           [-1, 32, 32, 32]          36,864
     BatchNorm2d-181          [-1, 576, 32, 32]           1,152
            ReLU-182          [-1, 576, 32, 32]               0
          Conv2d-183          [-1, 128, 32, 32]          73,728
     BatchNorm2d-184          [-1, 128, 32, 32]             256
            ReLU-185          [-1, 128, 32, 32]               0
          Conv2d-186           [-1, 32, 32, 32]          36,864
     BatchNorm2d-187          [-1, 608, 32, 32]           1,216
            ReLU-188          [-1, 608, 32, 32]               0
          Conv2d-189          [-1, 128, 32, 32]          77,824
     BatchNorm2d-190          [-1, 128, 32, 32]             256
            ReLU-191          [-1, 128, 32, 32]               0
          Conv2d-192           [-1, 32, 32, 32]          36,864
     BatchNorm2d-193          [-1, 640, 32, 32]           1,280
            ReLU-194          [-1, 640, 32, 32]               0
          Conv2d-195          [-1, 128, 32, 32]          81,920
     BatchNorm2d-196          [-1, 128, 32, 32]             256
            ReLU-197          [-1, 128, 32, 32]               0
          Conv2d-198           [-1, 32, 32, 32]          36,864
     BatchNorm2d-199          [-1, 672, 32, 32]           1,344
            ReLU-200          [-1, 672, 32, 32]               0
          Conv2d-201          [-1, 128, 32, 32]          86,016
     BatchNorm2d-202          [-1, 128, 32, 32]             256
            ReLU-203          [-1, 128, 32, 32]               0
          Conv2d-204           [-1, 32, 32, 32]          36,864
     BatchNorm2d-205          [-1, 704, 32, 32]           1,408
            ReLU-206          [-1, 704, 32, 32]               0
          Conv2d-207          [-1, 128, 32, 32]          90,112
     BatchNorm2d-208          [-1, 128, 32, 32]             256
            ReLU-209          [-1, 128, 32, 32]               0
          Conv2d-210           [-1, 32, 32, 32]          36,864
     BatchNorm2d-211          [-1, 736, 32, 32]           1,472
            ReLU-212          [-1, 736, 32, 32]               0
          Conv2d-213          [-1, 128, 32, 32]          94,208
     BatchNorm2d-214          [-1, 128, 32, 32]             256
            ReLU-215          [-1, 128, 32, 32]               0
          Conv2d-216           [-1, 32, 32, 32]          36,864
     BatchNorm2d-217          [-1, 768, 32, 32]           1,536
            ReLU-218          [-1, 768, 32, 32]               0
          Conv2d-219          [-1, 128, 32, 32]          98,304
     BatchNorm2d-220          [-1, 128, 32, 32]             256
            ReLU-221          [-1, 128, 32, 32]               0
          Conv2d-222           [-1, 32, 32, 32]          36,864
     BatchNorm2d-223          [-1, 800, 32, 32]           1,600
            ReLU-224          [-1, 800, 32, 32]               0
          Conv2d-225          [-1, 128, 32, 32]         102,400
     BatchNorm2d-226          [-1, 128, 32, 32]             256
            ReLU-227          [-1, 128, 32, 32]               0
          Conv2d-228           [-1, 32, 32, 32]          36,864
     BatchNorm2d-229          [-1, 832, 32, 32]           1,664
            ReLU-230          [-1, 832, 32, 32]               0
          Conv2d-231          [-1, 128, 32, 32]         106,496
     BatchNorm2d-232          [-1, 128, 32, 32]             256
            ReLU-233          [-1, 128, 32, 32]               0
          Conv2d-234           [-1, 32, 32, 32]          36,864
     BatchNorm2d-235          [-1, 864, 32, 32]           1,728
            ReLU-236          [-1, 864, 32, 32]               0
          Conv2d-237          [-1, 128, 32, 32]         110,592
     BatchNorm2d-238          [-1, 128, 32, 32]             256
            ReLU-239          [-1, 128, 32, 32]               0
          Conv2d-240           [-1, 32, 32, 32]          36,864
     BatchNorm2d-241          [-1, 896, 32, 32]           1,792
            ReLU-242          [-1, 896, 32, 32]               0
          Conv2d-243          [-1, 128, 32, 32]         114,688
     BatchNorm2d-244          [-1, 128, 32, 32]             256
            ReLU-245          [-1, 128, 32, 32]               0
          Conv2d-246           [-1, 32, 32, 32]          36,864
     BatchNorm2d-247          [-1, 928, 32, 32]           1,856
            ReLU-248          [-1, 928, 32, 32]               0
          Conv2d-249          [-1, 128, 32, 32]         118,784
     BatchNorm2d-250          [-1, 128, 32, 32]             256
            ReLU-251          [-1, 128, 32, 32]               0
          Conv2d-252           [-1, 32, 32, 32]          36,864
     BatchNorm2d-253          [-1, 960, 32, 32]           1,920
            ReLU-254          [-1, 960, 32, 32]               0
          Conv2d-255          [-1, 128, 32, 32]         122,880
     BatchNorm2d-256          [-1, 128, 32, 32]             256
            ReLU-257          [-1, 128, 32, 32]               0
          Conv2d-258           [-1, 32, 32, 32]          36,864
     BatchNorm2d-259          [-1, 992, 32, 32]           1,984
            ReLU-260          [-1, 992, 32, 32]               0
          Conv2d-261          [-1, 128, 32, 32]         126,976
     BatchNorm2d-262          [-1, 128, 32, 32]             256
            ReLU-263          [-1, 128, 32, 32]               0
          Conv2d-264           [-1, 32, 32, 32]          36,864
     BatchNorm2d-265         [-1, 1024, 32, 32]           2,048
            ReLU-266         [-1, 1024, 32, 32]               0
          Conv2d-267          [-1, 512, 32, 32]         524,288
       AvgPool2d-268          [-1, 512, 16, 16]               0
     BatchNorm2d-269          [-1, 512, 16, 16]           1,024
            ReLU-270          [-1, 512, 16, 16]               0
          Conv2d-271          [-1, 128, 16, 16]          65,536
     BatchNorm2d-272          [-1, 128, 16, 16]             256
            ReLU-273          [-1, 128, 16, 16]               0
          Conv2d-274           [-1, 32, 16, 16]          36,864
     BatchNorm2d-275          [-1, 544, 16, 16]           1,088
            ReLU-276          [-1, 544, 16, 16]               0
          Conv2d-277          [-1, 128, 16, 16]          69,632
     BatchNorm2d-278          [-1, 128, 16, 16]             256
            ReLU-279          [-1, 128, 16, 16]               0
          Conv2d-280           [-1, 32, 16, 16]          36,864
     BatchNorm2d-281          [-1, 576, 16, 16]           1,152
            ReLU-282          [-1, 576, 16, 16]               0
          Conv2d-283          [-1, 128, 16, 16]          73,728
     BatchNorm2d-284          [-1, 128, 16, 16]             256
            ReLU-285          [-1, 128, 16, 16]               0
          Conv2d-286           [-1, 32, 16, 16]          36,864
     BatchNorm2d-287          [-1, 608, 16, 16]           1,216
            ReLU-288          [-1, 608, 16, 16]               0
          Conv2d-289          [-1, 128, 16, 16]          77,824
     BatchNorm2d-290          [-1, 128, 16, 16]             256
            ReLU-291          [-1, 128, 16, 16]               0
          Conv2d-292           [-1, 32, 16, 16]          36,864
     BatchNorm2d-293          [-1, 640, 16, 16]           1,280
            ReLU-294          [-1, 640, 16, 16]               0
          Conv2d-295          [-1, 128, 16, 16]          81,920
     BatchNorm2d-296          [-1, 128, 16, 16]             256
            ReLU-297          [-1, 128, 16, 16]               0
          Conv2d-298           [-1, 32, 16, 16]          36,864
     BatchNorm2d-299          [-1, 672, 16, 16]           1,344
            ReLU-300          [-1, 672, 16, 16]               0
          Conv2d-301          [-1, 128, 16, 16]          86,016
     BatchNorm2d-302          [-1, 128, 16, 16]             256
            ReLU-303          [-1, 128, 16, 16]               0
          Conv2d-304           [-1, 32, 16, 16]          36,864
     BatchNorm2d-305          [-1, 704, 16, 16]           1,408
            ReLU-306          [-1, 704, 16, 16]               0
          Conv2d-307          [-1, 128, 16, 16]          90,112
     BatchNorm2d-308          [-1, 128, 16, 16]             256
            ReLU-309          [-1, 128, 16, 16]               0
          Conv2d-310           [-1, 32, 16, 16]          36,864
     BatchNorm2d-311          [-1, 736, 16, 16]           1,472
            ReLU-312          [-1, 736, 16, 16]               0
          Conv2d-313          [-1, 128, 16, 16]          94,208
     BatchNorm2d-314          [-1, 128, 16, 16]             256
            ReLU-315          [-1, 128, 16, 16]               0
          Conv2d-316           [-1, 32, 16, 16]          36,864
     BatchNorm2d-317          [-1, 768, 16, 16]           1,536
            ReLU-318          [-1, 768, 16, 16]               0
          Conv2d-319          [-1, 128, 16, 16]          98,304
     BatchNorm2d-320          [-1, 128, 16, 16]             256
            ReLU-321          [-1, 128, 16, 16]               0
          Conv2d-322           [-1, 32, 16, 16]          36,864
     BatchNorm2d-323          [-1, 800, 16, 16]           1,600
            ReLU-324          [-1, 800, 16, 16]               0
          Conv2d-325          [-1, 128, 16, 16]         102,400
     BatchNorm2d-326          [-1, 128, 16, 16]             256
            ReLU-327          [-1, 128, 16, 16]               0
          Conv2d-328           [-1, 32, 16, 16]          36,864
     BatchNorm2d-329          [-1, 832, 16, 16]           1,664
            ReLU-330          [-1, 832, 16, 16]               0
          Conv2d-331          [-1, 128, 16, 16]         106,496
     BatchNorm2d-332          [-1, 128, 16, 16]             256
            ReLU-333          [-1, 128, 16, 16]               0
          Conv2d-334           [-1, 32, 16, 16]          36,864
     BatchNorm2d-335          [-1, 864, 16, 16]           1,728
            ReLU-336          [-1, 864, 16, 16]               0
          Conv2d-337          [-1, 128, 16, 16]         110,592
     BatchNorm2d-338          [-1, 128, 16, 16]             256
            ReLU-339          [-1, 128, 16, 16]               0
          Conv2d-340           [-1, 32, 16, 16]          36,864
     BatchNorm2d-341          [-1, 896, 16, 16]           1,792
            ReLU-342          [-1, 896, 16, 16]               0
          Conv2d-343          [-1, 128, 16, 16]         114,688
     BatchNorm2d-344          [-1, 128, 16, 16]             256
            ReLU-345          [-1, 128, 16, 16]               0
          Conv2d-346           [-1, 32, 16, 16]          36,864
     BatchNorm2d-347          [-1, 928, 16, 16]           1,856
            ReLU-348          [-1, 928, 16, 16]               0
          Conv2d-349          [-1, 128, 16, 16]         118,784
     BatchNorm2d-350          [-1, 128, 16, 16]             256
            ReLU-351          [-1, 128, 16, 16]               0
          Conv2d-352           [-1, 32, 16, 16]          36,864
     BatchNorm2d-353          [-1, 960, 16, 16]           1,920
            ReLU-354          [-1, 960, 16, 16]               0
          Conv2d-355          [-1, 128, 16, 16]         122,880
     BatchNorm2d-356          [-1, 128, 16, 16]             256
            ReLU-357          [-1, 128, 16, 16]               0
          Conv2d-358           [-1, 32, 16, 16]          36,864
     BatchNorm2d-359          [-1, 992, 16, 16]           1,984
            ReLU-360          [-1, 992, 16, 16]               0
          Conv2d-361          [-1, 128, 16, 16]         126,976
     BatchNorm2d-362          [-1, 128, 16, 16]             256
            ReLU-363          [-1, 128, 16, 16]               0
          Conv2d-364           [-1, 32, 16, 16]          36,864
     BatchNorm2d-365         [-1, 1024, 16, 16]           2,048
        DenseNet-366         [-1, 1024, 16, 16]               0
AdaptiveAvgPool2d-367           [-1, 1024, 1, 1]               0
          Conv2d-368           [-1, 1024, 1, 1]       1,049,600
     BatchNorm2d-369           [-1, 1024, 1, 1]           2,048
            ReLU-370           [-1, 1024, 1, 1]               0
  Conv2dNormRelu-371           [-1, 1024, 1, 1]               0
          Conv2d-372         [-1, 1024, 16, 16]       1,049,600
     BatchNorm2d-373         [-1, 1024, 16, 16]           2,048
            ReLU-374         [-1, 1024, 16, 16]               0
  Conv2dNormRelu-375         [-1, 1024, 16, 16]               0
          Conv2d-376              [-1, 1, 8, 8]          50,177
     BatchNorm2d-377              [-1, 1, 8, 8]               2
            ReLU-378              [-1, 1, 8, 8]               0
  Conv2dNormRelu-379              [-1, 1, 8, 8]               0
          Conv2d-380              [-1, 1, 4, 4]              26
     BatchNorm2d-381              [-1, 1, 4, 4]               2
            ReLU-382              [-1, 1, 4, 4]               0
  Conv2dNormRelu-383              [-1, 1, 4, 4]               0
          Conv2d-384              [-1, 1, 2, 2]              10
     BatchNorm2d-385              [-1, 1, 2, 2]               2
            ReLU-386              [-1, 1, 2, 2]               0
  Conv2dNormRelu-387              [-1, 1, 2, 2]               0
          Conv2d-388              [-1, 1, 2, 2]              10
     BatchNorm2d-389              [-1, 1, 2, 2]               2
            ReLU-390              [-1, 1, 2, 2]               0
  Conv2dNormRelu-391              [-1, 1, 2, 2]               0
          Conv2d-392              [-1, 1, 4, 4]              26
     BatchNorm2d-393              [-1, 1, 4, 4]               2
            ReLU-394              [-1, 1, 4, 4]               0
  Conv2dNormRelu-395              [-1, 1, 4, 4]               0
          Conv2d-396              [-1, 1, 8, 8]              50
     BatchNorm2d-397              [-1, 1, 8, 8]               2
            ReLU-398              [-1, 1, 8, 8]               0
  Conv2dNormRelu-399              [-1, 1, 8, 8]               0
       FPAModule-400         [-1, 1024, 16, 16]               0
    AttentionMap-401         [-1, 1024, 16, 16]               0
          Conv2d-402            [-1, 1, 16, 16]           1,025
        PcamPool-403           [-1, 1024, 1, 1]               0
      GlobalPool-404           [-1, 1024, 1, 1]               0
     BatchNorm2d-405           [-1, 1024, 1, 1]           2,048
          Conv2d-406              [-1, 1, 1, 1]           1,025
        PcamPool-407           [-1, 1024, 1, 1]               0
      GlobalPool-408           [-1, 1024, 1, 1]               0
          Linear-409                    [-1, 1]           1,025
================================================================
Total params: 9,112,586
Trainable params: 9,112,586
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 3.00
Forward/backward pass size (MB): 1551.09
Params size (MB): 34.76
Estimated Total Size (MB): 1588.85
----------------------------------------------------------------
INFO:root:2024-04-14 09:02:29, Train, Epoch : 1, Step : 10, Loss : 0.64674, Acc : 0.606, Sensitive_Loss : 1.13908, Sensitive_Acc : 19.600, Run Time : 9.41 sec
INFO:root:2024-04-14 09:02:37, Train, Epoch : 1, Step : 20, Loss : 0.68578, Acc : 0.584, Sensitive_Loss : 1.07678, Sensitive_Acc : 18.700, Run Time : 8.17 sec
INFO:root:2024-04-14 09:02:45, Train, Epoch : 1, Step : 30, Loss : 0.73177, Acc : 0.613, Sensitive_Loss : 1.07609, Sensitive_Acc : 7.800, Run Time : 8.11 sec
INFO:root:2024-04-14 09:02:53, Train, Epoch : 1, Step : 40, Loss : 0.68890, Acc : 0.666, Sensitive_Loss : 0.90527, Sensitive_Acc : 13.500, Run Time : 8.03 sec
INFO:root:2024-04-14 09:03:01, Train, Epoch : 1, Step : 50, Loss : 0.66054, Acc : 0.644, Sensitive_Loss : 0.92270, Sensitive_Acc : 18.800, Run Time : 7.87 sec
INFO:root:2024-04-14 09:03:09, Train, Epoch : 1, Step : 60, Loss : 0.67530, Acc : 0.637, Sensitive_Loss : 0.92006, Sensitive_Acc : 20.900, Run Time : 7.81 sec
INFO:root:2024-04-14 09:03:17, Train, Epoch : 1, Step : 70, Loss : 0.60164, Acc : 0.659, Sensitive_Loss : 0.90999, Sensitive_Acc : 20.300, Run Time : 7.78 sec
INFO:root:2024-04-14 09:03:25, Train, Epoch : 1, Step : 80, Loss : 0.64203, Acc : 0.700, Sensitive_Loss : 0.85868, Sensitive_Acc : 17.900, Run Time : 8.09 sec
INFO:root:2024-04-14 09:03:33, Train, Epoch : 1, Step : 90, Loss : 0.60942, Acc : 0.688, Sensitive_Loss : 0.81428, Sensitive_Acc : 21.500, Run Time : 8.10 sec
INFO:root:2024-04-14 09:03:41, Train, Epoch : 1, Step : 100, Loss : 0.66051, Acc : 0.681, Sensitive_Loss : 0.73997, Sensitive_Acc : 19.300, Run Time : 7.89 sec
INFO:root:2024-04-14 09:05:23, Dev, Step : 100, Loss : 0.86129, Acc : 0.582, Auc : 0.725, Sensitive_Loss : 0.84267, Sensitive_Acc : 15.316, Sensitive_Auc : 0.858, Mean auc: 0.725, Run Time : 102.23 sec
INFO:root:2024-04-14 09:05:24, Best, Step : 100, Loss : 0.86129, Acc : 0.582, Auc : 0.725, Sensitive_Loss : 0.84267, Sensitive_Acc : 15.316, Sensitive_Auc : 0.858, Best Auc : 0.725
INFO:root:2024-04-14 09:05:29, Train, Epoch : 1, Step : 110, Loss : 0.65243, Acc : 0.675, Sensitive_Loss : 0.81327, Sensitive_Acc : 13.700, Run Time : 108.56 sec
INFO:root:2024-04-14 09:05:37, Train, Epoch : 1, Step : 120, Loss : 0.57825, Acc : 0.637, Sensitive_Loss : 0.71217, Sensitive_Acc : 15.500, Run Time : 7.97 sec
INFO:root:2024-04-14 09:05:45, Train, Epoch : 1, Step : 130, Loss : 0.58232, Acc : 0.703, Sensitive_Loss : 0.73215, Sensitive_Acc : 19.400, Run Time : 7.53 sec
INFO:root:2024-04-14 09:05:53, Train, Epoch : 1, Step : 140, Loss : 0.63251, Acc : 0.666, Sensitive_Loss : 0.68060, Sensitive_Acc : 21.000, Run Time : 7.91 sec
INFO:root:2024-04-14 09:06:01, Train, Epoch : 1, Step : 150, Loss : 0.61033, Acc : 0.659, Sensitive_Loss : 0.72109, Sensitive_Acc : 17.200, Run Time : 7.77 sec
INFO:root:2024-04-14 09:06:09, Train, Epoch : 1, Step : 160, Loss : 0.59766, Acc : 0.694, Sensitive_Loss : 0.85014, Sensitive_Acc : 13.700, Run Time : 8.21 sec
INFO:root:2024-04-14 09:06:17, Train, Epoch : 1, Step : 170, Loss : 0.66414, Acc : 0.688, Sensitive_Loss : 0.67530, Sensitive_Acc : 24.300, Run Time : 8.04 sec
INFO:root:2024-04-14 09:06:24, Train, Epoch : 1, Step : 180, Loss : 0.59844, Acc : 0.666, Sensitive_Loss : 0.63229, Sensitive_Acc : 23.300, Run Time : 7.62 sec
INFO:root:2024-04-14 09:06:33, Train, Epoch : 1, Step : 190, Loss : 0.59227, Acc : 0.694, Sensitive_Loss : 0.66829, Sensitive_Acc : 18.000, Run Time : 8.18 sec
INFO:root:2024-04-14 09:06:41, Train, Epoch : 1, Step : 200, Loss : 0.64552, Acc : 0.662, Sensitive_Loss : 0.65159, Sensitive_Acc : 23.600, Run Time : 7.92 sec
INFO:root:2024-04-14 09:08:09, Dev, Step : 200, Loss : 0.65911, Acc : 0.653, Auc : 0.756, Sensitive_Loss : 0.62137, Sensitive_Acc : 17.947, Sensitive_Auc : 0.879, Mean auc: 0.756, Run Time : 88.22 sec
INFO:root:2024-04-14 09:08:09, Best, Step : 200, Loss : 0.65911, Acc : 0.653, Auc : 0.756, Sensitive_Loss : 0.62137, Sensitive_Acc : 17.947, Sensitive_Auc : 0.879, Best Auc : 0.756
INFO:root:2024-04-14 09:08:15, Train, Epoch : 1, Step : 210, Loss : 0.58930, Acc : 0.672, Sensitive_Loss : 0.67624, Sensitive_Acc : 21.300, Run Time : 94.64 sec
INFO:root:2024-04-14 09:08:23, Train, Epoch : 1, Step : 220, Loss : 0.64356, Acc : 0.697, Sensitive_Loss : 0.68597, Sensitive_Acc : 23.200, Run Time : 7.65 sec
INFO:root:2024-04-14 09:08:30, Train, Epoch : 1, Step : 230, Loss : 0.66831, Acc : 0.675, Sensitive_Loss : 0.73937, Sensitive_Acc : 22.100, Run Time : 7.65 sec
INFO:root:2024-04-14 09:08:38, Train, Epoch : 1, Step : 240, Loss : 0.66720, Acc : 0.672, Sensitive_Loss : 0.67022, Sensitive_Acc : 19.000, Run Time : 7.91 sec
INFO:root:2024-04-14 09:08:46, Train, Epoch : 1, Step : 250, Loss : 0.57428, Acc : 0.716, Sensitive_Loss : 0.52656, Sensitive_Acc : 23.400, Run Time : 7.99 sec
INFO:root:2024-04-14 09:08:54, Train, Epoch : 1, Step : 260, Loss : 0.56666, Acc : 0.731, Sensitive_Loss : 0.67473, Sensitive_Acc : 16.700, Run Time : 7.89 sec
INFO:root:2024-04-14 09:09:02, Train, Epoch : 1, Step : 270, Loss : 0.56924, Acc : 0.709, Sensitive_Loss : 0.55144, Sensitive_Acc : 23.600, Run Time : 7.83 sec
INFO:root:2024-04-14 09:09:10, Train, Epoch : 1, Step : 280, Loss : 0.58420, Acc : 0.753, Sensitive_Loss : 0.54022, Sensitive_Acc : 20.200, Run Time : 7.74 sec
INFO:root:2024-04-14 09:09:18, Train, Epoch : 1, Step : 290, Loss : 0.54369, Acc : 0.731, Sensitive_Loss : 0.56826, Sensitive_Acc : 14.700, Run Time : 8.05 sec
INFO:root:2024-04-14 09:09:26, Train, Epoch : 1, Step : 300, Loss : 0.58327, Acc : 0.713, Sensitive_Loss : 0.66829, Sensitive_Acc : 21.000, Run Time : 7.66 sec
INFO:root:2024-04-14 09:10:54, Dev, Step : 300, Loss : 0.64485, Acc : 0.670, Auc : 0.746, Sensitive_Loss : 0.59065, Sensitive_Acc : 18.519, Sensitive_Auc : 0.919, Mean auc: 0.746, Run Time : 88.32 sec
INFO:root:2024-04-14 09:11:00, Train, Epoch : 1, Step : 310, Loss : 0.66102, Acc : 0.681, Sensitive_Loss : 0.51815, Sensitive_Acc : 16.500, Run Time : 94.20 sec
INFO:root:2024-04-14 09:11:08, Train, Epoch : 1, Step : 320, Loss : 0.57102, Acc : 0.659, Sensitive_Loss : 0.43368, Sensitive_Acc : 21.200, Run Time : 8.07 sec
INFO:root:2024-04-14 09:11:16, Train, Epoch : 1, Step : 330, Loss : 0.55608, Acc : 0.741, Sensitive_Loss : 0.50844, Sensitive_Acc : 15.400, Run Time : 8.02 sec
INFO:root:2024-04-14 09:11:24, Train, Epoch : 1, Step : 340, Loss : 0.49932, Acc : 0.703, Sensitive_Loss : 0.39473, Sensitive_Acc : 24.000, Run Time : 7.75 sec
INFO:root:2024-04-14 09:11:32, Train, Epoch : 1, Step : 350, Loss : 0.61759, Acc : 0.706, Sensitive_Loss : 0.47500, Sensitive_Acc : 23.800, Run Time : 8.15 sec
INFO:root:2024-04-14 09:11:40, Train, Epoch : 1, Step : 360, Loss : 0.62472, Acc : 0.666, Sensitive_Loss : 0.41181, Sensitive_Acc : 16.100, Run Time : 7.90 sec
INFO:root:2024-04-14 09:11:47, Train, Epoch : 1, Step : 370, Loss : 0.64181, Acc : 0.678, Sensitive_Loss : 0.44793, Sensitive_Acc : 16.400, Run Time : 7.50 sec
INFO:root:2024-04-14 09:11:55, Train, Epoch : 1, Step : 380, Loss : 0.62894, Acc : 0.672, Sensitive_Loss : 0.50273, Sensitive_Acc : 18.200, Run Time : 8.06 sec
INFO:root:2024-04-14 09:12:03, Train, Epoch : 1, Step : 390, Loss : 0.53758, Acc : 0.719, Sensitive_Loss : 0.43934, Sensitive_Acc : 22.400, Run Time : 7.85 sec
INFO:root:2024-04-14 09:12:11, Train, Epoch : 1, Step : 400, Loss : 0.55790, Acc : 0.747, Sensitive_Loss : 0.48206, Sensitive_Acc : 19.000, Run Time : 8.00 sec
INFO:root:2024-04-14 09:13:39, Dev, Step : 400, Loss : 0.57360, Acc : 0.713, Auc : 0.809, Sensitive_Loss : 0.51176, Sensitive_Acc : 18.203, Sensitive_Auc : 0.948, Mean auc: 0.809, Run Time : 87.88 sec
INFO:root:2024-04-14 09:13:40, Best, Step : 400, Loss : 0.57360, Acc : 0.713, Auc : 0.809, Sensitive_Loss : 0.51176, Sensitive_Acc : 18.203, Sensitive_Auc : 0.948, Best Auc : 0.809
INFO:root:2024-04-14 09:13:45, Train, Epoch : 1, Step : 410, Loss : 0.60874, Acc : 0.725, Sensitive_Loss : 0.36555, Sensitive_Acc : 20.800, Run Time : 94.17 sec
INFO:root:2024-04-14 09:13:53, Train, Epoch : 1, Step : 420, Loss : 0.58217, Acc : 0.728, Sensitive_Loss : 0.40864, Sensitive_Acc : 19.700, Run Time : 8.07 sec
INFO:root:2024-04-14 09:14:01, Train, Epoch : 1, Step : 430, Loss : 0.52827, Acc : 0.744, Sensitive_Loss : 0.40714, Sensitive_Acc : 18.800, Run Time : 7.90 sec
INFO:root:2024-04-14 09:14:09, Train, Epoch : 1, Step : 440, Loss : 0.62559, Acc : 0.694, Sensitive_Loss : 0.42594, Sensitive_Acc : 18.300, Run Time : 7.87 sec
INFO:root:2024-04-14 09:14:17, Train, Epoch : 1, Step : 450, Loss : 0.58766, Acc : 0.697, Sensitive_Loss : 0.44534, Sensitive_Acc : 23.000, Run Time : 8.19 sec
INFO:root:2024-04-14 09:14:25, Train, Epoch : 1, Step : 460, Loss : 0.61750, Acc : 0.700, Sensitive_Loss : 0.46078, Sensitive_Acc : 20.400, Run Time : 8.12 sec
INFO:root:2024-04-14 09:14:33, Train, Epoch : 1, Step : 470, Loss : 0.49260, Acc : 0.725, Sensitive_Loss : 0.51435, Sensitive_Acc : 22.200, Run Time : 7.74 sec
INFO:root:2024-04-14 09:14:41, Train, Epoch : 1, Step : 480, Loss : 0.54007, Acc : 0.694, Sensitive_Loss : 0.41624, Sensitive_Acc : 24.200, Run Time : 7.75 sec
INFO:root:2024-04-14 09:14:49, Train, Epoch : 1, Step : 490, Loss : 0.60444, Acc : 0.713, Sensitive_Loss : 0.40550, Sensitive_Acc : 16.300, Run Time : 8.13 sec
INFO:root:2024-04-14 09:14:57, Train, Epoch : 1, Step : 500, Loss : 0.57404, Acc : 0.731, Sensitive_Loss : 0.37589, Sensitive_Acc : 19.000, Run Time : 7.89 sec
INFO:root:2024-04-14 09:16:25, Dev, Step : 500, Loss : 0.57244, Acc : 0.730, Auc : 0.802, Sensitive_Loss : 0.53982, Sensitive_Acc : 17.782, Sensitive_Auc : 0.964, Mean auc: 0.802, Run Time : 87.92 sec
INFO:root:2024-04-14 09:16:30, Train, Epoch : 1, Step : 510, Loss : 0.56531, Acc : 0.706, Sensitive_Loss : 0.38094, Sensitive_Acc : 23.400, Run Time : 93.61 sec
INFO:root:2024-04-14 09:16:39, Train, Epoch : 1, Step : 520, Loss : 0.53181, Acc : 0.728, Sensitive_Loss : 0.36643, Sensitive_Acc : 20.400, Run Time : 8.02 sec
INFO:root:2024-04-14 09:16:46, Train, Epoch : 1, Step : 530, Loss : 0.62263, Acc : 0.706, Sensitive_Loss : 0.36476, Sensitive_Acc : 21.800, Run Time : 7.81 sec
INFO:root:2024-04-14 09:16:54, Train, Epoch : 1, Step : 540, Loss : 0.53512, Acc : 0.769, Sensitive_Loss : 0.34441, Sensitive_Acc : 17.900, Run Time : 7.77 sec
INFO:root:2024-04-14 09:17:02, Train, Epoch : 1, Step : 550, Loss : 0.52351, Acc : 0.722, Sensitive_Loss : 0.32156, Sensitive_Acc : 20.100, Run Time : 8.19 sec
INFO:root:2024-04-14 09:17:10, Train, Epoch : 1, Step : 560, Loss : 0.57110, Acc : 0.703, Sensitive_Loss : 0.32476, Sensitive_Acc : 15.700, Run Time : 7.77 sec
INFO:root:2024-04-14 09:17:18, Train, Epoch : 1, Step : 570, Loss : 0.57488, Acc : 0.716, Sensitive_Loss : 0.38750, Sensitive_Acc : 17.600, Run Time : 8.07 sec
INFO:root:2024-04-14 09:17:26, Train, Epoch : 1, Step : 580, Loss : 0.55036, Acc : 0.722, Sensitive_Loss : 0.35569, Sensitive_Acc : 24.100, Run Time : 8.14 sec
INFO:root:2024-04-14 09:17:34, Train, Epoch : 1, Step : 590, Loss : 0.51854, Acc : 0.753, Sensitive_Loss : 0.30364, Sensitive_Acc : 19.300, Run Time : 7.59 sec
INFO:root:2024-04-14 09:17:42, Train, Epoch : 1, Step : 600, Loss : 0.57934, Acc : 0.722, Sensitive_Loss : 0.32554, Sensitive_Acc : 23.800, Run Time : 7.67 sec
INFO:root:2024-04-14 09:19:10, Dev, Step : 600, Loss : 0.58599, Acc : 0.716, Auc : 0.816, Sensitive_Loss : 0.31338, Sensitive_Acc : 20.639, Sensitive_Auc : 0.964, Mean auc: 0.816, Run Time : 88.17 sec
INFO:root:2024-04-14 09:19:10, Best, Step : 600, Loss : 0.58599, Acc : 0.716, Auc : 0.816, Sensitive_Loss : 0.31338, Sensitive_Acc : 20.639, Sensitive_Auc : 0.964, Best Auc : 0.816
INFO:root:2024-04-14 09:19:16, Train, Epoch : 1, Step : 610, Loss : 0.55052, Acc : 0.731, Sensitive_Loss : 0.37934, Sensitive_Acc : 23.900, Run Time : 94.48 sec
INFO:root:2024-04-14 09:19:24, Train, Epoch : 1, Step : 620, Loss : 0.58572, Acc : 0.703, Sensitive_Loss : 0.31055, Sensitive_Acc : 22.100, Run Time : 7.98 sec
INFO:root:2024-04-14 09:19:32, Train, Epoch : 1, Step : 630, Loss : 0.52799, Acc : 0.722, Sensitive_Loss : 0.33566, Sensitive_Acc : 26.500, Run Time : 7.76 sec
INFO:root:2024-04-14 09:21:02
INFO:root:y_pred: [0.16427404 0.07452785 0.18121743 ... 0.13351282 0.10854349 0.26074868]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [4.7385204e-03 1.7397895e-02 2.1183895e-01 5.8120096e-01 4.8128441e-01
 6.1753359e-02 1.5110134e-02 3.4685217e-02 1.9324165e-02 9.9672842e-01
 6.5926522e-01 8.5572340e-03 1.8802188e-02 1.1885132e-03 9.9978417e-01
 1.9778745e-01 2.2170603e-01 9.9851865e-01 9.9938095e-01 2.1512119e-02
 9.3190217e-01 2.8652251e-02 3.4233835e-01 2.0378387e-01 2.6620856e-01
 4.4715789e-01 3.4902308e-03 3.5745226e-02 3.6015986e-03 3.2831670e-03
 2.0676656e-01 9.9751759e-01 2.8023797e-01 9.4771624e-01 2.3801934e-02
 4.2857616e-03 1.8505018e-02 7.1743920e-02 6.9022365e-02 2.8689501e-01
 4.9945343e-01 9.9423510e-01 5.3559434e-01 5.1613107e-02 9.9917763e-01
 6.5101093e-01 7.6648974e-01 8.1817371e-01 7.9495341e-01 9.9558097e-01
 9.3376493e-01 9.9885345e-01 9.9978095e-01 5.5696912e-02 4.2723134e-02
 8.3320296e-01 9.2321178e-03 1.1180217e-01 9.9796581e-01 3.6440596e-02
 1.7474009e-02 1.7704252e-03 1.3626257e-02 1.4045293e-04 9.9827945e-01
 1.2892878e-03 2.5170608e-04 3.0909923e-01 6.2031611e-03 9.7900486e-01
 9.9832278e-01 9.9960011e-01 2.5048351e-02 6.0078567e-01 1.9357760e-02
 9.4257283e-01 3.8000557e-01 4.4140540e-02 1.9205388e-02 1.9967237e-01
 2.0321052e-01 1.1033861e-03 9.6018595e-01 9.8906785e-01 1.3279666e-01
 1.6515455e-01 1.8889198e-01 1.2111578e-01 2.2356963e-02 2.0546477e-02
 4.0162493e-02 6.7153996e-01 3.8010732e-04 4.7415099e-03 5.8814186e-01
 7.1091145e-02 1.0433985e-03 1.3442513e-01 3.1759702e-02 5.8549829e-02
 1.2022242e-02 3.1232243e-02 3.8052788e-01 2.7958507e-02 6.5036613e-01
 1.3984585e-03 7.5144136e-01 9.5453984e-01 9.7699499e-01 5.7331866e-01
 1.6802130e-04 9.9966109e-01 9.9809474e-01 3.0078462e-04 9.6043572e-02
 6.8715620e-01 4.1881314e-01 1.1311689e-02 9.0185529e-01 5.2817516e-02
 1.3301970e-01 2.0881351e-03 1.3160184e-01 1.0470460e-02 2.6151663e-01
 9.7684890e-01 1.4067213e-03 9.9920827e-01 5.0226951e-01 6.6141754e-01
 9.9600041e-03 7.9165757e-01 2.9190539e-03]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-14 09:21:02, Dev, Step : 634, Loss : 0.57515, Acc : 0.733, Auc : 0.823, Sensitive_Loss : 0.40888, Sensitive_Acc : 19.000, Sensitive_Auc : 0.978, Mean auc: 0.823, Run Time : 86.92 sec
INFO:root:2024-04-14 09:21:02, Best, Step : 634, Loss : 0.57515, Acc : 0.733,Auc : 0.823, Best Auc : 0.823, Sensitive_Loss : 0.40888, Sensitive_Acc : 19.000, Sensitive_Auc : 0.978
INFO:root:2024-04-14 09:21:09, Train, Epoch : 2, Step : 640, Loss : 0.34594, Acc : 0.425, Sensitive_Loss : 0.16084, Sensitive_Acc : 15.300, Run Time : 5.57 sec
INFO:root:2024-04-14 09:21:15, Train, Epoch : 2, Step : 650, Loss : 0.50705, Acc : 0.731, Sensitive_Loss : 0.23831, Sensitive_Acc : 21.600, Run Time : 6.84 sec
INFO:root:2024-04-14 09:21:22, Train, Epoch : 2, Step : 660, Loss : 0.55394, Acc : 0.731, Sensitive_Loss : 0.40113, Sensitive_Acc : 15.000, Run Time : 7.12 sec
INFO:root:2024-04-14 09:21:30, Train, Epoch : 2, Step : 670, Loss : 0.51351, Acc : 0.794, Sensitive_Loss : 0.31111, Sensitive_Acc : 25.300, Run Time : 7.03 sec
INFO:root:2024-04-14 09:21:36, Train, Epoch : 2, Step : 680, Loss : 0.50931, Acc : 0.787, Sensitive_Loss : 0.36988, Sensitive_Acc : 19.100, Run Time : 6.81 sec
INFO:root:2024-04-14 09:21:44, Train, Epoch : 2, Step : 690, Loss : 0.48697, Acc : 0.747, Sensitive_Loss : 0.30177, Sensitive_Acc : 19.700, Run Time : 7.85 sec
INFO:root:2024-04-14 09:21:51, Train, Epoch : 2, Step : 700, Loss : 0.63779, Acc : 0.722, Sensitive_Loss : 0.28299, Sensitive_Acc : 19.200, Run Time : 6.69 sec
INFO:root:2024-04-14 09:23:19, Dev, Step : 700, Loss : 0.62166, Acc : 0.713, Auc : 0.816, Sensitive_Loss : 0.32499, Sensitive_Acc : 21.150, Sensitive_Auc : 0.975, Mean auc: 0.816, Run Time : 87.66 sec
INFO:root:2024-04-14 09:23:24, Train, Epoch : 2, Step : 710, Loss : 0.55746, Acc : 0.775, Sensitive_Loss : 0.26593, Sensitive_Acc : 23.500, Run Time : 93.54 sec
INFO:root:2024-04-14 09:23:32, Train, Epoch : 2, Step : 720, Loss : 0.54110, Acc : 0.741, Sensitive_Loss : 0.31961, Sensitive_Acc : 20.000, Run Time : 7.29 sec
INFO:root:2024-04-14 09:23:38, Train, Epoch : 2, Step : 730, Loss : 0.54355, Acc : 0.706, Sensitive_Loss : 0.34284, Sensitive_Acc : 23.400, Run Time : 6.62 sec
INFO:root:2024-04-14 09:23:45, Train, Epoch : 2, Step : 740, Loss : 0.49847, Acc : 0.747, Sensitive_Loss : 0.30726, Sensitive_Acc : 17.700, Run Time : 7.13 sec
INFO:root:2024-04-14 09:23:53, Train, Epoch : 2, Step : 750, Loss : 0.48008, Acc : 0.787, Sensitive_Loss : 0.29347, Sensitive_Acc : 18.900, Run Time : 7.44 sec
INFO:root:2024-04-14 09:24:00, Train, Epoch : 2, Step : 760, Loss : 0.57314, Acc : 0.725, Sensitive_Loss : 0.31058, Sensitive_Acc : 22.300, Run Time : 6.81 sec
INFO:root:2024-04-14 09:24:07, Train, Epoch : 2, Step : 770, Loss : 0.56143, Acc : 0.744, Sensitive_Loss : 0.44552, Sensitive_Acc : 21.500, Run Time : 7.02 sec
INFO:root:2024-04-14 09:24:14, Train, Epoch : 2, Step : 780, Loss : 0.60005, Acc : 0.719, Sensitive_Loss : 0.34738, Sensitive_Acc : 22.000, Run Time : 6.84 sec
INFO:root:2024-04-14 09:24:20, Train, Epoch : 2, Step : 790, Loss : 0.52326, Acc : 0.716, Sensitive_Loss : 0.32039, Sensitive_Acc : 20.000, Run Time : 6.69 sec
INFO:root:2024-04-14 09:24:27, Train, Epoch : 2, Step : 800, Loss : 0.50861, Acc : 0.709, Sensitive_Loss : 0.26053, Sensitive_Acc : 20.500, Run Time : 7.02 sec
INFO:root:2024-04-14 09:25:55, Dev, Step : 800, Loss : 0.61241, Acc : 0.723, Auc : 0.824, Sensitive_Loss : 0.37642, Sensitive_Acc : 20.098, Sensitive_Auc : 0.976, Mean auc: 0.824, Run Time : 87.89 sec
INFO:root:2024-04-14 09:25:56, Best, Step : 800, Loss : 0.61241, Acc : 0.723, Auc : 0.824, Sensitive_Loss : 0.37642, Sensitive_Acc : 20.098, Sensitive_Auc : 0.976, Best Auc : 0.824
INFO:root:2024-04-14 09:26:01, Train, Epoch : 2, Step : 810, Loss : 0.56038, Acc : 0.734, Sensitive_Loss : 0.38562, Sensitive_Acc : 23.600, Run Time : 93.81 sec
INFO:root:2024-04-14 09:26:08, Train, Epoch : 2, Step : 820, Loss : 0.58849, Acc : 0.716, Sensitive_Loss : 0.30502, Sensitive_Acc : 24.500, Run Time : 7.23 sec
INFO:root:2024-04-14 09:26:16, Train, Epoch : 2, Step : 830, Loss : 0.48267, Acc : 0.766, Sensitive_Loss : 0.19111, Sensitive_Acc : 22.700, Run Time : 7.41 sec
INFO:root:2024-04-14 09:26:23, Train, Epoch : 2, Step : 840, Loss : 0.49565, Acc : 0.759, Sensitive_Loss : 0.27924, Sensitive_Acc : 19.300, Run Time : 7.03 sec
INFO:root:2024-04-14 09:26:30, Train, Epoch : 2, Step : 850, Loss : 0.56376, Acc : 0.700, Sensitive_Loss : 0.34412, Sensitive_Acc : 22.300, Run Time : 7.62 sec
INFO:root:2024-04-14 09:26:37, Train, Epoch : 2, Step : 860, Loss : 0.54775, Acc : 0.734, Sensitive_Loss : 0.26912, Sensitive_Acc : 20.600, Run Time : 6.97 sec
INFO:root:2024-04-14 09:26:44, Train, Epoch : 2, Step : 870, Loss : 0.54881, Acc : 0.744, Sensitive_Loss : 0.25078, Sensitive_Acc : 22.900, Run Time : 6.80 sec
INFO:root:2024-04-14 09:26:51, Train, Epoch : 2, Step : 880, Loss : 0.53525, Acc : 0.772, Sensitive_Loss : 0.41862, Sensitive_Acc : 26.300, Run Time : 7.13 sec
INFO:root:2024-04-14 09:26:58, Train, Epoch : 2, Step : 890, Loss : 0.51848, Acc : 0.731, Sensitive_Loss : 0.18929, Sensitive_Acc : 23.400, Run Time : 7.08 sec
INFO:root:2024-04-14 09:27:05, Train, Epoch : 2, Step : 900, Loss : 0.47104, Acc : 0.787, Sensitive_Loss : 0.23422, Sensitive_Acc : 20.400, Run Time : 6.77 sec
INFO:root:2024-04-14 09:28:33, Dev, Step : 900, Loss : 0.56810, Acc : 0.739, Auc : 0.819, Sensitive_Loss : 0.36416, Sensitive_Acc : 19.602, Sensitive_Auc : 0.991, Mean auc: 0.819, Run Time : 88.25 sec
INFO:root:2024-04-14 09:28:39, Train, Epoch : 2, Step : 910, Loss : 0.47424, Acc : 0.744, Sensitive_Loss : 0.28711, Sensitive_Acc : 19.200, Run Time : 93.53 sec
INFO:root:2024-04-14 09:28:46, Train, Epoch : 2, Step : 920, Loss : 0.55565, Acc : 0.766, Sensitive_Loss : 0.25625, Sensitive_Acc : 21.200, Run Time : 7.44 sec
INFO:root:2024-04-14 09:28:53, Train, Epoch : 2, Step : 930, Loss : 0.54605, Acc : 0.709, Sensitive_Loss : 0.32513, Sensitive_Acc : 19.300, Run Time : 6.92 sec
INFO:root:2024-04-14 09:29:00, Train, Epoch : 2, Step : 940, Loss : 0.53048, Acc : 0.738, Sensitive_Loss : 0.23443, Sensitive_Acc : 20.900, Run Time : 7.17 sec
INFO:root:2024-04-14 09:29:07, Train, Epoch : 2, Step : 950, Loss : 0.50707, Acc : 0.753, Sensitive_Loss : 0.28728, Sensitive_Acc : 14.600, Run Time : 6.95 sec
INFO:root:2024-04-14 09:29:14, Train, Epoch : 2, Step : 960, Loss : 0.50306, Acc : 0.759, Sensitive_Loss : 0.20602, Sensitive_Acc : 22.800, Run Time : 7.19 sec
INFO:root:2024-04-14 09:29:21, Train, Epoch : 2, Step : 970, Loss : 0.53155, Acc : 0.753, Sensitive_Loss : 0.24171, Sensitive_Acc : 23.900, Run Time : 6.75 sec
INFO:root:2024-04-14 09:29:28, Train, Epoch : 2, Step : 980, Loss : 0.51931, Acc : 0.741, Sensitive_Loss : 0.26636, Sensitive_Acc : 19.200, Run Time : 7.42 sec
INFO:root:2024-04-14 09:29:36, Train, Epoch : 2, Step : 990, Loss : 0.53503, Acc : 0.722, Sensitive_Loss : 0.27571, Sensitive_Acc : 23.500, Run Time : 7.53 sec
INFO:root:2024-04-14 09:29:43, Train, Epoch : 2, Step : 1000, Loss : 0.50775, Acc : 0.728, Sensitive_Loss : 0.27523, Sensitive_Acc : 22.100, Run Time : 7.01 sec
INFO:root:2024-04-14 09:31:10, Dev, Step : 1000, Loss : 0.52522, Acc : 0.761, Auc : 0.838, Sensitive_Loss : 0.29684, Sensitive_Acc : 21.060, Sensitive_Auc : 0.988, Mean auc: 0.838, Run Time : 87.33 sec
INFO:root:2024-04-14 09:31:11, Best, Step : 1000, Loss : 0.52522, Acc : 0.761, Auc : 0.838, Sensitive_Loss : 0.29684, Sensitive_Acc : 21.060, Sensitive_Auc : 0.988, Best Auc : 0.838
INFO:root:2024-04-14 09:31:16, Train, Epoch : 2, Step : 1010, Loss : 0.49475, Acc : 0.794, Sensitive_Loss : 0.38349, Sensitive_Acc : 20.800, Run Time : 93.23 sec
INFO:root:2024-04-14 09:31:24, Train, Epoch : 2, Step : 1020, Loss : 0.54241, Acc : 0.747, Sensitive_Loss : 0.22170, Sensitive_Acc : 24.300, Run Time : 7.72 sec
INFO:root:2024-04-14 09:31:31, Train, Epoch : 2, Step : 1030, Loss : 0.54381, Acc : 0.759, Sensitive_Loss : 0.30515, Sensitive_Acc : 22.400, Run Time : 7.32 sec
INFO:root:2024-04-14 09:31:38, Train, Epoch : 2, Step : 1040, Loss : 0.50220, Acc : 0.734, Sensitive_Loss : 0.29811, Sensitive_Acc : 23.200, Run Time : 7.15 sec
INFO:root:2024-04-14 09:31:46, Train, Epoch : 2, Step : 1050, Loss : 0.52475, Acc : 0.741, Sensitive_Loss : 0.30487, Sensitive_Acc : 20.100, Run Time : 7.41 sec
INFO:root:2024-04-14 09:31:53, Train, Epoch : 2, Step : 1060, Loss : 0.55734, Acc : 0.750, Sensitive_Loss : 0.29610, Sensitive_Acc : 19.200, Run Time : 7.06 sec
INFO:root:2024-04-14 09:32:00, Train, Epoch : 2, Step : 1070, Loss : 0.48890, Acc : 0.787, Sensitive_Loss : 0.27929, Sensitive_Acc : 24.700, Run Time : 7.08 sec
INFO:root:2024-04-14 09:32:07, Train, Epoch : 2, Step : 1080, Loss : 0.52209, Acc : 0.750, Sensitive_Loss : 0.21606, Sensitive_Acc : 24.100, Run Time : 7.12 sec
INFO:root:2024-04-14 09:32:14, Train, Epoch : 2, Step : 1090, Loss : 0.58491, Acc : 0.722, Sensitive_Loss : 0.19015, Sensitive_Acc : 19.500, Run Time : 6.96 sec
INFO:root:2024-04-14 09:32:21, Train, Epoch : 2, Step : 1100, Loss : 0.48277, Acc : 0.794, Sensitive_Loss : 0.24826, Sensitive_Acc : 24.300, Run Time : 7.18 sec
INFO:root:2024-04-14 09:33:50, Dev, Step : 1100, Loss : 0.53787, Acc : 0.750, Auc : 0.829, Sensitive_Loss : 0.45524, Sensitive_Acc : 19.000, Sensitive_Auc : 0.975, Mean auc: 0.829, Run Time : 88.73 sec
INFO:root:2024-04-14 09:33:55, Train, Epoch : 2, Step : 1110, Loss : 0.54835, Acc : 0.731, Sensitive_Loss : 0.26192, Sensitive_Acc : 20.000, Run Time : 94.01 sec
INFO:root:2024-04-14 09:34:03, Train, Epoch : 2, Step : 1120, Loss : 0.60012, Acc : 0.713, Sensitive_Loss : 0.34796, Sensitive_Acc : 22.300, Run Time : 7.21 sec
INFO:root:2024-04-14 09:34:10, Train, Epoch : 2, Step : 1130, Loss : 0.52858, Acc : 0.781, Sensitive_Loss : 0.33458, Sensitive_Acc : 23.400, Run Time : 7.01 sec
INFO:root:2024-04-14 09:34:17, Train, Epoch : 2, Step : 1140, Loss : 0.42868, Acc : 0.791, Sensitive_Loss : 0.32100, Sensitive_Acc : 23.400, Run Time : 7.26 sec
INFO:root:2024-04-14 09:34:24, Train, Epoch : 2, Step : 1150, Loss : 0.48816, Acc : 0.750, Sensitive_Loss : 0.26773, Sensitive_Acc : 23.700, Run Time : 7.54 sec
INFO:root:2024-04-14 09:34:31, Train, Epoch : 2, Step : 1160, Loss : 0.54501, Acc : 0.762, Sensitive_Loss : 0.28658, Sensitive_Acc : 19.600, Run Time : 6.29 sec
INFO:root:2024-04-14 09:34:38, Train, Epoch : 2, Step : 1170, Loss : 0.46311, Acc : 0.778, Sensitive_Loss : 0.27669, Sensitive_Acc : 20.300, Run Time : 7.59 sec
INFO:root:2024-04-14 09:34:45, Train, Epoch : 2, Step : 1180, Loss : 0.51594, Acc : 0.744, Sensitive_Loss : 0.28085, Sensitive_Acc : 24.100, Run Time : 6.88 sec
INFO:root:2024-04-14 09:34:52, Train, Epoch : 2, Step : 1190, Loss : 0.57079, Acc : 0.769, Sensitive_Loss : 0.26250, Sensitive_Acc : 24.200, Run Time : 6.82 sec
INFO:root:2024-04-14 09:34:59, Train, Epoch : 2, Step : 1200, Loss : 0.58225, Acc : 0.725, Sensitive_Loss : 0.29060, Sensitive_Acc : 18.100, Run Time : 7.23 sec
INFO:root:2024-04-14 09:36:27, Dev, Step : 1200, Loss : 0.63228, Acc : 0.699, Auc : 0.823, Sensitive_Loss : 0.31201, Sensitive_Acc : 20.504, Sensitive_Auc : 0.987, Mean auc: 0.823, Run Time : 87.56 sec
INFO:root:2024-04-14 09:36:32, Train, Epoch : 2, Step : 1210, Loss : 0.55526, Acc : 0.731, Sensitive_Loss : 0.22700, Sensitive_Acc : 21.100, Run Time : 92.68 sec
INFO:root:2024-04-14 09:36:39, Train, Epoch : 2, Step : 1220, Loss : 0.49154, Acc : 0.769, Sensitive_Loss : 0.21752, Sensitive_Acc : 20.500, Run Time : 7.29 sec
INFO:root:2024-04-14 09:36:46, Train, Epoch : 2, Step : 1230, Loss : 0.49652, Acc : 0.759, Sensitive_Loss : 0.31149, Sensitive_Acc : 23.600, Run Time : 7.29 sec
INFO:root:2024-04-14 09:36:53, Train, Epoch : 2, Step : 1240, Loss : 0.56174, Acc : 0.725, Sensitive_Loss : 0.23262, Sensitive_Acc : 18.800, Run Time : 6.86 sec
INFO:root:2024-04-14 09:37:01, Train, Epoch : 2, Step : 1250, Loss : 0.55394, Acc : 0.750, Sensitive_Loss : 0.26423, Sensitive_Acc : 14.200, Run Time : 7.49 sec
INFO:root:2024-04-14 09:37:08, Train, Epoch : 2, Step : 1260, Loss : 0.51574, Acc : 0.734, Sensitive_Loss : 0.23299, Sensitive_Acc : 24.400, Run Time : 6.85 sec
INFO:root:2024-04-14 09:38:41
INFO:root:y_pred: [0.18670347 0.0492949  0.14723004 ... 0.48966765 0.3644067  0.5476076 ]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [1.87093264e-03 1.81471165e-02 5.54442331e-02 4.10417095e-02
 7.62531832e-02 4.66618128e-03 2.32875030e-02 1.53466184e-02
 3.20648812e-02 9.99660134e-01 3.40300918e-01 9.40840750e-04
 1.10197160e-02 2.67058029e-03 9.99697804e-01 9.68392491e-02
 1.05837826e-02 9.99542356e-01 9.99616504e-01 2.68390030e-03
 8.10992241e-01 1.16471201e-03 2.25124478e-01 8.81185159e-02
 5.79640090e-01 3.24184597e-01 4.34260262e-04 4.85092169e-03
 6.93877460e-04 7.73155093e-02 6.88818842e-02 9.98507440e-01
 5.99525310e-02 9.29887712e-01 2.17966605e-02 2.79700896e-03
 7.71004707e-03 1.09862775e-01 2.16507182e-01 2.05282882e-01
 2.32761368e-01 9.94967520e-01 1.98739856e-01 2.36342531e-02
 9.90953743e-01 7.89588571e-01 3.98992807e-01 1.43351465e-01
 8.03127229e-01 9.94583428e-01 9.84662890e-01 9.99848127e-01
 9.95472312e-01 4.51713130e-02 1.89290941e-02 6.47700846e-01
 1.80506315e-02 1.47823751e-01 9.98385072e-01 2.91993679e-03
 1.14569953e-02 4.20980109e-03 3.07335006e-03 4.54965957e-05
 9.93092895e-01 2.02972535e-03 3.96421936e-04 1.00874156e-02
 3.54787195e-03 9.81330812e-01 9.99774754e-01 9.99555290e-01
 1.10214751e-03 7.34778285e-01 9.87636521e-02 8.33716631e-01
 5.89962378e-02 1.22698245e-03 1.37473503e-03 2.65795691e-03
 6.85955063e-02 1.27216429e-02 9.87587750e-01 9.98846650e-01
 8.93345028e-02 6.74183190e-01 3.51737857e-01 9.86695588e-02
 6.41511194e-03 2.43690517e-03 4.75681797e-02 5.71006536e-01
 9.02289699e-04 6.08523493e-04 1.05781987e-01 8.09322856e-03
 4.90631443e-04 6.16092026e-01 1.40259638e-02 6.55048853e-03
 5.96291833e-02 7.85905588e-03 1.85032547e-01 2.58199647e-02
 1.45140558e-01 2.92503880e-03 8.30566525e-01 9.05616820e-01
 9.53833520e-01 9.03959751e-01 1.36811519e-04 9.99431193e-01
 9.99475181e-01 4.96494584e-04 7.45998502e-01 3.05064827e-01
 1.14755318e-01 8.45742470e-04 8.40316594e-01 2.37955432e-02
 5.07550547e-03 1.64457709e-02 1.10634547e-02 1.48011197e-03
 5.68138883e-02 7.52419114e-01 1.62808268e-04 9.98805165e-01
 4.20718603e-02 3.90283555e-01 2.66807096e-04 4.34835315e-01
 4.02395520e-03]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-14 09:38:41, Dev, Step : 1268, Loss : 0.56059, Acc : 0.727, Auc : 0.832, Sensitive_Loss : 0.27933, Sensitive_Acc : 20.113, Sensitive_Auc : 0.992, Mean auc: 0.832, Run Time : 87.76 sec
INFO:root:2024-04-14 09:38:44, Train, Epoch : 3, Step : 1270, Loss : 0.09590, Acc : 0.159, Sensitive_Loss : 0.07256, Sensitive_Acc : 2.900, Run Time : 3.08 sec
INFO:root:2024-04-14 09:38:51, Train, Epoch : 3, Step : 1280, Loss : 0.49586, Acc : 0.794, Sensitive_Loss : 0.26289, Sensitive_Acc : 22.600, Run Time : 6.58 sec
INFO:root:2024-04-14 09:38:58, Train, Epoch : 3, Step : 1290, Loss : 0.46031, Acc : 0.787, Sensitive_Loss : 0.24580, Sensitive_Acc : 21.600, Run Time : 7.23 sec
INFO:root:2024-04-14 09:39:05, Train, Epoch : 3, Step : 1300, Loss : 0.43489, Acc : 0.809, Sensitive_Loss : 0.22550, Sensitive_Acc : 22.100, Run Time : 7.24 sec
INFO:root:2024-04-14 09:40:33, Dev, Step : 1300, Loss : 0.51724, Acc : 0.764, Auc : 0.844, Sensitive_Loss : 0.25022, Sensitive_Acc : 20.609, Sensitive_Auc : 0.991, Mean auc: 0.844, Run Time : 87.75 sec
INFO:root:2024-04-14 09:40:34, Best, Step : 1300, Loss : 0.51724, Acc : 0.764, Auc : 0.844, Sensitive_Loss : 0.25022, Sensitive_Acc : 20.609, Sensitive_Auc : 0.991, Best Auc : 0.844
INFO:root:2024-04-14 09:40:40, Train, Epoch : 3, Step : 1310, Loss : 0.48579, Acc : 0.794, Sensitive_Loss : 0.21248, Sensitive_Acc : 21.400, Run Time : 94.11 sec
INFO:root:2024-04-14 09:40:47, Train, Epoch : 3, Step : 1320, Loss : 0.46687, Acc : 0.787, Sensitive_Loss : 0.18082, Sensitive_Acc : 20.200, Run Time : 6.97 sec
INFO:root:2024-04-14 09:40:53, Train, Epoch : 3, Step : 1330, Loss : 0.40021, Acc : 0.816, Sensitive_Loss : 0.18095, Sensitive_Acc : 19.300, Run Time : 6.92 sec
INFO:root:2024-04-14 09:41:01, Train, Epoch : 3, Step : 1340, Loss : 0.41097, Acc : 0.806, Sensitive_Loss : 0.14642, Sensitive_Acc : 19.900, Run Time : 7.50 sec
INFO:root:2024-04-14 09:41:08, Train, Epoch : 3, Step : 1350, Loss : 0.45657, Acc : 0.822, Sensitive_Loss : 0.16807, Sensitive_Acc : 26.200, Run Time : 7.10 sec
INFO:root:2024-04-14 09:41:15, Train, Epoch : 3, Step : 1360, Loss : 0.51683, Acc : 0.738, Sensitive_Loss : 0.10784, Sensitive_Acc : 23.800, Run Time : 6.86 sec
INFO:root:2024-04-14 09:41:22, Train, Epoch : 3, Step : 1370, Loss : 0.44496, Acc : 0.806, Sensitive_Loss : 0.16079, Sensitive_Acc : 21.700, Run Time : 7.15 sec
INFO:root:2024-04-14 09:41:29, Train, Epoch : 3, Step : 1380, Loss : 0.41255, Acc : 0.828, Sensitive_Loss : 0.21873, Sensitive_Acc : 22.900, Run Time : 6.89 sec
INFO:root:2024-04-14 09:41:36, Train, Epoch : 3, Step : 1390, Loss : 0.38148, Acc : 0.803, Sensitive_Loss : 0.23189, Sensitive_Acc : 23.100, Run Time : 6.96 sec
INFO:root:2024-04-14 09:41:44, Train, Epoch : 3, Step : 1400, Loss : 0.46084, Acc : 0.800, Sensitive_Loss : 0.20842, Sensitive_Acc : 24.300, Run Time : 7.70 sec
INFO:root:2024-04-14 09:43:11, Dev, Step : 1400, Loss : 0.51792, Acc : 0.770, Auc : 0.849, Sensitive_Loss : 0.27568, Sensitive_Acc : 20.368, Sensitive_Auc : 0.992, Mean auc: 0.849, Run Time : 87.68 sec
INFO:root:2024-04-14 09:43:12, Best, Step : 1400, Loss : 0.51792, Acc : 0.770, Auc : 0.849, Sensitive_Loss : 0.27568, Sensitive_Acc : 20.368, Sensitive_Auc : 0.992, Best Auc : 0.849
INFO:root:2024-04-14 09:43:18, Train, Epoch : 3, Step : 1410, Loss : 0.49760, Acc : 0.800, Sensitive_Loss : 0.21796, Sensitive_Acc : 22.500, Run Time : 94.02 sec
INFO:root:2024-04-14 09:43:24, Train, Epoch : 3, Step : 1420, Loss : 0.45393, Acc : 0.819, Sensitive_Loss : 0.17585, Sensitive_Acc : 24.100, Run Time : 6.85 sec
INFO:root:2024-04-14 09:43:32, Train, Epoch : 3, Step : 1430, Loss : 0.45429, Acc : 0.803, Sensitive_Loss : 0.20224, Sensitive_Acc : 18.300, Run Time : 7.14 sec
INFO:root:2024-04-14 09:43:39, Train, Epoch : 3, Step : 1440, Loss : 0.43130, Acc : 0.816, Sensitive_Loss : 0.19006, Sensitive_Acc : 20.100, Run Time : 6.99 sec
INFO:root:2024-04-14 09:43:46, Train, Epoch : 3, Step : 1450, Loss : 0.44039, Acc : 0.797, Sensitive_Loss : 0.19999, Sensitive_Acc : 21.200, Run Time : 7.11 sec
INFO:root:2024-04-14 09:43:53, Train, Epoch : 3, Step : 1460, Loss : 0.50344, Acc : 0.778, Sensitive_Loss : 0.22120, Sensitive_Acc : 17.400, Run Time : 7.14 sec
INFO:root:2024-04-14 09:44:00, Train, Epoch : 3, Step : 1470, Loss : 0.42045, Acc : 0.794, Sensitive_Loss : 0.18134, Sensitive_Acc : 17.600, Run Time : 6.95 sec
INFO:root:2024-04-14 09:44:07, Train, Epoch : 3, Step : 1480, Loss : 0.49971, Acc : 0.787, Sensitive_Loss : 0.20036, Sensitive_Acc : 24.000, Run Time : 7.63 sec
INFO:root:2024-04-14 09:44:14, Train, Epoch : 3, Step : 1490, Loss : 0.41973, Acc : 0.769, Sensitive_Loss : 0.16167, Sensitive_Acc : 19.600, Run Time : 7.05 sec
INFO:root:2024-04-14 09:44:21, Train, Epoch : 3, Step : 1500, Loss : 0.43433, Acc : 0.819, Sensitive_Loss : 0.17936, Sensitive_Acc : 24.000, Run Time : 6.82 sec
INFO:root:2024-04-14 09:45:49, Dev, Step : 1500, Loss : 0.50475, Acc : 0.771, Auc : 0.853, Sensitive_Loss : 0.23412, Sensitive_Acc : 20.729, Sensitive_Auc : 0.992, Mean auc: 0.853, Run Time : 88.07 sec
INFO:root:2024-04-14 09:45:50, Best, Step : 1500, Loss : 0.50475, Acc : 0.771, Auc : 0.853, Sensitive_Loss : 0.23412, Sensitive_Acc : 20.729, Sensitive_Auc : 0.992, Best Auc : 0.853
INFO:root:2024-04-14 09:45:56, Train, Epoch : 3, Step : 1510, Loss : 0.40411, Acc : 0.834, Sensitive_Loss : 0.13092, Sensitive_Acc : 23.900, Run Time : 94.91 sec
INFO:root:2024-04-14 09:46:03, Train, Epoch : 3, Step : 1520, Loss : 0.47075, Acc : 0.753, Sensitive_Loss : 0.21436, Sensitive_Acc : 19.600, Run Time : 6.67 sec
INFO:root:2024-04-14 09:46:10, Train, Epoch : 3, Step : 1530, Loss : 0.43497, Acc : 0.791, Sensitive_Loss : 0.17456, Sensitive_Acc : 24.500, Run Time : 7.29 sec
INFO:root:2024-04-14 09:46:18, Train, Epoch : 3, Step : 1540, Loss : 0.46041, Acc : 0.803, Sensitive_Loss : 0.19970, Sensitive_Acc : 24.800, Run Time : 7.40 sec
INFO:root:2024-04-14 09:46:24, Train, Epoch : 3, Step : 1550, Loss : 0.48086, Acc : 0.778, Sensitive_Loss : 0.17403, Sensitive_Acc : 15.900, Run Time : 6.79 sec
INFO:root:2024-04-14 09:46:31, Train, Epoch : 3, Step : 1560, Loss : 0.43479, Acc : 0.775, Sensitive_Loss : 0.17739, Sensitive_Acc : 18.500, Run Time : 6.72 sec
INFO:root:2024-04-14 09:46:38, Train, Epoch : 3, Step : 1570, Loss : 0.46473, Acc : 0.775, Sensitive_Loss : 0.24323, Sensitive_Acc : 19.700, Run Time : 6.90 sec
INFO:root:2024-04-14 09:46:45, Train, Epoch : 3, Step : 1580, Loss : 0.39962, Acc : 0.825, Sensitive_Loss : 0.18991, Sensitive_Acc : 24.700, Run Time : 7.25 sec
INFO:root:2024-04-14 09:46:53, Train, Epoch : 3, Step : 1590, Loss : 0.56265, Acc : 0.756, Sensitive_Loss : 0.14603, Sensitive_Acc : 22.500, Run Time : 7.30 sec
INFO:root:2024-04-14 09:47:00, Train, Epoch : 3, Step : 1600, Loss : 0.50517, Acc : 0.794, Sensitive_Loss : 0.14965, Sensitive_Acc : 16.600, Run Time : 7.06 sec
INFO:root:2024-04-14 09:48:28, Dev, Step : 1600, Loss : 0.50823, Acc : 0.772, Auc : 0.851, Sensitive_Loss : 0.22896, Sensitive_Acc : 21.015, Sensitive_Auc : 0.992, Mean auc: 0.851, Run Time : 87.97 sec
INFO:root:2024-04-14 09:48:33, Train, Epoch : 3, Step : 1610, Loss : 0.48552, Acc : 0.775, Sensitive_Loss : 0.25334, Sensitive_Acc : 13.900, Run Time : 93.62 sec
INFO:root:2024-04-14 09:48:40, Train, Epoch : 3, Step : 1620, Loss : 0.44767, Acc : 0.787, Sensitive_Loss : 0.19370, Sensitive_Acc : 17.500, Run Time : 7.20 sec
INFO:root:2024-04-14 09:48:47, Train, Epoch : 3, Step : 1630, Loss : 0.49643, Acc : 0.787, Sensitive_Loss : 0.19931, Sensitive_Acc : 23.300, Run Time : 6.98 sec
INFO:root:2024-04-14 09:48:54, Train, Epoch : 3, Step : 1640, Loss : 0.42330, Acc : 0.769, Sensitive_Loss : 0.16785, Sensitive_Acc : 22.500, Run Time : 6.53 sec
INFO:root:2024-04-14 09:49:02, Train, Epoch : 3, Step : 1650, Loss : 0.46245, Acc : 0.794, Sensitive_Loss : 0.16637, Sensitive_Acc : 24.800, Run Time : 7.74 sec
INFO:root:2024-04-14 09:49:08, Train, Epoch : 3, Step : 1660, Loss : 0.43058, Acc : 0.797, Sensitive_Loss : 0.17529, Sensitive_Acc : 20.000, Run Time : 6.65 sec
INFO:root:2024-04-14 09:49:15, Train, Epoch : 3, Step : 1670, Loss : 0.44334, Acc : 0.797, Sensitive_Loss : 0.15504, Sensitive_Acc : 23.200, Run Time : 6.93 sec
INFO:root:2024-04-14 09:49:22, Train, Epoch : 3, Step : 1680, Loss : 0.44336, Acc : 0.819, Sensitive_Loss : 0.18422, Sensitive_Acc : 20.000, Run Time : 6.95 sec
INFO:root:2024-04-14 09:49:30, Train, Epoch : 3, Step : 1690, Loss : 0.44731, Acc : 0.800, Sensitive_Loss : 0.23821, Sensitive_Acc : 19.700, Run Time : 7.39 sec
INFO:root:2024-04-14 09:49:37, Train, Epoch : 3, Step : 1700, Loss : 0.43712, Acc : 0.797, Sensitive_Loss : 0.18659, Sensitive_Acc : 19.100, Run Time : 7.49 sec
INFO:root:2024-04-14 09:51:05, Dev, Step : 1700, Loss : 0.51224, Acc : 0.773, Auc : 0.855, Sensitive_Loss : 0.23966, Sensitive_Acc : 21.150, Sensitive_Auc : 0.993, Mean auc: 0.855, Run Time : 87.49 sec
INFO:root:2024-04-14 09:51:05, Best, Step : 1700, Loss : 0.51224, Acc : 0.773, Auc : 0.855, Sensitive_Loss : 0.23966, Sensitive_Acc : 21.150, Sensitive_Auc : 0.993, Best Auc : 0.855
INFO:root:2024-04-14 09:51:11, Train, Epoch : 3, Step : 1710, Loss : 0.44375, Acc : 0.800, Sensitive_Loss : 0.17577, Sensitive_Acc : 22.200, Run Time : 93.69 sec
INFO:root:2024-04-14 09:51:18, Train, Epoch : 3, Step : 1720, Loss : 0.43785, Acc : 0.781, Sensitive_Loss : 0.23164, Sensitive_Acc : 25.300, Run Time : 7.35 sec
INFO:root:2024-04-14 09:51:25, Train, Epoch : 3, Step : 1730, Loss : 0.47192, Acc : 0.803, Sensitive_Loss : 0.16588, Sensitive_Acc : 22.300, Run Time : 6.95 sec
INFO:root:2024-04-14 09:51:32, Train, Epoch : 3, Step : 1740, Loss : 0.39691, Acc : 0.844, Sensitive_Loss : 0.22698, Sensitive_Acc : 21.600, Run Time : 7.27 sec
INFO:root:2024-04-14 09:51:40, Train, Epoch : 3, Step : 1750, Loss : 0.50467, Acc : 0.775, Sensitive_Loss : 0.23470, Sensitive_Acc : 19.400, Run Time : 7.35 sec
INFO:root:2024-04-14 09:51:46, Train, Epoch : 3, Step : 1760, Loss : 0.45366, Acc : 0.772, Sensitive_Loss : 0.19273, Sensitive_Acc : 23.000, Run Time : 6.79 sec
INFO:root:2024-04-14 09:51:53, Train, Epoch : 3, Step : 1770, Loss : 0.50679, Acc : 0.772, Sensitive_Loss : 0.17856, Sensitive_Acc : 22.200, Run Time : 6.95 sec
INFO:root:2024-04-14 09:52:00, Train, Epoch : 3, Step : 1780, Loss : 0.39620, Acc : 0.784, Sensitive_Loss : 0.19819, Sensitive_Acc : 20.000, Run Time : 6.77 sec
INFO:root:2024-04-14 09:52:08, Train, Epoch : 3, Step : 1790, Loss : 0.44703, Acc : 0.822, Sensitive_Loss : 0.29420, Sensitive_Acc : 22.600, Run Time : 7.71 sec
INFO:root:2024-04-14 09:52:15, Train, Epoch : 3, Step : 1800, Loss : 0.50654, Acc : 0.775, Sensitive_Loss : 0.23573, Sensitive_Acc : 22.500, Run Time : 6.98 sec
INFO:root:2024-04-14 09:53:43, Dev, Step : 1800, Loss : 0.49969, Acc : 0.774, Auc : 0.856, Sensitive_Loss : 0.31041, Sensitive_Acc : 20.008, Sensitive_Auc : 0.992, Mean auc: 0.856, Run Time : 87.92 sec
INFO:root:2024-04-14 09:53:43, Best, Step : 1800, Loss : 0.49969, Acc : 0.774, Auc : 0.856, Sensitive_Loss : 0.31041, Sensitive_Acc : 20.008, Sensitive_Auc : 0.992, Best Auc : 0.856
INFO:root:2024-04-14 09:53:49, Train, Epoch : 3, Step : 1810, Loss : 0.42141, Acc : 0.850, Sensitive_Loss : 0.20150, Sensitive_Acc : 18.300, Run Time : 94.13 sec
INFO:root:2024-04-14 09:53:57, Train, Epoch : 3, Step : 1820, Loss : 0.47681, Acc : 0.803, Sensitive_Loss : 0.20376, Sensitive_Acc : 15.400, Run Time : 7.52 sec
INFO:root:2024-04-14 09:54:04, Train, Epoch : 3, Step : 1830, Loss : 0.51457, Acc : 0.778, Sensitive_Loss : 0.15106, Sensitive_Acc : 20.000, Run Time : 7.37 sec
INFO:root:2024-04-14 09:54:11, Train, Epoch : 3, Step : 1840, Loss : 0.41442, Acc : 0.822, Sensitive_Loss : 0.14194, Sensitive_Acc : 22.900, Run Time : 6.71 sec
INFO:root:2024-04-14 09:54:17, Train, Epoch : 3, Step : 1850, Loss : 0.42050, Acc : 0.809, Sensitive_Loss : 0.16056, Sensitive_Acc : 21.600, Run Time : 6.59 sec
INFO:root:2024-04-14 09:54:25, Train, Epoch : 3, Step : 1860, Loss : 0.49391, Acc : 0.816, Sensitive_Loss : 0.21593, Sensitive_Acc : 18.900, Run Time : 7.55 sec
INFO:root:2024-04-14 09:54:32, Train, Epoch : 3, Step : 1870, Loss : 0.43356, Acc : 0.816, Sensitive_Loss : 0.15152, Sensitive_Acc : 21.300, Run Time : 6.99 sec
INFO:root:2024-04-14 09:54:39, Train, Epoch : 3, Step : 1880, Loss : 0.43211, Acc : 0.784, Sensitive_Loss : 0.14519, Sensitive_Acc : 18.500, Run Time : 7.15 sec
INFO:root:2024-04-14 09:54:46, Train, Epoch : 3, Step : 1890, Loss : 0.43716, Acc : 0.809, Sensitive_Loss : 0.19664, Sensitive_Acc : 21.500, Run Time : 7.19 sec
INFO:root:2024-04-14 09:54:53, Train, Epoch : 3, Step : 1900, Loss : 0.45106, Acc : 0.791, Sensitive_Loss : 0.16978, Sensitive_Acc : 24.200, Run Time : 7.00 sec
INFO:root:2024-04-14 09:56:20, Dev, Step : 1900, Loss : 0.50196, Acc : 0.775, Auc : 0.857, Sensitive_Loss : 0.23972, Sensitive_Acc : 20.759, Sensitive_Auc : 0.995, Mean auc: 0.857, Run Time : 86.73 sec
INFO:root:2024-04-14 09:56:20, Best, Step : 1900, Loss : 0.50196, Acc : 0.775, Auc : 0.857, Sensitive_Loss : 0.23972, Sensitive_Acc : 20.759, Sensitive_Auc : 0.995, Best Auc : 0.857
INFO:root:2024-04-14 09:57:48
INFO:root:y_pred: [0.12504344 0.0207325  0.06856407 ... 0.21722466 0.09865453 0.07355449]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [5.37960790e-03 1.24910232e-02 9.41640288e-02 2.01714009e-01
 9.64580104e-02 1.97826382e-02 1.91091802e-02 1.90631149e-03
 7.69513622e-02 9.99796689e-01 5.24657667e-01 2.95249932e-03
 1.32230064e-03 2.75367318e-04 9.99954700e-01 9.96088609e-02
 4.93430812e-03 9.99127209e-01 9.99336898e-01 1.77017506e-03
 7.63315976e-01 1.90443092e-03 6.66275248e-02 8.32401440e-02
 3.28972131e-01 3.58810514e-01 1.73727414e-04 4.55583259e-03
 3.47331545e-04 1.35483667e-01 9.87380370e-03 9.99464214e-01
 2.08914317e-02 8.97220790e-01 2.27981969e-03 1.50186010e-03
 4.66114562e-03 5.17451651e-02 4.83484775e-01 1.10258363e-01
 1.89118937e-01 9.96344507e-01 6.86217993e-02 7.07924366e-03
 9.85257924e-01 5.62469304e-01 3.42382759e-01 2.54620910e-01
 6.98710799e-01 9.96457160e-01 9.67847824e-01 9.99965549e-01
 9.97091413e-01 5.39646782e-02 3.56863365e-02 4.87602711e-01
 1.30243693e-02 6.13451749e-02 9.98547137e-01 1.95753388e-03
 5.31635387e-03 3.39012151e-03 1.05492147e-02 9.03110340e-05
 9.95824099e-01 2.48319423e-03 7.83437063e-05 4.03553918e-02
 2.29695570e-02 9.86847818e-01 9.99922872e-01 9.99870777e-01
 2.67344830e-03 6.21862113e-01 4.47536297e-02 7.88051665e-01
 1.01183340e-01 1.06170238e-03 1.74252153e-03 4.64199809e-03
 8.77370313e-02 2.98508466e-03 9.98514593e-01 9.96651351e-01
 4.81525473e-02 6.46575928e-01 8.76458585e-02 5.72655760e-02
 1.24599291e-02 1.12009398e-03 7.80564919e-02 1.24590553e-01
 7.37600785e-04 5.61032328e-04 2.22574454e-02 1.08028809e-02
 4.19316348e-04 5.58467805e-01 1.53359780e-02 1.94093119e-02
 2.67679174e-03 6.61289273e-03 1.86038241e-01 5.66714816e-03
 1.02136776e-01 1.36722089e-03 3.23324651e-01 9.37813640e-01
 7.19448984e-01 6.04680777e-01 1.10340749e-04 9.99932528e-01
 9.98153269e-01 1.54536276e-04 4.36748534e-01 1.69511750e-01
 1.01385906e-01 1.37069344e-03 7.51695812e-01 2.62272283e-02
 5.18159289e-03 1.08248182e-02 1.08678276e-02 6.49322523e-04
 5.60476221e-02 8.86771679e-01 1.02644488e-04 9.98955727e-01
 6.05862737e-02 5.59456944e-01 3.83233628e-03 2.19903603e-01
 1.02708850e-03]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-14 09:57:48, Dev, Step : 1902, Loss : 0.50189, Acc : 0.775, Auc : 0.857, Sensitive_Loss : 0.25201, Sensitive_Acc : 20.534, Sensitive_Auc : 0.994, Mean auc: 0.857, Run Time : 86.44 sec
INFO:root:2024-04-14 09:57:48, Best, Step : 1902, Loss : 0.50189, Acc : 0.775,Auc : 0.857, Best Auc : 0.857, Sensitive_Loss : 0.25201, Sensitive_Acc : 20.534, Sensitive_Auc : 0.994
INFO:root:2024-04-14 09:57:56, Train, Epoch : 4, Step : 1910, Loss : 0.38008, Acc : 0.628, Sensitive_Loss : 0.11156, Sensitive_Acc : 16.500, Run Time : 6.80 sec
INFO:root:2024-04-14 09:58:03, Train, Epoch : 4, Step : 1920, Loss : 0.40682, Acc : 0.831, Sensitive_Loss : 0.17795, Sensitive_Acc : 20.500, Run Time : 7.04 sec
INFO:root:2024-04-14 09:58:10, Train, Epoch : 4, Step : 1930, Loss : 0.36797, Acc : 0.850, Sensitive_Loss : 0.15833, Sensitive_Acc : 22.500, Run Time : 7.53 sec
INFO:root:2024-04-14 09:58:17, Train, Epoch : 4, Step : 1940, Loss : 0.42069, Acc : 0.812, Sensitive_Loss : 0.15469, Sensitive_Acc : 21.600, Run Time : 6.94 sec
INFO:root:2024-04-14 09:58:24, Train, Epoch : 4, Step : 1950, Loss : 0.37960, Acc : 0.803, Sensitive_Loss : 0.23830, Sensitive_Acc : 21.700, Run Time : 7.00 sec
INFO:root:2024-04-14 09:58:31, Train, Epoch : 4, Step : 1960, Loss : 0.40094, Acc : 0.794, Sensitive_Loss : 0.21974, Sensitive_Acc : 20.400, Run Time : 6.84 sec
INFO:root:2024-04-14 09:58:38, Train, Epoch : 4, Step : 1970, Loss : 0.33910, Acc : 0.847, Sensitive_Loss : 0.20159, Sensitive_Acc : 19.900, Run Time : 7.15 sec
INFO:root:2024-04-14 09:58:46, Train, Epoch : 4, Step : 1980, Loss : 0.35763, Acc : 0.850, Sensitive_Loss : 0.15745, Sensitive_Acc : 20.600, Run Time : 7.89 sec
INFO:root:2024-04-14 09:58:53, Train, Epoch : 4, Step : 1990, Loss : 0.38206, Acc : 0.828, Sensitive_Loss : 0.21424, Sensitive_Acc : 21.000, Run Time : 7.13 sec
INFO:root:2024-04-14 09:59:00, Train, Epoch : 4, Step : 2000, Loss : 0.44720, Acc : 0.822, Sensitive_Loss : 0.19254, Sensitive_Acc : 23.500, Run Time : 6.57 sec
INFO:root:2024-04-14 10:00:28, Dev, Step : 2000, Loss : 0.50568, Acc : 0.772, Auc : 0.854, Sensitive_Loss : 0.22506, Sensitive_Acc : 21.180, Sensitive_Auc : 0.994, Mean auc: 0.854, Run Time : 88.05 sec
INFO:root:2024-04-14 10:00:34, Train, Epoch : 4, Step : 2010, Loss : 0.45956, Acc : 0.828, Sensitive_Loss : 0.22719, Sensitive_Acc : 23.500, Run Time : 93.60 sec
INFO:root:2024-04-14 10:00:41, Train, Epoch : 4, Step : 2020, Loss : 0.44455, Acc : 0.787, Sensitive_Loss : 0.14877, Sensitive_Acc : 17.800, Run Time : 7.77 sec
INFO:root:2024-04-14 10:00:48, Train, Epoch : 4, Step : 2030, Loss : 0.47529, Acc : 0.787, Sensitive_Loss : 0.25811, Sensitive_Acc : 22.300, Run Time : 6.45 sec
INFO:root:2024-04-14 10:00:55, Train, Epoch : 4, Step : 2040, Loss : 0.44180, Acc : 0.803, Sensitive_Loss : 0.13750, Sensitive_Acc : 24.500, Run Time : 6.73 sec
INFO:root:2024-04-14 10:01:02, Train, Epoch : 4, Step : 2050, Loss : 0.48884, Acc : 0.809, Sensitive_Loss : 0.18586, Sensitive_Acc : 20.500, Run Time : 7.47 sec
INFO:root:2024-04-14 10:01:09, Train, Epoch : 4, Step : 2060, Loss : 0.44060, Acc : 0.797, Sensitive_Loss : 0.17720, Sensitive_Acc : 17.900, Run Time : 7.43 sec
INFO:root:2024-04-14 10:01:16, Train, Epoch : 4, Step : 2070, Loss : 0.41677, Acc : 0.812, Sensitive_Loss : 0.13273, Sensitive_Acc : 17.800, Run Time : 6.49 sec
INFO:root:2024-04-14 10:01:23, Train, Epoch : 4, Step : 2080, Loss : 0.42127, Acc : 0.819, Sensitive_Loss : 0.15022, Sensitive_Acc : 22.300, Run Time : 6.92 sec
INFO:root:2024-04-14 10:01:30, Train, Epoch : 4, Step : 2090, Loss : 0.42725, Acc : 0.812, Sensitive_Loss : 0.18205, Sensitive_Acc : 24.100, Run Time : 7.29 sec
INFO:root:2024-04-14 10:01:37, Train, Epoch : 4, Step : 2100, Loss : 0.45199, Acc : 0.797, Sensitive_Loss : 0.16240, Sensitive_Acc : 24.900, Run Time : 7.20 sec
INFO:root:2024-04-14 10:03:05, Dev, Step : 2100, Loss : 0.51144, Acc : 0.780, Auc : 0.858, Sensitive_Loss : 0.21580, Sensitive_Acc : 21.301, Sensitive_Auc : 0.993, Mean auc: 0.858, Run Time : 87.97 sec
INFO:root:2024-04-14 10:03:06, Best, Step : 2100, Loss : 0.51144, Acc : 0.780, Auc : 0.858, Sensitive_Loss : 0.21580, Sensitive_Acc : 21.301, Sensitive_Auc : 0.993, Best Auc : 0.858
INFO:root:2024-04-14 10:03:11, Train, Epoch : 4, Step : 2110, Loss : 0.41751, Acc : 0.838, Sensitive_Loss : 0.22422, Sensitive_Acc : 19.900, Run Time : 94.18 sec
INFO:root:2024-04-14 10:03:19, Train, Epoch : 4, Step : 2120, Loss : 0.44728, Acc : 0.828, Sensitive_Loss : 0.16833, Sensitive_Acc : 26.900, Run Time : 7.36 sec
INFO:root:2024-04-14 10:03:26, Train, Epoch : 4, Step : 2130, Loss : 0.41043, Acc : 0.812, Sensitive_Loss : 0.14727, Sensitive_Acc : 20.700, Run Time : 6.95 sec
INFO:root:2024-04-14 10:03:33, Train, Epoch : 4, Step : 2140, Loss : 0.44863, Acc : 0.822, Sensitive_Loss : 0.14011, Sensitive_Acc : 23.400, Run Time : 7.39 sec
INFO:root:2024-04-14 10:03:40, Train, Epoch : 4, Step : 2150, Loss : 0.39658, Acc : 0.819, Sensitive_Loss : 0.19250, Sensitive_Acc : 19.800, Run Time : 6.72 sec
INFO:root:2024-04-14 10:03:47, Train, Epoch : 4, Step : 2160, Loss : 0.37584, Acc : 0.791, Sensitive_Loss : 0.18761, Sensitive_Acc : 22.600, Run Time : 7.20 sec
INFO:root:2024-04-14 10:03:55, Train, Epoch : 4, Step : 2170, Loss : 0.45404, Acc : 0.850, Sensitive_Loss : 0.15348, Sensitive_Acc : 23.400, Run Time : 7.46 sec
INFO:root:2024-04-14 10:04:01, Train, Epoch : 4, Step : 2180, Loss : 0.48528, Acc : 0.809, Sensitive_Loss : 0.18161, Sensitive_Acc : 23.800, Run Time : 6.50 sec
INFO:root:2024-04-14 10:04:08, Train, Epoch : 4, Step : 2190, Loss : 0.42661, Acc : 0.800, Sensitive_Loss : 0.14338, Sensitive_Acc : 15.900, Run Time : 7.19 sec
INFO:root:2024-04-14 10:04:16, Train, Epoch : 4, Step : 2200, Loss : 0.42933, Acc : 0.838, Sensitive_Loss : 0.15502, Sensitive_Acc : 19.600, Run Time : 7.28 sec
INFO:root:2024-04-14 10:05:43, Dev, Step : 2200, Loss : 0.50631, Acc : 0.770, Auc : 0.855, Sensitive_Loss : 0.22364, Sensitive_Acc : 20.895, Sensitive_Auc : 0.995, Mean auc: 0.855, Run Time : 87.92 sec
INFO:root:2024-04-14 10:05:49, Train, Epoch : 4, Step : 2210, Loss : 0.51554, Acc : 0.794, Sensitive_Loss : 0.17504, Sensitive_Acc : 20.100, Run Time : 93.73 sec
INFO:root:2024-04-14 10:05:56, Train, Epoch : 4, Step : 2220, Loss : 0.38986, Acc : 0.838, Sensitive_Loss : 0.15740, Sensitive_Acc : 23.800, Run Time : 6.98 sec
INFO:root:2024-04-14 10:06:04, Train, Epoch : 4, Step : 2230, Loss : 0.49060, Acc : 0.787, Sensitive_Loss : 0.14091, Sensitive_Acc : 23.000, Run Time : 7.32 sec
INFO:root:2024-04-14 10:06:11, Train, Epoch : 4, Step : 2240, Loss : 0.38387, Acc : 0.828, Sensitive_Loss : 0.14168, Sensitive_Acc : 23.800, Run Time : 6.94 sec
INFO:root:2024-04-14 10:06:18, Train, Epoch : 4, Step : 2250, Loss : 0.44614, Acc : 0.791, Sensitive_Loss : 0.14815, Sensitive_Acc : 21.700, Run Time : 7.48 sec
INFO:root:2024-04-14 10:06:25, Train, Epoch : 4, Step : 2260, Loss : 0.43558, Acc : 0.784, Sensitive_Loss : 0.16595, Sensitive_Acc : 20.100, Run Time : 7.07 sec
INFO:root:2024-04-14 10:06:32, Train, Epoch : 4, Step : 2270, Loss : 0.43392, Acc : 0.809, Sensitive_Loss : 0.19017, Sensitive_Acc : 22.900, Run Time : 7.13 sec
INFO:root:2024-04-14 10:06:39, Train, Epoch : 4, Step : 2280, Loss : 0.38523, Acc : 0.828, Sensitive_Loss : 0.20615, Sensitive_Acc : 17.500, Run Time : 6.72 sec
INFO:root:2024-04-14 10:06:46, Train, Epoch : 4, Step : 2290, Loss : 0.46857, Acc : 0.819, Sensitive_Loss : 0.19666, Sensitive_Acc : 23.300, Run Time : 7.21 sec
INFO:root:2024-04-14 10:06:53, Train, Epoch : 4, Step : 2300, Loss : 0.52889, Acc : 0.781, Sensitive_Loss : 0.15136, Sensitive_Acc : 24.400, Run Time : 7.02 sec
INFO:root:2024-04-14 10:08:21, Dev, Step : 2300, Loss : 0.50817, Acc : 0.779, Auc : 0.857, Sensitive_Loss : 0.22991, Sensitive_Acc : 20.895, Sensitive_Auc : 0.997, Mean auc: 0.857, Run Time : 88.09 sec
INFO:root:2024-04-14 10:08:27, Train, Epoch : 4, Step : 2310, Loss : 0.39709, Acc : 0.791, Sensitive_Loss : 0.12853, Sensitive_Acc : 20.300, Run Time : 93.37 sec
INFO:root:2024-04-14 10:08:34, Train, Epoch : 4, Step : 2320, Loss : 0.46024, Acc : 0.809, Sensitive_Loss : 0.21959, Sensitive_Acc : 19.800, Run Time : 7.14 sec
INFO:root:2024-04-14 10:08:41, Train, Epoch : 4, Step : 2330, Loss : 0.46651, Acc : 0.816, Sensitive_Loss : 0.17982, Sensitive_Acc : 24.500, Run Time : 7.09 sec
INFO:root:2024-04-14 10:08:48, Train, Epoch : 4, Step : 2340, Loss : 0.36981, Acc : 0.834, Sensitive_Loss : 0.15940, Sensitive_Acc : 19.700, Run Time : 7.11 sec
INFO:root:2024-04-14 10:08:55, Train, Epoch : 4, Step : 2350, Loss : 0.52239, Acc : 0.744, Sensitive_Loss : 0.19705, Sensitive_Acc : 24.100, Run Time : 7.24 sec
INFO:root:2024-04-14 10:09:03, Train, Epoch : 4, Step : 2360, Loss : 0.36672, Acc : 0.819, Sensitive_Loss : 0.12322, Sensitive_Acc : 20.900, Run Time : 7.59 sec
INFO:root:2024-04-14 10:09:10, Train, Epoch : 4, Step : 2370, Loss : 0.32314, Acc : 0.822, Sensitive_Loss : 0.16315, Sensitive_Acc : 19.500, Run Time : 7.15 sec
INFO:root:2024-04-14 10:09:17, Train, Epoch : 4, Step : 2380, Loss : 0.47486, Acc : 0.769, Sensitive_Loss : 0.29741, Sensitive_Acc : 22.400, Run Time : 7.29 sec
INFO:root:2024-04-14 10:09:24, Train, Epoch : 4, Step : 2390, Loss : 0.39952, Acc : 0.822, Sensitive_Loss : 0.20099, Sensitive_Acc : 22.800, Run Time : 6.89 sec
INFO:root:2024-04-14 10:09:31, Train, Epoch : 4, Step : 2400, Loss : 0.37201, Acc : 0.819, Sensitive_Loss : 0.20433, Sensitive_Acc : 25.200, Run Time : 7.24 sec
INFO:root:2024-04-14 10:10:59, Dev, Step : 2400, Loss : 0.49958, Acc : 0.778, Auc : 0.860, Sensitive_Loss : 0.23124, Sensitive_Acc : 20.850, Sensitive_Auc : 0.997, Mean auc: 0.860, Run Time : 87.20 sec
INFO:root:2024-04-14 10:10:59, Best, Step : 2400, Loss : 0.49958, Acc : 0.778, Auc : 0.860, Sensitive_Loss : 0.23124, Sensitive_Acc : 20.850, Sensitive_Auc : 0.997, Best Auc : 0.860
INFO:root:2024-04-14 10:11:05, Train, Epoch : 4, Step : 2410, Loss : 0.41311, Acc : 0.831, Sensitive_Loss : 0.22033, Sensitive_Acc : 21.900, Run Time : 93.38 sec
INFO:root:2024-04-14 10:11:12, Train, Epoch : 4, Step : 2420, Loss : 0.41961, Acc : 0.797, Sensitive_Loss : 0.18769, Sensitive_Acc : 25.400, Run Time : 7.37 sec
INFO:root:2024-04-14 10:11:19, Train, Epoch : 4, Step : 2430, Loss : 0.41856, Acc : 0.816, Sensitive_Loss : 0.16272, Sensitive_Acc : 26.000, Run Time : 7.06 sec
INFO:root:2024-04-14 10:11:26, Train, Epoch : 4, Step : 2440, Loss : 0.46246, Acc : 0.759, Sensitive_Loss : 0.17860, Sensitive_Acc : 22.000, Run Time : 6.70 sec
INFO:root:2024-04-14 10:11:34, Train, Epoch : 4, Step : 2450, Loss : 0.38225, Acc : 0.831, Sensitive_Loss : 0.12262, Sensitive_Acc : 18.000, Run Time : 7.75 sec
INFO:root:2024-04-14 10:11:41, Train, Epoch : 4, Step : 2460, Loss : 0.33948, Acc : 0.831, Sensitive_Loss : 0.13572, Sensitive_Acc : 25.700, Run Time : 6.91 sec
INFO:root:2024-04-14 10:11:48, Train, Epoch : 4, Step : 2470, Loss : 0.38770, Acc : 0.819, Sensitive_Loss : 0.17488, Sensitive_Acc : 21.200, Run Time : 7.10 sec
INFO:root:2024-04-14 10:11:55, Train, Epoch : 4, Step : 2480, Loss : 0.34499, Acc : 0.834, Sensitive_Loss : 0.19521, Sensitive_Acc : 21.100, Run Time : 7.05 sec
INFO:root:2024-04-14 10:12:02, Train, Epoch : 4, Step : 2490, Loss : 0.46328, Acc : 0.812, Sensitive_Loss : 0.13985, Sensitive_Acc : 25.400, Run Time : 6.84 sec
INFO:root:2024-04-14 10:12:09, Train, Epoch : 4, Step : 2500, Loss : 0.40944, Acc : 0.822, Sensitive_Loss : 0.13593, Sensitive_Acc : 17.900, Run Time : 7.08 sec
INFO:root:2024-04-14 10:13:36, Dev, Step : 2500, Loss : 0.50904, Acc : 0.774, Auc : 0.859, Sensitive_Loss : 0.22511, Sensitive_Acc : 21.376, Sensitive_Auc : 0.994, Mean auc: 0.859, Run Time : 87.82 sec
INFO:root:2024-04-14 10:13:42, Train, Epoch : 4, Step : 2510, Loss : 0.32793, Acc : 0.844, Sensitive_Loss : 0.17567, Sensitive_Acc : 19.300, Run Time : 93.59 sec
INFO:root:2024-04-14 10:13:49, Train, Epoch : 4, Step : 2520, Loss : 0.44742, Acc : 0.791, Sensitive_Loss : 0.19345, Sensitive_Acc : 23.300, Run Time : 7.10 sec
INFO:root:2024-04-14 10:13:56, Train, Epoch : 4, Step : 2530, Loss : 0.39944, Acc : 0.803, Sensitive_Loss : 0.15149, Sensitive_Acc : 17.100, Run Time : 7.06 sec
INFO:root:2024-04-14 10:15:27
INFO:root:y_pred: [0.11610435 0.01763013 0.04492606 ... 0.11962609 0.1086523  0.03071514]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [4.08157147e-03 4.77587245e-03 4.22791950e-02 1.53351381e-01
 4.20435518e-02 1.04031339e-02 1.16722863e-02 1.12161925e-03
 1.25759169e-01 9.99740422e-01 4.27119434e-01 5.05507877e-03
 3.32879112e-03 2.24887393e-04 9.99935508e-01 6.62367865e-02
 2.29504611e-03 9.99243140e-01 9.99405026e-01 1.99949020e-03
 8.13519180e-01 6.92528149e-04 6.05439804e-02 4.08096723e-02
 1.94731966e-01 6.01251125e-01 1.41769677e-04 2.08965503e-03
 2.28264107e-04 1.28266916e-01 7.85824936e-03 9.99602139e-01
 3.47011127e-02 9.08772409e-01 9.31468268e-04 2.19257036e-03
 1.12915020e-02 4.05671783e-02 5.30855954e-01 7.23503530e-02
 8.70619342e-02 9.97867584e-01 6.51118383e-02 3.03494977e-03
 9.84360158e-01 3.88349414e-01 3.98258775e-01 3.32068741e-01
 4.22379673e-01 9.97881234e-01 9.90805924e-01 9.99964833e-01
 9.91822422e-01 6.42550290e-02 6.92175031e-02 5.23270309e-01
 4.51624719e-03 2.36509517e-02 9.98862386e-01 2.25701393e-03
 3.90850846e-03 8.45745672e-04 1.10407565e-02 1.42533885e-04
 9.97559667e-01 2.06781854e-03 1.75929672e-04 3.30980942e-02
 3.85650545e-02 9.86261427e-01 9.99933958e-01 9.99935031e-01
 2.73739896e-03 5.19017994e-01 1.73739232e-02 7.53544509e-01
 5.04857749e-02 6.93745562e-04 2.56537902e-03 1.69171125e-03
 1.12205058e-01 1.18721486e-03 9.96959329e-01 9.96028662e-01
 3.28731239e-02 6.01007104e-01 4.80412208e-02 2.50308923e-02
 2.33479626e-02 1.99678660e-04 8.57290477e-02 5.46166040e-02
 5.74865029e-04 2.45148985e-04 1.39332749e-02 9.65209957e-03
 4.65041026e-04 4.99587506e-01 1.69403143e-02 8.21720529e-03
 3.27341794e-03 1.10235726e-02 1.49232596e-01 5.38989715e-03
 1.11479245e-01 4.47952276e-04 3.30371529e-01 9.06276345e-01
 6.86504841e-01 4.48456705e-01 1.37162235e-04 9.99958873e-01
 9.99122918e-01 5.91203061e-05 3.26634228e-01 1.36558175e-01
 8.47894996e-02 1.62363704e-03 8.28423977e-01 2.75924373e-02
 2.13667867e-03 1.04671502e-02 2.31329501e-02 5.01439965e-04
 2.49881446e-02 8.69840264e-01 1.83036595e-04 9.99281943e-01
 6.17186688e-02 3.18031549e-01 4.12026467e-03 2.12494895e-01
 1.26063521e-03]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-14 10:15:27, Dev, Step : 2536, Loss : 0.50925, Acc : 0.773, Auc : 0.859, Sensitive_Loss : 0.23614, Sensitive_Acc : 20.985, Sensitive_Auc : 0.995, Mean auc: 0.859, Run Time : 86.84 sec
INFO:root:2024-04-14 10:15:32, Train, Epoch : 5, Step : 2540, Loss : 0.18457, Acc : 0.316, Sensitive_Loss : 0.05461, Sensitive_Acc : 7.500, Run Time : 4.54 sec
INFO:root:2024-04-14 10:15:39, Train, Epoch : 5, Step : 2550, Loss : 0.37851, Acc : 0.866, Sensitive_Loss : 0.15283, Sensitive_Acc : 19.800, Run Time : 6.59 sec
INFO:root:2024-04-14 10:15:46, Train, Epoch : 5, Step : 2560, Loss : 0.41802, Acc : 0.809, Sensitive_Loss : 0.12662, Sensitive_Acc : 22.600, Run Time : 7.31 sec
INFO:root:2024-04-14 10:15:53, Train, Epoch : 5, Step : 2570, Loss : 0.34962, Acc : 0.847, Sensitive_Loss : 0.16391, Sensitive_Acc : 22.500, Run Time : 7.14 sec
INFO:root:2024-04-14 10:16:00, Train, Epoch : 5, Step : 2580, Loss : 0.38996, Acc : 0.838, Sensitive_Loss : 0.13069, Sensitive_Acc : 23.100, Run Time : 7.05 sec
INFO:root:2024-04-14 10:16:07, Train, Epoch : 5, Step : 2590, Loss : 0.37808, Acc : 0.859, Sensitive_Loss : 0.22560, Sensitive_Acc : 22.400, Run Time : 6.99 sec
INFO:root:2024-04-14 10:16:15, Train, Epoch : 5, Step : 2600, Loss : 0.36380, Acc : 0.844, Sensitive_Loss : 0.10949, Sensitive_Acc : 18.700, Run Time : 7.61 sec
INFO:root:2024-04-14 10:17:45, Dev, Step : 2600, Loss : 0.51495, Acc : 0.778, Auc : 0.858, Sensitive_Loss : 0.20842, Sensitive_Acc : 21.481, Sensitive_Auc : 0.997, Mean auc: 0.858, Run Time : 90.02 sec
INFO:root:2024-04-14 10:17:50, Train, Epoch : 5, Step : 2610, Loss : 0.43553, Acc : 0.784, Sensitive_Loss : 0.14953, Sensitive_Acc : 19.600, Run Time : 95.58 sec
INFO:root:2024-04-14 10:17:58, Train, Epoch : 5, Step : 2620, Loss : 0.42023, Acc : 0.822, Sensitive_Loss : 0.15004, Sensitive_Acc : 20.700, Run Time : 7.59 sec
INFO:root:2024-04-14 10:18:06, Train, Epoch : 5, Step : 2630, Loss : 0.34627, Acc : 0.844, Sensitive_Loss : 0.10933, Sensitive_Acc : 21.600, Run Time : 7.99 sec
INFO:root:2024-04-14 10:18:13, Train, Epoch : 5, Step : 2640, Loss : 0.44443, Acc : 0.794, Sensitive_Loss : 0.12102, Sensitive_Acc : 23.000, Run Time : 6.75 sec
INFO:root:2024-04-14 10:18:19, Train, Epoch : 5, Step : 2650, Loss : 0.43797, Acc : 0.822, Sensitive_Loss : 0.22337, Sensitive_Acc : 20.200, Run Time : 6.73 sec
INFO:root:2024-04-14 10:18:26, Train, Epoch : 5, Step : 2660, Loss : 0.43602, Acc : 0.778, Sensitive_Loss : 0.18249, Sensitive_Acc : 20.600, Run Time : 7.10 sec
INFO:root:2024-04-14 10:18:34, Train, Epoch : 5, Step : 2670, Loss : 0.37250, Acc : 0.825, Sensitive_Loss : 0.18164, Sensitive_Acc : 24.900, Run Time : 7.24 sec
INFO:root:2024-04-14 10:18:41, Train, Epoch : 5, Step : 2680, Loss : 0.41133, Acc : 0.825, Sensitive_Loss : 0.19465, Sensitive_Acc : 23.100, Run Time : 7.04 sec
INFO:root:2024-04-14 10:18:48, Train, Epoch : 5, Step : 2690, Loss : 0.37774, Acc : 0.856, Sensitive_Loss : 0.18015, Sensitive_Acc : 23.700, Run Time : 7.34 sec
INFO:root:2024-04-14 10:18:55, Train, Epoch : 5, Step : 2700, Loss : 0.48466, Acc : 0.800, Sensitive_Loss : 0.15521, Sensitive_Acc : 24.500, Run Time : 7.20 sec
INFO:root:2024-04-14 10:20:23, Dev, Step : 2700, Loss : 0.51171, Acc : 0.777, Auc : 0.857, Sensitive_Loss : 0.23268, Sensitive_Acc : 20.805, Sensitive_Auc : 0.997, Mean auc: 0.857, Run Time : 87.49 sec
INFO:root:2024-04-14 10:20:29, Train, Epoch : 5, Step : 2710, Loss : 0.39452, Acc : 0.797, Sensitive_Loss : 0.15205, Sensitive_Acc : 15.800, Run Time : 93.37 sec
INFO:root:2024-04-14 10:20:36, Train, Epoch : 5, Step : 2720, Loss : 0.40804, Acc : 0.806, Sensitive_Loss : 0.13234, Sensitive_Acc : 21.900, Run Time : 7.45 sec
INFO:root:2024-04-14 10:20:43, Train, Epoch : 5, Step : 2730, Loss : 0.40275, Acc : 0.853, Sensitive_Loss : 0.13716, Sensitive_Acc : 19.500, Run Time : 6.42 sec
INFO:root:2024-04-14 10:20:50, Train, Epoch : 5, Step : 2740, Loss : 0.41071, Acc : 0.828, Sensitive_Loss : 0.15131, Sensitive_Acc : 22.200, Run Time : 7.02 sec
INFO:root:2024-04-14 10:20:57, Train, Epoch : 5, Step : 2750, Loss : 0.38086, Acc : 0.847, Sensitive_Loss : 0.11687, Sensitive_Acc : 19.300, Run Time : 7.07 sec
INFO:root:2024-04-14 10:21:04, Train, Epoch : 5, Step : 2760, Loss : 0.39947, Acc : 0.794, Sensitive_Loss : 0.18333, Sensitive_Acc : 19.700, Run Time : 7.24 sec
INFO:root:2024-04-14 10:21:11, Train, Epoch : 5, Step : 2770, Loss : 0.38894, Acc : 0.800, Sensitive_Loss : 0.16710, Sensitive_Acc : 21.500, Run Time : 7.14 sec
INFO:root:2024-04-14 10:21:18, Train, Epoch : 5, Step : 2780, Loss : 0.36528, Acc : 0.856, Sensitive_Loss : 0.20229, Sensitive_Acc : 24.600, Run Time : 7.15 sec
INFO:root:2024-04-14 10:21:25, Train, Epoch : 5, Step : 2790, Loss : 0.53586, Acc : 0.769, Sensitive_Loss : 0.18211, Sensitive_Acc : 24.200, Run Time : 7.25 sec
INFO:root:2024-04-14 10:21:32, Train, Epoch : 5, Step : 2800, Loss : 0.36495, Acc : 0.822, Sensitive_Loss : 0.18814, Sensitive_Acc : 26.800, Run Time : 7.05 sec
INFO:root:2024-04-14 10:23:00, Dev, Step : 2800, Loss : 0.56191, Acc : 0.769, Auc : 0.856, Sensitive_Loss : 0.24809, Sensitive_Acc : 20.820, Sensitive_Auc : 0.996, Mean auc: 0.856, Run Time : 87.73 sec
INFO:root:2024-04-14 10:23:06, Train, Epoch : 5, Step : 2810, Loss : 0.47265, Acc : 0.778, Sensitive_Loss : 0.19555, Sensitive_Acc : 16.900, Run Time : 93.15 sec
INFO:root:2024-04-14 10:23:13, Train, Epoch : 5, Step : 2820, Loss : 0.38029, Acc : 0.794, Sensitive_Loss : 0.17686, Sensitive_Acc : 21.600, Run Time : 7.15 sec
INFO:root:2024-04-14 10:23:20, Train, Epoch : 5, Step : 2830, Loss : 0.35605, Acc : 0.831, Sensitive_Loss : 0.16109, Sensitive_Acc : 26.300, Run Time : 7.33 sec
INFO:root:2024-04-14 10:23:27, Train, Epoch : 5, Step : 2840, Loss : 0.32848, Acc : 0.866, Sensitive_Loss : 0.15023, Sensitive_Acc : 21.800, Run Time : 7.41 sec
INFO:root:2024-04-14 10:23:35, Train, Epoch : 5, Step : 2850, Loss : 0.39279, Acc : 0.838, Sensitive_Loss : 0.15495, Sensitive_Acc : 24.300, Run Time : 7.05 sec
INFO:root:2024-04-14 10:23:42, Train, Epoch : 5, Step : 2860, Loss : 0.31433, Acc : 0.853, Sensitive_Loss : 0.11875, Sensitive_Acc : 18.000, Run Time : 7.48 sec
INFO:root:2024-04-14 10:23:49, Train, Epoch : 5, Step : 2870, Loss : 0.40287, Acc : 0.812, Sensitive_Loss : 0.12608, Sensitive_Acc : 20.900, Run Time : 7.04 sec
INFO:root:2024-04-14 10:23:56, Train, Epoch : 5, Step : 2880, Loss : 0.28098, Acc : 0.850, Sensitive_Loss : 0.17549, Sensitive_Acc : 17.300, Run Time : 7.22 sec
INFO:root:2024-04-14 10:24:03, Train, Epoch : 5, Step : 2890, Loss : 0.36433, Acc : 0.828, Sensitive_Loss : 0.10160, Sensitive_Acc : 21.300, Run Time : 6.83 sec
INFO:root:2024-04-14 10:24:10, Train, Epoch : 5, Step : 2900, Loss : 0.36138, Acc : 0.838, Sensitive_Loss : 0.13512, Sensitive_Acc : 23.000, Run Time : 7.23 sec
INFO:root:2024-04-14 10:25:38, Dev, Step : 2900, Loss : 0.51741, Acc : 0.777, Auc : 0.857, Sensitive_Loss : 0.21931, Sensitive_Acc : 21.000, Sensitive_Auc : 0.997, Mean auc: 0.857, Run Time : 88.08 sec
INFO:root:2024-04-14 10:25:44, Train, Epoch : 5, Step : 2910, Loss : 0.35333, Acc : 0.812, Sensitive_Loss : 0.20039, Sensitive_Acc : 22.600, Run Time : 93.40 sec
INFO:root:2024-04-14 10:25:51, Train, Epoch : 5, Step : 2920, Loss : 0.43956, Acc : 0.816, Sensitive_Loss : 0.21304, Sensitive_Acc : 21.900, Run Time : 7.36 sec
INFO:root:2024-04-14 10:25:59, Train, Epoch : 5, Step : 2930, Loss : 0.39296, Acc : 0.822, Sensitive_Loss : 0.17047, Sensitive_Acc : 23.600, Run Time : 7.58 sec
INFO:root:2024-04-14 10:26:05, Train, Epoch : 5, Step : 2940, Loss : 0.46520, Acc : 0.819, Sensitive_Loss : 0.18442, Sensitive_Acc : 14.800, Run Time : 6.68 sec
INFO:root:2024-04-14 10:26:12, Train, Epoch : 5, Step : 2950, Loss : 0.37925, Acc : 0.869, Sensitive_Loss : 0.20512, Sensitive_Acc : 26.500, Run Time : 6.92 sec
INFO:root:2024-04-14 10:26:20, Train, Epoch : 5, Step : 2960, Loss : 0.38920, Acc : 0.853, Sensitive_Loss : 0.12311, Sensitive_Acc : 22.600, Run Time : 7.28 sec
INFO:root:2024-04-14 10:26:27, Train, Epoch : 5, Step : 2970, Loss : 0.46685, Acc : 0.794, Sensitive_Loss : 0.15543, Sensitive_Acc : 18.400, Run Time : 7.56 sec
INFO:root:2024-04-14 10:26:34, Train, Epoch : 5, Step : 2980, Loss : 0.37265, Acc : 0.844, Sensitive_Loss : 0.12097, Sensitive_Acc : 21.300, Run Time : 7.07 sec
INFO:root:2024-04-14 10:26:41, Train, Epoch : 5, Step : 2990, Loss : 0.36795, Acc : 0.819, Sensitive_Loss : 0.09710, Sensitive_Acc : 25.500, Run Time : 6.76 sec
INFO:root:2024-04-14 10:26:48, Train, Epoch : 5, Step : 3000, Loss : 0.41824, Acc : 0.797, Sensitive_Loss : 0.15182, Sensitive_Acc : 24.500, Run Time : 7.14 sec
INFO:root:2024-04-14 10:28:16, Dev, Step : 3000, Loss : 0.55768, Acc : 0.763, Auc : 0.857, Sensitive_Loss : 0.24128, Sensitive_Acc : 20.639, Sensitive_Auc : 0.998, Mean auc: 0.857, Run Time : 88.05 sec
INFO:root:2024-04-14 10:28:22, Train, Epoch : 5, Step : 3010, Loss : 0.46734, Acc : 0.812, Sensitive_Loss : 0.21620, Sensitive_Acc : 20.700, Run Time : 93.73 sec
INFO:root:2024-04-14 10:28:30, Train, Epoch : 5, Step : 3020, Loss : 0.46802, Acc : 0.747, Sensitive_Loss : 0.12877, Sensitive_Acc : 26.200, Run Time : 7.71 sec
INFO:root:2024-04-14 10:28:36, Train, Epoch : 5, Step : 3030, Loss : 0.45213, Acc : 0.800, Sensitive_Loss : 0.16839, Sensitive_Acc : 20.300, Run Time : 6.78 sec
INFO:root:2024-04-14 10:28:43, Train, Epoch : 5, Step : 3040, Loss : 0.37820, Acc : 0.831, Sensitive_Loss : 0.21319, Sensitive_Acc : 14.800, Run Time : 6.52 sec
INFO:root:2024-04-14 10:28:50, Train, Epoch : 5, Step : 3050, Loss : 0.38845, Acc : 0.828, Sensitive_Loss : 0.11968, Sensitive_Acc : 21.100, Run Time : 6.99 sec
INFO:root:2024-04-14 10:28:57, Train, Epoch : 5, Step : 3060, Loss : 0.40299, Acc : 0.847, Sensitive_Loss : 0.19159, Sensitive_Acc : 22.300, Run Time : 7.53 sec
INFO:root:2024-04-14 10:29:04, Train, Epoch : 5, Step : 3070, Loss : 0.33212, Acc : 0.847, Sensitive_Loss : 0.16596, Sensitive_Acc : 21.300, Run Time : 6.76 sec
INFO:root:2024-04-14 10:29:11, Train, Epoch : 5, Step : 3080, Loss : 0.37258, Acc : 0.872, Sensitive_Loss : 0.14304, Sensitive_Acc : 21.600, Run Time : 7.22 sec
INFO:root:2024-04-14 10:29:19, Train, Epoch : 5, Step : 3090, Loss : 0.48326, Acc : 0.806, Sensitive_Loss : 0.16696, Sensitive_Acc : 24.200, Run Time : 7.40 sec
INFO:root:2024-04-14 10:29:26, Train, Epoch : 5, Step : 3100, Loss : 0.37009, Acc : 0.850, Sensitive_Loss : 0.20482, Sensitive_Acc : 23.900, Run Time : 7.70 sec
INFO:root:2024-04-14 10:30:54, Dev, Step : 3100, Loss : 0.50860, Acc : 0.772, Auc : 0.858, Sensitive_Loss : 0.21659, Sensitive_Acc : 21.376, Sensitive_Auc : 0.998, Mean auc: 0.858, Run Time : 87.34 sec
INFO:root:2024-04-14 10:30:59, Train, Epoch : 5, Step : 3110, Loss : 0.35259, Acc : 0.850, Sensitive_Loss : 0.15989, Sensitive_Acc : 22.600, Run Time : 92.90 sec
INFO:root:2024-04-14 10:31:07, Train, Epoch : 5, Step : 3120, Loss : 0.38794, Acc : 0.806, Sensitive_Loss : 0.16888, Sensitive_Acc : 20.400, Run Time : 7.76 sec
INFO:root:2024-04-14 10:31:14, Train, Epoch : 5, Step : 3130, Loss : 0.43845, Acc : 0.819, Sensitive_Loss : 0.14828, Sensitive_Acc : 20.200, Run Time : 6.49 sec
INFO:root:2024-04-14 10:31:21, Train, Epoch : 5, Step : 3140, Loss : 0.31933, Acc : 0.869, Sensitive_Loss : 0.16984, Sensitive_Acc : 23.200, Run Time : 7.26 sec
INFO:root:2024-04-14 10:31:28, Train, Epoch : 5, Step : 3150, Loss : 0.44348, Acc : 0.816, Sensitive_Loss : 0.11321, Sensitive_Acc : 21.400, Run Time : 7.32 sec
INFO:root:2024-04-14 10:31:35, Train, Epoch : 5, Step : 3160, Loss : 0.43883, Acc : 0.800, Sensitive_Loss : 0.13640, Sensitive_Acc : 26.000, Run Time : 6.79 sec
INFO:root:2024-04-14 10:31:42, Train, Epoch : 5, Step : 3170, Loss : 0.48414, Acc : 0.806, Sensitive_Loss : 0.17018, Sensitive_Acc : 23.000, Run Time : 6.67 sec
INFO:root:2024-04-14 10:33:09
INFO:root:y_pred: [0.08091056 0.01874522 0.05423592 ... 0.11672684 0.1173123  0.03185283]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [3.26945819e-03 4.41039400e-03 2.43392028e-02 3.68180662e-01
 4.94210683e-02 5.70438663e-03 8.64150561e-03 1.06417574e-03
 1.09034717e-01 9.99864697e-01 3.42562675e-01 2.09823577e-03
 3.34022613e-03 2.66753923e-04 9.99941111e-01 1.65148433e-02
 1.10348384e-03 9.99145031e-01 9.99757946e-01 2.11924803e-03
 6.92686856e-01 5.29044366e-04 4.59475294e-02 3.69131677e-02
 1.39197797e-01 4.74399537e-01 6.77238640e-05 1.22876035e-03
 9.27136643e-05 1.26401752e-01 4.15253919e-03 9.99539018e-01
 1.38670048e-02 9.33985770e-01 2.36008651e-04 1.16437534e-03
 7.26528466e-03 9.61382780e-03 4.96182263e-01 2.09545102e-02
 6.32668957e-02 9.98860478e-01 2.82796510e-02 3.24773346e-03
 9.89349604e-01 2.70991355e-01 3.22730124e-01 3.16326857e-01
 4.55183119e-01 9.98247147e-01 9.93158281e-01 9.99963164e-01
 9.90487635e-01 4.12230156e-02 6.05129749e-02 4.29158658e-01
 2.75153271e-03 3.45064811e-02 9.98391807e-01 2.44586822e-03
 1.59449584e-03 9.53686133e-04 3.28404387e-03 4.39651958e-05
 9.97199535e-01 2.68999673e-03 8.04613373e-05 1.70419235e-02
 3.78768295e-02 9.80571091e-01 9.99815881e-01 9.99913692e-01
 4.68873914e-04 3.69605631e-01 5.80455735e-03 6.67371154e-01
 2.28441097e-02 6.61287777e-05 5.45382616e-04 1.29561243e-03
 1.21781446e-01 1.05037540e-03 9.97728288e-01 9.93997812e-01
 2.29159985e-02 6.50893748e-01 3.98303308e-02 1.18649499e-02
 7.90700316e-03 1.82067583e-04 2.36771666e-02 2.88623981e-02
 7.59062706e-04 8.07384931e-05 7.08712731e-03 4.05362342e-03
 1.19425698e-04 7.23959804e-01 1.53132118e-02 4.23097704e-03
 2.48108571e-03 7.18834437e-03 8.26183632e-02 1.63247343e-03
 6.77979141e-02 3.38224374e-04 1.56255707e-01 9.47994173e-01
 3.97904247e-01 3.16815585e-01 7.35603971e-05 9.99975443e-01
 9.99321580e-01 7.03811384e-05 2.71326363e-01 5.29792979e-02
 7.31414557e-02 6.05570502e-04 8.04993749e-01 1.19921714e-02
 7.86696735e-04 5.50816907e-03 1.54296653e-02 4.60777606e-04
 1.00250170e-02 8.91414404e-01 1.82193660e-04 9.98454690e-01
 2.34710947e-02 4.94296908e-01 1.77048414e-03 1.42907679e-01
 1.99796355e-04]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-14 10:33:09, Dev, Step : 3170, Loss : 0.51515, Acc : 0.775, Auc : 0.858, Sensitive_Loss : 0.22170, Sensitive_Acc : 21.376, Sensitive_Auc : 0.997, Mean auc: 0.858, Run Time : 87.28 sec
INFO:root:2024-04-14 10:33:18, Train, Epoch : 6, Step : 3180, Loss : 0.41601, Acc : 0.797, Sensitive_Loss : 0.16895, Sensitive_Acc : 20.900, Run Time : 8.18 sec
INFO:root:2024-04-14 10:33:25, Train, Epoch : 6, Step : 3190, Loss : 0.40061, Acc : 0.863, Sensitive_Loss : 0.12377, Sensitive_Acc : 25.600, Run Time : 7.26 sec
INFO:root:2024-04-14 10:33:32, Train, Epoch : 6, Step : 3200, Loss : 0.37190, Acc : 0.822, Sensitive_Loss : 0.14064, Sensitive_Acc : 22.000, Run Time : 6.77 sec
INFO:root:2024-04-14 10:35:00, Dev, Step : 3200, Loss : 0.51219, Acc : 0.772, Auc : 0.855, Sensitive_Loss : 0.21735, Sensitive_Acc : 21.301, Sensitive_Auc : 0.997, Mean auc: 0.855, Run Time : 88.26 sec
INFO:root:2024-04-14 10:35:06, Train, Epoch : 6, Step : 3210, Loss : 0.37603, Acc : 0.841, Sensitive_Loss : 0.15195, Sensitive_Acc : 24.200, Run Time : 93.93 sec
INFO:root:2024-04-14 10:35:13, Train, Epoch : 6, Step : 3220, Loss : 0.33508, Acc : 0.850, Sensitive_Loss : 0.14989, Sensitive_Acc : 26.000, Run Time : 7.24 sec
INFO:root:2024-04-14 10:35:21, Train, Epoch : 6, Step : 3230, Loss : 0.37522, Acc : 0.809, Sensitive_Loss : 0.20309, Sensitive_Acc : 23.700, Run Time : 7.76 sec
INFO:root:2024-04-14 10:35:28, Train, Epoch : 6, Step : 3240, Loss : 0.42511, Acc : 0.828, Sensitive_Loss : 0.12250, Sensitive_Acc : 21.100, Run Time : 6.87 sec
INFO:root:2024-04-14 10:35:35, Train, Epoch : 6, Step : 3250, Loss : 0.35702, Acc : 0.828, Sensitive_Loss : 0.12784, Sensitive_Acc : 23.900, Run Time : 7.26 sec
INFO:root:2024-04-14 10:35:43, Train, Epoch : 6, Step : 3260, Loss : 0.36074, Acc : 0.866, Sensitive_Loss : 0.10676, Sensitive_Acc : 19.900, Run Time : 7.42 sec
INFO:root:2024-04-14 10:35:50, Train, Epoch : 6, Step : 3270, Loss : 0.37530, Acc : 0.853, Sensitive_Loss : 0.17713, Sensitive_Acc : 20.700, Run Time : 7.38 sec
INFO:root:2024-04-14 10:35:57, Train, Epoch : 6, Step : 3280, Loss : 0.34226, Acc : 0.875, Sensitive_Loss : 0.11857, Sensitive_Acc : 21.200, Run Time : 7.13 sec
INFO:root:2024-04-14 10:36:04, Train, Epoch : 6, Step : 3290, Loss : 0.42607, Acc : 0.825, Sensitive_Loss : 0.15301, Sensitive_Acc : 18.100, Run Time : 7.23 sec
INFO:root:2024-04-14 10:36:11, Train, Epoch : 6, Step : 3300, Loss : 0.39842, Acc : 0.853, Sensitive_Loss : 0.14608, Sensitive_Acc : 22.400, Run Time : 6.98 sec
INFO:root:2024-04-14 10:37:39, Dev, Step : 3300, Loss : 0.50862, Acc : 0.777, Auc : 0.858, Sensitive_Loss : 0.23385, Sensitive_Acc : 21.165, Sensitive_Auc : 0.997, Mean auc: 0.858, Run Time : 88.02 sec
INFO:root:2024-04-14 10:37:45, Train, Epoch : 6, Step : 3310, Loss : 0.32712, Acc : 0.841, Sensitive_Loss : 0.14842, Sensitive_Acc : 20.400, Run Time : 93.52 sec
INFO:root:2024-04-14 10:37:52, Train, Epoch : 6, Step : 3320, Loss : 0.36678, Acc : 0.831, Sensitive_Loss : 0.11338, Sensitive_Acc : 23.900, Run Time : 6.87 sec
INFO:root:2024-04-14 10:37:59, Train, Epoch : 6, Step : 3330, Loss : 0.37755, Acc : 0.831, Sensitive_Loss : 0.16089, Sensitive_Acc : 19.000, Run Time : 7.29 sec
INFO:root:2024-04-14 10:38:06, Train, Epoch : 6, Step : 3340, Loss : 0.40636, Acc : 0.838, Sensitive_Loss : 0.18631, Sensitive_Acc : 24.000, Run Time : 6.85 sec
INFO:root:2024-04-14 10:38:13, Train, Epoch : 6, Step : 3350, Loss : 0.36205, Acc : 0.841, Sensitive_Loss : 0.17394, Sensitive_Acc : 25.900, Run Time : 7.46 sec
INFO:root:2024-04-14 10:38:21, Train, Epoch : 6, Step : 3360, Loss : 0.36206, Acc : 0.850, Sensitive_Loss : 0.12495, Sensitive_Acc : 21.200, Run Time : 7.48 sec
INFO:root:2024-04-14 10:38:28, Train, Epoch : 6, Step : 3370, Loss : 0.50264, Acc : 0.784, Sensitive_Loss : 0.12883, Sensitive_Acc : 23.500, Run Time : 7.09 sec
INFO:root:2024-04-14 10:38:35, Train, Epoch : 6, Step : 3380, Loss : 0.34912, Acc : 0.831, Sensitive_Loss : 0.14525, Sensitive_Acc : 24.700, Run Time : 7.08 sec
INFO:root:2024-04-14 10:38:42, Train, Epoch : 6, Step : 3390, Loss : 0.37769, Acc : 0.856, Sensitive_Loss : 0.08679, Sensitive_Acc : 20.200, Run Time : 6.90 sec
INFO:root:2024-04-14 10:38:49, Train, Epoch : 6, Step : 3400, Loss : 0.38913, Acc : 0.828, Sensitive_Loss : 0.17832, Sensitive_Acc : 19.600, Run Time : 6.91 sec
INFO:root:2024-04-14 10:40:17, Dev, Step : 3400, Loss : 0.50871, Acc : 0.777, Auc : 0.858, Sensitive_Loss : 0.22506, Sensitive_Acc : 21.376, Sensitive_Auc : 0.997, Mean auc: 0.858, Run Time : 87.97 sec
INFO:root:2024-04-14 10:40:22, Train, Epoch : 6, Step : 3410, Loss : 0.38989, Acc : 0.812, Sensitive_Loss : 0.11918, Sensitive_Acc : 15.000, Run Time : 93.56 sec
INFO:root:2024-04-14 10:40:30, Train, Epoch : 6, Step : 3420, Loss : 0.36755, Acc : 0.819, Sensitive_Loss : 0.22082, Sensitive_Acc : 25.600, Run Time : 7.92 sec
INFO:root:2024-04-14 10:40:37, Train, Epoch : 6, Step : 3430, Loss : 0.38750, Acc : 0.850, Sensitive_Loss : 0.11901, Sensitive_Acc : 24.200, Run Time : 7.02 sec
INFO:root:2024-04-14 10:40:44, Train, Epoch : 6, Step : 3440, Loss : 0.46567, Acc : 0.791, Sensitive_Loss : 0.17660, Sensitive_Acc : 23.500, Run Time : 6.53 sec
INFO:root:2024-04-14 10:40:52, Train, Epoch : 6, Step : 3450, Loss : 0.35186, Acc : 0.844, Sensitive_Loss : 0.18278, Sensitive_Acc : 23.700, Run Time : 7.79 sec
INFO:root:2024-04-14 10:40:58, Train, Epoch : 6, Step : 3460, Loss : 0.33439, Acc : 0.859, Sensitive_Loss : 0.12765, Sensitive_Acc : 25.100, Run Time : 6.67 sec
INFO:root:2024-04-14 10:41:05, Train, Epoch : 6, Step : 3470, Loss : 0.43066, Acc : 0.838, Sensitive_Loss : 0.15860, Sensitive_Acc : 19.700, Run Time : 7.12 sec
INFO:root:2024-04-14 10:41:12, Train, Epoch : 6, Step : 3480, Loss : 0.35787, Acc : 0.856, Sensitive_Loss : 0.15002, Sensitive_Acc : 16.900, Run Time : 6.76 sec
INFO:root:2024-04-14 10:41:19, Train, Epoch : 6, Step : 3490, Loss : 0.36468, Acc : 0.831, Sensitive_Loss : 0.22068, Sensitive_Acc : 20.700, Run Time : 7.11 sec
INFO:root:2024-04-14 10:41:26, Train, Epoch : 6, Step : 3500, Loss : 0.35815, Acc : 0.856, Sensitive_Loss : 0.16206, Sensitive_Acc : 21.900, Run Time : 7.09 sec
INFO:root:2024-04-14 10:42:55, Dev, Step : 3500, Loss : 0.52029, Acc : 0.782, Auc : 0.859, Sensitive_Loss : 0.20202, Sensitive_Acc : 21.511, Sensitive_Auc : 0.998, Mean auc: 0.859, Run Time : 88.36 sec
INFO:root:2024-04-14 10:43:00, Train, Epoch : 6, Step : 3510, Loss : 0.34438, Acc : 0.856, Sensitive_Loss : 0.15189, Sensitive_Acc : 19.100, Run Time : 93.68 sec
INFO:root:2024-04-14 10:43:08, Train, Epoch : 6, Step : 3520, Loss : 0.37415, Acc : 0.850, Sensitive_Loss : 0.15148, Sensitive_Acc : 23.900, Run Time : 7.60 sec
INFO:root:2024-04-14 10:43:14, Train, Epoch : 6, Step : 3530, Loss : 0.43854, Acc : 0.822, Sensitive_Loss : 0.18549, Sensitive_Acc : 21.000, Run Time : 6.51 sec
INFO:root:2024-04-14 10:43:21, Train, Epoch : 6, Step : 3540, Loss : 0.38004, Acc : 0.838, Sensitive_Loss : 0.16278, Sensitive_Acc : 20.500, Run Time : 7.17 sec
INFO:root:2024-04-14 10:43:29, Train, Epoch : 6, Step : 3550, Loss : 0.34093, Acc : 0.853, Sensitive_Loss : 0.14445, Sensitive_Acc : 24.000, Run Time : 7.23 sec
INFO:root:2024-04-14 10:43:36, Train, Epoch : 6, Step : 3560, Loss : 0.32496, Acc : 0.859, Sensitive_Loss : 0.14233, Sensitive_Acc : 24.800, Run Time : 7.06 sec
INFO:root:2024-04-14 10:43:43, Train, Epoch : 6, Step : 3570, Loss : 0.32365, Acc : 0.859, Sensitive_Loss : 0.12508, Sensitive_Acc : 22.200, Run Time : 7.60 sec
INFO:root:2024-04-14 10:43:50, Train, Epoch : 6, Step : 3580, Loss : 0.38641, Acc : 0.834, Sensitive_Loss : 0.19438, Sensitive_Acc : 21.500, Run Time : 6.93 sec
INFO:root:2024-04-14 10:43:57, Train, Epoch : 6, Step : 3590, Loss : 0.39105, Acc : 0.850, Sensitive_Loss : 0.13068, Sensitive_Acc : 23.500, Run Time : 6.70 sec
INFO:root:2024-04-14 10:44:04, Train, Epoch : 6, Step : 3600, Loss : 0.41946, Acc : 0.822, Sensitive_Loss : 0.19908, Sensitive_Acc : 17.800, Run Time : 7.09 sec
INFO:root:2024-04-14 10:45:32, Dev, Step : 3600, Loss : 0.52513, Acc : 0.777, Auc : 0.855, Sensitive_Loss : 0.20348, Sensitive_Acc : 21.376, Sensitive_Auc : 0.998, Mean auc: 0.855, Run Time : 88.49 sec
INFO:root:2024-04-14 10:45:38, Train, Epoch : 6, Step : 3610, Loss : 0.32534, Acc : 0.841, Sensitive_Loss : 0.12403, Sensitive_Acc : 19.900, Run Time : 94.08 sec
INFO:root:2024-04-14 10:45:46, Train, Epoch : 6, Step : 3620, Loss : 0.33798, Acc : 0.850, Sensitive_Loss : 0.16704, Sensitive_Acc : 22.400, Run Time : 7.52 sec
INFO:root:2024-04-14 10:45:53, Train, Epoch : 6, Step : 3630, Loss : 0.30882, Acc : 0.856, Sensitive_Loss : 0.15434, Sensitive_Acc : 19.800, Run Time : 7.28 sec
INFO:root:2024-04-14 10:45:59, Train, Epoch : 6, Step : 3640, Loss : 0.38569, Acc : 0.863, Sensitive_Loss : 0.11252, Sensitive_Acc : 22.300, Run Time : 6.57 sec
INFO:root:2024-04-14 10:46:06, Train, Epoch : 6, Step : 3650, Loss : 0.39415, Acc : 0.822, Sensitive_Loss : 0.16210, Sensitive_Acc : 22.500, Run Time : 7.11 sec
INFO:root:2024-04-14 10:46:14, Train, Epoch : 6, Step : 3660, Loss : 0.34169, Acc : 0.841, Sensitive_Loss : 0.15395, Sensitive_Acc : 22.400, Run Time : 7.11 sec
INFO:root:2024-04-14 10:46:21, Train, Epoch : 6, Step : 3670, Loss : 0.43398, Acc : 0.787, Sensitive_Loss : 0.09980, Sensitive_Acc : 17.800, Run Time : 7.29 sec
INFO:root:2024-04-14 10:46:28, Train, Epoch : 6, Step : 3680, Loss : 0.39340, Acc : 0.853, Sensitive_Loss : 0.18115, Sensitive_Acc : 24.500, Run Time : 6.76 sec
INFO:root:2024-04-14 10:46:35, Train, Epoch : 6, Step : 3690, Loss : 0.36906, Acc : 0.831, Sensitive_Loss : 0.20742, Sensitive_Acc : 22.000, Run Time : 7.11 sec
INFO:root:2024-04-14 10:46:42, Train, Epoch : 6, Step : 3700, Loss : 0.34677, Acc : 0.847, Sensitive_Loss : 0.14861, Sensitive_Acc : 23.300, Run Time : 7.59 sec
INFO:root:2024-04-14 10:48:10, Dev, Step : 3700, Loss : 0.54606, Acc : 0.778, Auc : 0.854, Sensitive_Loss : 0.23144, Sensitive_Acc : 20.865, Sensitive_Auc : 0.998, Mean auc: 0.854, Run Time : 87.92 sec
INFO:root:2024-04-14 10:48:16, Train, Epoch : 6, Step : 3710, Loss : 0.33673, Acc : 0.831, Sensitive_Loss : 0.12038, Sensitive_Acc : 21.000, Run Time : 93.81 sec
INFO:root:2024-04-14 10:48:23, Train, Epoch : 6, Step : 3720, Loss : 0.32958, Acc : 0.878, Sensitive_Loss : 0.12551, Sensitive_Acc : 21.200, Run Time : 6.93 sec
INFO:root:2024-04-14 10:48:30, Train, Epoch : 6, Step : 3730, Loss : 0.43718, Acc : 0.812, Sensitive_Loss : 0.21391, Sensitive_Acc : 21.400, Run Time : 6.91 sec
INFO:root:2024-04-14 10:48:37, Train, Epoch : 6, Step : 3740, Loss : 0.35370, Acc : 0.847, Sensitive_Loss : 0.13991, Sensitive_Acc : 19.300, Run Time : 7.07 sec
INFO:root:2024-04-14 10:48:44, Train, Epoch : 6, Step : 3750, Loss : 0.35638, Acc : 0.847, Sensitive_Loss : 0.14836, Sensitive_Acc : 20.600, Run Time : 7.39 sec
INFO:root:2024-04-14 10:48:51, Train, Epoch : 6, Step : 3760, Loss : 0.30143, Acc : 0.875, Sensitive_Loss : 0.18715, Sensitive_Acc : 23.700, Run Time : 6.75 sec
INFO:root:2024-04-14 10:48:58, Train, Epoch : 6, Step : 3770, Loss : 0.40717, Acc : 0.834, Sensitive_Loss : 0.15134, Sensitive_Acc : 19.400, Run Time : 7.26 sec
INFO:root:2024-04-14 10:49:06, Train, Epoch : 6, Step : 3780, Loss : 0.33835, Acc : 0.853, Sensitive_Loss : 0.13330, Sensitive_Acc : 22.200, Run Time : 7.37 sec
INFO:root:2024-04-14 10:49:13, Train, Epoch : 6, Step : 3790, Loss : 0.43855, Acc : 0.797, Sensitive_Loss : 0.15136, Sensitive_Acc : 24.000, Run Time : 7.49 sec
INFO:root:2024-04-14 10:49:20, Train, Epoch : 6, Step : 3800, Loss : 0.48674, Acc : 0.797, Sensitive_Loss : 0.17823, Sensitive_Acc : 24.000, Run Time : 6.60 sec
INFO:root:2024-04-14 10:50:51, Dev, Step : 3800, Loss : 0.52552, Acc : 0.777, Auc : 0.855, Sensitive_Loss : 0.24041, Sensitive_Acc : 20.865, Sensitive_Auc : 0.997, Mean auc: 0.855, Run Time : 91.42 sec
INFO:root:2024-04-14 10:52:19
INFO:root:y_pred: [0.05554226 0.01181032 0.04276001 ... 0.17247733 0.06992082 0.07634456]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [3.53605929e-03 1.50592776e-03 9.25026275e-03 3.28637451e-01
 5.91492839e-02 4.19789180e-03 5.24592353e-03 1.09229970e-03
 9.39980596e-02 9.99927521e-01 1.71233922e-01 1.41376676e-03
 8.83824006e-03 4.91220388e-04 9.99966979e-01 1.00678597e-02
 2.17780774e-03 9.99353468e-01 9.99897480e-01 1.06350321e-03
 8.37970853e-01 5.85849455e-04 5.27452454e-02 2.91217361e-02
 2.16365680e-01 6.00286365e-01 9.81445992e-05 1.00009947e-03
 1.01389873e-04 1.13375381e-01 2.99560023e-03 9.99604285e-01
 4.29328866e-02 9.39546645e-01 6.31945033e-04 9.66190768e-04
 5.00720181e-03 2.03406941e-02 2.65236318e-01 1.53059307e-02
 9.52712595e-02 9.97050047e-01 3.01430598e-02 1.01607607e-03
 9.92431879e-01 2.92584479e-01 3.86494845e-01 4.50807214e-01
 5.28875351e-01 9.95822549e-01 9.96990085e-01 9.99972820e-01
 9.92498100e-01 3.69967744e-02 6.62844479e-02 4.59395707e-01
 1.30623905e-02 2.31507048e-02 9.98496890e-01 1.21723756e-03
 2.31138663e-03 8.52571859e-04 8.13580211e-03 3.11264266e-05
 9.98474419e-01 1.97593402e-03 6.88873115e-05 8.99990182e-03
 5.30661717e-02 9.81720448e-01 9.99935389e-01 9.99948740e-01
 5.99233957e-04 6.17055297e-01 1.06739355e-02 7.77695358e-01
 1.19567430e-02 7.31958353e-05 2.04313709e-03 1.50990870e-03
 1.47552639e-01 1.54252886e-03 9.98746991e-01 9.96649086e-01
 2.21678652e-02 7.24354446e-01 2.76016444e-02 5.66161005e-03
 2.54469179e-02 2.16799803e-04 3.21044996e-02 1.95456892e-02
 6.23295375e-04 1.50676977e-04 1.55548484e-03 6.55834051e-03
 2.70912482e-04 6.64013743e-01 8.86242371e-03 1.70240726e-03
 6.77856756e-03 6.01600949e-03 1.94635898e-01 2.27316096e-03
 7.23397508e-02 2.47332820e-04 2.42697999e-01 9.03891861e-01
 4.40106988e-01 1.72210142e-01 3.01442051e-05 9.99984980e-01
 9.99709427e-01 4.86444405e-05 1.01678699e-01 2.84980480e-02
 3.71196344e-02 5.53832622e-04 7.21375763e-01 7.89677631e-03
 2.17928784e-03 2.63741966e-02 3.47719751e-02 4.74163855e-04
 7.02567725e-03 8.77853274e-01 7.62907366e-05 9.98273253e-01
 2.07839366e-02 4.69873071e-01 2.44647218e-03 8.60981867e-02
 4.23589692e-04]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-14 10:52:19, Dev, Step : 3804, Loss : 0.52299, Acc : 0.779, Auc : 0.854, Sensitive_Loss : 0.22555, Sensitive_Acc : 21.060, Sensitive_Auc : 0.997, Mean auc: 0.854, Run Time : 86.53 sec
INFO:root:2024-04-14 10:52:26, Train, Epoch : 7, Step : 3810, Loss : 0.22055, Acc : 0.500, Sensitive_Loss : 0.07288, Sensitive_Acc : 13.500, Run Time : 5.80 sec
INFO:root:2024-04-14 10:52:32, Train, Epoch : 7, Step : 3820, Loss : 0.36107, Acc : 0.866, Sensitive_Loss : 0.12452, Sensitive_Acc : 23.800, Run Time : 6.64 sec
INFO:root:2024-04-14 10:52:40, Train, Epoch : 7, Step : 3830, Loss : 0.35196, Acc : 0.856, Sensitive_Loss : 0.13391, Sensitive_Acc : 25.500, Run Time : 7.31 sec
INFO:root:2024-04-14 10:52:47, Train, Epoch : 7, Step : 3840, Loss : 0.30234, Acc : 0.875, Sensitive_Loss : 0.10454, Sensitive_Acc : 24.600, Run Time : 7.03 sec
INFO:root:2024-04-14 10:52:54, Train, Epoch : 7, Step : 3850, Loss : 0.38276, Acc : 0.859, Sensitive_Loss : 0.18628, Sensitive_Acc : 21.600, Run Time : 7.28 sec
INFO:root:2024-04-14 10:53:01, Train, Epoch : 7, Step : 3860, Loss : 0.30369, Acc : 0.872, Sensitive_Loss : 0.13908, Sensitive_Acc : 22.900, Run Time : 7.00 sec
INFO:root:2024-04-14 10:53:08, Train, Epoch : 7, Step : 3870, Loss : 0.35345, Acc : 0.866, Sensitive_Loss : 0.11212, Sensitive_Acc : 20.500, Run Time : 6.99 sec
INFO:root:2024-04-14 10:53:16, Train, Epoch : 7, Step : 3880, Loss : 0.32375, Acc : 0.847, Sensitive_Loss : 0.14671, Sensitive_Acc : 18.200, Run Time : 7.53 sec
INFO:root:2024-04-14 10:53:23, Train, Epoch : 7, Step : 3890, Loss : 0.34147, Acc : 0.859, Sensitive_Loss : 0.15076, Sensitive_Acc : 25.600, Run Time : 7.26 sec
INFO:root:2024-04-14 10:53:30, Train, Epoch : 7, Step : 3900, Loss : 0.34663, Acc : 0.863, Sensitive_Loss : 0.12690, Sensitive_Acc : 20.700, Run Time : 7.02 sec
INFO:root:2024-04-14 10:55:01, Dev, Step : 3900, Loss : 0.53733, Acc : 0.774, Auc : 0.855, Sensitive_Loss : 0.20760, Sensitive_Acc : 21.286, Sensitive_Auc : 0.998, Mean auc: 0.855, Run Time : 91.51 sec
INFO:root:2024-04-14 10:55:07, Train, Epoch : 7, Step : 3910, Loss : 0.34105, Acc : 0.847, Sensitive_Loss : 0.11190, Sensitive_Acc : 20.200, Run Time : 97.25 sec
INFO:root:2024-04-14 10:55:14, Train, Epoch : 7, Step : 3920, Loss : 0.34116, Acc : 0.847, Sensitive_Loss : 0.10341, Sensitive_Acc : 22.900, Run Time : 7.40 sec
INFO:root:2024-04-14 10:55:21, Train, Epoch : 7, Step : 3930, Loss : 0.32430, Acc : 0.863, Sensitive_Loss : 0.15719, Sensitive_Acc : 26.600, Run Time : 6.90 sec
INFO:root:2024-04-14 10:55:28, Train, Epoch : 7, Step : 3940, Loss : 0.32419, Acc : 0.847, Sensitive_Loss : 0.10703, Sensitive_Acc : 18.000, Run Time : 6.72 sec
INFO:root:2024-04-14 10:55:35, Train, Epoch : 7, Step : 3950, Loss : 0.39216, Acc : 0.834, Sensitive_Loss : 0.24872, Sensitive_Acc : 20.800, Run Time : 6.86 sec
INFO:root:2024-04-14 10:55:42, Train, Epoch : 7, Step : 3960, Loss : 0.30162, Acc : 0.856, Sensitive_Loss : 0.14459, Sensitive_Acc : 19.700, Run Time : 7.33 sec
INFO:root:2024-04-14 10:55:50, Train, Epoch : 7, Step : 3970, Loss : 0.34866, Acc : 0.856, Sensitive_Loss : 0.11870, Sensitive_Acc : 26.800, Run Time : 7.28 sec
INFO:root:2024-04-14 10:55:57, Train, Epoch : 7, Step : 3980, Loss : 0.33691, Acc : 0.856, Sensitive_Loss : 0.11476, Sensitive_Acc : 23.600, Run Time : 7.51 sec
INFO:root:2024-04-14 10:56:04, Train, Epoch : 7, Step : 3990, Loss : 0.34780, Acc : 0.856, Sensitive_Loss : 0.09408, Sensitive_Acc : 19.600, Run Time : 6.67 sec
INFO:root:2024-04-14 10:56:11, Train, Epoch : 7, Step : 4000, Loss : 0.30090, Acc : 0.884, Sensitive_Loss : 0.16320, Sensitive_Acc : 23.400, Run Time : 7.22 sec
INFO:root:2024-04-14 10:57:39, Dev, Step : 4000, Loss : 0.55245, Acc : 0.775, Auc : 0.853, Sensitive_Loss : 0.22764, Sensitive_Acc : 21.120, Sensitive_Auc : 0.998, Mean auc: 0.853, Run Time : 87.96 sec
INFO:root:2024-04-14 10:57:44, Train, Epoch : 7, Step : 4010, Loss : 0.37229, Acc : 0.838, Sensitive_Loss : 0.11231, Sensitive_Acc : 19.800, Run Time : 93.38 sec
INFO:root:2024-04-14 10:57:52, Train, Epoch : 7, Step : 4020, Loss : 0.36906, Acc : 0.850, Sensitive_Loss : 0.13080, Sensitive_Acc : 21.300, Run Time : 7.40 sec
INFO:root:2024-04-14 10:57:59, Train, Epoch : 7, Step : 4030, Loss : 0.38245, Acc : 0.809, Sensitive_Loss : 0.18913, Sensitive_Acc : 20.100, Run Time : 7.09 sec
INFO:root:2024-04-14 10:58:06, Train, Epoch : 7, Step : 4040, Loss : 0.34215, Acc : 0.866, Sensitive_Loss : 0.10909, Sensitive_Acc : 19.400, Run Time : 7.12 sec
INFO:root:2024-04-14 10:58:12, Train, Epoch : 7, Step : 4050, Loss : 0.31762, Acc : 0.831, Sensitive_Loss : 0.18700, Sensitive_Acc : 23.800, Run Time : 6.47 sec
INFO:root:2024-04-14 10:58:20, Train, Epoch : 7, Step : 4060, Loss : 0.36649, Acc : 0.844, Sensitive_Loss : 0.18100, Sensitive_Acc : 19.200, Run Time : 7.52 sec
INFO:root:2024-04-14 10:58:27, Train, Epoch : 7, Step : 4070, Loss : 0.40931, Acc : 0.831, Sensitive_Loss : 0.09116, Sensitive_Acc : 21.400, Run Time : 6.69 sec
INFO:root:2024-04-14 10:58:34, Train, Epoch : 7, Step : 4080, Loss : 0.34967, Acc : 0.869, Sensitive_Loss : 0.13228, Sensitive_Acc : 24.600, Run Time : 7.24 sec
INFO:root:2024-04-14 10:58:41, Train, Epoch : 7, Step : 4090, Loss : 0.33629, Acc : 0.863, Sensitive_Loss : 0.12382, Sensitive_Acc : 25.200, Run Time : 7.22 sec
INFO:root:2024-04-14 10:58:48, Train, Epoch : 7, Step : 4100, Loss : 0.33265, Acc : 0.884, Sensitive_Loss : 0.20222, Sensitive_Acc : 18.300, Run Time : 7.10 sec
INFO:root:2024-04-14 11:00:16, Dev, Step : 4100, Loss : 0.53722, Acc : 0.776, Auc : 0.853, Sensitive_Loss : 0.23874, Sensitive_Acc : 20.880, Sensitive_Auc : 0.997, Mean auc: 0.853, Run Time : 87.98 sec
INFO:root:2024-04-14 11:00:22, Train, Epoch : 7, Step : 4110, Loss : 0.37835, Acc : 0.847, Sensitive_Loss : 0.19582, Sensitive_Acc : 21.200, Run Time : 93.58 sec
INFO:root:2024-04-14 11:00:29, Train, Epoch : 7, Step : 4120, Loss : 0.39762, Acc : 0.844, Sensitive_Loss : 0.13266, Sensitive_Acc : 18.600, Run Time : 7.37 sec
INFO:root:2024-04-14 11:00:36, Train, Epoch : 7, Step : 4130, Loss : 0.28584, Acc : 0.866, Sensitive_Loss : 0.12321, Sensitive_Acc : 26.600, Run Time : 7.16 sec
INFO:root:2024-04-14 11:00:44, Train, Epoch : 7, Step : 4140, Loss : 0.37697, Acc : 0.819, Sensitive_Loss : 0.13062, Sensitive_Acc : 20.500, Run Time : 7.21 sec
INFO:root:2024-04-14 11:00:50, Train, Epoch : 7, Step : 4150, Loss : 0.35035, Acc : 0.822, Sensitive_Loss : 0.10688, Sensitive_Acc : 25.600, Run Time : 6.76 sec
INFO:root:2024-04-14 11:00:57, Train, Epoch : 7, Step : 4160, Loss : 0.31147, Acc : 0.869, Sensitive_Loss : 0.12560, Sensitive_Acc : 19.200, Run Time : 6.95 sec
INFO:root:2024-04-14 11:01:04, Train, Epoch : 7, Step : 4170, Loss : 0.28461, Acc : 0.878, Sensitive_Loss : 0.16633, Sensitive_Acc : 25.400, Run Time : 7.18 sec
INFO:root:2024-04-14 11:01:12, Train, Epoch : 7, Step : 4180, Loss : 0.44622, Acc : 0.825, Sensitive_Loss : 0.09683, Sensitive_Acc : 15.900, Run Time : 7.43 sec
INFO:root:2024-04-14 11:01:19, Train, Epoch : 7, Step : 4190, Loss : 0.36245, Acc : 0.847, Sensitive_Loss : 0.11639, Sensitive_Acc : 21.300, Run Time : 7.23 sec
INFO:root:2024-04-14 11:01:26, Train, Epoch : 7, Step : 4200, Loss : 0.34912, Acc : 0.850, Sensitive_Loss : 0.12900, Sensitive_Acc : 24.000, Run Time : 7.11 sec
INFO:root:2024-04-14 11:02:54, Dev, Step : 4200, Loss : 0.54418, Acc : 0.772, Auc : 0.853, Sensitive_Loss : 0.20498, Sensitive_Acc : 21.301, Sensitive_Auc : 0.997, Mean auc: 0.853, Run Time : 87.59 sec
INFO:root:2024-04-14 11:02:59, Train, Epoch : 7, Step : 4210, Loss : 0.37343, Acc : 0.847, Sensitive_Loss : 0.12307, Sensitive_Acc : 17.400, Run Time : 93.01 sec
INFO:root:2024-04-14 11:03:06, Train, Epoch : 7, Step : 4220, Loss : 0.32243, Acc : 0.856, Sensitive_Loss : 0.09747, Sensitive_Acc : 20.100, Run Time : 6.88 sec
INFO:root:2024-04-14 11:03:13, Train, Epoch : 7, Step : 4230, Loss : 0.31314, Acc : 0.863, Sensitive_Loss : 0.15550, Sensitive_Acc : 21.200, Run Time : 7.08 sec
INFO:root:2024-04-14 11:03:21, Train, Epoch : 7, Step : 4240, Loss : 0.32464, Acc : 0.887, Sensitive_Loss : 0.13173, Sensitive_Acc : 23.600, Run Time : 7.85 sec
INFO:root:2024-04-14 11:03:28, Train, Epoch : 7, Step : 4250, Loss : 0.46717, Acc : 0.794, Sensitive_Loss : 0.16067, Sensitive_Acc : 22.400, Run Time : 6.81 sec
INFO:root:2024-04-14 11:03:35, Train, Epoch : 7, Step : 4260, Loss : 0.35684, Acc : 0.863, Sensitive_Loss : 0.12790, Sensitive_Acc : 22.100, Run Time : 7.15 sec
INFO:root:2024-04-14 11:03:42, Train, Epoch : 7, Step : 4270, Loss : 0.42705, Acc : 0.834, Sensitive_Loss : 0.11051, Sensitive_Acc : 21.400, Run Time : 6.87 sec
INFO:root:2024-04-14 11:03:49, Train, Epoch : 7, Step : 4280, Loss : 0.35278, Acc : 0.847, Sensitive_Loss : 0.18019, Sensitive_Acc : 18.800, Run Time : 6.76 sec
INFO:root:2024-04-14 11:03:56, Train, Epoch : 7, Step : 4290, Loss : 0.45116, Acc : 0.831, Sensitive_Loss : 0.11728, Sensitive_Acc : 22.600, Run Time : 6.99 sec
INFO:root:2024-04-14 11:04:03, Train, Epoch : 7, Step : 4300, Loss : 0.42042, Acc : 0.784, Sensitive_Loss : 0.15999, Sensitive_Acc : 16.100, Run Time : 7.07 sec
INFO:root:2024-04-14 11:05:31, Dev, Step : 4300, Loss : 0.56805, Acc : 0.767, Auc : 0.849, Sensitive_Loss : 0.21129, Sensitive_Acc : 21.150, Sensitive_Auc : 0.997, Mean auc: 0.849, Run Time : 88.03 sec
INFO:root:2024-04-14 11:05:36, Train, Epoch : 7, Step : 4310, Loss : 0.37965, Acc : 0.850, Sensitive_Loss : 0.10867, Sensitive_Acc : 19.900, Run Time : 93.19 sec
INFO:root:2024-04-14 11:05:44, Train, Epoch : 7, Step : 4320, Loss : 0.38212, Acc : 0.828, Sensitive_Loss : 0.11453, Sensitive_Acc : 23.600, Run Time : 7.72 sec
INFO:root:2024-04-14 11:05:51, Train, Epoch : 7, Step : 4330, Loss : 0.41535, Acc : 0.841, Sensitive_Loss : 0.18914, Sensitive_Acc : 21.200, Run Time : 7.53 sec
INFO:root:2024-04-14 11:05:57, Train, Epoch : 7, Step : 4340, Loss : 0.37432, Acc : 0.819, Sensitive_Loss : 0.16254, Sensitive_Acc : 21.200, Run Time : 6.31 sec
INFO:root:2024-04-14 11:06:05, Train, Epoch : 7, Step : 4350, Loss : 0.36846, Acc : 0.866, Sensitive_Loss : 0.15500, Sensitive_Acc : 22.200, Run Time : 7.25 sec
INFO:root:2024-04-14 11:06:12, Train, Epoch : 7, Step : 4360, Loss : 0.35600, Acc : 0.859, Sensitive_Loss : 0.15783, Sensitive_Acc : 17.800, Run Time : 7.40 sec
INFO:root:2024-04-14 11:06:19, Train, Epoch : 7, Step : 4370, Loss : 0.37634, Acc : 0.825, Sensitive_Loss : 0.10953, Sensitive_Acc : 22.800, Run Time : 6.66 sec
INFO:root:2024-04-14 11:06:26, Train, Epoch : 7, Step : 4380, Loss : 0.32608, Acc : 0.847, Sensitive_Loss : 0.17184, Sensitive_Acc : 22.500, Run Time : 7.30 sec
INFO:root:2024-04-14 11:06:33, Train, Epoch : 7, Step : 4390, Loss : 0.33021, Acc : 0.844, Sensitive_Loss : 0.15744, Sensitive_Acc : 22.000, Run Time : 7.04 sec
INFO:root:2024-04-14 11:06:40, Train, Epoch : 7, Step : 4400, Loss : 0.37423, Acc : 0.841, Sensitive_Loss : 0.12595, Sensitive_Acc : 19.800, Run Time : 7.14 sec
INFO:root:2024-04-14 11:08:08, Dev, Step : 4400, Loss : 0.55770, Acc : 0.770, Auc : 0.849, Sensitive_Loss : 0.20745, Sensitive_Acc : 21.361, Sensitive_Auc : 0.998, Mean auc: 0.849, Run Time : 87.59 sec
INFO:root:2024-04-14 11:08:14, Train, Epoch : 7, Step : 4410, Loss : 0.40772, Acc : 0.866, Sensitive_Loss : 0.14135, Sensitive_Acc : 22.600, Run Time : 93.28 sec
INFO:root:2024-04-14 11:08:21, Train, Epoch : 7, Step : 4420, Loss : 0.38440, Acc : 0.838, Sensitive_Loss : 0.16601, Sensitive_Acc : 24.300, Run Time : 7.65 sec
INFO:root:2024-04-14 11:08:28, Train, Epoch : 7, Step : 4430, Loss : 0.38202, Acc : 0.863, Sensitive_Loss : 0.12365, Sensitive_Acc : 18.600, Run Time : 6.98 sec
INFO:root:2024-04-14 11:10:00
INFO:root:y_pred: [0.05436378 0.01802585 0.02895071 ... 0.10463521 0.04991313 0.0455999 ]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [3.6172657e-03 1.1950106e-03 3.6789965e-02 5.3923672e-01 6.4138331e-02
 8.2064942e-03 1.0019283e-02 4.7225735e-04 9.4302781e-02 9.9997222e-01
 1.5105981e-01 2.4758573e-03 4.2692092e-03 1.0293453e-04 9.9997544e-01
 1.1315439e-02 1.4617904e-03 9.9955219e-01 9.9980408e-01 8.8174763e-04
 7.5135726e-01 9.1370608e-04 1.7663432e-02 1.7411148e-02 9.3377195e-02
 6.3071293e-01 5.6941135e-05 1.0068944e-03 2.5843859e-05 9.0249196e-02
 1.9337392e-03 9.9958390e-01 3.0269083e-02 9.7277898e-01 1.3503808e-04
 7.9804217e-04 6.0869511e-03 1.3785002e-02 4.3552798e-01 1.0915880e-02
 9.3586266e-02 9.9958104e-01 3.1828526e-02 1.4166341e-03 9.9257034e-01
 5.9916282e-01 3.1086764e-01 5.9772533e-01 2.6985201e-01 9.9775875e-01
 9.9706692e-01 9.9997377e-01 9.9237871e-01 3.6601845e-02 3.6395323e-02
 5.1231796e-01 9.4765145e-03 5.0525241e-02 9.9891174e-01 1.2255290e-03
 1.5634730e-03 9.4664173e-04 3.9793430e-03 1.1487716e-05 9.9719149e-01
 2.3146844e-03 9.9253775e-06 4.1107077e-02 1.7519454e-02 9.7712040e-01
 9.9992585e-01 9.9997163e-01 6.7613501e-04 5.3460556e-01 5.0422600e-03
 8.0908734e-01 3.0806970e-02 4.4452308e-06 3.2694344e-04 1.3638739e-03
 2.0765921e-01 1.0722929e-03 9.9941409e-01 9.9385953e-01 2.0171365e-02
 4.7121400e-01 4.2961378e-02 7.4313367e-03 1.1255805e-02 2.3586492e-05
 1.3666910e-02 2.0791288e-02 4.6066893e-04 8.1304745e-05 1.9945758e-03
 2.0779537e-03 6.7554611e-05 9.1606122e-01 1.7270198e-02 3.5014364e-03
 9.8870858e-04 4.1024983e-03 9.6366771e-02 7.2808017e-04 6.4867690e-02
 1.2317921e-04 1.8002011e-01 9.5576662e-01 2.5170654e-01 7.0911221e-02
 2.6137195e-05 9.9998569e-01 9.9968159e-01 4.3724031e-05 2.4107085e-01
 2.2125470e-02 3.1306349e-02 2.1212609e-04 7.3821539e-01 6.6673644e-03
 1.6297176e-03 1.0062186e-02 1.8664034e-02 1.9964990e-04 8.1881108e-03
 9.4675165e-01 5.6350393e-05 9.9787462e-01 2.8633552e-02 5.0311381e-01
 2.3037789e-03 1.3835382e-01 1.8760699e-04]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-14 11:10:00, Dev, Step : 4438, Loss : 0.54201, Acc : 0.768, Auc : 0.848, Sensitive_Loss : 0.22508, Sensitive_Acc : 20.744, Sensitive_Auc : 0.998, Mean auc: 0.848, Run Time : 87.23 sec
INFO:root:2024-04-14 11:10:04, Train, Epoch : 8, Step : 4440, Loss : 0.06666, Acc : 0.175, Sensitive_Loss : 0.03569, Sensitive_Acc : 3.200, Run Time : 2.69 sec
INFO:root:2024-04-14 11:10:11, Train, Epoch : 8, Step : 4450, Loss : 0.28554, Acc : 0.894, Sensitive_Loss : 0.17290, Sensitive_Acc : 21.500, Run Time : 7.09 sec
INFO:root:2024-04-14 11:10:18, Train, Epoch : 8, Step : 4460, Loss : 0.35662, Acc : 0.841, Sensitive_Loss : 0.15410, Sensitive_Acc : 21.900, Run Time : 6.91 sec
INFO:root:2024-04-14 11:10:25, Train, Epoch : 8, Step : 4470, Loss : 0.36450, Acc : 0.863, Sensitive_Loss : 0.11317, Sensitive_Acc : 20.600, Run Time : 6.99 sec
INFO:root:2024-04-14 11:10:32, Train, Epoch : 8, Step : 4480, Loss : 0.33880, Acc : 0.853, Sensitive_Loss : 0.13111, Sensitive_Acc : 15.500, Run Time : 7.23 sec
INFO:root:2024-04-14 11:10:39, Train, Epoch : 8, Step : 4490, Loss : 0.26355, Acc : 0.881, Sensitive_Loss : 0.11193, Sensitive_Acc : 20.300, Run Time : 7.27 sec
INFO:root:2024-04-14 11:10:46, Train, Epoch : 8, Step : 4500, Loss : 0.27801, Acc : 0.872, Sensitive_Loss : 0.14418, Sensitive_Acc : 23.900, Run Time : 7.08 sec
INFO:root:2024-04-14 11:12:14, Dev, Step : 4500, Loss : 0.54891, Acc : 0.772, Auc : 0.852, Sensitive_Loss : 0.20079, Sensitive_Acc : 21.511, Sensitive_Auc : 0.998, Mean auc: 0.852, Run Time : 87.97 sec
INFO:root:2024-04-14 11:12:20, Train, Epoch : 8, Step : 4510, Loss : 0.31362, Acc : 0.878, Sensitive_Loss : 0.13430, Sensitive_Acc : 16.000, Run Time : 93.67 sec
INFO:root:2024-04-14 11:12:27, Train, Epoch : 8, Step : 4520, Loss : 0.31739, Acc : 0.853, Sensitive_Loss : 0.12466, Sensitive_Acc : 24.000, Run Time : 7.18 sec
INFO:root:2024-04-14 11:12:34, Train, Epoch : 8, Step : 4530, Loss : 0.33587, Acc : 0.850, Sensitive_Loss : 0.17834, Sensitive_Acc : 22.000, Run Time : 6.96 sec
INFO:root:2024-04-14 11:12:41, Train, Epoch : 8, Step : 4540, Loss : 0.32603, Acc : 0.866, Sensitive_Loss : 0.15897, Sensitive_Acc : 19.900, Run Time : 6.98 sec
INFO:root:2024-04-14 11:12:48, Train, Epoch : 8, Step : 4550, Loss : 0.29712, Acc : 0.869, Sensitive_Loss : 0.10464, Sensitive_Acc : 16.700, Run Time : 7.42 sec
INFO:root:2024-04-14 11:12:55, Train, Epoch : 8, Step : 4560, Loss : 0.34051, Acc : 0.850, Sensitive_Loss : 0.19489, Sensitive_Acc : 25.100, Run Time : 6.76 sec
INFO:root:2024-04-14 11:13:02, Train, Epoch : 8, Step : 4570, Loss : 0.25146, Acc : 0.887, Sensitive_Loss : 0.11264, Sensitive_Acc : 21.700, Run Time : 7.21 sec
INFO:root:2024-04-14 11:13:10, Train, Epoch : 8, Step : 4580, Loss : 0.31956, Acc : 0.875, Sensitive_Loss : 0.18117, Sensitive_Acc : 22.900, Run Time : 7.32 sec
INFO:root:2024-04-14 11:13:17, Train, Epoch : 8, Step : 4590, Loss : 0.36719, Acc : 0.863, Sensitive_Loss : 0.15573, Sensitive_Acc : 21.700, Run Time : 6.82 sec
INFO:root:2024-04-14 11:13:24, Train, Epoch : 8, Step : 4600, Loss : 0.34025, Acc : 0.847, Sensitive_Loss : 0.15174, Sensitive_Acc : 24.400, Run Time : 7.32 sec
INFO:root:2024-04-14 11:14:52, Dev, Step : 4600, Loss : 0.57304, Acc : 0.773, Auc : 0.851, Sensitive_Loss : 0.22182, Sensitive_Acc : 20.940, Sensitive_Auc : 0.998, Mean auc: 0.851, Run Time : 87.71 sec
INFO:root:2024-04-14 11:14:57, Train, Epoch : 8, Step : 4610, Loss : 0.28777, Acc : 0.850, Sensitive_Loss : 0.14252, Sensitive_Acc : 20.500, Run Time : 93.22 sec
INFO:root:2024-04-14 11:15:04, Train, Epoch : 8, Step : 4620, Loss : 0.26335, Acc : 0.887, Sensitive_Loss : 0.14872, Sensitive_Acc : 22.500, Run Time : 7.14 sec
INFO:root:2024-04-14 11:15:11, Train, Epoch : 8, Step : 4630, Loss : 0.34666, Acc : 0.853, Sensitive_Loss : 0.11002, Sensitive_Acc : 25.400, Run Time : 6.79 sec
INFO:root:2024-04-14 11:15:18, Train, Epoch : 8, Step : 4640, Loss : 0.29721, Acc : 0.891, Sensitive_Loss : 0.12984, Sensitive_Acc : 22.000, Run Time : 7.19 sec
INFO:root:2024-04-14 11:15:25, Train, Epoch : 8, Step : 4650, Loss : 0.36146, Acc : 0.884, Sensitive_Loss : 0.15932, Sensitive_Acc : 19.700, Run Time : 7.06 sec
INFO:root:2024-04-14 11:15:32, Train, Epoch : 8, Step : 4660, Loss : 0.34519, Acc : 0.831, Sensitive_Loss : 0.13378, Sensitive_Acc : 20.900, Run Time : 6.77 sec
INFO:root:2024-04-14 11:15:40, Train, Epoch : 8, Step : 4670, Loss : 0.34698, Acc : 0.834, Sensitive_Loss : 0.11268, Sensitive_Acc : 25.900, Run Time : 7.54 sec
INFO:root:2024-04-14 11:15:47, Train, Epoch : 8, Step : 4680, Loss : 0.41659, Acc : 0.819, Sensitive_Loss : 0.16309, Sensitive_Acc : 18.800, Run Time : 6.96 sec
INFO:root:2024-04-14 11:15:53, Train, Epoch : 8, Step : 4690, Loss : 0.32232, Acc : 0.850, Sensitive_Loss : 0.09743, Sensitive_Acc : 22.400, Run Time : 6.74 sec
INFO:root:2024-04-14 11:16:01, Train, Epoch : 8, Step : 4700, Loss : 0.37872, Acc : 0.847, Sensitive_Loss : 0.11041, Sensitive_Acc : 19.300, Run Time : 7.53 sec
INFO:root:2024-04-14 11:17:29, Dev, Step : 4700, Loss : 0.55900, Acc : 0.774, Auc : 0.850, Sensitive_Loss : 0.20439, Sensitive_Acc : 21.376, Sensitive_Auc : 0.998, Mean auc: 0.850, Run Time : 88.13 sec
INFO:root:2024-04-14 11:17:35, Train, Epoch : 8, Step : 4710, Loss : 0.39557, Acc : 0.828, Sensitive_Loss : 0.13728, Sensitive_Acc : 22.400, Run Time : 93.81 sec
INFO:root:2024-04-14 11:17:42, Train, Epoch : 8, Step : 4720, Loss : 0.31502, Acc : 0.859, Sensitive_Loss : 0.13888, Sensitive_Acc : 20.900, Run Time : 7.18 sec
INFO:root:2024-04-14 11:17:49, Train, Epoch : 8, Step : 4730, Loss : 0.38064, Acc : 0.828, Sensitive_Loss : 0.14223, Sensitive_Acc : 27.400, Run Time : 6.90 sec
INFO:root:2024-04-14 11:17:56, Train, Epoch : 8, Step : 4740, Loss : 0.32865, Acc : 0.853, Sensitive_Loss : 0.11974, Sensitive_Acc : 22.200, Run Time : 7.47 sec
INFO:root:2024-04-14 11:18:03, Train, Epoch : 8, Step : 4750, Loss : 0.33941, Acc : 0.872, Sensitive_Loss : 0.12022, Sensitive_Acc : 24.000, Run Time : 7.27 sec
INFO:root:2024-04-14 11:18:10, Train, Epoch : 8, Step : 4760, Loss : 0.32666, Acc : 0.850, Sensitive_Loss : 0.13200, Sensitive_Acc : 21.800, Run Time : 6.82 sec
INFO:root:2024-04-14 11:18:17, Train, Epoch : 8, Step : 4770, Loss : 0.30025, Acc : 0.863, Sensitive_Loss : 0.14045, Sensitive_Acc : 21.400, Run Time : 6.74 sec
INFO:root:2024-04-14 11:18:24, Train, Epoch : 8, Step : 4780, Loss : 0.42437, Acc : 0.841, Sensitive_Loss : 0.16402, Sensitive_Acc : 22.500, Run Time : 7.25 sec
INFO:root:2024-04-14 11:18:31, Train, Epoch : 8, Step : 4790, Loss : 0.29411, Acc : 0.894, Sensitive_Loss : 0.13693, Sensitive_Acc : 21.100, Run Time : 6.64 sec
INFO:root:2024-04-14 11:18:38, Train, Epoch : 8, Step : 4800, Loss : 0.38178, Acc : 0.828, Sensitive_Loss : 0.15566, Sensitive_Acc : 22.700, Run Time : 7.26 sec
INFO:root:2024-04-14 11:20:06, Dev, Step : 4800, Loss : 0.54848, Acc : 0.773, Auc : 0.850, Sensitive_Loss : 0.19675, Sensitive_Acc : 21.511, Sensitive_Auc : 0.997, Mean auc: 0.850, Run Time : 87.89 sec
INFO:root:2024-04-14 11:20:11, Train, Epoch : 8, Step : 4810, Loss : 0.32284, Acc : 0.853, Sensitive_Loss : 0.13593, Sensitive_Acc : 19.900, Run Time : 93.13 sec
INFO:root:2024-04-14 11:20:19, Train, Epoch : 8, Step : 4820, Loss : 0.32088, Acc : 0.844, Sensitive_Loss : 0.15251, Sensitive_Acc : 22.900, Run Time : 7.32 sec
INFO:root:2024-04-14 11:20:26, Train, Epoch : 8, Step : 4830, Loss : 0.31030, Acc : 0.853, Sensitive_Loss : 0.10162, Sensitive_Acc : 22.900, Run Time : 7.67 sec
INFO:root:2024-04-14 11:20:33, Train, Epoch : 8, Step : 4840, Loss : 0.35120, Acc : 0.847, Sensitive_Loss : 0.16169, Sensitive_Acc : 25.700, Run Time : 6.40 sec
INFO:root:2024-04-14 11:20:40, Train, Epoch : 8, Step : 4850, Loss : 0.32257, Acc : 0.878, Sensitive_Loss : 0.14228, Sensitive_Acc : 22.600, Run Time : 7.44 sec
INFO:root:2024-04-14 11:20:47, Train, Epoch : 8, Step : 4860, Loss : 0.28547, Acc : 0.859, Sensitive_Loss : 0.11150, Sensitive_Acc : 18.100, Run Time : 7.14 sec
INFO:root:2024-04-14 11:20:55, Train, Epoch : 8, Step : 4870, Loss : 0.35671, Acc : 0.878, Sensitive_Loss : 0.12163, Sensitive_Acc : 24.500, Run Time : 7.38 sec
INFO:root:2024-04-14 11:21:01, Train, Epoch : 8, Step : 4880, Loss : 0.35901, Acc : 0.834, Sensitive_Loss : 0.12317, Sensitive_Acc : 20.300, Run Time : 6.70 sec
INFO:root:2024-04-14 11:21:09, Train, Epoch : 8, Step : 4890, Loss : 0.31932, Acc : 0.850, Sensitive_Loss : 0.16852, Sensitive_Acc : 17.700, Run Time : 7.37 sec
INFO:root:2024-04-14 11:21:16, Train, Epoch : 8, Step : 4900, Loss : 0.33341, Acc : 0.875, Sensitive_Loss : 0.18102, Sensitive_Acc : 24.100, Run Time : 7.30 sec
INFO:root:2024-04-14 11:22:44, Dev, Step : 4900, Loss : 0.58133, Acc : 0.768, Auc : 0.848, Sensitive_Loss : 0.20649, Sensitive_Acc : 21.060, Sensitive_Auc : 0.998, Mean auc: 0.848, Run Time : 87.66 sec
INFO:root:2024-04-14 11:22:49, Train, Epoch : 8, Step : 4910, Loss : 0.35035, Acc : 0.859, Sensitive_Loss : 0.13125, Sensitive_Acc : 20.200, Run Time : 93.15 sec
INFO:root:2024-04-14 11:22:57, Train, Epoch : 8, Step : 4920, Loss : 0.33435, Acc : 0.869, Sensitive_Loss : 0.11280, Sensitive_Acc : 23.100, Run Time : 7.67 sec
INFO:root:2024-04-14 11:23:03, Train, Epoch : 8, Step : 4930, Loss : 0.29427, Acc : 0.875, Sensitive_Loss : 0.14333, Sensitive_Acc : 23.200, Run Time : 6.45 sec
INFO:root:2024-04-14 11:23:11, Train, Epoch : 8, Step : 4940, Loss : 0.36388, Acc : 0.828, Sensitive_Loss : 0.17049, Sensitive_Acc : 26.500, Run Time : 7.60 sec
INFO:root:2024-04-14 11:23:18, Train, Epoch : 8, Step : 4950, Loss : 0.33534, Acc : 0.859, Sensitive_Loss : 0.17315, Sensitive_Acc : 20.800, Run Time : 7.31 sec
INFO:root:2024-04-14 11:23:25, Train, Epoch : 8, Step : 4960, Loss : 0.30616, Acc : 0.872, Sensitive_Loss : 0.21880, Sensitive_Acc : 24.700, Run Time : 6.31 sec
INFO:root:2024-04-14 11:23:32, Train, Epoch : 8, Step : 4970, Loss : 0.40856, Acc : 0.831, Sensitive_Loss : 0.12783, Sensitive_Acc : 17.800, Run Time : 7.49 sec
INFO:root:2024-04-14 11:23:39, Train, Epoch : 8, Step : 4980, Loss : 0.31253, Acc : 0.878, Sensitive_Loss : 0.16086, Sensitive_Acc : 23.800, Run Time : 6.83 sec
INFO:root:2024-04-14 11:23:46, Train, Epoch : 8, Step : 4990, Loss : 0.35334, Acc : 0.853, Sensitive_Loss : 0.14471, Sensitive_Acc : 18.900, Run Time : 7.46 sec
INFO:root:2024-04-14 11:23:54, Train, Epoch : 8, Step : 5000, Loss : 0.30448, Acc : 0.856, Sensitive_Loss : 0.15019, Sensitive_Acc : 18.200, Run Time : 7.39 sec
INFO:root:2024-04-14 11:25:21, Dev, Step : 5000, Loss : 0.57046, Acc : 0.773, Auc : 0.847, Sensitive_Loss : 0.22358, Sensitive_Acc : 21.030, Sensitive_Auc : 0.997, Mean auc: 0.847, Run Time : 87.73 sec
INFO:root:2024-04-14 11:25:27, Train, Epoch : 8, Step : 5010, Loss : 0.37171, Acc : 0.841, Sensitive_Loss : 0.13425, Sensitive_Acc : 22.700, Run Time : 93.25 sec
INFO:root:2024-04-14 11:25:34, Train, Epoch : 8, Step : 5020, Loss : 0.34617, Acc : 0.856, Sensitive_Loss : 0.12030, Sensitive_Acc : 23.500, Run Time : 7.02 sec
INFO:root:2024-04-14 11:25:41, Train, Epoch : 8, Step : 5030, Loss : 0.35710, Acc : 0.866, Sensitive_Loss : 0.19925, Sensitive_Acc : 22.700, Run Time : 7.03 sec
INFO:root:2024-04-14 11:25:49, Train, Epoch : 8, Step : 5040, Loss : 0.34426, Acc : 0.872, Sensitive_Loss : 0.09864, Sensitive_Acc : 24.200, Run Time : 7.49 sec
INFO:root:2024-04-14 11:25:56, Train, Epoch : 8, Step : 5050, Loss : 0.31222, Acc : 0.856, Sensitive_Loss : 0.08981, Sensitive_Acc : 19.700, Run Time : 7.15 sec
INFO:root:2024-04-14 11:26:03, Train, Epoch : 8, Step : 5060, Loss : 0.37515, Acc : 0.812, Sensitive_Loss : 0.22017, Sensitive_Acc : 19.900, Run Time : 7.10 sec
INFO:root:2024-04-14 11:26:10, Train, Epoch : 8, Step : 5070, Loss : 0.28897, Acc : 0.847, Sensitive_Loss : 0.10391, Sensitive_Acc : 16.100, Run Time : 6.85 sec
INFO:root:2024-04-14 11:27:38
INFO:root:y_pred: [0.03513999 0.02530818 0.01665517 ... 0.10229623 0.1274831  0.02893943]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [6.84860209e-03 3.71374306e-04 3.52166854e-02 3.52338940e-01
 4.08710465e-02 4.88396408e-03 6.36805594e-03 5.51266712e-04
 8.92513692e-02 9.99951482e-01 2.19690785e-01 1.21087965e-03
 1.04843611e-02 7.23243138e-05 9.99985456e-01 1.93003863e-02
 1.75163511e-03 9.99627709e-01 9.99946237e-01 2.94169091e-04
 8.50761414e-01 2.46094598e-04 5.14793061e-02 2.15765983e-02
 2.85373211e-01 6.58223987e-01 5.11901453e-05 8.04361072e-04
 2.06110944e-05 5.00512822e-03 2.71732709e-03 9.99871731e-01
 3.43039669e-02 9.71481323e-01 1.62699944e-04 8.62812041e-04
 1.12719815e-02 9.83282644e-03 2.01526999e-01 9.74553823e-03
 3.59444879e-02 9.98979986e-01 2.41999533e-02 2.45165848e-03
 9.95403528e-01 6.11453474e-01 3.95958602e-01 2.39963979e-01
 2.75092393e-01 9.98686612e-01 9.97757733e-01 9.99954939e-01
 9.93305504e-01 2.08277274e-02 9.00203586e-02 6.52614713e-01
 1.79561339e-02 8.64441618e-02 9.99250114e-01 5.71398763e-04
 1.05048239e-03 4.70599160e-04 4.85467305e-03 7.75218432e-05
 9.97906446e-01 2.07119645e-03 1.84985165e-05 9.70083755e-03
 2.30237562e-02 9.83470380e-01 9.99897480e-01 9.99948382e-01
 5.11078630e-04 3.38295400e-01 2.75195157e-03 6.92139089e-01
 1.47959692e-02 1.21257799e-05 6.81286969e-04 1.27257721e-03
 1.93540394e-01 1.01337547e-03 9.99131620e-01 9.98438299e-01
 1.30330576e-02 5.56804538e-01 3.16561721e-02 2.51918612e-03
 3.24847922e-02 2.12142022e-05 1.17496382e-02 2.01404393e-02
 2.44755211e-04 8.53195670e-05 9.53212846e-04 3.41068115e-03
 5.04543568e-05 6.93294346e-01 1.53180230e-02 4.23435494e-03
 5.79530466e-03 1.07477792e-02 1.13759264e-01 2.15920154e-03
 2.77858060e-02 1.01089732e-04 1.00281782e-01 9.54316735e-01
 3.81926864e-01 8.77244398e-02 2.26232369e-05 9.99992967e-01
 9.99643445e-01 5.72878598e-05 1.87306419e-01 6.29779771e-02
 7.29916915e-02 1.96626832e-04 7.88477957e-01 1.18442159e-02
 1.44793338e-03 1.58292037e-02 2.13528983e-02 3.27572721e-04
 1.14614144e-02 8.90274048e-01 4.21200966e-05 9.99014974e-01
 4.24180143e-02 4.00175184e-01 1.99060654e-03 2.76642263e-01
 2.99264357e-04]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-14 11:27:38, Dev, Step : 5072, Loss : 0.56832, Acc : 0.772, Auc : 0.846, Sensitive_Loss : 0.21403, Sensitive_Acc : 21.060, Sensitive_Auc : 0.998, Mean auc: 0.846, Run Time : 87.45 sec
INFO:root:2024-04-14 11:27:46, Train, Epoch : 9, Step : 5080, Loss : 0.25780, Acc : 0.697, Sensitive_Loss : 0.08290, Sensitive_Acc : 18.800, Run Time : 6.94 sec
INFO:root:2024-04-14 11:27:53, Train, Epoch : 9, Step : 5090, Loss : 0.27054, Acc : 0.878, Sensitive_Loss : 0.14109, Sensitive_Acc : 24.600, Run Time : 7.20 sec
INFO:root:2024-04-14 11:28:00, Train, Epoch : 9, Step : 5100, Loss : 0.31654, Acc : 0.853, Sensitive_Loss : 0.11303, Sensitive_Acc : 21.900, Run Time : 7.11 sec
INFO:root:2024-04-14 11:29:28, Dev, Step : 5100, Loss : 0.56122, Acc : 0.773, Auc : 0.847, Sensitive_Loss : 0.19912, Sensitive_Acc : 21.195, Sensitive_Auc : 0.997, Mean auc: 0.847, Run Time : 87.69 sec
INFO:root:2024-04-14 11:29:33, Train, Epoch : 9, Step : 5110, Loss : 0.34659, Acc : 0.856, Sensitive_Loss : 0.15206, Sensitive_Acc : 21.700, Run Time : 93.05 sec
INFO:root:2024-04-14 11:29:41, Train, Epoch : 9, Step : 5120, Loss : 0.33474, Acc : 0.850, Sensitive_Loss : 0.11584, Sensitive_Acc : 24.100, Run Time : 7.50 sec
INFO:root:2024-04-14 11:29:48, Train, Epoch : 9, Step : 5130, Loss : 0.35577, Acc : 0.850, Sensitive_Loss : 0.11882, Sensitive_Acc : 21.400, Run Time : 7.39 sec
INFO:root:2024-04-14 11:29:55, Train, Epoch : 9, Step : 5140, Loss : 0.22264, Acc : 0.884, Sensitive_Loss : 0.16518, Sensitive_Acc : 21.100, Run Time : 6.82 sec
INFO:root:2024-04-14 11:30:02, Train, Epoch : 9, Step : 5150, Loss : 0.27013, Acc : 0.912, Sensitive_Loss : 0.17495, Sensitive_Acc : 23.300, Run Time : 7.15 sec
INFO:root:2024-04-14 11:30:09, Train, Epoch : 9, Step : 5160, Loss : 0.31932, Acc : 0.853, Sensitive_Loss : 0.16961, Sensitive_Acc : 16.800, Run Time : 7.20 sec
INFO:root:2024-04-14 11:30:16, Train, Epoch : 9, Step : 5170, Loss : 0.27928, Acc : 0.872, Sensitive_Loss : 0.14350, Sensitive_Acc : 21.000, Run Time : 7.15 sec
INFO:root:2024-04-14 11:30:24, Train, Epoch : 9, Step : 5180, Loss : 0.38078, Acc : 0.844, Sensitive_Loss : 0.19025, Sensitive_Acc : 16.300, Run Time : 7.18 sec
INFO:root:2024-04-14 11:30:31, Train, Epoch : 9, Step : 5190, Loss : 0.29292, Acc : 0.878, Sensitive_Loss : 0.12325, Sensitive_Acc : 20.100, Run Time : 7.19 sec
INFO:root:2024-04-14 11:30:38, Train, Epoch : 9, Step : 5200, Loss : 0.36280, Acc : 0.856, Sensitive_Loss : 0.13328, Sensitive_Acc : 23.000, Run Time : 6.97 sec
INFO:root:2024-04-14 11:32:05, Dev, Step : 5200, Loss : 0.56951, Acc : 0.769, Auc : 0.848, Sensitive_Loss : 0.22399, Sensitive_Acc : 20.970, Sensitive_Auc : 0.997, Mean auc: 0.848, Run Time : 87.77 sec
INFO:root:2024-04-14 11:32:11, Train, Epoch : 9, Step : 5210, Loss : 0.41117, Acc : 0.844, Sensitive_Loss : 0.17672, Sensitive_Acc : 20.000, Run Time : 93.03 sec
INFO:root:2024-04-14 11:32:18, Train, Epoch : 9, Step : 5220, Loss : 0.33754, Acc : 0.863, Sensitive_Loss : 0.21021, Sensitive_Acc : 24.300, Run Time : 7.68 sec
INFO:root:2024-04-14 11:32:25, Train, Epoch : 9, Step : 5230, Loss : 0.31748, Acc : 0.856, Sensitive_Loss : 0.14132, Sensitive_Acc : 22.200, Run Time : 6.47 sec
INFO:root:2024-04-14 11:32:32, Train, Epoch : 9, Step : 5240, Loss : 0.36751, Acc : 0.859, Sensitive_Loss : 0.11250, Sensitive_Acc : 23.600, Run Time : 7.34 sec
INFO:root:2024-04-14 11:32:39, Train, Epoch : 9, Step : 5250, Loss : 0.28768, Acc : 0.850, Sensitive_Loss : 0.11947, Sensitive_Acc : 20.400, Run Time : 7.05 sec
INFO:root:2024-04-14 11:32:46, Train, Epoch : 9, Step : 5260, Loss : 0.32194, Acc : 0.884, Sensitive_Loss : 0.11438, Sensitive_Acc : 21.200, Run Time : 7.08 sec
INFO:root:2024-04-14 11:32:54, Train, Epoch : 9, Step : 5270, Loss : 0.36741, Acc : 0.866, Sensitive_Loss : 0.10617, Sensitive_Acc : 23.800, Run Time : 7.19 sec
INFO:root:2024-04-14 11:33:01, Train, Epoch : 9, Step : 5280, Loss : 0.31774, Acc : 0.847, Sensitive_Loss : 0.12274, Sensitive_Acc : 19.500, Run Time : 7.27 sec
INFO:root:2024-04-14 11:33:08, Train, Epoch : 9, Step : 5290, Loss : 0.26985, Acc : 0.891, Sensitive_Loss : 0.14468, Sensitive_Acc : 25.200, Run Time : 7.17 sec
INFO:root:2024-04-14 11:33:16, Train, Epoch : 9, Step : 5300, Loss : 0.28237, Acc : 0.878, Sensitive_Loss : 0.15743, Sensitive_Acc : 17.900, Run Time : 7.58 sec
INFO:root:2024-04-14 11:34:43, Dev, Step : 5300, Loss : 0.55756, Acc : 0.770, Auc : 0.848, Sensitive_Loss : 0.20052, Sensitive_Acc : 21.286, Sensitive_Auc : 0.998, Mean auc: 0.848, Run Time : 87.69 sec
INFO:root:2024-04-14 11:34:49, Train, Epoch : 9, Step : 5310, Loss : 0.27784, Acc : 0.881, Sensitive_Loss : 0.11508, Sensitive_Acc : 21.500, Run Time : 93.18 sec
INFO:root:2024-04-14 11:34:56, Train, Epoch : 9, Step : 5320, Loss : 0.26472, Acc : 0.906, Sensitive_Loss : 0.12127, Sensitive_Acc : 24.100, Run Time : 7.02 sec
INFO:root:2024-04-14 11:35:03, Train, Epoch : 9, Step : 5330, Loss : 0.28250, Acc : 0.894, Sensitive_Loss : 0.16258, Sensitive_Acc : 23.400, Run Time : 7.46 sec
INFO:root:2024-04-14 11:35:11, Train, Epoch : 9, Step : 5340, Loss : 0.24491, Acc : 0.912, Sensitive_Loss : 0.14894, Sensitive_Acc : 21.800, Run Time : 7.39 sec
INFO:root:2024-04-14 11:35:18, Train, Epoch : 9, Step : 5350, Loss : 0.31065, Acc : 0.869, Sensitive_Loss : 0.09073, Sensitive_Acc : 23.200, Run Time : 6.94 sec
INFO:root:2024-04-14 11:35:25, Train, Epoch : 9, Step : 5360, Loss : 0.26681, Acc : 0.903, Sensitive_Loss : 0.11664, Sensitive_Acc : 20.700, Run Time : 7.13 sec
INFO:root:2024-04-14 11:35:32, Train, Epoch : 9, Step : 5370, Loss : 0.30925, Acc : 0.866, Sensitive_Loss : 0.12839, Sensitive_Acc : 24.300, Run Time : 7.24 sec
INFO:root:2024-04-14 11:35:39, Train, Epoch : 9, Step : 5380, Loss : 0.29028, Acc : 0.850, Sensitive_Loss : 0.11118, Sensitive_Acc : 23.900, Run Time : 7.42 sec
INFO:root:2024-04-14 11:35:46, Train, Epoch : 9, Step : 5390, Loss : 0.28240, Acc : 0.906, Sensitive_Loss : 0.14238, Sensitive_Acc : 24.900, Run Time : 6.44 sec
INFO:root:2024-04-14 11:35:53, Train, Epoch : 9, Step : 5400, Loss : 0.31428, Acc : 0.831, Sensitive_Loss : 0.15373, Sensitive_Acc : 23.600, Run Time : 7.27 sec
INFO:root:2024-04-14 11:37:21, Dev, Step : 5400, Loss : 0.57821, Acc : 0.771, Auc : 0.848, Sensitive_Loss : 0.20726, Sensitive_Acc : 21.286, Sensitive_Auc : 0.997, Mean auc: 0.848, Run Time : 87.97 sec
INFO:root:2024-04-14 11:37:26, Train, Epoch : 9, Step : 5410, Loss : 0.27219, Acc : 0.863, Sensitive_Loss : 0.19212, Sensitive_Acc : 21.000, Run Time : 93.28 sec
INFO:root:2024-04-14 11:37:34, Train, Epoch : 9, Step : 5420, Loss : 0.28793, Acc : 0.878, Sensitive_Loss : 0.10883, Sensitive_Acc : 19.800, Run Time : 7.29 sec
INFO:root:2024-04-14 11:37:41, Train, Epoch : 9, Step : 5430, Loss : 0.33626, Acc : 0.866, Sensitive_Loss : 0.10897, Sensitive_Acc : 21.300, Run Time : 7.27 sec
INFO:root:2024-04-14 11:37:48, Train, Epoch : 9, Step : 5440, Loss : 0.35289, Acc : 0.869, Sensitive_Loss : 0.14142, Sensitive_Acc : 24.000, Run Time : 6.78 sec
INFO:root:2024-04-14 11:37:55, Train, Epoch : 9, Step : 5450, Loss : 0.30223, Acc : 0.875, Sensitive_Loss : 0.10498, Sensitive_Acc : 20.300, Run Time : 7.37 sec
INFO:root:2024-04-14 11:38:02, Train, Epoch : 9, Step : 5460, Loss : 0.27656, Acc : 0.909, Sensitive_Loss : 0.10064, Sensitive_Acc : 20.500, Run Time : 7.28 sec
INFO:root:2024-04-14 11:38:09, Train, Epoch : 9, Step : 5470, Loss : 0.31727, Acc : 0.900, Sensitive_Loss : 0.09785, Sensitive_Acc : 23.500, Run Time : 7.09 sec
INFO:root:2024-04-14 11:38:17, Train, Epoch : 9, Step : 5480, Loss : 0.32581, Acc : 0.869, Sensitive_Loss : 0.17490, Sensitive_Acc : 20.100, Run Time : 7.50 sec
INFO:root:2024-04-14 11:38:24, Train, Epoch : 9, Step : 5490, Loss : 0.31036, Acc : 0.866, Sensitive_Loss : 0.15725, Sensitive_Acc : 22.600, Run Time : 6.58 sec
INFO:root:2024-04-14 11:38:31, Train, Epoch : 9, Step : 5500, Loss : 0.31838, Acc : 0.872, Sensitive_Loss : 0.11080, Sensitive_Acc : 23.000, Run Time : 7.79 sec
INFO:root:2024-04-14 11:39:59, Dev, Step : 5500, Loss : 0.58114, Acc : 0.772, Auc : 0.846, Sensitive_Loss : 0.20477, Sensitive_Acc : 21.361, Sensitive_Auc : 0.997, Mean auc: 0.846, Run Time : 87.74 sec
INFO:root:2024-04-14 11:40:05, Train, Epoch : 9, Step : 5510, Loss : 0.25236, Acc : 0.878, Sensitive_Loss : 0.10496, Sensitive_Acc : 20.600, Run Time : 93.29 sec
INFO:root:2024-04-14 11:40:12, Train, Epoch : 9, Step : 5520, Loss : 0.29929, Acc : 0.869, Sensitive_Loss : 0.08829, Sensitive_Acc : 25.900, Run Time : 7.19 sec
INFO:root:2024-04-14 11:40:18, Train, Epoch : 9, Step : 5530, Loss : 0.32329, Acc : 0.872, Sensitive_Loss : 0.15451, Sensitive_Acc : 19.200, Run Time : 6.73 sec
INFO:root:2024-04-14 11:40:26, Train, Epoch : 9, Step : 5540, Loss : 0.28144, Acc : 0.878, Sensitive_Loss : 0.12310, Sensitive_Acc : 22.700, Run Time : 7.24 sec
INFO:root:2024-04-14 11:40:33, Train, Epoch : 9, Step : 5550, Loss : 0.35663, Acc : 0.866, Sensitive_Loss : 0.11896, Sensitive_Acc : 24.200, Run Time : 7.21 sec
INFO:root:2024-04-14 11:40:40, Train, Epoch : 9, Step : 5560, Loss : 0.27108, Acc : 0.897, Sensitive_Loss : 0.11273, Sensitive_Acc : 19.100, Run Time : 7.39 sec
INFO:root:2024-04-14 11:40:47, Train, Epoch : 9, Step : 5570, Loss : 0.26547, Acc : 0.881, Sensitive_Loss : 0.09594, Sensitive_Acc : 16.200, Run Time : 6.76 sec
INFO:root:2024-04-14 11:40:55, Train, Epoch : 9, Step : 5580, Loss : 0.28955, Acc : 0.878, Sensitive_Loss : 0.09249, Sensitive_Acc : 22.700, Run Time : 7.50 sec
INFO:root:2024-04-14 11:41:01, Train, Epoch : 9, Step : 5590, Loss : 0.33006, Acc : 0.838, Sensitive_Loss : 0.15604, Sensitive_Acc : 18.000, Run Time : 6.77 sec
INFO:root:2024-04-14 11:41:08, Train, Epoch : 9, Step : 5600, Loss : 0.31754, Acc : 0.869, Sensitive_Loss : 0.09204, Sensitive_Acc : 17.700, Run Time : 6.91 sec
INFO:root:2024-04-14 11:42:36, Dev, Step : 5600, Loss : 0.57672, Acc : 0.773, Auc : 0.849, Sensitive_Loss : 0.21265, Sensitive_Acc : 21.150, Sensitive_Auc : 0.996, Mean auc: 0.849, Run Time : 88.15 sec
INFO:root:2024-04-14 11:42:42, Train, Epoch : 9, Step : 5610, Loss : 0.30216, Acc : 0.859, Sensitive_Loss : 0.15292, Sensitive_Acc : 22.900, Run Time : 93.89 sec
INFO:root:2024-04-14 11:42:50, Train, Epoch : 9, Step : 5620, Loss : 0.24025, Acc : 0.894, Sensitive_Loss : 0.13285, Sensitive_Acc : 21.600, Run Time : 7.61 sec
INFO:root:2024-04-14 11:42:56, Train, Epoch : 9, Step : 5630, Loss : 0.33416, Acc : 0.863, Sensitive_Loss : 0.15420, Sensitive_Acc : 20.300, Run Time : 6.38 sec
INFO:root:2024-04-14 11:43:04, Train, Epoch : 9, Step : 5640, Loss : 0.25364, Acc : 0.887, Sensitive_Loss : 0.12059, Sensitive_Acc : 19.100, Run Time : 7.79 sec
INFO:root:2024-04-14 11:43:11, Train, Epoch : 9, Step : 5650, Loss : 0.31931, Acc : 0.847, Sensitive_Loss : 0.10775, Sensitive_Acc : 20.700, Run Time : 7.49 sec
INFO:root:2024-04-14 11:43:18, Train, Epoch : 9, Step : 5660, Loss : 0.29120, Acc : 0.878, Sensitive_Loss : 0.13027, Sensitive_Acc : 20.400, Run Time : 6.96 sec
INFO:root:2024-04-14 11:43:25, Train, Epoch : 9, Step : 5670, Loss : 0.35628, Acc : 0.828, Sensitive_Loss : 0.12898, Sensitive_Acc : 20.400, Run Time : 6.79 sec
INFO:root:2024-04-14 11:43:32, Train, Epoch : 9, Step : 5680, Loss : 0.35656, Acc : 0.850, Sensitive_Loss : 0.10593, Sensitive_Acc : 21.900, Run Time : 7.01 sec
INFO:root:2024-04-14 11:43:39, Train, Epoch : 9, Step : 5690, Loss : 0.27866, Acc : 0.875, Sensitive_Loss : 0.16164, Sensitive_Acc : 21.800, Run Time : 7.24 sec
INFO:root:2024-04-14 11:43:47, Train, Epoch : 9, Step : 5700, Loss : 0.29128, Acc : 0.878, Sensitive_Loss : 0.14023, Sensitive_Acc : 20.200, Run Time : 7.28 sec
INFO:root:2024-04-14 11:45:14, Dev, Step : 5700, Loss : 0.58077, Acc : 0.770, Auc : 0.842, Sensitive_Loss : 0.21084, Sensitive_Acc : 21.195, Sensitive_Auc : 0.997, Mean auc: 0.842, Run Time : 87.72 sec
INFO:root:2024-04-14 11:46:44
INFO:root:y_pred: [0.04017465 0.02873548 0.01090723 ... 0.06480948 0.05823086 0.01955269]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [4.07779682e-03 5.09138801e-04 1.24189248e-02 3.87689918e-01
 4.66638505e-02 2.03757663e-03 2.33631837e-03 8.20668414e-04
 1.44805729e-01 9.99964237e-01 2.09609166e-01 4.03895415e-03
 7.98897725e-03 1.81917319e-04 9.99979138e-01 6.89741038e-03
 7.22912839e-04 9.99425888e-01 9.99812543e-01 1.22664648e-03
 5.92264891e-01 4.33895912e-04 2.87064407e-02 1.95463616e-02
 3.08942825e-01 6.87071025e-01 5.23331073e-05 6.59419165e-04
 1.96287929e-05 5.66549711e-02 3.97336175e-04 9.99858856e-01
 3.03823836e-02 9.79729176e-01 1.61104777e-04 5.89790056e-04
 5.94332581e-03 1.39450328e-02 3.02508831e-01 6.21082401e-03
 1.07536241e-01 9.99402523e-01 4.56303842e-02 1.07071071e-03
 9.84607041e-01 6.30932093e-01 2.89432466e-01 5.77560306e-01
 3.46951872e-01 9.98924196e-01 9.97940004e-01 9.99940515e-01
 9.94006634e-01 2.02736426e-02 5.62148169e-02 5.06442070e-01
 1.17770769e-02 6.78639114e-02 9.99454081e-01 4.86161886e-03
 7.71102495e-04 6.58574048e-04 1.03086997e-02 9.92718415e-05
 9.96899605e-01 4.06069262e-03 8.83099710e-06 1.22945476e-02
 1.25551308e-02 9.80883300e-01 9.99938965e-01 9.99966621e-01
 1.05206983e-03 2.63909280e-01 1.06477225e-02 7.76838541e-01
 2.35127714e-02 7.25950349e-06 4.23966965e-04 8.20847519e-04
 2.60031074e-01 7.72165775e-04 9.98582482e-01 9.94642496e-01
 1.16572781e-02 5.14603078e-01 1.50223654e-02 4.13808879e-03
 2.00555548e-02 5.57807252e-05 1.25244223e-02 1.17718615e-02
 3.51823110e-04 5.39462308e-05 4.04710969e-04 2.25138036e-03
 9.91457418e-05 8.09215128e-01 2.74727587e-02 3.83306644e-03
 1.03403814e-03 8.34828708e-03 1.20598003e-01 5.54807717e-04
 1.01850614e-01 5.03287360e-04 1.01509534e-01 9.37009573e-01
 3.57433259e-01 9.00748596e-02 1.22049023e-05 9.99992609e-01
 9.99550283e-01 4.39635623e-05 1.74030781e-01 2.21926440e-02
 7.99911693e-02 6.39609178e-04 8.21337223e-01 1.44593921e-02
 6.72998081e-04 1.42963398e-02 2.30127219e-02 3.81692866e-04
 7.78248394e-03 9.43352163e-01 2.81030720e-04 9.96341884e-01
 2.54148170e-02 5.56683600e-01 2.43176636e-03 2.65549839e-01
 5.03309420e-04]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-14 11:46:44, Dev, Step : 5706, Loss : 0.58302, Acc : 0.771, Auc : 0.843, Sensitive_Loss : 0.22363, Sensitive_Acc : 20.850, Sensitive_Auc : 0.997, Mean auc: 0.843, Run Time : 86.64 sec
INFO:root:2024-04-14 11:46:48, Train, Epoch : 10, Step : 5710, Loss : 0.10313, Acc : 0.350, Sensitive_Loss : 0.05904, Sensitive_Acc : 10.600, Run Time : 4.05 sec
INFO:root:2024-04-14 11:46:56, Train, Epoch : 10, Step : 5720, Loss : 0.30528, Acc : 0.887, Sensitive_Loss : 0.08869, Sensitive_Acc : 17.300, Run Time : 7.16 sec
INFO:root:2024-04-14 11:47:03, Train, Epoch : 10, Step : 5730, Loss : 0.25047, Acc : 0.887, Sensitive_Loss : 0.14471, Sensitive_Acc : 18.600, Run Time : 7.21 sec
INFO:root:2024-04-14 11:47:10, Train, Epoch : 10, Step : 5740, Loss : 0.25956, Acc : 0.916, Sensitive_Loss : 0.13398, Sensitive_Acc : 23.800, Run Time : 6.83 sec
INFO:root:2024-04-14 11:47:17, Train, Epoch : 10, Step : 5750, Loss : 0.26914, Acc : 0.878, Sensitive_Loss : 0.22420, Sensitive_Acc : 20.400, Run Time : 7.55 sec
INFO:root:2024-04-14 11:47:24, Train, Epoch : 10, Step : 5760, Loss : 0.29758, Acc : 0.872, Sensitive_Loss : 0.12098, Sensitive_Acc : 20.200, Run Time : 6.84 sec
INFO:root:2024-04-14 11:47:31, Train, Epoch : 10, Step : 5770, Loss : 0.26903, Acc : 0.887, Sensitive_Loss : 0.10875, Sensitive_Acc : 20.800, Run Time : 7.23 sec
INFO:root:2024-04-14 11:47:38, Train, Epoch : 10, Step : 5780, Loss : 0.29140, Acc : 0.872, Sensitive_Loss : 0.14200, Sensitive_Acc : 20.300, Run Time : 6.94 sec
INFO:root:2024-04-14 11:47:46, Train, Epoch : 10, Step : 5790, Loss : 0.30623, Acc : 0.847, Sensitive_Loss : 0.10679, Sensitive_Acc : 17.500, Run Time : 7.39 sec
INFO:root:2024-04-14 11:47:52, Train, Epoch : 10, Step : 5800, Loss : 0.37388, Acc : 0.834, Sensitive_Loss : 0.11895, Sensitive_Acc : 22.300, Run Time : 6.88 sec
INFO:root:2024-04-14 11:49:20, Dev, Step : 5800, Loss : 0.58731, Acc : 0.770, Auc : 0.843, Sensitive_Loss : 0.23140, Sensitive_Acc : 20.820, Sensitive_Auc : 0.997, Mean auc: 0.843, Run Time : 87.71 sec
INFO:root:2024-04-14 11:49:26, Train, Epoch : 10, Step : 5810, Loss : 0.25634, Acc : 0.872, Sensitive_Loss : 0.15156, Sensitive_Acc : 19.900, Run Time : 93.37 sec
INFO:root:2024-04-14 11:49:33, Train, Epoch : 10, Step : 5820, Loss : 0.29385, Acc : 0.869, Sensitive_Loss : 0.15930, Sensitive_Acc : 25.300, Run Time : 7.25 sec
INFO:root:2024-04-14 11:49:40, Train, Epoch : 10, Step : 5830, Loss : 0.26526, Acc : 0.891, Sensitive_Loss : 0.13163, Sensitive_Acc : 18.600, Run Time : 6.60 sec
INFO:root:2024-04-14 11:49:47, Train, Epoch : 10, Step : 5840, Loss : 0.22368, Acc : 0.900, Sensitive_Loss : 0.11755, Sensitive_Acc : 23.400, Run Time : 6.99 sec
INFO:root:2024-04-14 11:49:54, Train, Epoch : 10, Step : 5850, Loss : 0.29338, Acc : 0.881, Sensitive_Loss : 0.13485, Sensitive_Acc : 20.500, Run Time : 7.41 sec
INFO:root:2024-04-14 11:50:01, Train, Epoch : 10, Step : 5860, Loss : 0.26016, Acc : 0.887, Sensitive_Loss : 0.12908, Sensitive_Acc : 16.200, Run Time : 7.11 sec
INFO:root:2024-04-14 11:50:09, Train, Epoch : 10, Step : 5870, Loss : 0.30625, Acc : 0.878, Sensitive_Loss : 0.17276, Sensitive_Acc : 21.100, Run Time : 7.35 sec
INFO:root:2024-04-14 11:50:15, Train, Epoch : 10, Step : 5880, Loss : 0.29600, Acc : 0.875, Sensitive_Loss : 0.11124, Sensitive_Acc : 23.900, Run Time : 6.83 sec
INFO:root:2024-04-14 11:50:23, Train, Epoch : 10, Step : 5890, Loss : 0.33441, Acc : 0.847, Sensitive_Loss : 0.16585, Sensitive_Acc : 22.700, Run Time : 7.46 sec
INFO:root:2024-04-14 11:50:30, Train, Epoch : 10, Step : 5900, Loss : 0.33585, Acc : 0.834, Sensitive_Loss : 0.11561, Sensitive_Acc : 23.000, Run Time : 6.80 sec
INFO:root:2024-04-14 11:51:58, Dev, Step : 5900, Loss : 0.63064, Acc : 0.768, Auc : 0.844, Sensitive_Loss : 0.20898, Sensitive_Acc : 21.436, Sensitive_Auc : 0.997, Mean auc: 0.844, Run Time : 87.92 sec
INFO:root:2024-04-14 11:52:03, Train, Epoch : 10, Step : 5910, Loss : 0.33477, Acc : 0.853, Sensitive_Loss : 0.15263, Sensitive_Acc : 25.400, Run Time : 93.73 sec
INFO:root:2024-04-14 11:52:10, Train, Epoch : 10, Step : 5920, Loss : 0.26808, Acc : 0.875, Sensitive_Loss : 0.11639, Sensitive_Acc : 16.200, Run Time : 6.90 sec
INFO:root:2024-04-14 11:52:18, Train, Epoch : 10, Step : 5930, Loss : 0.28936, Acc : 0.878, Sensitive_Loss : 0.10111, Sensitive_Acc : 22.400, Run Time : 7.30 sec
INFO:root:2024-04-14 11:52:25, Train, Epoch : 10, Step : 5940, Loss : 0.32896, Acc : 0.859, Sensitive_Loss : 0.14817, Sensitive_Acc : 21.700, Run Time : 7.46 sec
INFO:root:2024-04-14 11:52:32, Train, Epoch : 10, Step : 5950, Loss : 0.26234, Acc : 0.894, Sensitive_Loss : 0.14798, Sensitive_Acc : 23.100, Run Time : 6.94 sec
INFO:root:2024-04-14 11:52:39, Train, Epoch : 10, Step : 5960, Loss : 0.34934, Acc : 0.822, Sensitive_Loss : 0.06506, Sensitive_Acc : 23.400, Run Time : 7.36 sec
INFO:root:2024-04-14 11:52:46, Train, Epoch : 10, Step : 5970, Loss : 0.29907, Acc : 0.859, Sensitive_Loss : 0.12682, Sensitive_Acc : 26.600, Run Time : 6.93 sec
INFO:root:2024-04-14 11:52:53, Train, Epoch : 10, Step : 5980, Loss : 0.26114, Acc : 0.891, Sensitive_Loss : 0.12838, Sensitive_Acc : 20.900, Run Time : 6.67 sec
INFO:root:2024-04-14 11:53:00, Train, Epoch : 10, Step : 5990, Loss : 0.27871, Acc : 0.891, Sensitive_Loss : 0.09623, Sensitive_Acc : 17.400, Run Time : 7.20 sec
INFO:root:2024-04-14 11:53:07, Train, Epoch : 10, Step : 6000, Loss : 0.31914, Acc : 0.859, Sensitive_Loss : 0.12766, Sensitive_Acc : 20.100, Run Time : 7.05 sec
INFO:root:2024-04-14 11:54:35, Dev, Step : 6000, Loss : 0.58550, Acc : 0.768, Auc : 0.846, Sensitive_Loss : 0.19744, Sensitive_Acc : 21.511, Sensitive_Auc : 0.998, Mean auc: 0.846, Run Time : 88.34 sec
INFO:root:2024-04-14 11:54:41, Train, Epoch : 10, Step : 6010, Loss : 0.24824, Acc : 0.894, Sensitive_Loss : 0.09029, Sensitive_Acc : 20.400, Run Time : 93.82 sec
INFO:root:2024-04-14 11:54:48, Train, Epoch : 10, Step : 6020, Loss : 0.28652, Acc : 0.869, Sensitive_Loss : 0.15299, Sensitive_Acc : 25.400, Run Time : 7.23 sec
INFO:root:2024-04-14 11:54:56, Train, Epoch : 10, Step : 6030, Loss : 0.26802, Acc : 0.878, Sensitive_Loss : 0.07524, Sensitive_Acc : 19.800, Run Time : 7.56 sec
INFO:root:2024-04-14 11:55:03, Train, Epoch : 10, Step : 6040, Loss : 0.34547, Acc : 0.859, Sensitive_Loss : 0.11530, Sensitive_Acc : 25.600, Run Time : 6.81 sec
INFO:root:2024-04-14 11:55:09, Train, Epoch : 10, Step : 6050, Loss : 0.32889, Acc : 0.859, Sensitive_Loss : 0.16484, Sensitive_Acc : 21.500, Run Time : 6.90 sec
INFO:root:2024-04-14 11:55:17, Train, Epoch : 10, Step : 6060, Loss : 0.23048, Acc : 0.919, Sensitive_Loss : 0.17413, Sensitive_Acc : 20.400, Run Time : 7.31 sec
INFO:root:2024-04-14 11:55:24, Train, Epoch : 10, Step : 6070, Loss : 0.27083, Acc : 0.881, Sensitive_Loss : 0.15747, Sensitive_Acc : 21.700, Run Time : 6.96 sec
INFO:root:2024-04-14 11:55:31, Train, Epoch : 10, Step : 6080, Loss : 0.32020, Acc : 0.853, Sensitive_Loss : 0.15733, Sensitive_Acc : 25.700, Run Time : 7.07 sec
INFO:root:2024-04-14 11:55:38, Train, Epoch : 10, Step : 6090, Loss : 0.33999, Acc : 0.847, Sensitive_Loss : 0.11263, Sensitive_Acc : 21.900, Run Time : 7.52 sec
INFO:root:2024-04-14 11:55:45, Train, Epoch : 10, Step : 6100, Loss : 0.26303, Acc : 0.878, Sensitive_Loss : 0.14280, Sensitive_Acc : 19.900, Run Time : 6.88 sec
INFO:root:2024-04-14 11:57:13, Dev, Step : 6100, Loss : 0.61994, Acc : 0.769, Auc : 0.842, Sensitive_Loss : 0.19992, Sensitive_Acc : 21.511, Sensitive_Auc : 0.998, Mean auc: 0.842, Run Time : 87.80 sec
INFO:root:2024-04-14 11:57:18, Train, Epoch : 10, Step : 6110, Loss : 0.26271, Acc : 0.884, Sensitive_Loss : 0.15230, Sensitive_Acc : 19.200, Run Time : 93.24 sec
INFO:root:2024-04-14 11:57:25, Train, Epoch : 10, Step : 6120, Loss : 0.33749, Acc : 0.853, Sensitive_Loss : 0.07761, Sensitive_Acc : 18.400, Run Time : 6.99 sec
INFO:root:2024-04-14 11:57:33, Train, Epoch : 10, Step : 6130, Loss : 0.33012, Acc : 0.875, Sensitive_Loss : 0.09367, Sensitive_Acc : 16.900, Run Time : 7.62 sec
INFO:root:2024-04-14 11:57:40, Train, Epoch : 10, Step : 6140, Loss : 0.29785, Acc : 0.869, Sensitive_Loss : 0.12778, Sensitive_Acc : 21.900, Run Time : 7.00 sec
INFO:root:2024-04-14 11:57:47, Train, Epoch : 10, Step : 6150, Loss : 0.25118, Acc : 0.897, Sensitive_Loss : 0.13199, Sensitive_Acc : 19.400, Run Time : 6.96 sec
INFO:root:2024-04-14 11:57:54, Train, Epoch : 10, Step : 6160, Loss : 0.27655, Acc : 0.875, Sensitive_Loss : 0.14382, Sensitive_Acc : 20.200, Run Time : 6.91 sec
INFO:root:2024-04-14 11:58:01, Train, Epoch : 10, Step : 6170, Loss : 0.26892, Acc : 0.881, Sensitive_Loss : 0.10162, Sensitive_Acc : 19.900, Run Time : 7.15 sec
INFO:root:2024-04-14 11:58:08, Train, Epoch : 10, Step : 6180, Loss : 0.24094, Acc : 0.884, Sensitive_Loss : 0.09159, Sensitive_Acc : 21.400, Run Time : 6.91 sec
INFO:root:2024-04-14 11:58:15, Train, Epoch : 10, Step : 6190, Loss : 0.22463, Acc : 0.897, Sensitive_Loss : 0.10421, Sensitive_Acc : 21.000, Run Time : 7.17 sec
INFO:root:2024-04-14 11:58:22, Train, Epoch : 10, Step : 6200, Loss : 0.28530, Acc : 0.900, Sensitive_Loss : 0.11693, Sensitive_Acc : 20.200, Run Time : 7.26 sec
INFO:root:2024-04-14 11:59:50, Dev, Step : 6200, Loss : 0.63971, Acc : 0.759, Auc : 0.840, Sensitive_Loss : 0.19312, Sensitive_Acc : 21.361, Sensitive_Auc : 0.998, Mean auc: 0.840, Run Time : 87.93 sec
INFO:root:2024-04-14 11:59:56, Train, Epoch : 10, Step : 6210, Loss : 0.30464, Acc : 0.844, Sensitive_Loss : 0.11349, Sensitive_Acc : 24.400, Run Time : 93.16 sec
INFO:root:2024-04-14 12:00:04, Train, Epoch : 10, Step : 6220, Loss : 0.32761, Acc : 0.844, Sensitive_Loss : 0.11712, Sensitive_Acc : 18.600, Run Time : 7.88 sec
INFO:root:2024-04-14 12:00:10, Train, Epoch : 10, Step : 6230, Loss : 0.32566, Acc : 0.878, Sensitive_Loss : 0.16620, Sensitive_Acc : 22.400, Run Time : 6.22 sec
INFO:root:2024-04-14 12:00:17, Train, Epoch : 10, Step : 6240, Loss : 0.24026, Acc : 0.881, Sensitive_Loss : 0.11845, Sensitive_Acc : 16.400, Run Time : 7.49 sec
INFO:root:2024-04-14 12:00:24, Train, Epoch : 10, Step : 6250, Loss : 0.38409, Acc : 0.841, Sensitive_Loss : 0.11587, Sensitive_Acc : 21.800, Run Time : 6.84 sec
INFO:root:2024-04-14 12:00:31, Train, Epoch : 10, Step : 6260, Loss : 0.25585, Acc : 0.887, Sensitive_Loss : 0.13880, Sensitive_Acc : 19.400, Run Time : 7.35 sec
INFO:root:2024-04-14 12:00:39, Train, Epoch : 10, Step : 6270, Loss : 0.29974, Acc : 0.891, Sensitive_Loss : 0.15170, Sensitive_Acc : 18.600, Run Time : 7.19 sec
INFO:root:2024-04-14 12:00:45, Train, Epoch : 10, Step : 6280, Loss : 0.25520, Acc : 0.875, Sensitive_Loss : 0.09496, Sensitive_Acc : 26.700, Run Time : 6.86 sec
INFO:root:2024-04-14 12:00:53, Train, Epoch : 10, Step : 6290, Loss : 0.30389, Acc : 0.869, Sensitive_Loss : 0.11086, Sensitive_Acc : 22.000, Run Time : 7.23 sec
INFO:root:2024-04-14 12:01:00, Train, Epoch : 10, Step : 6300, Loss : 0.33922, Acc : 0.850, Sensitive_Loss : 0.13645, Sensitive_Acc : 19.300, Run Time : 7.30 sec
INFO:root:2024-04-14 12:02:28, Dev, Step : 6300, Loss : 0.67126, Acc : 0.759, Auc : 0.841, Sensitive_Loss : 0.20607, Sensitive_Acc : 21.286, Sensitive_Auc : 0.998, Mean auc: 0.841, Run Time : 88.06 sec
INFO:root:2024-04-14 12:02:33, Train, Epoch : 10, Step : 6310, Loss : 0.23894, Acc : 0.884, Sensitive_Loss : 0.10476, Sensitive_Acc : 19.000, Run Time : 93.45 sec
INFO:root:2024-04-14 12:02:41, Train, Epoch : 10, Step : 6320, Loss : 0.34464, Acc : 0.853, Sensitive_Loss : 0.09047, Sensitive_Acc : 17.300, Run Time : 7.11 sec
INFO:root:2024-04-14 12:02:48, Train, Epoch : 10, Step : 6330, Loss : 0.22386, Acc : 0.909, Sensitive_Loss : 0.14230, Sensitive_Acc : 24.900, Run Time : 7.27 sec
INFO:root:2024-04-14 12:02:54, Train, Epoch : 10, Step : 6340, Loss : 0.32738, Acc : 0.869, Sensitive_Loss : 0.08171, Sensitive_Acc : 20.900, Run Time : 6.43 sec
INFO:root:2024-04-14 12:04:21
INFO:root:y_pred: [0.03558752 0.01499897 0.00904122 ... 0.03355084 0.06105108 0.01571479]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [7.5429636e-03 4.1805021e-04 2.6394732e-02 5.2848077e-01 5.0927818e-02
 2.1035122e-03 4.0877708e-03 3.1380006e-04 5.4496977e-02 9.9999130e-01
 2.2383799e-01 3.5622383e-03 4.7572022e-03 9.1801274e-05 9.9997914e-01
 1.9655023e-02 1.2654454e-03 9.9935645e-01 9.9981719e-01 2.7383835e-04
 8.3377177e-01 7.6171622e-04 1.2550716e-02 1.9871643e-02 2.6742062e-01
 7.1880186e-01 4.8617447e-05 4.4774055e-04 1.1870242e-05 5.9983343e-02
 3.2254963e-04 9.9987721e-01 5.1717948e-02 9.9038690e-01 2.0978446e-04
 7.5274613e-04 7.0015211e-03 1.0549106e-02 1.7879628e-01 6.7317290e-03
 1.0898871e-01 9.9965608e-01 3.2645520e-02 1.7485555e-03 9.9336511e-01
 6.7198342e-01 3.0764401e-01 3.3014181e-01 4.0000701e-01 9.9931312e-01
 9.9847180e-01 9.9994874e-01 9.9351972e-01 4.7486473e-02 9.5049821e-02
 5.6325918e-01 5.3528994e-03 1.4486898e-01 9.9959189e-01 1.7991104e-03
 8.4773201e-04 7.7795587e-04 8.1043681e-03 4.9373088e-05 9.9898869e-01
 3.7551248e-03 1.7337759e-05 3.8200393e-02 5.2411803e-03 9.9013317e-01
 9.9997449e-01 9.9998689e-01 5.1131198e-04 2.7020535e-01 1.8479377e-03
 8.8446271e-01 3.3332024e-02 2.7140100e-05 3.8156484e-04 4.6636083e-04
 5.0768209e-01 1.4357864e-03 9.9924821e-01 9.9243283e-01 1.1559147e-02
 5.5795556e-01 7.0253059e-02 3.7978441e-03 1.7948374e-02 2.2008810e-05
 4.3759393e-03 1.5851252e-02 3.5219561e-04 4.3809967e-05 9.3027315e-04
 3.7371311e-03 8.4926360e-05 8.0835813e-01 4.9708292e-02 7.1775275e-03
 9.3824702e-04 6.7078997e-03 1.5998699e-01 3.3683570e-03 1.9263452e-02
 2.2231543e-04 1.1973537e-01 9.6809632e-01 3.4375647e-01 6.4498782e-02
 8.8817405e-06 9.9999702e-01 9.9979776e-01 2.2533084e-05 1.2739100e-01
 1.1259245e-02 6.1052788e-02 1.5896221e-04 6.5260100e-01 5.1930547e-03
 1.2682943e-03 2.3352651e-02 1.8564215e-02 3.9538238e-04 9.7206971e-03
 9.5077920e-01 6.8451387e-05 9.9777406e-01 2.9843494e-02 6.0909295e-01
 1.6057816e-03 2.6362494e-01 1.2576384e-04]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-14 12:04:21, Dev, Step : 6340, Loss : 0.61897, Acc : 0.764, Auc : 0.842, Sensitive_Loss : 0.22910, Sensitive_Acc : 20.669, Sensitive_Auc : 0.998, Mean auc: 0.842, Run Time : 87.13 sec
