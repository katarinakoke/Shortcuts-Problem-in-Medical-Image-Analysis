Running on desktop18:
stdin: is not a tty
Activating chexpert environment...
/home/katkr/.conda/envs/chexpert/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'
4
Using the specified args:
Namespace(cfg_path='/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/config/config_katkr.json', device_ids='0', logtofile=False, num_workers=2, pre_train=None, resume=0, save_path='/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/logdirs/logdir-30k-2', verbose=True)
{
    "base_path": "/home/data_shares/purrlab/CheXpert/CheXpert-v1.0-small",
    "train_csv": "/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/biased_dataset_train.csv",
    "dev_csv": "/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/biased_dataset_val.csv",
    "pred_csv": "/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/predictions/Pred_Balanced_Sex_0_0.csv",
    "pred_model": "/home/katkr/Shortcuts-Problem-in-Medical-Image-Analysis/shortcuts-chest-xray/logdirs/logdir-30k-2/Best_Balanced_Sex_0_01.ckpt",
    "backbone": "densenet121",
    "sensitive_attribute": "Sex",
    "lambda_val": 0.05,
    "num_heads": 2,
    "width": 512,
    "height": 512,
    "long_side": 512,
    "fix_ratio": true,
    "pixel_mean": 128.0,
    "pixel_std": 64.0,
    "use_pixel_std": true,
    "use_equalizeHist": true,
    "use_transforms_type": "Aug",
    "gaussian_blur": 3,
    "border_pad": "pixel_mean",
    "num_classes": [
        1
    ],
    "batch_weight": true,
    "batch_weight_sensitive": true,
    "enhance_index": [
        2,
        6
    ],
    "enhance_times": 1,
    "pos_weight": [
        1
    ],
    "sensitive_pos_weight": [
        1
    ],
    "train_batch_size": 32,
    "dev_batch_size": 32,
    "pretrained": true,
    "log_every": 10,
    "test_every": 100,
    "epoch": 10,
    "norm_type": "BatchNorm",
    "global_pool": "PCAM",
    "fc_bn": true,
    "attention_map": "FPA",
    "lse_gamma": 0.5,
    "fc_drop": 0,
    "optimizer": "Adam",
    "criterion": "BCE",
    "sensitive_criterion": "BCE",
    "lr": 0.0001,
    "lr_factor": 0.1,
    "lr_epochs": [
        2
    ],
    "momentum": 0.9,
    "weight_decay": 0.0,
    "best_target": "auc",
    "save_top_k": 3,
    "save_index": [
        0
    ]
}
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 256, 256]           9,408
       BatchNorm2d-2         [-1, 64, 256, 256]             128
              ReLU-3         [-1, 64, 256, 256]               0
         MaxPool2d-4         [-1, 64, 128, 128]               0
       BatchNorm2d-5         [-1, 64, 128, 128]             128
              ReLU-6         [-1, 64, 128, 128]               0
            Conv2d-7        [-1, 128, 128, 128]           8,192
       BatchNorm2d-8        [-1, 128, 128, 128]             256
              ReLU-9        [-1, 128, 128, 128]               0
           Conv2d-10         [-1, 32, 128, 128]          36,864
      BatchNorm2d-11         [-1, 96, 128, 128]             192
             ReLU-12         [-1, 96, 128, 128]               0
           Conv2d-13        [-1, 128, 128, 128]          12,288
      BatchNorm2d-14        [-1, 128, 128, 128]             256
             ReLU-15        [-1, 128, 128, 128]               0
           Conv2d-16         [-1, 32, 128, 128]          36,864
      BatchNorm2d-17        [-1, 128, 128, 128]             256
             ReLU-18        [-1, 128, 128, 128]               0
           Conv2d-19        [-1, 128, 128, 128]          16,384
      BatchNorm2d-20        [-1, 128, 128, 128]             256
             ReLU-21        [-1, 128, 128, 128]               0
           Conv2d-22         [-1, 32, 128, 128]          36,864
      BatchNorm2d-23        [-1, 160, 128, 128]             320
             ReLU-24        [-1, 160, 128, 128]               0
           Conv2d-25        [-1, 128, 128, 128]          20,480
      BatchNorm2d-26        [-1, 128, 128, 128]             256
             ReLU-27        [-1, 128, 128, 128]               0
           Conv2d-28         [-1, 32, 128, 128]          36,864
      BatchNorm2d-29        [-1, 192, 128, 128]             384
             ReLU-30        [-1, 192, 128, 128]               0
           Conv2d-31        [-1, 128, 128, 128]          24,576
      BatchNorm2d-32        [-1, 128, 128, 128]             256
             ReLU-33        [-1, 128, 128, 128]               0
           Conv2d-34         [-1, 32, 128, 128]          36,864
      BatchNorm2d-35        [-1, 224, 128, 128]             448
             ReLU-36        [-1, 224, 128, 128]               0
           Conv2d-37        [-1, 128, 128, 128]          28,672
      BatchNorm2d-38        [-1, 128, 128, 128]             256
             ReLU-39        [-1, 128, 128, 128]               0
           Conv2d-40         [-1, 32, 128, 128]          36,864
      BatchNorm2d-41        [-1, 256, 128, 128]             512
             ReLU-42        [-1, 256, 128, 128]               0
           Conv2d-43        [-1, 128, 128, 128]          32,768
        AvgPool2d-44          [-1, 128, 64, 64]               0
      BatchNorm2d-45          [-1, 128, 64, 64]             256
             ReLU-46          [-1, 128, 64, 64]               0
           Conv2d-47          [-1, 128, 64, 64]          16,384
      BatchNorm2d-48          [-1, 128, 64, 64]             256
             ReLU-49          [-1, 128, 64, 64]               0
           Conv2d-50           [-1, 32, 64, 64]          36,864
      BatchNorm2d-51          [-1, 160, 64, 64]             320
             ReLU-52          [-1, 160, 64, 64]               0
           Conv2d-53          [-1, 128, 64, 64]          20,480
      BatchNorm2d-54          [-1, 128, 64, 64]             256
             ReLU-55          [-1, 128, 64, 64]               0
           Conv2d-56           [-1, 32, 64, 64]          36,864
      BatchNorm2d-57          [-1, 192, 64, 64]             384
             ReLU-58          [-1, 192, 64, 64]               0
           Conv2d-59          [-1, 128, 64, 64]          24,576
      BatchNorm2d-60          [-1, 128, 64, 64]             256
             ReLU-61          [-1, 128, 64, 64]               0
           Conv2d-62           [-1, 32, 64, 64]          36,864
      BatchNorm2d-63          [-1, 224, 64, 64]             448
             ReLU-64          [-1, 224, 64, 64]               0
           Conv2d-65          [-1, 128, 64, 64]          28,672
      BatchNorm2d-66          [-1, 128, 64, 64]             256
             ReLU-67          [-1, 128, 64, 64]               0
           Conv2d-68           [-1, 32, 64, 64]          36,864
      BatchNorm2d-69          [-1, 256, 64, 64]             512
             ReLU-70          [-1, 256, 64, 64]               0
           Conv2d-71          [-1, 128, 64, 64]          32,768
      BatchNorm2d-72          [-1, 128, 64, 64]             256
             ReLU-73          [-1, 128, 64, 64]               0
           Conv2d-74           [-1, 32, 64, 64]          36,864
      BatchNorm2d-75          [-1, 288, 64, 64]             576
             ReLU-76          [-1, 288, 64, 64]               0
           Conv2d-77          [-1, 128, 64, 64]          36,864
      BatchNorm2d-78          [-1, 128, 64, 64]             256
             ReLU-79          [-1, 128, 64, 64]               0
           Conv2d-80           [-1, 32, 64, 64]          36,864
      BatchNorm2d-81          [-1, 320, 64, 64]             640
             ReLU-82          [-1, 320, 64, 64]               0
           Conv2d-83          [-1, 128, 64, 64]          40,960
      BatchNorm2d-84          [-1, 128, 64, 64]             256
             ReLU-85          [-1, 128, 64, 64]               0
           Conv2d-86           [-1, 32, 64, 64]          36,864
      BatchNorm2d-87          [-1, 352, 64, 64]             704
             ReLU-88          [-1, 352, 64, 64]               0
           Conv2d-89          [-1, 128, 64, 64]          45,056
      BatchNorm2d-90          [-1, 128, 64, 64]             256
             ReLU-91          [-1, 128, 64, 64]               0
           Conv2d-92           [-1, 32, 64, 64]          36,864
      BatchNorm2d-93          [-1, 384, 64, 64]             768
             ReLU-94          [-1, 384, 64, 64]               0
           Conv2d-95          [-1, 128, 64, 64]          49,152
      BatchNorm2d-96          [-1, 128, 64, 64]             256
             ReLU-97          [-1, 128, 64, 64]               0
           Conv2d-98           [-1, 32, 64, 64]          36,864
      BatchNorm2d-99          [-1, 416, 64, 64]             832
            ReLU-100          [-1, 416, 64, 64]               0
          Conv2d-101          [-1, 128, 64, 64]          53,248
     BatchNorm2d-102          [-1, 128, 64, 64]             256
            ReLU-103          [-1, 128, 64, 64]               0
          Conv2d-104           [-1, 32, 64, 64]          36,864
     BatchNorm2d-105          [-1, 448, 64, 64]             896
            ReLU-106          [-1, 448, 64, 64]               0
          Conv2d-107          [-1, 128, 64, 64]          57,344
     BatchNorm2d-108          [-1, 128, 64, 64]             256
            ReLU-109          [-1, 128, 64, 64]               0
          Conv2d-110           [-1, 32, 64, 64]          36,864
     BatchNorm2d-111          [-1, 480, 64, 64]             960
            ReLU-112          [-1, 480, 64, 64]               0
          Conv2d-113          [-1, 128, 64, 64]          61,440
     BatchNorm2d-114          [-1, 128, 64, 64]             256
            ReLU-115          [-1, 128, 64, 64]               0
          Conv2d-116           [-1, 32, 64, 64]          36,864
     BatchNorm2d-117          [-1, 512, 64, 64]           1,024
            ReLU-118          [-1, 512, 64, 64]               0
          Conv2d-119          [-1, 256, 64, 64]         131,072
       AvgPool2d-120          [-1, 256, 32, 32]               0
     BatchNorm2d-121          [-1, 256, 32, 32]             512
            ReLU-122          [-1, 256, 32, 32]               0
          Conv2d-123          [-1, 128, 32, 32]          32,768
     BatchNorm2d-124          [-1, 128, 32, 32]             256
            ReLU-125          [-1, 128, 32, 32]               0
          Conv2d-126           [-1, 32, 32, 32]          36,864
     BatchNorm2d-127          [-1, 288, 32, 32]             576
            ReLU-128          [-1, 288, 32, 32]               0
          Conv2d-129          [-1, 128, 32, 32]          36,864
     BatchNorm2d-130          [-1, 128, 32, 32]             256
            ReLU-131          [-1, 128, 32, 32]               0
          Conv2d-132           [-1, 32, 32, 32]          36,864
     BatchNorm2d-133          [-1, 320, 32, 32]             640
            ReLU-134          [-1, 320, 32, 32]               0
          Conv2d-135          [-1, 128, 32, 32]          40,960
     BatchNorm2d-136          [-1, 128, 32, 32]             256
            ReLU-137          [-1, 128, 32, 32]               0
          Conv2d-138           [-1, 32, 32, 32]          36,864
     BatchNorm2d-139          [-1, 352, 32, 32]             704
            ReLU-140          [-1, 352, 32, 32]               0
          Conv2d-141          [-1, 128, 32, 32]          45,056
     BatchNorm2d-142          [-1, 128, 32, 32]             256
            ReLU-143          [-1, 128, 32, 32]               0
          Conv2d-144           [-1, 32, 32, 32]          36,864
     BatchNorm2d-145          [-1, 384, 32, 32]             768
            ReLU-146          [-1, 384, 32, 32]               0
          Conv2d-147          [-1, 128, 32, 32]          49,152
     BatchNorm2d-148          [-1, 128, 32, 32]             256
            ReLU-149          [-1, 128, 32, 32]               0
          Conv2d-150           [-1, 32, 32, 32]          36,864
     BatchNorm2d-151          [-1, 416, 32, 32]             832
            ReLU-152          [-1, 416, 32, 32]               0
          Conv2d-153          [-1, 128, 32, 32]          53,248
     BatchNorm2d-154          [-1, 128, 32, 32]             256
            ReLU-155          [-1, 128, 32, 32]               0
          Conv2d-156           [-1, 32, 32, 32]          36,864
     BatchNorm2d-157          [-1, 448, 32, 32]             896
            ReLU-158          [-1, 448, 32, 32]               0
          Conv2d-159          [-1, 128, 32, 32]          57,344
     BatchNorm2d-160          [-1, 128, 32, 32]             256
            ReLU-161          [-1, 128, 32, 32]               0
          Conv2d-162           [-1, 32, 32, 32]          36,864
     BatchNorm2d-163          [-1, 480, 32, 32]             960
            ReLU-164          [-1, 480, 32, 32]               0
          Conv2d-165          [-1, 128, 32, 32]          61,440
     BatchNorm2d-166          [-1, 128, 32, 32]             256
            ReLU-167          [-1, 128, 32, 32]               0
          Conv2d-168           [-1, 32, 32, 32]          36,864
     BatchNorm2d-169          [-1, 512, 32, 32]           1,024
            ReLU-170          [-1, 512, 32, 32]               0
          Conv2d-171          [-1, 128, 32, 32]          65,536
     BatchNorm2d-172          [-1, 128, 32, 32]             256
            ReLU-173          [-1, 128, 32, 32]               0
          Conv2d-174           [-1, 32, 32, 32]          36,864
     BatchNorm2d-175          [-1, 544, 32, 32]           1,088
            ReLU-176          [-1, 544, 32, 32]               0
          Conv2d-177          [-1, 128, 32, 32]          69,632
     BatchNorm2d-178          [-1, 128, 32, 32]             256
            ReLU-179          [-1, 128, 32, 32]               0
          Conv2d-180           [-1, 32, 32, 32]          36,864
     BatchNorm2d-181          [-1, 576, 32, 32]           1,152
            ReLU-182          [-1, 576, 32, 32]               0
          Conv2d-183          [-1, 128, 32, 32]          73,728
     BatchNorm2d-184          [-1, 128, 32, 32]             256
            ReLU-185          [-1, 128, 32, 32]               0
          Conv2d-186           [-1, 32, 32, 32]          36,864
     BatchNorm2d-187          [-1, 608, 32, 32]           1,216
            ReLU-188          [-1, 608, 32, 32]               0
          Conv2d-189          [-1, 128, 32, 32]          77,824
     BatchNorm2d-190          [-1, 128, 32, 32]             256
            ReLU-191          [-1, 128, 32, 32]               0
          Conv2d-192           [-1, 32, 32, 32]          36,864
     BatchNorm2d-193          [-1, 640, 32, 32]           1,280
            ReLU-194          [-1, 640, 32, 32]               0
          Conv2d-195          [-1, 128, 32, 32]          81,920
     BatchNorm2d-196          [-1, 128, 32, 32]             256
            ReLU-197          [-1, 128, 32, 32]               0
          Conv2d-198           [-1, 32, 32, 32]          36,864
     BatchNorm2d-199          [-1, 672, 32, 32]           1,344
            ReLU-200          [-1, 672, 32, 32]               0
          Conv2d-201          [-1, 128, 32, 32]          86,016
     BatchNorm2d-202          [-1, 128, 32, 32]             256
            ReLU-203          [-1, 128, 32, 32]               0
          Conv2d-204           [-1, 32, 32, 32]          36,864
     BatchNorm2d-205          [-1, 704, 32, 32]           1,408
            ReLU-206          [-1, 704, 32, 32]               0
          Conv2d-207          [-1, 128, 32, 32]          90,112
     BatchNorm2d-208          [-1, 128, 32, 32]             256
            ReLU-209          [-1, 128, 32, 32]               0
          Conv2d-210           [-1, 32, 32, 32]          36,864
     BatchNorm2d-211          [-1, 736, 32, 32]           1,472
            ReLU-212          [-1, 736, 32, 32]               0
          Conv2d-213          [-1, 128, 32, 32]          94,208
     BatchNorm2d-214          [-1, 128, 32, 32]             256
            ReLU-215          [-1, 128, 32, 32]               0
          Conv2d-216           [-1, 32, 32, 32]          36,864
     BatchNorm2d-217          [-1, 768, 32, 32]           1,536
            ReLU-218          [-1, 768, 32, 32]               0
          Conv2d-219          [-1, 128, 32, 32]          98,304
     BatchNorm2d-220          [-1, 128, 32, 32]             256
            ReLU-221          [-1, 128, 32, 32]               0
          Conv2d-222           [-1, 32, 32, 32]          36,864
     BatchNorm2d-223          [-1, 800, 32, 32]           1,600
            ReLU-224          [-1, 800, 32, 32]               0
          Conv2d-225          [-1, 128, 32, 32]         102,400
     BatchNorm2d-226          [-1, 128, 32, 32]             256
            ReLU-227          [-1, 128, 32, 32]               0
          Conv2d-228           [-1, 32, 32, 32]          36,864
     BatchNorm2d-229          [-1, 832, 32, 32]           1,664
            ReLU-230          [-1, 832, 32, 32]               0
          Conv2d-231          [-1, 128, 32, 32]         106,496
     BatchNorm2d-232          [-1, 128, 32, 32]             256
            ReLU-233          [-1, 128, 32, 32]               0
          Conv2d-234           [-1, 32, 32, 32]          36,864
     BatchNorm2d-235          [-1, 864, 32, 32]           1,728
            ReLU-236          [-1, 864, 32, 32]               0
          Conv2d-237          [-1, 128, 32, 32]         110,592
     BatchNorm2d-238          [-1, 128, 32, 32]             256
            ReLU-239          [-1, 128, 32, 32]               0
          Conv2d-240           [-1, 32, 32, 32]          36,864
     BatchNorm2d-241          [-1, 896, 32, 32]           1,792
            ReLU-242          [-1, 896, 32, 32]               0
          Conv2d-243          [-1, 128, 32, 32]         114,688
     BatchNorm2d-244          [-1, 128, 32, 32]             256
            ReLU-245          [-1, 128, 32, 32]               0
          Conv2d-246           [-1, 32, 32, 32]          36,864
     BatchNorm2d-247          [-1, 928, 32, 32]           1,856
            ReLU-248          [-1, 928, 32, 32]               0
          Conv2d-249          [-1, 128, 32, 32]         118,784
     BatchNorm2d-250          [-1, 128, 32, 32]             256
            ReLU-251          [-1, 128, 32, 32]               0
          Conv2d-252           [-1, 32, 32, 32]          36,864
     BatchNorm2d-253          [-1, 960, 32, 32]           1,920
            ReLU-254          [-1, 960, 32, 32]               0
          Conv2d-255          [-1, 128, 32, 32]         122,880
     BatchNorm2d-256          [-1, 128, 32, 32]             256
            ReLU-257          [-1, 128, 32, 32]               0
          Conv2d-258           [-1, 32, 32, 32]          36,864
     BatchNorm2d-259          [-1, 992, 32, 32]           1,984
            ReLU-260          [-1, 992, 32, 32]               0
          Conv2d-261          [-1, 128, 32, 32]         126,976
     BatchNorm2d-262          [-1, 128, 32, 32]             256
            ReLU-263          [-1, 128, 32, 32]               0
          Conv2d-264           [-1, 32, 32, 32]          36,864
     BatchNorm2d-265         [-1, 1024, 32, 32]           2,048
            ReLU-266         [-1, 1024, 32, 32]               0
          Conv2d-267          [-1, 512, 32, 32]         524,288
       AvgPool2d-268          [-1, 512, 16, 16]               0
     BatchNorm2d-269          [-1, 512, 16, 16]           1,024
            ReLU-270          [-1, 512, 16, 16]               0
          Conv2d-271          [-1, 128, 16, 16]          65,536
     BatchNorm2d-272          [-1, 128, 16, 16]             256
            ReLU-273          [-1, 128, 16, 16]               0
          Conv2d-274           [-1, 32, 16, 16]          36,864
     BatchNorm2d-275          [-1, 544, 16, 16]           1,088
            ReLU-276          [-1, 544, 16, 16]               0
          Conv2d-277          [-1, 128, 16, 16]          69,632
     BatchNorm2d-278          [-1, 128, 16, 16]             256
            ReLU-279          [-1, 128, 16, 16]               0
          Conv2d-280           [-1, 32, 16, 16]          36,864
     BatchNorm2d-281          [-1, 576, 16, 16]           1,152
            ReLU-282          [-1, 576, 16, 16]               0
          Conv2d-283          [-1, 128, 16, 16]          73,728
     BatchNorm2d-284          [-1, 128, 16, 16]             256
            ReLU-285          [-1, 128, 16, 16]               0
          Conv2d-286           [-1, 32, 16, 16]          36,864
     BatchNorm2d-287          [-1, 608, 16, 16]           1,216
            ReLU-288          [-1, 608, 16, 16]               0
          Conv2d-289          [-1, 128, 16, 16]          77,824
     BatchNorm2d-290          [-1, 128, 16, 16]             256
            ReLU-291          [-1, 128, 16, 16]               0
          Conv2d-292           [-1, 32, 16, 16]          36,864
     BatchNorm2d-293          [-1, 640, 16, 16]           1,280
            ReLU-294          [-1, 640, 16, 16]               0
          Conv2d-295          [-1, 128, 16, 16]          81,920
     BatchNorm2d-296          [-1, 128, 16, 16]             256
            ReLU-297          [-1, 128, 16, 16]               0
          Conv2d-298           [-1, 32, 16, 16]          36,864
     BatchNorm2d-299          [-1, 672, 16, 16]           1,344
            ReLU-300          [-1, 672, 16, 16]               0
          Conv2d-301          [-1, 128, 16, 16]          86,016
     BatchNorm2d-302          [-1, 128, 16, 16]             256
            ReLU-303          [-1, 128, 16, 16]               0
          Conv2d-304           [-1, 32, 16, 16]          36,864
     BatchNorm2d-305          [-1, 704, 16, 16]           1,408
            ReLU-306          [-1, 704, 16, 16]               0
          Conv2d-307          [-1, 128, 16, 16]          90,112
     BatchNorm2d-308          [-1, 128, 16, 16]             256
            ReLU-309          [-1, 128, 16, 16]               0
          Conv2d-310           [-1, 32, 16, 16]          36,864
     BatchNorm2d-311          [-1, 736, 16, 16]           1,472
            ReLU-312          [-1, 736, 16, 16]               0
          Conv2d-313          [-1, 128, 16, 16]          94,208
     BatchNorm2d-314          [-1, 128, 16, 16]             256
            ReLU-315          [-1, 128, 16, 16]               0
          Conv2d-316           [-1, 32, 16, 16]          36,864
     BatchNorm2d-317          [-1, 768, 16, 16]           1,536
            ReLU-318          [-1, 768, 16, 16]               0
          Conv2d-319          [-1, 128, 16, 16]          98,304
     BatchNorm2d-320          [-1, 128, 16, 16]             256
            ReLU-321          [-1, 128, 16, 16]               0
          Conv2d-322           [-1, 32, 16, 16]          36,864
     BatchNorm2d-323          [-1, 800, 16, 16]           1,600
            ReLU-324          [-1, 800, 16, 16]               0
          Conv2d-325          [-1, 128, 16, 16]         102,400
     BatchNorm2d-326          [-1, 128, 16, 16]             256
            ReLU-327          [-1, 128, 16, 16]               0
          Conv2d-328           [-1, 32, 16, 16]          36,864
     BatchNorm2d-329          [-1, 832, 16, 16]           1,664
            ReLU-330          [-1, 832, 16, 16]               0
          Conv2d-331          [-1, 128, 16, 16]         106,496
     BatchNorm2d-332          [-1, 128, 16, 16]             256
            ReLU-333          [-1, 128, 16, 16]               0
          Conv2d-334           [-1, 32, 16, 16]          36,864
     BatchNorm2d-335          [-1, 864, 16, 16]           1,728
            ReLU-336          [-1, 864, 16, 16]               0
          Conv2d-337          [-1, 128, 16, 16]         110,592
     BatchNorm2d-338          [-1, 128, 16, 16]             256
            ReLU-339          [-1, 128, 16, 16]               0
          Conv2d-340           [-1, 32, 16, 16]          36,864
     BatchNorm2d-341          [-1, 896, 16, 16]           1,792
            ReLU-342          [-1, 896, 16, 16]               0
          Conv2d-343          [-1, 128, 16, 16]         114,688
     BatchNorm2d-344          [-1, 128, 16, 16]             256
            ReLU-345          [-1, 128, 16, 16]               0
          Conv2d-346           [-1, 32, 16, 16]          36,864
     BatchNorm2d-347          [-1, 928, 16, 16]           1,856
            ReLU-348          [-1, 928, 16, 16]               0
          Conv2d-349          [-1, 128, 16, 16]         118,784
     BatchNorm2d-350          [-1, 128, 16, 16]             256
            ReLU-351          [-1, 128, 16, 16]               0
          Conv2d-352           [-1, 32, 16, 16]          36,864
     BatchNorm2d-353          [-1, 960, 16, 16]           1,920
            ReLU-354          [-1, 960, 16, 16]               0
          Conv2d-355          [-1, 128, 16, 16]         122,880
     BatchNorm2d-356          [-1, 128, 16, 16]             256
            ReLU-357          [-1, 128, 16, 16]               0
          Conv2d-358           [-1, 32, 16, 16]          36,864
     BatchNorm2d-359          [-1, 992, 16, 16]           1,984
            ReLU-360          [-1, 992, 16, 16]               0
          Conv2d-361          [-1, 128, 16, 16]         126,976
     BatchNorm2d-362          [-1, 128, 16, 16]             256
            ReLU-363          [-1, 128, 16, 16]               0
          Conv2d-364           [-1, 32, 16, 16]          36,864
     BatchNorm2d-365         [-1, 1024, 16, 16]           2,048
        DenseNet-366         [-1, 1024, 16, 16]               0
AdaptiveAvgPool2d-367           [-1, 1024, 1, 1]               0
          Conv2d-368           [-1, 1024, 1, 1]       1,049,600
     BatchNorm2d-369           [-1, 1024, 1, 1]           2,048
            ReLU-370           [-1, 1024, 1, 1]               0
  Conv2dNormRelu-371           [-1, 1024, 1, 1]               0
          Conv2d-372         [-1, 1024, 16, 16]       1,049,600
     BatchNorm2d-373         [-1, 1024, 16, 16]           2,048
            ReLU-374         [-1, 1024, 16, 16]               0
  Conv2dNormRelu-375         [-1, 1024, 16, 16]               0
          Conv2d-376              [-1, 1, 8, 8]          50,177
     BatchNorm2d-377              [-1, 1, 8, 8]               2
            ReLU-378              [-1, 1, 8, 8]               0
  Conv2dNormRelu-379              [-1, 1, 8, 8]               0
          Conv2d-380              [-1, 1, 4, 4]              26
     BatchNorm2d-381              [-1, 1, 4, 4]               2
            ReLU-382              [-1, 1, 4, 4]               0
  Conv2dNormRelu-383              [-1, 1, 4, 4]               0
          Conv2d-384              [-1, 1, 2, 2]              10
     BatchNorm2d-385              [-1, 1, 2, 2]               2
            ReLU-386              [-1, 1, 2, 2]               0
  Conv2dNormRelu-387              [-1, 1, 2, 2]               0
          Conv2d-388              [-1, 1, 2, 2]              10
     BatchNorm2d-389              [-1, 1, 2, 2]               2
            ReLU-390              [-1, 1, 2, 2]               0
  Conv2dNormRelu-391              [-1, 1, 2, 2]               0
          Conv2d-392              [-1, 1, 4, 4]              26
     BatchNorm2d-393              [-1, 1, 4, 4]               2
            ReLU-394              [-1, 1, 4, 4]               0
  Conv2dNormRelu-395              [-1, 1, 4, 4]               0
          Conv2d-396              [-1, 1, 8, 8]              50
     BatchNorm2d-397              [-1, 1, 8, 8]               2
            ReLU-398              [-1, 1, 8, 8]               0
  Conv2dNormRelu-399              [-1, 1, 8, 8]               0
       FPAModule-400         [-1, 1024, 16, 16]               0
    AttentionMap-401         [-1, 1024, 16, 16]               0
          Conv2d-402            [-1, 1, 16, 16]           1,025
        PcamPool-403           [-1, 1024, 1, 1]               0
      GlobalPool-404           [-1, 1024, 1, 1]               0
     BatchNorm2d-405           [-1, 1024, 1, 1]           2,048
          Conv2d-406              [-1, 1, 1, 1]           1,025
        PcamPool-407           [-1, 1024, 1, 1]               0
      GlobalPool-408           [-1, 1024, 1, 1]               0
          Linear-409                    [-1, 1]           1,025
================================================================
Total params: 9,112,586
Trainable params: 9,112,586
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 3.00
Forward/backward pass size (MB): 1551.09
Params size (MB): 34.76
Estimated Total Size (MB): 1588.85
----------------------------------------------------------------
INFO:root:2024-04-19 07:36:06, Train, Epoch : 1, Step : 10, Loss : 0.72568, Acc : 0.550, Sensitive_Loss : 1.14776, Sensitive_Acc : 10.200, Run Time : 21.77 sec
INFO:root:2024-04-19 07:36:23, Train, Epoch : 1, Step : 20, Loss : 0.64726, Acc : 0.619, Sensitive_Loss : 1.10377, Sensitive_Acc : 21.200, Run Time : 16.96 sec
INFO:root:2024-04-19 07:36:40, Train, Epoch : 1, Step : 30, Loss : 0.60595, Acc : 0.631, Sensitive_Loss : 1.01321, Sensitive_Acc : 15.000, Run Time : 16.90 sec
INFO:root:2024-04-19 07:36:57, Train, Epoch : 1, Step : 40, Loss : 0.67475, Acc : 0.619, Sensitive_Loss : 1.05721, Sensitive_Acc : 21.000, Run Time : 17.41 sec
INFO:root:2024-04-19 07:37:15, Train, Epoch : 1, Step : 50, Loss : 0.63147, Acc : 0.659, Sensitive_Loss : 0.96680, Sensitive_Acc : 17.900, Run Time : 17.93 sec
INFO:root:2024-04-19 07:37:32, Train, Epoch : 1, Step : 60, Loss : 0.59265, Acc : 0.688, Sensitive_Loss : 0.94178, Sensitive_Acc : 15.600, Run Time : 16.88 sec
INFO:root:2024-04-19 07:37:51, Train, Epoch : 1, Step : 70, Loss : 0.60701, Acc : 0.675, Sensitive_Loss : 0.88045, Sensitive_Acc : 14.700, Run Time : 19.54 sec
INFO:root:2024-04-19 07:38:08, Train, Epoch : 1, Step : 80, Loss : 0.67811, Acc : 0.641, Sensitive_Loss : 0.83582, Sensitive_Acc : 24.400, Run Time : 16.83 sec
INFO:root:2024-04-19 07:38:25, Train, Epoch : 1, Step : 90, Loss : 0.70334, Acc : 0.637, Sensitive_Loss : 0.87707, Sensitive_Acc : 21.900, Run Time : 16.55 sec
INFO:root:2024-04-19 07:38:42, Train, Epoch : 1, Step : 100, Loss : 0.66118, Acc : 0.656, Sensitive_Loss : 0.80682, Sensitive_Acc : 20.500, Run Time : 17.42 sec
INFO:root:2024-04-19 07:42:35, Dev, Step : 100, Loss : 0.68265, Acc : 0.649, Auc : 0.722, Sensitive_Loss : 0.82310, Sensitive_Acc : 14.474, Sensitive_Auc : 0.837, Mean auc: 0.722, Run Time : 232.48 sec
INFO:root:2024-04-19 07:42:35, Best, Step : 100, Loss : 0.68265, Acc : 0.649, Auc : 0.722, Sensitive_Loss : 0.82310, Sensitive_Acc : 14.474, Sensitive_Auc : 0.837, Best Auc : 0.722
INFO:root:2024-04-19 07:42:49, Train, Epoch : 1, Step : 110, Loss : 0.61397, Acc : 0.609, Sensitive_Loss : 0.76430, Sensitive_Acc : 21.800, Run Time : 246.68 sec
INFO:root:2024-04-19 07:43:05, Train, Epoch : 1, Step : 120, Loss : 0.63542, Acc : 0.691, Sensitive_Loss : 0.79005, Sensitive_Acc : 14.000, Run Time : 15.96 sec
INFO:root:2024-04-19 07:43:23, Train, Epoch : 1, Step : 130, Loss : 0.61867, Acc : 0.688, Sensitive_Loss : 0.77763, Sensitive_Acc : 15.700, Run Time : 18.12 sec
INFO:root:2024-04-19 07:43:40, Train, Epoch : 1, Step : 140, Loss : 0.63397, Acc : 0.675, Sensitive_Loss : 0.75439, Sensitive_Acc : 21.100, Run Time : 17.19 sec
INFO:root:2024-04-19 07:43:57, Train, Epoch : 1, Step : 150, Loss : 0.69420, Acc : 0.688, Sensitive_Loss : 0.83573, Sensitive_Acc : 17.800, Run Time : 17.22 sec
INFO:root:2024-04-19 07:44:16, Train, Epoch : 1, Step : 160, Loss : 0.59403, Acc : 0.666, Sensitive_Loss : 0.69438, Sensitive_Acc : 23.200, Run Time : 18.41 sec
INFO:root:2024-04-19 07:44:33, Train, Epoch : 1, Step : 170, Loss : 0.61670, Acc : 0.681, Sensitive_Loss : 0.64316, Sensitive_Acc : 18.800, Run Time : 17.41 sec
INFO:root:2024-04-19 07:44:51, Train, Epoch : 1, Step : 180, Loss : 0.53482, Acc : 0.719, Sensitive_Loss : 0.64961, Sensitive_Acc : 18.500, Run Time : 18.27 sec
INFO:root:2024-04-19 07:45:09, Train, Epoch : 1, Step : 190, Loss : 0.60280, Acc : 0.659, Sensitive_Loss : 0.65267, Sensitive_Acc : 18.200, Run Time : 17.09 sec
INFO:root:2024-04-19 07:45:26, Train, Epoch : 1, Step : 200, Loss : 0.63563, Acc : 0.703, Sensitive_Loss : 0.71888, Sensitive_Acc : 18.500, Run Time : 17.79 sec
INFO:root:2024-04-19 07:49:17, Dev, Step : 200, Loss : 0.61385, Acc : 0.704, Auc : 0.780, Sensitive_Loss : 0.67039, Sensitive_Acc : 16.504, Sensitive_Auc : 0.905, Mean auc: 0.780, Run Time : 230.17 sec
INFO:root:2024-04-19 07:49:17, Best, Step : 200, Loss : 0.61385, Acc : 0.704, Auc : 0.780, Sensitive_Loss : 0.67039, Sensitive_Acc : 16.504, Sensitive_Auc : 0.905, Best Auc : 0.780
INFO:root:2024-04-19 07:49:30, Train, Epoch : 1, Step : 210, Loss : 0.60005, Acc : 0.703, Sensitive_Loss : 0.64679, Sensitive_Acc : 19.500, Run Time : 243.36 sec
INFO:root:2024-04-19 07:49:49, Train, Epoch : 1, Step : 220, Loss : 0.60598, Acc : 0.694, Sensitive_Loss : 0.51413, Sensitive_Acc : 19.500, Run Time : 18.93 sec
INFO:root:2024-04-19 07:50:05, Train, Epoch : 1, Step : 230, Loss : 0.68841, Acc : 0.675, Sensitive_Loss : 0.61793, Sensitive_Acc : 16.700, Run Time : 16.47 sec
INFO:root:2024-04-19 07:50:24, Train, Epoch : 1, Step : 240, Loss : 0.63944, Acc : 0.666, Sensitive_Loss : 0.59683, Sensitive_Acc : 22.500, Run Time : 18.71 sec
INFO:root:2024-04-19 07:50:40, Train, Epoch : 1, Step : 250, Loss : 0.64031, Acc : 0.681, Sensitive_Loss : 0.49532, Sensitive_Acc : 18.900, Run Time : 16.11 sec
INFO:root:2024-04-19 07:50:58, Train, Epoch : 1, Step : 260, Loss : 0.48692, Acc : 0.728, Sensitive_Loss : 0.46426, Sensitive_Acc : 16.900, Run Time : 17.95 sec
INFO:root:2024-04-19 07:51:15, Train, Epoch : 1, Step : 270, Loss : 0.61355, Acc : 0.672, Sensitive_Loss : 0.50959, Sensitive_Acc : 19.300, Run Time : 17.44 sec
INFO:root:2024-04-19 07:51:33, Train, Epoch : 1, Step : 280, Loss : 0.56294, Acc : 0.706, Sensitive_Loss : 0.60689, Sensitive_Acc : 24.100, Run Time : 17.14 sec
INFO:root:2024-04-19 07:51:50, Train, Epoch : 1, Step : 290, Loss : 0.65375, Acc : 0.659, Sensitive_Loss : 0.49055, Sensitive_Acc : 24.000, Run Time : 17.92 sec
INFO:root:2024-04-19 07:52:08, Train, Epoch : 1, Step : 300, Loss : 0.61165, Acc : 0.706, Sensitive_Loss : 0.51116, Sensitive_Acc : 23.400, Run Time : 17.31 sec
INFO:root:2024-04-19 07:55:57, Dev, Step : 300, Loss : 0.62320, Acc : 0.681, Auc : 0.756, Sensitive_Loss : 0.62335, Sensitive_Acc : 16.789, Sensitive_Auc : 0.914, Mean auc: 0.756, Run Time : 228.89 sec
INFO:root:2024-04-19 07:56:09, Train, Epoch : 1, Step : 310, Loss : 0.65936, Acc : 0.694, Sensitive_Loss : 0.62350, Sensitive_Acc : 15.900, Run Time : 241.68 sec
INFO:root:2024-04-19 07:56:28, Train, Epoch : 1, Step : 320, Loss : 0.66669, Acc : 0.688, Sensitive_Loss : 0.50975, Sensitive_Acc : 20.700, Run Time : 18.59 sec
INFO:root:2024-04-19 07:56:45, Train, Epoch : 1, Step : 330, Loss : 0.63421, Acc : 0.653, Sensitive_Loss : 0.46771, Sensitive_Acc : 26.100, Run Time : 16.96 sec
INFO:root:2024-04-19 07:57:04, Train, Epoch : 1, Step : 340, Loss : 0.59454, Acc : 0.734, Sensitive_Loss : 0.47329, Sensitive_Acc : 23.700, Run Time : 18.59 sec
INFO:root:2024-04-19 07:57:22, Train, Epoch : 1, Step : 350, Loss : 0.61837, Acc : 0.697, Sensitive_Loss : 0.47585, Sensitive_Acc : 20.800, Run Time : 18.37 sec
INFO:root:2024-04-19 07:57:39, Train, Epoch : 1, Step : 360, Loss : 0.63172, Acc : 0.650, Sensitive_Loss : 0.45078, Sensitive_Acc : 16.000, Run Time : 16.65 sec
INFO:root:2024-04-19 07:57:57, Train, Epoch : 1, Step : 370, Loss : 0.58533, Acc : 0.719, Sensitive_Loss : 0.43215, Sensitive_Acc : 19.500, Run Time : 18.84 sec
INFO:root:2024-04-19 07:58:13, Train, Epoch : 1, Step : 380, Loss : 0.57155, Acc : 0.691, Sensitive_Loss : 0.37462, Sensitive_Acc : 19.400, Run Time : 15.64 sec
INFO:root:2024-04-19 07:58:32, Train, Epoch : 1, Step : 390, Loss : 0.64290, Acc : 0.700, Sensitive_Loss : 0.41769, Sensitive_Acc : 12.400, Run Time : 18.98 sec
INFO:root:2024-04-19 07:58:48, Train, Epoch : 1, Step : 400, Loss : 0.56546, Acc : 0.706, Sensitive_Loss : 0.38002, Sensitive_Acc : 19.200, Run Time : 16.33 sec
INFO:root:2024-04-19 08:02:38, Dev, Step : 400, Loss : 0.65926, Acc : 0.676, Auc : 0.804, Sensitive_Loss : 0.48252, Sensitive_Acc : 18.579, Sensitive_Auc : 0.949, Mean auc: 0.804, Run Time : 229.96 sec
INFO:root:2024-04-19 08:02:39, Best, Step : 400, Loss : 0.65926, Acc : 0.676, Auc : 0.804, Sensitive_Loss : 0.48252, Sensitive_Acc : 18.579, Sensitive_Auc : 0.949, Best Auc : 0.804
INFO:root:2024-04-19 08:02:51, Train, Epoch : 1, Step : 410, Loss : 0.52393, Acc : 0.725, Sensitive_Loss : 0.35582, Sensitive_Acc : 22.600, Run Time : 242.86 sec
INFO:root:2024-04-19 08:03:11, Train, Epoch : 1, Step : 420, Loss : 0.54948, Acc : 0.731, Sensitive_Loss : 0.34191, Sensitive_Acc : 17.800, Run Time : 19.78 sec
INFO:root:2024-04-19 08:03:29, Train, Epoch : 1, Step : 430, Loss : 0.56643, Acc : 0.678, Sensitive_Loss : 0.46225, Sensitive_Acc : 21.500, Run Time : 17.98 sec
INFO:root:2024-04-19 08:03:47, Train, Epoch : 1, Step : 440, Loss : 0.47949, Acc : 0.728, Sensitive_Loss : 0.41338, Sensitive_Acc : 24.800, Run Time : 17.60 sec
INFO:root:2024-04-19 08:04:05, Train, Epoch : 1, Step : 450, Loss : 0.63221, Acc : 0.719, Sensitive_Loss : 0.36103, Sensitive_Acc : 22.700, Run Time : 17.86 sec
INFO:root:2024-04-19 08:04:22, Train, Epoch : 1, Step : 460, Loss : 0.64830, Acc : 0.694, Sensitive_Loss : 0.35962, Sensitive_Acc : 14.600, Run Time : 17.41 sec
INFO:root:2024-04-19 08:04:38, Train, Epoch : 1, Step : 470, Loss : 0.60887, Acc : 0.681, Sensitive_Loss : 0.31477, Sensitive_Acc : 21.800, Run Time : 16.13 sec
INFO:root:2024-04-19 08:04:57, Train, Epoch : 1, Step : 480, Loss : 0.58392, Acc : 0.725, Sensitive_Loss : 0.39733, Sensitive_Acc : 18.700, Run Time : 18.71 sec
INFO:root:2024-04-19 08:05:14, Train, Epoch : 1, Step : 490, Loss : 0.67385, Acc : 0.678, Sensitive_Loss : 0.29958, Sensitive_Acc : 23.400, Run Time : 17.52 sec
INFO:root:2024-04-19 08:05:31, Train, Epoch : 1, Step : 500, Loss : 0.52385, Acc : 0.722, Sensitive_Loss : 0.41991, Sensitive_Acc : 26.800, Run Time : 16.54 sec
INFO:root:2024-04-19 08:09:22, Dev, Step : 500, Loss : 0.59394, Acc : 0.708, Auc : 0.792, Sensitive_Loss : 0.66984, Sensitive_Acc : 18.278, Sensitive_Auc : 0.950, Mean auc: 0.792, Run Time : 230.85 sec
INFO:root:2024-04-19 08:09:36, Train, Epoch : 1, Step : 510, Loss : 0.64748, Acc : 0.713, Sensitive_Loss : 0.33977, Sensitive_Acc : 18.800, Run Time : 244.88 sec
INFO:root:2024-04-19 08:09:52, Train, Epoch : 1, Step : 520, Loss : 0.58735, Acc : 0.728, Sensitive_Loss : 0.38335, Sensitive_Acc : 22.900, Run Time : 16.59 sec
INFO:root:2024-04-19 08:10:09, Train, Epoch : 1, Step : 530, Loss : 0.59814, Acc : 0.738, Sensitive_Loss : 0.29341, Sensitive_Acc : 16.500, Run Time : 17.06 sec
INFO:root:2024-04-19 08:10:26, Train, Epoch : 1, Step : 540, Loss : 0.57452, Acc : 0.738, Sensitive_Loss : 0.29811, Sensitive_Acc : 19.100, Run Time : 16.32 sec
INFO:root:2024-04-19 08:10:44, Train, Epoch : 1, Step : 550, Loss : 0.61935, Acc : 0.684, Sensitive_Loss : 0.30622, Sensitive_Acc : 20.800, Run Time : 18.01 sec
INFO:root:2024-04-19 08:11:01, Train, Epoch : 1, Step : 560, Loss : 0.52248, Acc : 0.741, Sensitive_Loss : 0.30872, Sensitive_Acc : 21.400, Run Time : 17.01 sec
INFO:root:2024-04-19 08:11:19, Train, Epoch : 1, Step : 570, Loss : 0.58305, Acc : 0.706, Sensitive_Loss : 0.30854, Sensitive_Acc : 20.200, Run Time : 18.59 sec
INFO:root:2024-04-19 08:11:36, Train, Epoch : 1, Step : 580, Loss : 0.47874, Acc : 0.759, Sensitive_Loss : 0.41409, Sensitive_Acc : 18.000, Run Time : 16.95 sec
INFO:root:2024-04-19 08:11:55, Train, Epoch : 1, Step : 590, Loss : 0.47486, Acc : 0.738, Sensitive_Loss : 0.36365, Sensitive_Acc : 24.900, Run Time : 18.94 sec
INFO:root:2024-04-19 08:12:13, Train, Epoch : 1, Step : 600, Loss : 0.55946, Acc : 0.716, Sensitive_Loss : 0.28644, Sensitive_Acc : 19.800, Run Time : 17.28 sec
INFO:root:2024-04-19 08:16:03, Dev, Step : 600, Loss : 0.68106, Acc : 0.692, Auc : 0.823, Sensitive_Loss : 0.31016, Sensitive_Acc : 21.045, Sensitive_Auc : 0.965, Mean auc: 0.823, Run Time : 230.85 sec
INFO:root:2024-04-19 08:16:04, Best, Step : 600, Loss : 0.68106, Acc : 0.692, Auc : 0.823, Sensitive_Loss : 0.31016, Sensitive_Acc : 21.045, Sensitive_Auc : 0.965, Best Auc : 0.823
INFO:root:2024-04-19 08:16:17, Train, Epoch : 1, Step : 610, Loss : 0.55485, Acc : 0.750, Sensitive_Loss : 0.36329, Sensitive_Acc : 22.900, Run Time : 244.95 sec
INFO:root:2024-04-19 08:16:35, Train, Epoch : 1, Step : 620, Loss : 0.53705, Acc : 0.728, Sensitive_Loss : 0.30354, Sensitive_Acc : 17.500, Run Time : 17.16 sec
INFO:root:2024-04-19 08:16:53, Train, Epoch : 1, Step : 630, Loss : 0.47396, Acc : 0.738, Sensitive_Loss : 0.28321, Sensitive_Acc : 22.200, Run Time : 18.02 sec
INFO:root:2024-04-19 08:21:16
INFO:root:y_pred: [0.29687935 0.00794352 0.29247528 ... 0.06046569 0.07351387 0.07492372]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [1.62508804e-02 3.08685936e-02 2.95096952e-02 9.58502829e-01
 4.37053442e-02 1.03988601e-02 2.06114519e-02 1.15265092e-02
 3.70573938e-01 9.93817985e-01 1.76194217e-02 7.55790947e-03
 2.33785212e-01 9.16905049e-03 9.99631643e-01 1.06469635e-02
 1.48190424e-01 9.99925375e-01 9.84454393e-01 1.32841870e-01
 4.74386901e-01 2.06571468e-03 6.16064250e-01 5.49829658e-03
 3.87112319e-01 6.58163965e-01 3.39175276e-02 2.91876663e-02
 2.25919159e-03 4.66272905e-02 1.21622704e-01 9.98241186e-01
 8.99242580e-01 8.30498755e-01 1.40110284e-01 2.79486855e-03
 2.94200401e-03 5.08124113e-01 2.70841241e-01 3.52063537e-01
 5.96711338e-01 8.39994609e-01 1.34243891e-01 1.55442173e-03
 9.52314913e-01 7.82939076e-01 5.80342114e-01 3.33620369e-01
 2.43246943e-01 9.95911002e-01 9.82841730e-01 9.97729599e-01
 9.79597032e-01 3.24792974e-02 6.59850419e-01 4.23996925e-01
 3.84090006e-01 7.81614035e-02 9.80155647e-01 4.17231815e-03
 2.12828312e-02 2.61721537e-02 1.97292422e-03 5.32270689e-03
 9.96809423e-01 5.34564614e-01 1.67267043e-02 8.75121355e-02
 1.51199847e-01 9.61773753e-01 9.98352766e-01 9.94889617e-01
 1.07016288e-01 8.01804900e-01 2.78462991e-02 9.70130622e-01
 1.09724496e-02 9.34002746e-04 3.97231895e-03 1.02897584e-02
 8.35614383e-01 1.88450776e-02 9.97484326e-01 9.69980657e-01
 2.54351981e-02 4.73422483e-02 3.34224920e-03 4.35471768e-03
 3.98384094e-01 1.80303212e-02 1.16918525e-02 8.75537336e-01
 3.31202615e-03 8.70654732e-03 4.54057567e-03 1.02948219e-01
 3.18377418e-03 9.74064991e-02 2.10359767e-02 4.66208579e-03
 1.66596800e-01 3.34753931e-01 3.82905841e-01 1.07459933e-01
 1.34506613e-01 3.84638947e-03 1.77890852e-01 1.70520514e-01
 3.48696202e-01 7.35787153e-01 4.06608451e-03 9.99234557e-01
 9.99121487e-01 6.30155046e-05 3.85831930e-02 4.63395417e-01
 7.56044835e-02 4.08686418e-03 1.98960125e-01 1.92868710e-02
 1.60497148e-02 7.16924435e-03 9.15960893e-02 3.47920600e-03
 4.43109237e-02 9.60979342e-01 7.03844614e-03 9.89827633e-01
 5.06082177e-03 8.91246080e-01 8.99674818e-02 1.98197827e-01
 1.12745538e-03]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-19 08:21:16, Dev, Step : 634, Loss : 0.58876, Acc : 0.727, Auc : 0.818, Sensitive_Loss : 0.37798, Sensitive_Acc : 19.947, Sensitive_Auc : 0.969, Mean auc: 0.818, Run Time : 258.59 sec
INFO:root:2024-04-19 08:21:37, Train, Epoch : 2, Step : 640, Loss : 0.33214, Acc : 0.466, Sensitive_Loss : 0.18553, Sensitive_Acc : 9.700, Run Time : 20.33 sec
INFO:root:2024-04-19 08:22:01, Train, Epoch : 2, Step : 650, Loss : 0.51202, Acc : 0.741, Sensitive_Loss : 0.27052, Sensitive_Acc : 22.100, Run Time : 23.88 sec
INFO:root:2024-04-19 08:22:19, Train, Epoch : 2, Step : 660, Loss : 0.48893, Acc : 0.694, Sensitive_Loss : 0.29885, Sensitive_Acc : 23.300, Run Time : 17.61 sec
INFO:root:2024-04-19 08:22:36, Train, Epoch : 2, Step : 670, Loss : 0.56491, Acc : 0.703, Sensitive_Loss : 0.21411, Sensitive_Acc : 20.400, Run Time : 17.18 sec
INFO:root:2024-04-19 08:22:55, Train, Epoch : 2, Step : 680, Loss : 0.56443, Acc : 0.744, Sensitive_Loss : 0.19709, Sensitive_Acc : 24.900, Run Time : 18.36 sec
INFO:root:2024-04-19 08:23:11, Train, Epoch : 2, Step : 690, Loss : 0.47942, Acc : 0.769, Sensitive_Loss : 0.37139, Sensitive_Acc : 24.400, Run Time : 16.82 sec
INFO:root:2024-04-19 08:23:27, Train, Epoch : 2, Step : 700, Loss : 0.56251, Acc : 0.728, Sensitive_Loss : 0.28450, Sensitive_Acc : 18.700, Run Time : 15.74 sec
INFO:root:2024-04-19 08:27:18, Dev, Step : 700, Loss : 0.58897, Acc : 0.727, Auc : 0.792, Sensitive_Loss : 0.27602, Sensitive_Acc : 21.541, Sensitive_Auc : 0.980, Mean auc: 0.792, Run Time : 230.97 sec
INFO:root:2024-04-19 08:27:31, Train, Epoch : 2, Step : 710, Loss : 0.57444, Acc : 0.725, Sensitive_Loss : 0.39191, Sensitive_Acc : 21.900, Run Time : 244.04 sec
INFO:root:2024-04-19 08:27:50, Train, Epoch : 2, Step : 720, Loss : 0.50218, Acc : 0.741, Sensitive_Loss : 0.35215, Sensitive_Acc : 21.500, Run Time : 18.89 sec
INFO:root:2024-04-19 08:28:07, Train, Epoch : 2, Step : 730, Loss : 0.55872, Acc : 0.741, Sensitive_Loss : 0.36526, Sensitive_Acc : 21.200, Run Time : 16.52 sec
INFO:root:2024-04-19 08:28:24, Train, Epoch : 2, Step : 740, Loss : 0.53293, Acc : 0.734, Sensitive_Loss : 0.29061, Sensitive_Acc : 20.400, Run Time : 17.64 sec
INFO:root:2024-04-19 08:28:41, Train, Epoch : 2, Step : 750, Loss : 0.51069, Acc : 0.741, Sensitive_Loss : 0.28574, Sensitive_Acc : 19.400, Run Time : 16.69 sec
INFO:root:2024-04-19 08:28:59, Train, Epoch : 2, Step : 760, Loss : 0.58296, Acc : 0.719, Sensitive_Loss : 0.23716, Sensitive_Acc : 20.200, Run Time : 17.97 sec
INFO:root:2024-04-19 08:29:18, Train, Epoch : 2, Step : 770, Loss : 0.58916, Acc : 0.759, Sensitive_Loss : 0.22081, Sensitive_Acc : 19.300, Run Time : 18.96 sec
INFO:root:2024-04-19 08:29:35, Train, Epoch : 2, Step : 780, Loss : 0.56590, Acc : 0.738, Sensitive_Loss : 0.31841, Sensitive_Acc : 20.200, Run Time : 17.12 sec
INFO:root:2024-04-19 08:29:52, Train, Epoch : 2, Step : 790, Loss : 0.56416, Acc : 0.747, Sensitive_Loss : 0.18906, Sensitive_Acc : 23.400, Run Time : 16.64 sec
INFO:root:2024-04-19 08:30:08, Train, Epoch : 2, Step : 800, Loss : 0.47660, Acc : 0.756, Sensitive_Loss : 0.25964, Sensitive_Acc : 16.800, Run Time : 16.27 sec
INFO:root:2024-04-19 08:33:59, Dev, Step : 800, Loss : 0.58533, Acc : 0.700, Auc : 0.816, Sensitive_Loss : 0.44245, Sensitive_Acc : 19.060, Sensitive_Auc : 0.960, Mean auc: 0.816, Run Time : 230.74 sec
INFO:root:2024-04-19 08:34:11, Train, Epoch : 2, Step : 810, Loss : 0.54638, Acc : 0.741, Sensitive_Loss : 0.26642, Sensitive_Acc : 18.300, Run Time : 243.51 sec
INFO:root:2024-04-19 08:34:30, Train, Epoch : 2, Step : 820, Loss : 0.52349, Acc : 0.725, Sensitive_Loss : 0.29220, Sensitive_Acc : 21.500, Run Time : 18.25 sec
INFO:root:2024-04-19 08:34:48, Train, Epoch : 2, Step : 830, Loss : 0.43946, Acc : 0.759, Sensitive_Loss : 0.24500, Sensitive_Acc : 18.900, Run Time : 18.14 sec
INFO:root:2024-04-19 08:35:06, Train, Epoch : 2, Step : 840, Loss : 0.51903, Acc : 0.725, Sensitive_Loss : 0.32332, Sensitive_Acc : 21.900, Run Time : 18.48 sec
INFO:root:2024-04-19 08:35:22, Train, Epoch : 2, Step : 850, Loss : 0.58302, Acc : 0.722, Sensitive_Loss : 0.23721, Sensitive_Acc : 22.600, Run Time : 15.80 sec
INFO:root:2024-04-19 08:35:39, Train, Epoch : 2, Step : 860, Loss : 0.54947, Acc : 0.769, Sensitive_Loss : 0.23506, Sensitive_Acc : 18.900, Run Time : 16.77 sec
INFO:root:2024-04-19 08:35:57, Train, Epoch : 2, Step : 870, Loss : 0.52498, Acc : 0.750, Sensitive_Loss : 0.24733, Sensitive_Acc : 19.100, Run Time : 17.77 sec
INFO:root:2024-04-19 08:36:14, Train, Epoch : 2, Step : 880, Loss : 0.54151, Acc : 0.703, Sensitive_Loss : 0.36756, Sensitive_Acc : 16.900, Run Time : 17.71 sec
INFO:root:2024-04-19 08:36:31, Train, Epoch : 2, Step : 890, Loss : 0.51305, Acc : 0.722, Sensitive_Loss : 0.24598, Sensitive_Acc : 23.100, Run Time : 16.98 sec
INFO:root:2024-04-19 08:36:49, Train, Epoch : 2, Step : 900, Loss : 0.54012, Acc : 0.725, Sensitive_Loss : 0.23542, Sensitive_Acc : 20.200, Run Time : 17.85 sec
INFO:root:2024-04-19 08:40:39, Dev, Step : 900, Loss : 0.57506, Acc : 0.732, Auc : 0.818, Sensitive_Loss : 0.32913, Sensitive_Acc : 20.293, Sensitive_Auc : 0.980, Mean auc: 0.818, Run Time : 229.47 sec
INFO:root:2024-04-19 08:40:52, Train, Epoch : 2, Step : 910, Loss : 0.53065, Acc : 0.741, Sensitive_Loss : 0.25533, Sensitive_Acc : 23.700, Run Time : 243.18 sec
INFO:root:2024-04-19 08:41:10, Train, Epoch : 2, Step : 920, Loss : 0.50341, Acc : 0.775, Sensitive_Loss : 0.23857, Sensitive_Acc : 23.600, Run Time : 17.82 sec
INFO:root:2024-04-19 08:41:28, Train, Epoch : 2, Step : 930, Loss : 0.57496, Acc : 0.731, Sensitive_Loss : 0.28655, Sensitive_Acc : 22.700, Run Time : 17.85 sec
INFO:root:2024-04-19 08:41:44, Train, Epoch : 2, Step : 940, Loss : 0.50119, Acc : 0.772, Sensitive_Loss : 0.31411, Sensitive_Acc : 23.500, Run Time : 15.57 sec
INFO:root:2024-04-19 08:42:02, Train, Epoch : 2, Step : 950, Loss : 0.49171, Acc : 0.769, Sensitive_Loss : 0.25061, Sensitive_Acc : 20.000, Run Time : 18.68 sec
INFO:root:2024-04-19 08:42:20, Train, Epoch : 2, Step : 960, Loss : 0.51037, Acc : 0.784, Sensitive_Loss : 0.18218, Sensitive_Acc : 18.800, Run Time : 17.82 sec
INFO:root:2024-04-19 08:42:37, Train, Epoch : 2, Step : 970, Loss : 0.57586, Acc : 0.725, Sensitive_Loss : 0.30531, Sensitive_Acc : 20.300, Run Time : 17.42 sec
INFO:root:2024-04-19 08:42:53, Train, Epoch : 2, Step : 980, Loss : 0.53222, Acc : 0.719, Sensitive_Loss : 0.20196, Sensitive_Acc : 21.400, Run Time : 15.96 sec
INFO:root:2024-04-19 08:43:13, Train, Epoch : 2, Step : 990, Loss : 0.49510, Acc : 0.756, Sensitive_Loss : 0.20221, Sensitive_Acc : 18.600, Run Time : 19.99 sec
INFO:root:2024-04-19 08:43:31, Train, Epoch : 2, Step : 1000, Loss : 0.50632, Acc : 0.756, Sensitive_Loss : 0.19731, Sensitive_Acc : 19.000, Run Time : 17.13 sec
INFO:root:2024-04-19 08:47:19, Dev, Step : 1000, Loss : 0.57219, Acc : 0.749, Auc : 0.824, Sensitive_Loss : 0.27132, Sensitive_Acc : 21.571, Sensitive_Auc : 0.984, Mean auc: 0.824, Run Time : 228.28 sec
INFO:root:2024-04-19 08:47:19, Best, Step : 1000, Loss : 0.57219, Acc : 0.749, Auc : 0.824, Sensitive_Loss : 0.27132, Sensitive_Acc : 21.571, Sensitive_Auc : 0.984, Best Auc : 0.824
INFO:root:2024-04-19 08:47:32, Train, Epoch : 2, Step : 1010, Loss : 0.50380, Acc : 0.756, Sensitive_Loss : 0.31635, Sensitive_Acc : 21.700, Run Time : 241.86 sec
INFO:root:2024-04-19 08:47:51, Train, Epoch : 2, Step : 1020, Loss : 0.53294, Acc : 0.734, Sensitive_Loss : 0.22579, Sensitive_Acc : 22.600, Run Time : 18.19 sec
INFO:root:2024-04-19 08:48:08, Train, Epoch : 2, Step : 1030, Loss : 0.54712, Acc : 0.750, Sensitive_Loss : 0.32891, Sensitive_Acc : 21.600, Run Time : 17.49 sec
INFO:root:2024-04-19 08:48:26, Train, Epoch : 2, Step : 1040, Loss : 0.57749, Acc : 0.753, Sensitive_Loss : 0.24453, Sensitive_Acc : 22.900, Run Time : 18.06 sec
INFO:root:2024-04-19 08:48:43, Train, Epoch : 2, Step : 1050, Loss : 0.58543, Acc : 0.728, Sensitive_Loss : 0.20371, Sensitive_Acc : 25.000, Run Time : 17.20 sec
INFO:root:2024-04-19 08:48:59, Train, Epoch : 2, Step : 1060, Loss : 0.52388, Acc : 0.756, Sensitive_Loss : 0.19452, Sensitive_Acc : 21.300, Run Time : 15.86 sec
INFO:root:2024-04-19 08:49:17, Train, Epoch : 2, Step : 1070, Loss : 0.49774, Acc : 0.738, Sensitive_Loss : 0.19251, Sensitive_Acc : 21.200, Run Time : 17.59 sec
INFO:root:2024-04-19 08:49:35, Train, Epoch : 2, Step : 1080, Loss : 0.58573, Acc : 0.734, Sensitive_Loss : 0.26822, Sensitive_Acc : 13.900, Run Time : 17.93 sec
INFO:root:2024-04-19 08:49:52, Train, Epoch : 2, Step : 1090, Loss : 0.55637, Acc : 0.756, Sensitive_Loss : 0.32864, Sensitive_Acc : 24.200, Run Time : 17.09 sec
INFO:root:2024-04-19 08:50:09, Train, Epoch : 2, Step : 1100, Loss : 0.56353, Acc : 0.725, Sensitive_Loss : 0.32547, Sensitive_Acc : 21.100, Run Time : 17.60 sec
INFO:root:2024-04-19 08:53:59, Dev, Step : 1100, Loss : 0.55713, Acc : 0.744, Auc : 0.835, Sensitive_Loss : 0.24637, Sensitive_Acc : 21.376, Sensitive_Auc : 0.989, Mean auc: 0.835, Run Time : 229.88 sec
INFO:root:2024-04-19 08:54:01, Best, Step : 1100, Loss : 0.55713, Acc : 0.744, Auc : 0.835, Sensitive_Loss : 0.24637, Sensitive_Acc : 21.376, Sensitive_Auc : 0.989, Best Auc : 0.835
INFO:root:2024-04-19 08:54:15, Train, Epoch : 2, Step : 1110, Loss : 0.52290, Acc : 0.762, Sensitive_Loss : 0.29964, Sensitive_Acc : 18.800, Run Time : 245.12 sec
INFO:root:2024-04-19 08:54:33, Train, Epoch : 2, Step : 1120, Loss : 0.54547, Acc : 0.784, Sensitive_Loss : 0.21757, Sensitive_Acc : 17.300, Run Time : 18.00 sec
INFO:root:2024-04-19 08:54:49, Train, Epoch : 2, Step : 1130, Loss : 0.42612, Acc : 0.806, Sensitive_Loss : 0.23439, Sensitive_Acc : 21.900, Run Time : 16.36 sec
INFO:root:2024-04-19 08:55:07, Train, Epoch : 2, Step : 1140, Loss : 0.51410, Acc : 0.762, Sensitive_Loss : 0.25945, Sensitive_Acc : 22.200, Run Time : 18.20 sec
INFO:root:2024-04-19 08:55:26, Train, Epoch : 2, Step : 1150, Loss : 0.53536, Acc : 0.731, Sensitive_Loss : 0.22121, Sensitive_Acc : 22.100, Run Time : 18.77 sec
INFO:root:2024-04-19 08:55:44, Train, Epoch : 2, Step : 1160, Loss : 0.47492, Acc : 0.738, Sensitive_Loss : 0.20971, Sensitive_Acc : 17.500, Run Time : 17.86 sec
INFO:root:2024-04-19 08:56:01, Train, Epoch : 2, Step : 1170, Loss : 0.54555, Acc : 0.753, Sensitive_Loss : 0.24457, Sensitive_Acc : 23.600, Run Time : 17.28 sec
INFO:root:2024-04-19 08:56:19, Train, Epoch : 2, Step : 1180, Loss : 0.54913, Acc : 0.750, Sensitive_Loss : 0.23964, Sensitive_Acc : 22.200, Run Time : 17.89 sec
INFO:root:2024-04-19 08:56:38, Train, Epoch : 2, Step : 1190, Loss : 0.50387, Acc : 0.756, Sensitive_Loss : 0.23734, Sensitive_Acc : 25.300, Run Time : 19.02 sec
INFO:root:2024-04-19 08:56:55, Train, Epoch : 2, Step : 1200, Loss : 0.53196, Acc : 0.766, Sensitive_Loss : 0.33332, Sensitive_Acc : 15.600, Run Time : 17.19 sec
INFO:root:2024-04-19 09:00:45, Dev, Step : 1200, Loss : 0.53718, Acc : 0.756, Auc : 0.834, Sensitive_Loss : 0.29203, Sensitive_Acc : 21.105, Sensitive_Auc : 0.990, Mean auc: 0.834, Run Time : 229.84 sec
INFO:root:2024-04-19 09:00:59, Train, Epoch : 2, Step : 1210, Loss : 0.53578, Acc : 0.728, Sensitive_Loss : 0.26654, Sensitive_Acc : 19.300, Run Time : 243.40 sec
INFO:root:2024-04-19 09:01:16, Train, Epoch : 2, Step : 1220, Loss : 0.52019, Acc : 0.753, Sensitive_Loss : 0.23475, Sensitive_Acc : 19.000, Run Time : 17.42 sec
INFO:root:2024-04-19 09:01:33, Train, Epoch : 2, Step : 1230, Loss : 0.50213, Acc : 0.728, Sensitive_Loss : 0.28578, Sensitive_Acc : 18.400, Run Time : 16.85 sec
INFO:root:2024-04-19 09:01:52, Train, Epoch : 2, Step : 1240, Loss : 0.51961, Acc : 0.791, Sensitive_Loss : 0.23519, Sensitive_Acc : 17.500, Run Time : 18.73 sec
INFO:root:2024-04-19 09:02:09, Train, Epoch : 2, Step : 1250, Loss : 0.53685, Acc : 0.744, Sensitive_Loss : 0.27509, Sensitive_Acc : 16.200, Run Time : 17.32 sec
INFO:root:2024-04-19 09:02:26, Train, Epoch : 2, Step : 1260, Loss : 0.56181, Acc : 0.688, Sensitive_Loss : 0.23670, Sensitive_Acc : 14.400, Run Time : 17.03 sec
INFO:root:2024-04-19 09:06:24
INFO:root:y_pred: [0.10547379 0.03861921 0.48308513 ... 0.32561088 0.12255372 0.07122185]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [2.28426978e-03 1.37543203e-02 6.89991284e-03 7.46945664e-02
 3.32497209e-02 6.01556432e-03 3.00275371e-03 2.31623650e-03
 1.24280944e-01 9.99154568e-01 7.43328854e-02 3.03149759e-03
 2.02983931e-01 8.58290237e-04 9.99937892e-01 2.45774984e-02
 1.21642221e-02 9.99411821e-01 9.86945927e-01 1.42928690e-01
 4.48359817e-01 1.30971210e-04 3.35900366e-01 9.17381956e-04
 1.98003158e-01 3.56261879e-01 2.14417349e-03 1.32468902e-02
 1.99717656e-03 9.21476632e-03 2.42482468e-01 9.96091425e-01
 1.06121704e-01 7.52680063e-01 3.10263201e-03 1.14998012e-03
 1.66079481e-04 5.03895544e-02 1.12968221e-01 2.19516203e-01
 1.48396626e-01 9.91250634e-01 5.36247948e-03 2.24898307e-04
 7.93192744e-01 1.44544616e-01 2.37331092e-01 6.33960843e-01
 1.42528946e-02 9.96031225e-01 9.41034138e-01 9.98269320e-01
 9.95765686e-01 3.84809537e-04 4.88333665e-02 2.13028088e-01
 1.05926879e-01 1.04305358e-03 9.78939712e-01 2.94054131e-04
 1.03750681e-04 2.23420837e-04 1.73083246e-02 2.96734273e-03
 9.98694241e-01 3.24815094e-01 6.91376394e-04 1.36363925e-02
 5.24802841e-02 9.43396270e-01 9.98854518e-01 9.99682069e-01
 1.96149712e-03 1.39205337e-01 1.95934670e-03 8.77659500e-01
 3.34669813e-03 3.81605932e-04 1.07043714e-04 5.59475012e-02
 1.04383521e-01 5.91214513e-04 9.82266247e-01 9.53924537e-01
 9.86796687e-04 1.27871260e-01 3.28212488e-03 3.45627632e-04
 4.95675835e-04 3.04299803e-03 1.63234342e-02 5.44868596e-02
 1.01138721e-04 3.37674919e-06 1.30563176e-05 3.99568863e-03
 9.29201255e-04 1.39993489e-01 2.99902093e-02 7.68470112e-03
 7.97674991e-03 4.27805074e-02 1.94012582e-01 6.03105780e-03
 3.85329612e-02 3.06735135e-04 1.56292170e-01 1.15301445e-01
 4.33883965e-02 3.49344879e-01 4.73472523e-04 9.99049366e-01
 9.99451697e-01 9.83104575e-04 7.70956576e-02 1.47403419e-01
 2.94851780e-01 1.37277844e-03 1.92427561e-01 9.59377270e-03
 4.09835856e-03 1.07883266e-03 9.72735509e-03 2.56050378e-04
 1.90692954e-04 9.76349354e-01 1.30068802e-03 9.94360268e-01
 2.41885483e-02 5.04882216e-01 7.88466260e-03 7.55475275e-03
 1.34857674e-03]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-19 09:06:24, Dev, Step : 1268, Loss : 0.55288, Acc : 0.748, Auc : 0.821, Sensitive_Loss : 0.25507, Sensitive_Acc : 21.797, Sensitive_Auc : 0.987, Mean auc: 0.821, Run Time : 226.74 sec
INFO:root:2024-04-19 09:06:32, Train, Epoch : 3, Step : 1270, Loss : 0.07973, Acc : 0.159, Sensitive_Loss : 0.05007, Sensitive_Acc : 5.000, Run Time : 6.50 sec
INFO:root:2024-04-19 09:06:50, Train, Epoch : 3, Step : 1280, Loss : 0.47917, Acc : 0.766, Sensitive_Loss : 0.19365, Sensitive_Acc : 19.200, Run Time : 18.28 sec
INFO:root:2024-04-19 09:07:07, Train, Epoch : 3, Step : 1290, Loss : 0.46972, Acc : 0.766, Sensitive_Loss : 0.10267, Sensitive_Acc : 19.800, Run Time : 16.41 sec
INFO:root:2024-04-19 09:07:24, Train, Epoch : 3, Step : 1300, Loss : 0.45225, Acc : 0.822, Sensitive_Loss : 0.21466, Sensitive_Acc : 24.500, Run Time : 17.16 sec
INFO:root:2024-04-19 09:11:14, Dev, Step : 1300, Loss : 0.54038, Acc : 0.757, Auc : 0.835, Sensitive_Loss : 0.25332, Sensitive_Acc : 21.767, Sensitive_Auc : 0.990, Mean auc: 0.835, Run Time : 230.62 sec
INFO:root:2024-04-19 09:11:27, Train, Epoch : 3, Step : 1310, Loss : 0.47939, Acc : 0.769, Sensitive_Loss : 0.20850, Sensitive_Acc : 21.400, Run Time : 243.50 sec
INFO:root:2024-04-19 09:11:45, Train, Epoch : 3, Step : 1320, Loss : 0.53351, Acc : 0.728, Sensitive_Loss : 0.18596, Sensitive_Acc : 17.300, Run Time : 18.00 sec
INFO:root:2024-04-19 09:12:02, Train, Epoch : 3, Step : 1330, Loss : 0.47874, Acc : 0.812, Sensitive_Loss : 0.19896, Sensitive_Acc : 21.000, Run Time : 17.10 sec
INFO:root:2024-04-19 09:12:21, Train, Epoch : 3, Step : 1340, Loss : 0.47686, Acc : 0.778, Sensitive_Loss : 0.18581, Sensitive_Acc : 21.700, Run Time : 19.03 sec
INFO:root:2024-04-19 09:12:37, Train, Epoch : 3, Step : 1350, Loss : 0.53443, Acc : 0.738, Sensitive_Loss : 0.18548, Sensitive_Acc : 22.000, Run Time : 16.08 sec
INFO:root:2024-04-19 09:12:55, Train, Epoch : 3, Step : 1360, Loss : 0.52378, Acc : 0.772, Sensitive_Loss : 0.20594, Sensitive_Acc : 22.200, Run Time : 17.26 sec
INFO:root:2024-04-19 09:13:11, Train, Epoch : 3, Step : 1370, Loss : 0.54247, Acc : 0.772, Sensitive_Loss : 0.21072, Sensitive_Acc : 18.800, Run Time : 16.08 sec
INFO:root:2024-04-19 09:13:28, Train, Epoch : 3, Step : 1380, Loss : 0.48783, Acc : 0.784, Sensitive_Loss : 0.17495, Sensitive_Acc : 19.100, Run Time : 17.50 sec
INFO:root:2024-04-19 09:13:48, Train, Epoch : 3, Step : 1390, Loss : 0.46981, Acc : 0.750, Sensitive_Loss : 0.16881, Sensitive_Acc : 23.900, Run Time : 20.16 sec
INFO:root:2024-04-19 09:14:05, Train, Epoch : 3, Step : 1400, Loss : 0.42788, Acc : 0.775, Sensitive_Loss : 0.20334, Sensitive_Acc : 25.900, Run Time : 16.41 sec
INFO:root:2024-04-19 09:17:55, Dev, Step : 1400, Loss : 0.54498, Acc : 0.757, Auc : 0.843, Sensitive_Loss : 0.25253, Sensitive_Acc : 21.526, Sensitive_Auc : 0.992, Mean auc: 0.843, Run Time : 230.05 sec
INFO:root:2024-04-19 09:17:56, Best, Step : 1400, Loss : 0.54498, Acc : 0.757, Auc : 0.843, Sensitive_Loss : 0.25253, Sensitive_Acc : 21.526, Sensitive_Auc : 0.992, Best Auc : 0.843
INFO:root:2024-04-19 09:18:08, Train, Epoch : 3, Step : 1410, Loss : 0.54538, Acc : 0.775, Sensitive_Loss : 0.21646, Sensitive_Acc : 21.400, Run Time : 243.42 sec
INFO:root:2024-04-19 09:18:26, Train, Epoch : 3, Step : 1420, Loss : 0.45708, Acc : 0.794, Sensitive_Loss : 0.14654, Sensitive_Acc : 24.000, Run Time : 17.86 sec
INFO:root:2024-04-19 09:18:43, Train, Epoch : 3, Step : 1430, Loss : 0.49061, Acc : 0.784, Sensitive_Loss : 0.16065, Sensitive_Acc : 23.600, Run Time : 16.92 sec
INFO:root:2024-04-19 09:19:00, Train, Epoch : 3, Step : 1440, Loss : 0.48007, Acc : 0.800, Sensitive_Loss : 0.18100, Sensitive_Acc : 22.500, Run Time : 17.12 sec
INFO:root:2024-04-19 09:19:17, Train, Epoch : 3, Step : 1450, Loss : 0.51642, Acc : 0.797, Sensitive_Loss : 0.19145, Sensitive_Acc : 21.600, Run Time : 16.60 sec
INFO:root:2024-04-19 09:19:36, Train, Epoch : 3, Step : 1460, Loss : 0.48488, Acc : 0.775, Sensitive_Loss : 0.23473, Sensitive_Acc : 19.600, Run Time : 19.46 sec
INFO:root:2024-04-19 09:19:53, Train, Epoch : 3, Step : 1470, Loss : 0.48926, Acc : 0.778, Sensitive_Loss : 0.22218, Sensitive_Acc : 19.600, Run Time : 16.28 sec
INFO:root:2024-04-19 09:20:10, Train, Epoch : 3, Step : 1480, Loss : 0.42948, Acc : 0.819, Sensitive_Loss : 0.24784, Sensitive_Acc : 21.000, Run Time : 17.54 sec
INFO:root:2024-04-19 09:20:26, Train, Epoch : 3, Step : 1490, Loss : 0.49315, Acc : 0.784, Sensitive_Loss : 0.13987, Sensitive_Acc : 20.900, Run Time : 16.11 sec
INFO:root:2024-04-19 09:20:44, Train, Epoch : 3, Step : 1500, Loss : 0.41788, Acc : 0.778, Sensitive_Loss : 0.15836, Sensitive_Acc : 20.300, Run Time : 17.97 sec
INFO:root:2024-04-19 09:24:33, Dev, Step : 1500, Loss : 0.53790, Acc : 0.763, Auc : 0.847, Sensitive_Loss : 0.21447, Sensitive_Acc : 21.737, Sensitive_Auc : 0.992, Mean auc: 0.847, Run Time : 228.27 sec
INFO:root:2024-04-19 09:24:33, Best, Step : 1500, Loss : 0.53790, Acc : 0.763, Auc : 0.847, Sensitive_Loss : 0.21447, Sensitive_Acc : 21.737, Sensitive_Auc : 0.992, Best Auc : 0.847
INFO:root:2024-04-19 09:24:46, Train, Epoch : 3, Step : 1510, Loss : 0.41838, Acc : 0.812, Sensitive_Loss : 0.16042, Sensitive_Acc : 22.500, Run Time : 242.00 sec
INFO:root:2024-04-19 09:25:02, Train, Epoch : 3, Step : 1520, Loss : 0.43726, Acc : 0.812, Sensitive_Loss : 0.14296, Sensitive_Acc : 24.400, Run Time : 15.99 sec
INFO:root:2024-04-19 09:25:21, Train, Epoch : 3, Step : 1530, Loss : 0.38206, Acc : 0.825, Sensitive_Loss : 0.17965, Sensitive_Acc : 22.600, Run Time : 18.35 sec
INFO:root:2024-04-19 09:25:38, Train, Epoch : 3, Step : 1540, Loss : 0.39634, Acc : 0.803, Sensitive_Loss : 0.13050, Sensitive_Acc : 21.300, Run Time : 16.79 sec
INFO:root:2024-04-19 09:25:55, Train, Epoch : 3, Step : 1550, Loss : 0.48559, Acc : 0.762, Sensitive_Loss : 0.18701, Sensitive_Acc : 21.500, Run Time : 17.57 sec
INFO:root:2024-04-19 09:26:13, Train, Epoch : 3, Step : 1560, Loss : 0.44116, Acc : 0.794, Sensitive_Loss : 0.23579, Sensitive_Acc : 26.000, Run Time : 17.86 sec
INFO:root:2024-04-19 09:26:32, Train, Epoch : 3, Step : 1570, Loss : 0.54330, Acc : 0.769, Sensitive_Loss : 0.16505, Sensitive_Acc : 20.600, Run Time : 19.03 sec
INFO:root:2024-04-19 09:26:49, Train, Epoch : 3, Step : 1580, Loss : 0.44154, Acc : 0.797, Sensitive_Loss : 0.24269, Sensitive_Acc : 18.800, Run Time : 16.83 sec
INFO:root:2024-04-19 09:27:05, Train, Epoch : 3, Step : 1590, Loss : 0.38620, Acc : 0.825, Sensitive_Loss : 0.20648, Sensitive_Acc : 20.400, Run Time : 16.58 sec
INFO:root:2024-04-19 09:27:24, Train, Epoch : 3, Step : 1600, Loss : 0.53400, Acc : 0.756, Sensitive_Loss : 0.20243, Sensitive_Acc : 23.900, Run Time : 18.52 sec
INFO:root:2024-04-19 09:31:10, Dev, Step : 1600, Loss : 0.51781, Acc : 0.773, Auc : 0.851, Sensitive_Loss : 0.21462, Sensitive_Acc : 21.361, Sensitive_Auc : 0.993, Mean auc: 0.851, Run Time : 225.73 sec
INFO:root:2024-04-19 09:31:10, Best, Step : 1600, Loss : 0.51781, Acc : 0.773, Auc : 0.851, Sensitive_Loss : 0.21462, Sensitive_Acc : 21.361, Sensitive_Auc : 0.993, Best Auc : 0.851
INFO:root:2024-04-19 09:31:24, Train, Epoch : 3, Step : 1610, Loss : 0.47243, Acc : 0.769, Sensitive_Loss : 0.16503, Sensitive_Acc : 19.000, Run Time : 239.97 sec
INFO:root:2024-04-19 09:31:41, Train, Epoch : 3, Step : 1620, Loss : 0.46239, Acc : 0.806, Sensitive_Loss : 0.27588, Sensitive_Acc : 22.000, Run Time : 17.12 sec
INFO:root:2024-04-19 09:31:59, Train, Epoch : 3, Step : 1630, Loss : 0.47918, Acc : 0.800, Sensitive_Loss : 0.14382, Sensitive_Acc : 23.900, Run Time : 17.73 sec
INFO:root:2024-04-19 09:32:16, Train, Epoch : 3, Step : 1640, Loss : 0.41194, Acc : 0.800, Sensitive_Loss : 0.12987, Sensitive_Acc : 17.900, Run Time : 17.38 sec
INFO:root:2024-04-19 09:32:33, Train, Epoch : 3, Step : 1650, Loss : 0.42603, Acc : 0.819, Sensitive_Loss : 0.18937, Sensitive_Acc : 22.100, Run Time : 16.74 sec
INFO:root:2024-04-19 09:32:51, Train, Epoch : 3, Step : 1660, Loss : 0.46030, Acc : 0.762, Sensitive_Loss : 0.23132, Sensitive_Acc : 25.100, Run Time : 17.67 sec
INFO:root:2024-04-19 09:33:08, Train, Epoch : 3, Step : 1670, Loss : 0.44253, Acc : 0.825, Sensitive_Loss : 0.22706, Sensitive_Acc : 22.800, Run Time : 17.14 sec
INFO:root:2024-04-19 09:33:24, Train, Epoch : 3, Step : 1680, Loss : 0.45734, Acc : 0.778, Sensitive_Loss : 0.17567, Sensitive_Acc : 23.100, Run Time : 16.58 sec
INFO:root:2024-04-19 09:33:43, Train, Epoch : 3, Step : 1690, Loss : 0.47297, Acc : 0.803, Sensitive_Loss : 0.17945, Sensitive_Acc : 24.000, Run Time : 18.24 sec
INFO:root:2024-04-19 09:33:58, Train, Epoch : 3, Step : 1700, Loss : 0.41770, Acc : 0.778, Sensitive_Loss : 0.14217, Sensitive_Acc : 23.200, Run Time : 15.26 sec
INFO:root:2024-04-19 09:37:46, Dev, Step : 1700, Loss : 0.52315, Acc : 0.771, Auc : 0.849, Sensitive_Loss : 0.21123, Sensitive_Acc : 21.737, Sensitive_Auc : 0.992, Mean auc: 0.849, Run Time : 228.67 sec
INFO:root:2024-04-19 09:37:58, Train, Epoch : 3, Step : 1710, Loss : 0.54288, Acc : 0.769, Sensitive_Loss : 0.17237, Sensitive_Acc : 23.500, Run Time : 239.85 sec
INFO:root:2024-04-19 09:38:15, Train, Epoch : 3, Step : 1720, Loss : 0.41392, Acc : 0.812, Sensitive_Loss : 0.11370, Sensitive_Acc : 22.100, Run Time : 16.88 sec
INFO:root:2024-04-19 09:38:34, Train, Epoch : 3, Step : 1730, Loss : 0.51251, Acc : 0.762, Sensitive_Loss : 0.14688, Sensitive_Acc : 21.100, Run Time : 19.12 sec
INFO:root:2024-04-19 09:38:51, Train, Epoch : 3, Step : 1740, Loss : 0.41128, Acc : 0.787, Sensitive_Loss : 0.17748, Sensitive_Acc : 21.300, Run Time : 16.99 sec
INFO:root:2024-04-19 09:39:07, Train, Epoch : 3, Step : 1750, Loss : 0.41591, Acc : 0.812, Sensitive_Loss : 0.20000, Sensitive_Acc : 22.500, Run Time : 16.09 sec
INFO:root:2024-04-19 09:39:24, Train, Epoch : 3, Step : 1760, Loss : 0.43193, Acc : 0.816, Sensitive_Loss : 0.14274, Sensitive_Acc : 21.900, Run Time : 17.40 sec
INFO:root:2024-04-19 09:39:41, Train, Epoch : 3, Step : 1770, Loss : 0.45336, Acc : 0.781, Sensitive_Loss : 0.14113, Sensitive_Acc : 22.900, Run Time : 17.11 sec
INFO:root:2024-04-19 09:40:00, Train, Epoch : 3, Step : 1780, Loss : 0.44113, Acc : 0.784, Sensitive_Loss : 0.12860, Sensitive_Acc : 17.800, Run Time : 18.92 sec
INFO:root:2024-04-19 09:40:17, Train, Epoch : 3, Step : 1790, Loss : 0.47016, Acc : 0.769, Sensitive_Loss : 0.20251, Sensitive_Acc : 20.200, Run Time : 16.95 sec
INFO:root:2024-04-19 09:40:34, Train, Epoch : 3, Step : 1800, Loss : 0.43331, Acc : 0.819, Sensitive_Loss : 0.19029, Sensitive_Acc : 21.100, Run Time : 16.77 sec
INFO:root:2024-04-19 09:44:24, Dev, Step : 1800, Loss : 0.51767, Acc : 0.773, Auc : 0.856, Sensitive_Loss : 0.19486, Sensitive_Acc : 21.737, Sensitive_Auc : 0.994, Mean auc: 0.856, Run Time : 229.76 sec
INFO:root:2024-04-19 09:44:25, Best, Step : 1800, Loss : 0.51767, Acc : 0.773, Auc : 0.856, Sensitive_Loss : 0.19486, Sensitive_Acc : 21.737, Sensitive_Auc : 0.994, Best Auc : 0.856
INFO:root:2024-04-19 09:44:37, Train, Epoch : 3, Step : 1810, Loss : 0.39990, Acc : 0.825, Sensitive_Loss : 0.10310, Sensitive_Acc : 22.500, Run Time : 243.16 sec
INFO:root:2024-04-19 09:44:53, Train, Epoch : 3, Step : 1820, Loss : 0.49846, Acc : 0.803, Sensitive_Loss : 0.23298, Sensitive_Acc : 17.900, Run Time : 16.13 sec
INFO:root:2024-04-19 09:45:11, Train, Epoch : 3, Step : 1830, Loss : 0.36019, Acc : 0.850, Sensitive_Loss : 0.11611, Sensitive_Acc : 19.700, Run Time : 17.68 sec
INFO:root:2024-04-19 09:45:30, Train, Epoch : 3, Step : 1840, Loss : 0.42017, Acc : 0.800, Sensitive_Loss : 0.16339, Sensitive_Acc : 15.600, Run Time : 18.72 sec
INFO:root:2024-04-19 09:45:45, Train, Epoch : 3, Step : 1850, Loss : 0.37609, Acc : 0.816, Sensitive_Loss : 0.17373, Sensitive_Acc : 24.000, Run Time : 15.49 sec
INFO:root:2024-04-19 09:46:02, Train, Epoch : 3, Step : 1860, Loss : 0.50622, Acc : 0.778, Sensitive_Loss : 0.18714, Sensitive_Acc : 23.600, Run Time : 16.95 sec
INFO:root:2024-04-19 09:46:18, Train, Epoch : 3, Step : 1870, Loss : 0.40827, Acc : 0.812, Sensitive_Loss : 0.20469, Sensitive_Acc : 21.500, Run Time : 15.96 sec
INFO:root:2024-04-19 09:46:35, Train, Epoch : 3, Step : 1880, Loss : 0.44322, Acc : 0.794, Sensitive_Loss : 0.23422, Sensitive_Acc : 23.600, Run Time : 17.33 sec
INFO:root:2024-04-19 09:46:52, Train, Epoch : 3, Step : 1890, Loss : 0.44194, Acc : 0.819, Sensitive_Loss : 0.22721, Sensitive_Acc : 23.200, Run Time : 16.33 sec
INFO:root:2024-04-19 09:47:09, Train, Epoch : 3, Step : 1900, Loss : 0.45043, Acc : 0.803, Sensitive_Loss : 0.24769, Sensitive_Acc : 21.200, Run Time : 17.65 sec
INFO:root:2024-04-19 09:50:57, Dev, Step : 1900, Loss : 0.53295, Acc : 0.770, Auc : 0.855, Sensitive_Loss : 0.19841, Sensitive_Acc : 21.737, Sensitive_Auc : 0.995, Mean auc: 0.855, Run Time : 228.15 sec
INFO:root:2024-04-19 09:54:56
INFO:root:y_pred: [0.06434096 0.00246369 0.14977446 ... 0.11996693 0.0205279  0.01664868]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [2.49365275e-03 1.80809181e-02 6.26093298e-02 1.37901828e-01
 1.26499617e-02 6.64923387e-03 5.87404985e-03 2.19289563e-04
 8.41523707e-02 9.99942541e-01 1.05764054e-01 2.63136229e-03
 1.98160350e-01 1.68711922e-04 9.99825418e-01 1.08122500e-02
 1.25986198e-02 9.99463260e-01 9.95870411e-01 1.16693556e-01
 6.82488620e-01 5.35360363e-04 3.26133035e-02 9.69215704e-04
 1.26252696e-01 3.55972230e-01 4.14898340e-03 2.03164611e-02
 2.87054601e-04 9.04379133e-03 1.98199041e-02 9.90421653e-01
 1.86911970e-01 6.36624217e-01 2.51531065e-03 3.02280358e-04
 1.35328635e-04 1.22533411e-01 7.50050247e-02 6.84415475e-02
 4.07505363e-01 9.95461881e-01 9.73564945e-03 3.43495212e-03
 9.93254006e-01 6.77609801e-01 8.46358463e-02 4.24963504e-01
 5.80268092e-02 9.85668540e-01 9.74420071e-01 9.99295831e-01
 9.96265471e-01 3.47785186e-04 8.59275907e-02 1.32792756e-01
 6.63024113e-02 2.14034524e-02 9.69434321e-01 1.14708368e-04
 1.96888359e-04 3.69855552e-03 1.42634511e-02 2.07008957e-03
 9.99635339e-01 4.00714099e-01 3.94358678e-04 7.19247237e-02
 2.12638453e-02 9.93793964e-01 9.99829531e-01 9.99897599e-01
 1.97816943e-03 2.71669120e-01 5.95039502e-03 7.37482607e-01
 2.23849583e-02 7.61601914e-05 7.44598801e-05 1.73582751e-02
 2.22516149e-01 6.50226604e-04 9.97951925e-01 9.67085302e-01
 1.24559458e-03 2.68883258e-02 1.78073086e-02 2.15386419e-04
 1.21015380e-03 1.49738742e-03 9.55092441e-03 1.02456197e-01
 1.63865610e-04 2.63825859e-05 2.49947392e-04 4.00336459e-03
 6.74559094e-04 3.31606805e-01 1.67500041e-02 3.69088799e-02
 1.16445846e-03 2.59811617e-02 9.49159414e-02 1.29267399e-03
 1.45951444e-02 3.43436957e-04 1.12335987e-01 1.93620428e-01
 1.05830142e-02 1.24011472e-01 5.30445308e-04 9.92893636e-01
 9.99788225e-01 2.59840366e-04 2.00279489e-01 1.47389891e-02
 6.26845956e-02 4.30874294e-04 2.14026242e-01 7.85856880e-03
 2.09230129e-04 1.03430555e-03 4.08785976e-02 1.48927356e-04
 4.01684642e-03 9.14765298e-01 2.51745427e-04 9.98203993e-01
 2.53534075e-02 4.31648880e-01 2.62066405e-02 8.29869043e-03
 1.99161674e-04]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-19 09:54:56, Dev, Step : 1902, Loss : 0.53314, Acc : 0.771, Auc : 0.856, Sensitive_Loss : 0.20236, Sensitive_Acc : 21.737, Sensitive_Auc : 0.995, Mean auc: 0.856, Run Time : 237.33 sec
INFO:root:2024-04-19 09:55:18, Train, Epoch : 4, Step : 1910, Loss : 0.35195, Acc : 0.672, Sensitive_Loss : 0.17197, Sensitive_Acc : 15.400, Run Time : 20.27 sec
INFO:root:2024-04-19 09:55:37, Train, Epoch : 4, Step : 1920, Loss : 0.35950, Acc : 0.831, Sensitive_Loss : 0.14634, Sensitive_Acc : 20.500, Run Time : 19.38 sec
INFO:root:2024-04-19 09:55:56, Train, Epoch : 4, Step : 1930, Loss : 0.39356, Acc : 0.847, Sensitive_Loss : 0.16361, Sensitive_Acc : 17.600, Run Time : 18.66 sec
INFO:root:2024-04-19 09:56:16, Train, Epoch : 4, Step : 1940, Loss : 0.39120, Acc : 0.819, Sensitive_Loss : 0.16950, Sensitive_Acc : 19.700, Run Time : 19.47 sec
INFO:root:2024-04-19 09:56:32, Train, Epoch : 4, Step : 1950, Loss : 0.41894, Acc : 0.828, Sensitive_Loss : 0.16213, Sensitive_Acc : 22.700, Run Time : 16.54 sec
INFO:root:2024-04-19 09:56:48, Train, Epoch : 4, Step : 1960, Loss : 0.39113, Acc : 0.800, Sensitive_Loss : 0.21216, Sensitive_Acc : 19.900, Run Time : 16.12 sec
INFO:root:2024-04-19 09:57:05, Train, Epoch : 4, Step : 1970, Loss : 0.39272, Acc : 0.819, Sensitive_Loss : 0.11861, Sensitive_Acc : 22.900, Run Time : 17.04 sec
INFO:root:2024-04-19 09:57:22, Train, Epoch : 4, Step : 1980, Loss : 0.40506, Acc : 0.819, Sensitive_Loss : 0.14210, Sensitive_Acc : 20.600, Run Time : 16.84 sec
INFO:root:2024-04-19 09:57:40, Train, Epoch : 4, Step : 1990, Loss : 0.48262, Acc : 0.794, Sensitive_Loss : 0.14692, Sensitive_Acc : 20.400, Run Time : 17.98 sec
INFO:root:2024-04-19 09:57:56, Train, Epoch : 4, Step : 2000, Loss : 0.41413, Acc : 0.806, Sensitive_Loss : 0.14529, Sensitive_Acc : 15.400, Run Time : 15.87 sec
INFO:root:2024-04-19 10:01:46, Dev, Step : 2000, Loss : 0.55792, Acc : 0.765, Auc : 0.855, Sensitive_Loss : 0.21958, Sensitive_Acc : 21.481, Sensitive_Auc : 0.996, Mean auc: 0.855, Run Time : 230.03 sec
INFO:root:2024-04-19 10:01:58, Train, Epoch : 4, Step : 2010, Loss : 0.37286, Acc : 0.825, Sensitive_Loss : 0.18622, Sensitive_Acc : 16.300, Run Time : 242.22 sec
INFO:root:2024-04-19 10:02:15, Train, Epoch : 4, Step : 2020, Loss : 0.41356, Acc : 0.803, Sensitive_Loss : 0.19508, Sensitive_Acc : 24.600, Run Time : 16.44 sec
INFO:root:2024-04-19 10:02:32, Train, Epoch : 4, Step : 2030, Loss : 0.37959, Acc : 0.816, Sensitive_Loss : 0.15231, Sensitive_Acc : 19.500, Run Time : 17.56 sec
INFO:root:2024-04-19 10:02:48, Train, Epoch : 4, Step : 2040, Loss : 0.43334, Acc : 0.803, Sensitive_Loss : 0.21243, Sensitive_Acc : 18.100, Run Time : 15.96 sec
INFO:root:2024-04-19 10:03:06, Train, Epoch : 4, Step : 2050, Loss : 0.48295, Acc : 0.772, Sensitive_Loss : 0.15489, Sensitive_Acc : 24.600, Run Time : 18.05 sec
INFO:root:2024-04-19 10:03:23, Train, Epoch : 4, Step : 2060, Loss : 0.40745, Acc : 0.806, Sensitive_Loss : 0.21068, Sensitive_Acc : 19.500, Run Time : 16.81 sec
INFO:root:2024-04-19 10:03:39, Train, Epoch : 4, Step : 2070, Loss : 0.47643, Acc : 0.816, Sensitive_Loss : 0.24506, Sensitive_Acc : 22.200, Run Time : 16.18 sec
INFO:root:2024-04-19 10:03:58, Train, Epoch : 4, Step : 2080, Loss : 0.45415, Acc : 0.809, Sensitive_Loss : 0.19098, Sensitive_Acc : 19.800, Run Time : 18.74 sec
INFO:root:2024-04-19 10:04:14, Train, Epoch : 4, Step : 2090, Loss : 0.40363, Acc : 0.847, Sensitive_Loss : 0.13916, Sensitive_Acc : 19.500, Run Time : 16.12 sec
INFO:root:2024-04-19 10:04:30, Train, Epoch : 4, Step : 2100, Loss : 0.46622, Acc : 0.800, Sensitive_Loss : 0.16718, Sensitive_Acc : 17.600, Run Time : 16.27 sec
INFO:root:2024-04-19 10:08:21, Dev, Step : 2100, Loss : 0.50960, Acc : 0.774, Auc : 0.855, Sensitive_Loss : 0.21451, Sensitive_Acc : 21.481, Sensitive_Auc : 0.994, Mean auc: 0.855, Run Time : 230.64 sec
INFO:root:2024-04-19 10:08:34, Train, Epoch : 4, Step : 2110, Loss : 0.44732, Acc : 0.816, Sensitive_Loss : 0.21115, Sensitive_Acc : 24.800, Run Time : 244.05 sec
INFO:root:2024-04-19 10:08:50, Train, Epoch : 4, Step : 2120, Loss : 0.43098, Acc : 0.781, Sensitive_Loss : 0.13663, Sensitive_Acc : 19.200, Run Time : 15.96 sec
INFO:root:2024-04-19 10:09:07, Train, Epoch : 4, Step : 2130, Loss : 0.40075, Acc : 0.812, Sensitive_Loss : 0.19519, Sensitive_Acc : 24.400, Run Time : 16.84 sec
INFO:root:2024-04-19 10:09:25, Train, Epoch : 4, Step : 2140, Loss : 0.37964, Acc : 0.800, Sensitive_Loss : 0.18116, Sensitive_Acc : 23.500, Run Time : 17.34 sec
INFO:root:2024-04-19 10:09:41, Train, Epoch : 4, Step : 2150, Loss : 0.45130, Acc : 0.791, Sensitive_Loss : 0.16384, Sensitive_Acc : 21.700, Run Time : 16.37 sec
INFO:root:2024-04-19 10:09:57, Train, Epoch : 4, Step : 2160, Loss : 0.44236, Acc : 0.781, Sensitive_Loss : 0.12700, Sensitive_Acc : 18.700, Run Time : 16.51 sec
INFO:root:2024-04-19 10:10:15, Train, Epoch : 4, Step : 2170, Loss : 0.46161, Acc : 0.809, Sensitive_Loss : 0.17021, Sensitive_Acc : 23.500, Run Time : 17.48 sec
INFO:root:2024-04-19 10:10:32, Train, Epoch : 4, Step : 2180, Loss : 0.46374, Acc : 0.791, Sensitive_Loss : 0.15489, Sensitive_Acc : 23.300, Run Time : 16.67 sec
INFO:root:2024-04-19 10:10:48, Train, Epoch : 4, Step : 2190, Loss : 0.45894, Acc : 0.787, Sensitive_Loss : 0.14161, Sensitive_Acc : 23.300, Run Time : 16.57 sec
INFO:root:2024-04-19 10:11:05, Train, Epoch : 4, Step : 2200, Loss : 0.50322, Acc : 0.794, Sensitive_Loss : 0.16050, Sensitive_Acc : 19.900, Run Time : 16.40 sec
INFO:root:2024-04-19 10:14:55, Dev, Step : 2200, Loss : 0.50739, Acc : 0.780, Auc : 0.858, Sensitive_Loss : 0.23019, Sensitive_Acc : 21.316, Sensitive_Auc : 0.995, Mean auc: 0.858, Run Time : 230.62 sec
INFO:root:2024-04-19 10:14:56, Best, Step : 2200, Loss : 0.50739, Acc : 0.780, Auc : 0.858, Sensitive_Loss : 0.23019, Sensitive_Acc : 21.316, Sensitive_Auc : 0.995, Best Auc : 0.858
INFO:root:2024-04-19 10:15:09, Train, Epoch : 4, Step : 2210, Loss : 0.39762, Acc : 0.844, Sensitive_Loss : 0.19273, Sensitive_Acc : 19.400, Run Time : 244.13 sec
INFO:root:2024-04-19 10:15:27, Train, Epoch : 4, Step : 2220, Loss : 0.35884, Acc : 0.825, Sensitive_Loss : 0.15365, Sensitive_Acc : 18.500, Run Time : 17.95 sec
INFO:root:2024-04-19 10:15:42, Train, Epoch : 4, Step : 2230, Loss : 0.47366, Acc : 0.809, Sensitive_Loss : 0.13306, Sensitive_Acc : 18.500, Run Time : 15.56 sec
INFO:root:2024-04-19 10:15:59, Train, Epoch : 4, Step : 2240, Loss : 0.43774, Acc : 0.825, Sensitive_Loss : 0.12499, Sensitive_Acc : 22.400, Run Time : 17.24 sec
INFO:root:2024-04-19 10:16:18, Train, Epoch : 4, Step : 2250, Loss : 0.41061, Acc : 0.828, Sensitive_Loss : 0.14856, Sensitive_Acc : 21.500, Run Time : 18.62 sec
INFO:root:2024-04-19 10:16:36, Train, Epoch : 4, Step : 2260, Loss : 0.41596, Acc : 0.844, Sensitive_Loss : 0.15848, Sensitive_Acc : 21.900, Run Time : 17.79 sec
INFO:root:2024-04-19 10:16:50, Train, Epoch : 4, Step : 2270, Loss : 0.45636, Acc : 0.781, Sensitive_Loss : 0.16241, Sensitive_Acc : 22.900, Run Time : 14.65 sec
INFO:root:2024-04-19 10:17:07, Train, Epoch : 4, Step : 2280, Loss : 0.43029, Acc : 0.816, Sensitive_Loss : 0.13809, Sensitive_Acc : 20.100, Run Time : 16.33 sec
INFO:root:2024-04-19 10:17:24, Train, Epoch : 4, Step : 2290, Loss : 0.48243, Acc : 0.775, Sensitive_Loss : 0.14253, Sensitive_Acc : 21.300, Run Time : 17.46 sec
INFO:root:2024-04-19 10:17:41, Train, Epoch : 4, Step : 2300, Loss : 0.39000, Acc : 0.838, Sensitive_Loss : 0.24136, Sensitive_Acc : 21.400, Run Time : 17.12 sec
INFO:root:2024-04-19 10:21:31, Dev, Step : 2300, Loss : 0.52493, Acc : 0.774, Auc : 0.855, Sensitive_Loss : 0.21664, Sensitive_Acc : 21.376, Sensitive_Auc : 0.995, Mean auc: 0.855, Run Time : 229.53 sec
INFO:root:2024-04-19 10:21:43, Train, Epoch : 4, Step : 2310, Loss : 0.49663, Acc : 0.762, Sensitive_Loss : 0.13487, Sensitive_Acc : 22.800, Run Time : 241.77 sec
INFO:root:2024-04-19 10:22:00, Train, Epoch : 4, Step : 2320, Loss : 0.42041, Acc : 0.828, Sensitive_Loss : 0.11670, Sensitive_Acc : 19.100, Run Time : 16.39 sec
INFO:root:2024-04-19 10:22:18, Train, Epoch : 4, Step : 2330, Loss : 0.45383, Acc : 0.791, Sensitive_Loss : 0.17152, Sensitive_Acc : 18.100, Run Time : 18.68 sec
INFO:root:2024-04-19 10:22:35, Train, Epoch : 4, Step : 2340, Loss : 0.40024, Acc : 0.809, Sensitive_Loss : 0.13357, Sensitive_Acc : 24.800, Run Time : 16.25 sec
INFO:root:2024-04-19 10:22:52, Train, Epoch : 4, Step : 2350, Loss : 0.39872, Acc : 0.809, Sensitive_Loss : 0.13546, Sensitive_Acc : 23.400, Run Time : 17.52 sec
INFO:root:2024-04-19 10:23:08, Train, Epoch : 4, Step : 2360, Loss : 0.35555, Acc : 0.819, Sensitive_Loss : 0.13224, Sensitive_Acc : 17.800, Run Time : 15.82 sec
INFO:root:2024-04-19 10:23:25, Train, Epoch : 4, Step : 2370, Loss : 0.42392, Acc : 0.816, Sensitive_Loss : 0.11292, Sensitive_Acc : 19.500, Run Time : 17.08 sec
INFO:root:2024-04-19 10:23:42, Train, Epoch : 4, Step : 2380, Loss : 0.49512, Acc : 0.778, Sensitive_Loss : 0.13610, Sensitive_Acc : 17.500, Run Time : 16.67 sec
INFO:root:2024-04-19 10:23:58, Train, Epoch : 4, Step : 2390, Loss : 0.47129, Acc : 0.809, Sensitive_Loss : 0.17026, Sensitive_Acc : 18.000, Run Time : 16.32 sec
INFO:root:2024-04-19 10:24:15, Train, Epoch : 4, Step : 2400, Loss : 0.41733, Acc : 0.809, Sensitive_Loss : 0.10418, Sensitive_Acc : 22.500, Run Time : 17.40 sec
INFO:root:2024-04-19 10:28:04, Dev, Step : 2400, Loss : 0.53661, Acc : 0.769, Auc : 0.857, Sensitive_Loss : 0.21420, Sensitive_Acc : 21.391, Sensitive_Auc : 0.996, Mean auc: 0.857, Run Time : 228.93 sec
INFO:root:2024-04-19 10:28:17, Train, Epoch : 4, Step : 2410, Loss : 0.40799, Acc : 0.844, Sensitive_Loss : 0.13170, Sensitive_Acc : 23.800, Run Time : 241.93 sec
INFO:root:2024-04-19 10:28:34, Train, Epoch : 4, Step : 2420, Loss : 0.40160, Acc : 0.800, Sensitive_Loss : 0.18549, Sensitive_Acc : 18.200, Run Time : 16.33 sec
INFO:root:2024-04-19 10:28:50, Train, Epoch : 4, Step : 2430, Loss : 0.43660, Acc : 0.794, Sensitive_Loss : 0.13396, Sensitive_Acc : 23.200, Run Time : 16.74 sec
INFO:root:2024-04-19 10:29:08, Train, Epoch : 4, Step : 2440, Loss : 0.40317, Acc : 0.841, Sensitive_Loss : 0.17592, Sensitive_Acc : 15.900, Run Time : 17.97 sec
INFO:root:2024-04-19 10:29:26, Train, Epoch : 4, Step : 2450, Loss : 0.43966, Acc : 0.809, Sensitive_Loss : 0.23906, Sensitive_Acc : 20.700, Run Time : 17.22 sec
INFO:root:2024-04-19 10:29:43, Train, Epoch : 4, Step : 2460, Loss : 0.45066, Acc : 0.812, Sensitive_Loss : 0.16606, Sensitive_Acc : 22.400, Run Time : 17.12 sec
INFO:root:2024-04-19 10:30:00, Train, Epoch : 4, Step : 2470, Loss : 0.46036, Acc : 0.806, Sensitive_Loss : 0.19565, Sensitive_Acc : 22.500, Run Time : 17.38 sec
INFO:root:2024-04-19 10:30:18, Train, Epoch : 4, Step : 2480, Loss : 0.40586, Acc : 0.841, Sensitive_Loss : 0.13385, Sensitive_Acc : 16.500, Run Time : 17.96 sec
INFO:root:2024-04-19 10:30:35, Train, Epoch : 4, Step : 2490, Loss : 0.40854, Acc : 0.806, Sensitive_Loss : 0.15688, Sensitive_Acc : 25.100, Run Time : 17.38 sec
INFO:root:2024-04-19 10:30:52, Train, Epoch : 4, Step : 2500, Loss : 0.46693, Acc : 0.806, Sensitive_Loss : 0.10849, Sensitive_Acc : 23.800, Run Time : 16.44 sec
INFO:root:2024-04-19 10:34:41, Dev, Step : 2500, Loss : 0.50633, Acc : 0.779, Auc : 0.859, Sensitive_Loss : 0.21272, Sensitive_Acc : 21.541, Sensitive_Auc : 0.995, Mean auc: 0.859, Run Time : 228.68 sec
INFO:root:2024-04-19 10:34:41, Best, Step : 2500, Loss : 0.50633, Acc : 0.779, Auc : 0.859, Sensitive_Loss : 0.21272, Sensitive_Acc : 21.541, Sensitive_Auc : 0.995, Best Auc : 0.859
INFO:root:2024-04-19 10:34:54, Train, Epoch : 4, Step : 2510, Loss : 0.42455, Acc : 0.816, Sensitive_Loss : 0.10091, Sensitive_Acc : 20.000, Run Time : 242.12 sec
INFO:root:2024-04-19 10:35:10, Train, Epoch : 4, Step : 2520, Loss : 0.46424, Acc : 0.791, Sensitive_Loss : 0.11048, Sensitive_Acc : 23.900, Run Time : 15.58 sec
INFO:root:2024-04-19 10:35:27, Train, Epoch : 4, Step : 2530, Loss : 0.38124, Acc : 0.809, Sensitive_Loss : 0.13933, Sensitive_Acc : 25.000, Run Time : 17.19 sec
INFO:root:2024-04-19 10:39:24
INFO:root:y_pred: [0.07481759 0.00229743 0.15366939 ... 0.16470475 0.01473143 0.01265868]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [3.33421864e-03 9.78006516e-03 8.48525688e-02 1.70648515e-01
 1.01368017e-02 4.93481616e-03 1.22000566e-02 2.91031611e-04
 1.02331519e-01 9.99967217e-01 8.33606571e-02 8.45054514e-04
 1.26493797e-01 6.60920341e-05 9.99868393e-01 6.31707860e-03
 1.24850655e-02 9.99760926e-01 9.99509335e-01 1.82905778e-01
 9.34057593e-01 3.87047330e-04 4.32927646e-02 1.13684288e-03
 1.40945271e-01 5.89915037e-01 6.69582107e-04 1.48767745e-02
 1.50323394e-04 4.19277837e-03 1.16253486e-02 9.90040243e-01
 3.82455349e-01 6.22353554e-01 1.12321181e-03 8.68399875e-05
 2.70714168e-04 1.45348310e-01 6.68522641e-02 5.39036542e-02
 3.51020187e-01 9.95851517e-01 9.45685524e-03 7.32416846e-03
 9.98779595e-01 8.61568093e-01 2.53109545e-01 4.87390935e-01
 3.88663188e-02 9.94148612e-01 9.90469694e-01 9.99418974e-01
 9.96779859e-01 4.27654450e-04 1.34194791e-01 1.99786112e-01
 9.41979587e-02 4.37065028e-02 9.86405015e-01 6.24297027e-05
 1.59089133e-04 8.97512538e-04 1.43112922e-02 2.15369277e-03
 9.99778688e-01 5.13030648e-01 1.53722372e-04 8.67520869e-02
 4.60807905e-02 9.94145155e-01 9.99908328e-01 9.99912977e-01
 2.34235427e-03 4.46697831e-01 3.73360724e-03 7.70950198e-01
 2.63400972e-02 1.82407057e-05 4.13727430e-05 1.24953641e-02
 2.05613017e-01 4.82933043e-04 9.98380303e-01 9.83156502e-01
 1.98183302e-03 9.26156994e-03 1.36066526e-02 4.00087520e-05
 1.56413717e-03 1.28028810e-03 6.14459161e-03 2.09162652e-01
 9.62597114e-05 2.50587800e-05 4.74820990e-04 4.11769841e-03
 2.76712701e-04 3.20992112e-01 2.24618409e-02 4.94394936e-02
 2.04961584e-03 1.95455980e-02 9.21123847e-02 7.35236099e-04
 9.79171786e-03 2.99655774e-04 9.95496884e-02 2.21245468e-01
 1.29068391e-02 4.40549701e-02 2.02573588e-04 9.97742176e-01
 9.99902368e-01 1.18925105e-04 9.55691859e-02 1.92166138e-02
 6.73695430e-02 7.20406126e-04 1.61813483e-01 6.55717216e-03
 2.29133031e-04 7.22568075e-04 1.30095452e-01 9.12350661e-05
 7.83720985e-03 9.39142108e-01 2.64454342e-04 9.99172986e-01
 4.50844765e-02 3.32121313e-01 2.64790524e-02 1.89283583e-02
 1.41208162e-04]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-19 10:39:24, Dev, Step : 2536, Loss : 0.52309, Acc : 0.777, Auc : 0.859, Sensitive_Loss : 0.20982, Sensitive_Acc : 21.496, Sensitive_Auc : 0.995, Mean auc: 0.859, Run Time : 227.19 sec
INFO:root:2024-04-19 10:39:25, Best, Step : 2536, Loss : 0.52309, Acc : 0.777,Auc : 0.859, Best Auc : 0.859, Sensitive_Loss : 0.20982, Sensitive_Acc : 21.496, Sensitive_Auc : 0.995
INFO:root:2024-04-19 10:39:36, Train, Epoch : 5, Step : 2540, Loss : 0.16801, Acc : 0.344, Sensitive_Loss : 0.06971, Sensitive_Acc : 9.000, Run Time : 9.65 sec
INFO:root:2024-04-19 10:39:55, Train, Epoch : 5, Step : 2550, Loss : 0.36748, Acc : 0.834, Sensitive_Loss : 0.10922, Sensitive_Acc : 22.100, Run Time : 19.01 sec
INFO:root:2024-04-19 10:40:13, Train, Epoch : 5, Step : 2560, Loss : 0.37398, Acc : 0.841, Sensitive_Loss : 0.14565, Sensitive_Acc : 18.200, Run Time : 17.93 sec
INFO:root:2024-04-19 10:40:31, Train, Epoch : 5, Step : 2570, Loss : 0.42135, Acc : 0.812, Sensitive_Loss : 0.14398, Sensitive_Acc : 20.800, Run Time : 17.65 sec
INFO:root:2024-04-19 10:40:48, Train, Epoch : 5, Step : 2580, Loss : 0.38714, Acc : 0.812, Sensitive_Loss : 0.08738, Sensitive_Acc : 26.600, Run Time : 17.10 sec
INFO:root:2024-04-19 10:41:04, Train, Epoch : 5, Step : 2590, Loss : 0.45354, Acc : 0.803, Sensitive_Loss : 0.17117, Sensitive_Acc : 21.600, Run Time : 16.56 sec
INFO:root:2024-04-19 10:41:24, Train, Epoch : 5, Step : 2600, Loss : 0.45060, Acc : 0.822, Sensitive_Loss : 0.15534, Sensitive_Acc : 20.200, Run Time : 20.19 sec
INFO:root:2024-04-19 10:45:13, Dev, Step : 2600, Loss : 0.51190, Acc : 0.775, Auc : 0.856, Sensitive_Loss : 0.19229, Sensitive_Acc : 21.571, Sensitive_Auc : 0.995, Mean auc: 0.856, Run Time : 228.93 sec
INFO:root:2024-04-19 10:45:26, Train, Epoch : 5, Step : 2610, Loss : 0.42584, Acc : 0.825, Sensitive_Loss : 0.16886, Sensitive_Acc : 22.200, Run Time : 241.19 sec
INFO:root:2024-04-19 10:45:43, Train, Epoch : 5, Step : 2620, Loss : 0.39503, Acc : 0.838, Sensitive_Loss : 0.16801, Sensitive_Acc : 22.300, Run Time : 17.57 sec
INFO:root:2024-04-19 10:46:03, Train, Epoch : 5, Step : 2630, Loss : 0.47219, Acc : 0.838, Sensitive_Loss : 0.09546, Sensitive_Acc : 21.700, Run Time : 19.59 sec
INFO:root:2024-04-19 10:46:20, Train, Epoch : 5, Step : 2640, Loss : 0.44536, Acc : 0.819, Sensitive_Loss : 0.16071, Sensitive_Acc : 19.700, Run Time : 16.87 sec
INFO:root:2024-04-19 10:46:36, Train, Epoch : 5, Step : 2650, Loss : 0.36660, Acc : 0.863, Sensitive_Loss : 0.13559, Sensitive_Acc : 22.300, Run Time : 16.72 sec
INFO:root:2024-04-19 10:46:54, Train, Epoch : 5, Step : 2660, Loss : 0.39169, Acc : 0.803, Sensitive_Loss : 0.17428, Sensitive_Acc : 15.700, Run Time : 17.51 sec
INFO:root:2024-04-19 10:47:12, Train, Epoch : 5, Step : 2670, Loss : 0.44332, Acc : 0.816, Sensitive_Loss : 0.18389, Sensitive_Acc : 20.200, Run Time : 17.56 sec
INFO:root:2024-04-19 10:47:28, Train, Epoch : 5, Step : 2680, Loss : 0.42542, Acc : 0.803, Sensitive_Loss : 0.16945, Sensitive_Acc : 22.200, Run Time : 16.69 sec
INFO:root:2024-04-19 10:47:44, Train, Epoch : 5, Step : 2690, Loss : 0.38467, Acc : 0.841, Sensitive_Loss : 0.08517, Sensitive_Acc : 19.300, Run Time : 15.98 sec
INFO:root:2024-04-19 10:48:02, Train, Epoch : 5, Step : 2700, Loss : 0.39611, Acc : 0.844, Sensitive_Loss : 0.13014, Sensitive_Acc : 21.500, Run Time : 17.59 sec
INFO:root:2024-04-19 10:51:53, Dev, Step : 2700, Loss : 0.51446, Acc : 0.777, Auc : 0.859, Sensitive_Loss : 0.19138, Sensitive_Acc : 21.571, Sensitive_Auc : 0.997, Mean auc: 0.859, Run Time : 231.02 sec
INFO:root:2024-04-19 10:51:54, Best, Step : 2700, Loss : 0.51446, Acc : 0.777, Auc : 0.859, Sensitive_Loss : 0.19138, Sensitive_Acc : 21.571, Sensitive_Auc : 0.997, Best Auc : 0.859
INFO:root:2024-04-19 10:52:05, Train, Epoch : 5, Step : 2710, Loss : 0.38155, Acc : 0.844, Sensitive_Loss : 0.22969, Sensitive_Acc : 20.300, Run Time : 243.67 sec
INFO:root:2024-04-19 10:52:21, Train, Epoch : 5, Step : 2720, Loss : 0.41885, Acc : 0.841, Sensitive_Loss : 0.15610, Sensitive_Acc : 16.700, Run Time : 15.93 sec
INFO:root:2024-04-19 10:52:38, Train, Epoch : 5, Step : 2730, Loss : 0.42259, Acc : 0.803, Sensitive_Loss : 0.15192, Sensitive_Acc : 23.000, Run Time : 16.74 sec
INFO:root:2024-04-19 10:52:58, Train, Epoch : 5, Step : 2740, Loss : 0.44587, Acc : 0.809, Sensitive_Loss : 0.09460, Sensitive_Acc : 23.200, Run Time : 19.97 sec
INFO:root:2024-04-19 10:53:18, Train, Epoch : 5, Step : 2750, Loss : 0.38804, Acc : 0.797, Sensitive_Loss : 0.13644, Sensitive_Acc : 18.500, Run Time : 19.90 sec
INFO:root:2024-04-19 10:53:36, Train, Epoch : 5, Step : 2760, Loss : 0.32977, Acc : 0.875, Sensitive_Loss : 0.16454, Sensitive_Acc : 16.300, Run Time : 17.72 sec
INFO:root:2024-04-19 10:53:56, Train, Epoch : 5, Step : 2770, Loss : 0.39055, Acc : 0.828, Sensitive_Loss : 0.15902, Sensitive_Acc : 21.200, Run Time : 19.88 sec
INFO:root:2024-04-19 10:54:15, Train, Epoch : 5, Step : 2780, Loss : 0.36735, Acc : 0.816, Sensitive_Loss : 0.14098, Sensitive_Acc : 24.800, Run Time : 19.04 sec
INFO:root:2024-04-19 10:54:33, Train, Epoch : 5, Step : 2790, Loss : 0.46073, Acc : 0.806, Sensitive_Loss : 0.14809, Sensitive_Acc : 19.600, Run Time : 18.14 sec
INFO:root:2024-04-19 10:54:50, Train, Epoch : 5, Step : 2800, Loss : 0.31386, Acc : 0.881, Sensitive_Loss : 0.14968, Sensitive_Acc : 22.600, Run Time : 17.06 sec
INFO:root:2024-04-19 10:58:39, Dev, Step : 2800, Loss : 0.50845, Acc : 0.784, Auc : 0.860, Sensitive_Loss : 0.21933, Sensitive_Acc : 21.316, Sensitive_Auc : 0.995, Mean auc: 0.860, Run Time : 228.84 sec
INFO:root:2024-04-19 10:58:40, Best, Step : 2800, Loss : 0.50845, Acc : 0.784, Auc : 0.860, Sensitive_Loss : 0.21933, Sensitive_Acc : 21.316, Sensitive_Auc : 0.995, Best Auc : 0.860
INFO:root:2024-04-19 10:58:52, Train, Epoch : 5, Step : 2810, Loss : 0.37052, Acc : 0.812, Sensitive_Loss : 0.11841, Sensitive_Acc : 23.900, Run Time : 242.26 sec
INFO:root:2024-04-19 10:59:10, Train, Epoch : 5, Step : 2820, Loss : 0.36121, Acc : 0.828, Sensitive_Loss : 0.14909, Sensitive_Acc : 23.800, Run Time : 18.05 sec
INFO:root:2024-04-19 10:59:26, Train, Epoch : 5, Step : 2830, Loss : 0.39423, Acc : 0.831, Sensitive_Loss : 0.21497, Sensitive_Acc : 25.600, Run Time : 15.49 sec
INFO:root:2024-04-19 10:59:43, Train, Epoch : 5, Step : 2840, Loss : 0.33976, Acc : 0.866, Sensitive_Loss : 0.13580, Sensitive_Acc : 21.100, Run Time : 16.91 sec
INFO:root:2024-04-19 10:59:59, Train, Epoch : 5, Step : 2850, Loss : 0.33435, Acc : 0.844, Sensitive_Loss : 0.15916, Sensitive_Acc : 17.500, Run Time : 16.72 sec
INFO:root:2024-04-19 11:00:17, Train, Epoch : 5, Step : 2860, Loss : 0.30774, Acc : 0.856, Sensitive_Loss : 0.12433, Sensitive_Acc : 19.700, Run Time : 18.18 sec
INFO:root:2024-04-19 11:00:34, Train, Epoch : 5, Step : 2870, Loss : 0.39168, Acc : 0.828, Sensitive_Loss : 0.11967, Sensitive_Acc : 24.600, Run Time : 16.95 sec
INFO:root:2024-04-19 11:00:50, Train, Epoch : 5, Step : 2880, Loss : 0.41801, Acc : 0.816, Sensitive_Loss : 0.16684, Sensitive_Acc : 16.800, Run Time : 15.79 sec
INFO:root:2024-04-19 11:01:07, Train, Epoch : 5, Step : 2890, Loss : 0.37388, Acc : 0.831, Sensitive_Loss : 0.16255, Sensitive_Acc : 21.100, Run Time : 17.22 sec
INFO:root:2024-04-19 11:01:24, Train, Epoch : 5, Step : 2900, Loss : 0.40654, Acc : 0.816, Sensitive_Loss : 0.16590, Sensitive_Acc : 19.600, Run Time : 16.28 sec
INFO:root:2024-04-19 11:05:14, Dev, Step : 2900, Loss : 0.53541, Acc : 0.779, Auc : 0.857, Sensitive_Loss : 0.23990, Sensitive_Acc : 21.436, Sensitive_Auc : 0.996, Mean auc: 0.857, Run Time : 230.22 sec
INFO:root:2024-04-19 11:05:26, Train, Epoch : 5, Step : 2910, Loss : 0.35591, Acc : 0.847, Sensitive_Loss : 0.11364, Sensitive_Acc : 22.200, Run Time : 242.23 sec
INFO:root:2024-04-19 11:05:43, Train, Epoch : 5, Step : 2920, Loss : 0.40134, Acc : 0.838, Sensitive_Loss : 0.12611, Sensitive_Acc : 21.900, Run Time : 17.19 sec
INFO:root:2024-04-19 11:06:00, Train, Epoch : 5, Step : 2930, Loss : 0.43140, Acc : 0.816, Sensitive_Loss : 0.11163, Sensitive_Acc : 22.100, Run Time : 16.63 sec
INFO:root:2024-04-19 11:06:16, Train, Epoch : 5, Step : 2940, Loss : 0.42785, Acc : 0.809, Sensitive_Loss : 0.11348, Sensitive_Acc : 21.900, Run Time : 16.19 sec
INFO:root:2024-04-19 11:06:33, Train, Epoch : 5, Step : 2950, Loss : 0.39089, Acc : 0.828, Sensitive_Loss : 0.15855, Sensitive_Acc : 20.600, Run Time : 17.56 sec
INFO:root:2024-04-19 11:06:50, Train, Epoch : 5, Step : 2960, Loss : 0.37524, Acc : 0.809, Sensitive_Loss : 0.15540, Sensitive_Acc : 16.200, Run Time : 16.74 sec
INFO:root:2024-04-19 11:07:06, Train, Epoch : 5, Step : 2970, Loss : 0.35567, Acc : 0.831, Sensitive_Loss : 0.17370, Sensitive_Acc : 19.700, Run Time : 15.94 sec
INFO:root:2024-04-19 11:07:24, Train, Epoch : 5, Step : 2980, Loss : 0.41327, Acc : 0.844, Sensitive_Loss : 0.15608, Sensitive_Acc : 18.500, Run Time : 17.42 sec
INFO:root:2024-04-19 11:07:40, Train, Epoch : 5, Step : 2990, Loss : 0.35433, Acc : 0.819, Sensitive_Loss : 0.21699, Sensitive_Acc : 19.700, Run Time : 16.04 sec
INFO:root:2024-04-19 11:07:57, Train, Epoch : 5, Step : 3000, Loss : 0.40672, Acc : 0.806, Sensitive_Loss : 0.12774, Sensitive_Acc : 22.200, Run Time : 17.01 sec
INFO:root:2024-04-19 11:11:47, Dev, Step : 3000, Loss : 0.53129, Acc : 0.775, Auc : 0.855, Sensitive_Loss : 0.22767, Sensitive_Acc : 21.571, Sensitive_Auc : 0.995, Mean auc: 0.855, Run Time : 230.83 sec
INFO:root:2024-04-19 11:11:59, Train, Epoch : 5, Step : 3010, Loss : 0.46044, Acc : 0.778, Sensitive_Loss : 0.14086, Sensitive_Acc : 19.900, Run Time : 242.77 sec
INFO:root:2024-04-19 11:12:18, Train, Epoch : 5, Step : 3020, Loss : 0.45643, Acc : 0.784, Sensitive_Loss : 0.18876, Sensitive_Acc : 16.800, Run Time : 18.85 sec
INFO:root:2024-04-19 11:12:35, Train, Epoch : 5, Step : 3030, Loss : 0.43973, Acc : 0.806, Sensitive_Loss : 0.14123, Sensitive_Acc : 18.100, Run Time : 16.75 sec
INFO:root:2024-04-19 11:12:52, Train, Epoch : 5, Step : 3040, Loss : 0.42826, Acc : 0.791, Sensitive_Loss : 0.14445, Sensitive_Acc : 21.400, Run Time : 17.16 sec
INFO:root:2024-04-19 11:13:09, Train, Epoch : 5, Step : 3050, Loss : 0.43571, Acc : 0.812, Sensitive_Loss : 0.16107, Sensitive_Acc : 22.300, Run Time : 16.82 sec
INFO:root:2024-04-19 11:13:26, Train, Epoch : 5, Step : 3060, Loss : 0.36269, Acc : 0.828, Sensitive_Loss : 0.14489, Sensitive_Acc : 17.000, Run Time : 17.24 sec
INFO:root:2024-04-19 11:13:44, Train, Epoch : 5, Step : 3070, Loss : 0.45078, Acc : 0.825, Sensitive_Loss : 0.18097, Sensitive_Acc : 15.900, Run Time : 18.05 sec
INFO:root:2024-04-19 11:14:01, Train, Epoch : 5, Step : 3080, Loss : 0.49195, Acc : 0.784, Sensitive_Loss : 0.14319, Sensitive_Acc : 22.100, Run Time : 16.40 sec
INFO:root:2024-04-19 11:14:17, Train, Epoch : 5, Step : 3090, Loss : 0.44690, Acc : 0.819, Sensitive_Loss : 0.10617, Sensitive_Acc : 19.700, Run Time : 16.86 sec
INFO:root:2024-04-19 11:14:35, Train, Epoch : 5, Step : 3100, Loss : 0.35814, Acc : 0.816, Sensitive_Loss : 0.12820, Sensitive_Acc : 23.300, Run Time : 17.56 sec
INFO:root:2024-04-19 11:18:24, Dev, Step : 3100, Loss : 0.52553, Acc : 0.776, Auc : 0.855, Sensitive_Loss : 0.21676, Sensitive_Acc : 21.571, Sensitive_Auc : 0.996, Mean auc: 0.855, Run Time : 228.86 sec
INFO:root:2024-04-19 11:18:36, Train, Epoch : 5, Step : 3110, Loss : 0.38420, Acc : 0.831, Sensitive_Loss : 0.15019, Sensitive_Acc : 23.800, Run Time : 240.86 sec
INFO:root:2024-04-19 11:18:53, Train, Epoch : 5, Step : 3120, Loss : 0.45285, Acc : 0.806, Sensitive_Loss : 0.11775, Sensitive_Acc : 21.400, Run Time : 17.40 sec
INFO:root:2024-04-19 11:19:11, Train, Epoch : 5, Step : 3130, Loss : 0.42305, Acc : 0.828, Sensitive_Loss : 0.13853, Sensitive_Acc : 21.500, Run Time : 17.41 sec
INFO:root:2024-04-19 11:19:27, Train, Epoch : 5, Step : 3140, Loss : 0.44407, Acc : 0.825, Sensitive_Loss : 0.16700, Sensitive_Acc : 22.100, Run Time : 16.47 sec
INFO:root:2024-04-19 11:19:44, Train, Epoch : 5, Step : 3150, Loss : 0.44003, Acc : 0.806, Sensitive_Loss : 0.16045, Sensitive_Acc : 23.400, Run Time : 16.89 sec
INFO:root:2024-04-19 11:20:00, Train, Epoch : 5, Step : 3160, Loss : 0.42755, Acc : 0.797, Sensitive_Loss : 0.14621, Sensitive_Acc : 25.200, Run Time : 16.37 sec
INFO:root:2024-04-19 11:20:17, Train, Epoch : 5, Step : 3170, Loss : 0.36772, Acc : 0.844, Sensitive_Loss : 0.14964, Sensitive_Acc : 21.200, Run Time : 16.96 sec
INFO:root:2024-04-19 11:24:04
INFO:root:y_pred: [0.03664112 0.00300329 0.18962015 ... 0.31588018 0.01005787 0.01572302]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [5.9502712e-03 7.3406924e-03 9.4773374e-02 2.3221296e-01 1.0404587e-02
 3.6748915e-03 1.4789632e-02 1.1181596e-03 5.6081843e-02 9.9999344e-01
 1.9451192e-01 9.6764724e-04 7.3086828e-02 1.7637359e-04 9.9993110e-01
 1.3773247e-02 1.6272742e-02 9.9983847e-01 9.9929965e-01 1.7642112e-01
 9.4609851e-01 1.4652626e-04 2.4809284e-02 2.2748433e-04 3.4453022e-01
 5.7144248e-01 9.0710621e-04 1.0924987e-02 3.3313167e-04 4.3524685e-03
 1.8464943e-02 9.9779451e-01 3.6621422e-01 7.6102638e-01 9.4955676e-04
 1.6211737e-04 1.1170164e-04 1.2346759e-01 1.6657607e-01 9.6240856e-02
 4.1503447e-01 9.9754637e-01 6.8851821e-03 7.0495619e-03 9.9983847e-01
 9.1180360e-01 3.7196445e-01 5.6386012e-01 5.7197694e-02 9.9587667e-01
 9.8860979e-01 9.9965715e-01 9.9899644e-01 5.8505713e-04 2.8529066e-01
 3.7448579e-01 6.4573348e-02 6.0371999e-02 9.9277097e-01 1.7284491e-04
 4.1097603e-05 2.4292702e-03 2.2951895e-02 1.6916365e-03 9.9988294e-01
 5.1374429e-01 3.2989756e-04 2.2491968e-01 3.7566703e-02 9.9514836e-01
 9.9996281e-01 9.9991763e-01 1.2795615e-03 4.6236375e-01 5.2623148e-03
 8.9645875e-01 2.1620367e-02 1.1961082e-05 1.0522646e-05 1.5738964e-02
 2.9844734e-01 8.0883893e-04 9.9906892e-01 9.9169427e-01 2.1614579e-03
 9.1661355e-03 1.1158679e-02 3.9093284e-05 9.6388115e-04 2.1134908e-03
 1.2684935e-02 1.4961711e-01 5.4808570e-05 3.7372808e-06 3.5791233e-04
 4.0143463e-03 2.5315612e-04 3.7406233e-01 4.0873896e-02 3.4862000e-02
 9.5039752e-04 2.0989502e-02 1.1498063e-01 1.2568317e-03 1.7859668e-02
 3.1648244e-04 1.1735004e-01 4.4288787e-01 4.9559947e-02 5.9376799e-02
 2.6848132e-04 9.9948186e-01 9.9992990e-01 1.2607938e-04 1.6807011e-01
 1.8279752e-02 5.8520276e-02 4.1960450e-04 2.8107998e-01 1.7604053e-02
 1.2583569e-04 6.0745323e-04 7.3303498e-02 1.4029242e-04 4.9271514e-03
 9.4820410e-01 1.6181235e-04 9.9969983e-01 1.2566411e-01 2.8518975e-01
 3.6511309e-02 4.2136151e-02 3.3588716e-04]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-19 11:24:04, Dev, Step : 3170, Loss : 0.52478, Acc : 0.781, Auc : 0.858, Sensitive_Loss : 0.23806, Sensitive_Acc : 21.376, Sensitive_Auc : 0.995, Mean auc: 0.858, Run Time : 226.55 sec
INFO:root:2024-04-19 11:24:27, Train, Epoch : 6, Step : 3180, Loss : 0.33345, Acc : 0.872, Sensitive_Loss : 0.19325, Sensitive_Acc : 21.800, Run Time : 21.41 sec
INFO:root:2024-04-19 11:24:44, Train, Epoch : 6, Step : 3190, Loss : 0.42501, Acc : 0.772, Sensitive_Loss : 0.12625, Sensitive_Acc : 23.800, Run Time : 17.54 sec
INFO:root:2024-04-19 11:25:00, Train, Epoch : 6, Step : 3200, Loss : 0.31990, Acc : 0.853, Sensitive_Loss : 0.11921, Sensitive_Acc : 22.500, Run Time : 16.32 sec
INFO:root:2024-04-19 11:28:51, Dev, Step : 3200, Loss : 0.52122, Acc : 0.778, Auc : 0.857, Sensitive_Loss : 0.19427, Sensitive_Acc : 21.737, Sensitive_Auc : 0.994, Mean auc: 0.857, Run Time : 230.11 sec
INFO:root:2024-04-19 11:29:04, Train, Epoch : 6, Step : 3210, Loss : 0.32715, Acc : 0.859, Sensitive_Loss : 0.11007, Sensitive_Acc : 23.200, Run Time : 243.38 sec
INFO:root:2024-04-19 11:29:22, Train, Epoch : 6, Step : 3220, Loss : 0.38504, Acc : 0.844, Sensitive_Loss : 0.18452, Sensitive_Acc : 21.900, Run Time : 17.69 sec
INFO:root:2024-04-19 11:29:40, Train, Epoch : 6, Step : 3230, Loss : 0.39557, Acc : 0.850, Sensitive_Loss : 0.11602, Sensitive_Acc : 21.800, Run Time : 18.05 sec
INFO:root:2024-04-19 11:29:55, Train, Epoch : 6, Step : 3240, Loss : 0.37964, Acc : 0.847, Sensitive_Loss : 0.18280, Sensitive_Acc : 20.900, Run Time : 15.86 sec
INFO:root:2024-04-19 11:30:14, Train, Epoch : 6, Step : 3250, Loss : 0.39164, Acc : 0.828, Sensitive_Loss : 0.12898, Sensitive_Acc : 21.900, Run Time : 18.30 sec
INFO:root:2024-04-19 11:30:32, Train, Epoch : 6, Step : 3260, Loss : 0.35842, Acc : 0.853, Sensitive_Loss : 0.16081, Sensitive_Acc : 20.700, Run Time : 18.29 sec
INFO:root:2024-04-19 11:30:48, Train, Epoch : 6, Step : 3270, Loss : 0.37610, Acc : 0.822, Sensitive_Loss : 0.10528, Sensitive_Acc : 22.400, Run Time : 16.39 sec
INFO:root:2024-04-19 11:31:05, Train, Epoch : 6, Step : 3280, Loss : 0.38420, Acc : 0.809, Sensitive_Loss : 0.14204, Sensitive_Acc : 21.200, Run Time : 16.96 sec
INFO:root:2024-04-19 11:31:23, Train, Epoch : 6, Step : 3290, Loss : 0.37474, Acc : 0.838, Sensitive_Loss : 0.10465, Sensitive_Acc : 23.800, Run Time : 17.92 sec
INFO:root:2024-04-19 11:31:41, Train, Epoch : 6, Step : 3300, Loss : 0.34680, Acc : 0.850, Sensitive_Loss : 0.12686, Sensitive_Acc : 20.400, Run Time : 17.30 sec
INFO:root:2024-04-19 11:35:28, Dev, Step : 3300, Loss : 0.51500, Acc : 0.784, Auc : 0.860, Sensitive_Loss : 0.19836, Sensitive_Acc : 21.571, Sensitive_Auc : 0.994, Mean auc: 0.860, Run Time : 227.71 sec
INFO:root:2024-04-19 11:35:41, Train, Epoch : 6, Step : 3310, Loss : 0.34704, Acc : 0.856, Sensitive_Loss : 0.12964, Sensitive_Acc : 22.600, Run Time : 240.72 sec
INFO:root:2024-04-19 11:35:58, Train, Epoch : 6, Step : 3320, Loss : 0.38137, Acc : 0.850, Sensitive_Loss : 0.12136, Sensitive_Acc : 26.100, Run Time : 17.17 sec
INFO:root:2024-04-19 11:36:16, Train, Epoch : 6, Step : 3330, Loss : 0.42795, Acc : 0.803, Sensitive_Loss : 0.11025, Sensitive_Acc : 22.900, Run Time : 17.08 sec
INFO:root:2024-04-19 11:36:35, Train, Epoch : 6, Step : 3340, Loss : 0.46215, Acc : 0.816, Sensitive_Loss : 0.12505, Sensitive_Acc : 19.100, Run Time : 19.04 sec
INFO:root:2024-04-19 11:36:52, Train, Epoch : 6, Step : 3350, Loss : 0.36767, Acc : 0.844, Sensitive_Loss : 0.12421, Sensitive_Acc : 17.700, Run Time : 17.69 sec
INFO:root:2024-04-19 11:37:09, Train, Epoch : 6, Step : 3360, Loss : 0.31423, Acc : 0.825, Sensitive_Loss : 0.09752, Sensitive_Acc : 25.200, Run Time : 17.16 sec
INFO:root:2024-04-19 11:37:25, Train, Epoch : 6, Step : 3370, Loss : 0.38768, Acc : 0.838, Sensitive_Loss : 0.14903, Sensitive_Acc : 21.400, Run Time : 15.96 sec
INFO:root:2024-04-19 11:37:42, Train, Epoch : 6, Step : 3380, Loss : 0.38636, Acc : 0.809, Sensitive_Loss : 0.18881, Sensitive_Acc : 22.100, Run Time : 16.61 sec
INFO:root:2024-04-19 11:37:59, Train, Epoch : 6, Step : 3390, Loss : 0.35595, Acc : 0.844, Sensitive_Loss : 0.14613, Sensitive_Acc : 22.800, Run Time : 17.38 sec
INFO:root:2024-04-19 11:38:17, Train, Epoch : 6, Step : 3400, Loss : 0.29789, Acc : 0.844, Sensitive_Loss : 0.13956, Sensitive_Acc : 15.300, Run Time : 17.78 sec
INFO:root:2024-04-19 11:42:07, Dev, Step : 3400, Loss : 0.53876, Acc : 0.777, Auc : 0.856, Sensitive_Loss : 0.19481, Sensitive_Acc : 21.857, Sensitive_Auc : 0.997, Mean auc: 0.856, Run Time : 229.38 sec
INFO:root:2024-04-19 11:42:18, Train, Epoch : 6, Step : 3410, Loss : 0.39880, Acc : 0.831, Sensitive_Loss : 0.16061, Sensitive_Acc : 20.900, Run Time : 241.02 sec
INFO:root:2024-04-19 11:42:36, Train, Epoch : 6, Step : 3420, Loss : 0.36532, Acc : 0.853, Sensitive_Loss : 0.12676, Sensitive_Acc : 21.800, Run Time : 17.70 sec
INFO:root:2024-04-19 11:42:53, Train, Epoch : 6, Step : 3430, Loss : 0.32682, Acc : 0.834, Sensitive_Loss : 0.11468, Sensitive_Acc : 20.400, Run Time : 16.73 sec
INFO:root:2024-04-19 11:43:09, Train, Epoch : 6, Step : 3440, Loss : 0.30387, Acc : 0.847, Sensitive_Loss : 0.18095, Sensitive_Acc : 19.100, Run Time : 16.61 sec
INFO:root:2024-04-19 11:43:27, Train, Epoch : 6, Step : 3450, Loss : 0.38446, Acc : 0.809, Sensitive_Loss : 0.12648, Sensitive_Acc : 24.000, Run Time : 17.51 sec
INFO:root:2024-04-19 11:43:43, Train, Epoch : 6, Step : 3460, Loss : 0.36570, Acc : 0.856, Sensitive_Loss : 0.13324, Sensitive_Acc : 20.700, Run Time : 16.50 sec
INFO:root:2024-04-19 11:44:00, Train, Epoch : 6, Step : 3470, Loss : 0.43422, Acc : 0.812, Sensitive_Loss : 0.18307, Sensitive_Acc : 23.300, Run Time : 17.04 sec
INFO:root:2024-04-19 11:44:18, Train, Epoch : 6, Step : 3480, Loss : 0.39895, Acc : 0.831, Sensitive_Loss : 0.11622, Sensitive_Acc : 16.100, Run Time : 17.31 sec
INFO:root:2024-04-19 11:44:34, Train, Epoch : 6, Step : 3490, Loss : 0.34645, Acc : 0.866, Sensitive_Loss : 0.18762, Sensitive_Acc : 20.000, Run Time : 16.52 sec
INFO:root:2024-04-19 11:44:52, Train, Epoch : 6, Step : 3500, Loss : 0.36451, Acc : 0.859, Sensitive_Loss : 0.08665, Sensitive_Acc : 23.700, Run Time : 17.73 sec
INFO:root:2024-04-19 11:48:42, Dev, Step : 3500, Loss : 0.52249, Acc : 0.779, Auc : 0.856, Sensitive_Loss : 0.21162, Sensitive_Acc : 21.496, Sensitive_Auc : 0.997, Mean auc: 0.856, Run Time : 229.78 sec
INFO:root:2024-04-19 11:48:53, Train, Epoch : 6, Step : 3510, Loss : 0.39201, Acc : 0.828, Sensitive_Loss : 0.10332, Sensitive_Acc : 25.700, Run Time : 241.25 sec
INFO:root:2024-04-19 11:49:10, Train, Epoch : 6, Step : 3520, Loss : 0.39516, Acc : 0.825, Sensitive_Loss : 0.11487, Sensitive_Acc : 17.800, Run Time : 16.89 sec
INFO:root:2024-04-19 11:49:27, Train, Epoch : 6, Step : 3530, Loss : 0.36842, Acc : 0.847, Sensitive_Loss : 0.13272, Sensitive_Acc : 20.200, Run Time : 17.50 sec
INFO:root:2024-04-19 11:49:46, Train, Epoch : 6, Step : 3540, Loss : 0.41154, Acc : 0.803, Sensitive_Loss : 0.12812, Sensitive_Acc : 23.400, Run Time : 18.15 sec
INFO:root:2024-04-19 11:50:00, Train, Epoch : 6, Step : 3550, Loss : 0.38196, Acc : 0.850, Sensitive_Loss : 0.10923, Sensitive_Acc : 21.400, Run Time : 14.78 sec
INFO:root:2024-04-19 11:50:19, Train, Epoch : 6, Step : 3560, Loss : 0.43789, Acc : 0.822, Sensitive_Loss : 0.18218, Sensitive_Acc : 24.900, Run Time : 18.86 sec
INFO:root:2024-04-19 11:50:36, Train, Epoch : 6, Step : 3570, Loss : 0.37287, Acc : 0.819, Sensitive_Loss : 0.10954, Sensitive_Acc : 23.800, Run Time : 16.69 sec
INFO:root:2024-04-19 11:50:52, Train, Epoch : 6, Step : 3580, Loss : 0.47218, Acc : 0.844, Sensitive_Loss : 0.16090, Sensitive_Acc : 16.300, Run Time : 16.20 sec
INFO:root:2024-04-19 11:51:10, Train, Epoch : 6, Step : 3590, Loss : 0.40978, Acc : 0.806, Sensitive_Loss : 0.12543, Sensitive_Acc : 25.900, Run Time : 17.44 sec
INFO:root:2024-04-19 11:51:26, Train, Epoch : 6, Step : 3600, Loss : 0.36730, Acc : 0.834, Sensitive_Loss : 0.18499, Sensitive_Acc : 18.000, Run Time : 16.85 sec
INFO:root:2024-04-19 11:55:31, Dev, Step : 3600, Loss : 0.53133, Acc : 0.779, Auc : 0.854, Sensitive_Loss : 0.21581, Sensitive_Acc : 21.451, Sensitive_Auc : 0.995, Mean auc: 0.854, Run Time : 244.47 sec
INFO:root:2024-04-19 11:55:44, Train, Epoch : 6, Step : 3610, Loss : 0.42233, Acc : 0.834, Sensitive_Loss : 0.20378, Sensitive_Acc : 20.300, Run Time : 257.38 sec
INFO:root:2024-04-19 11:56:03, Train, Epoch : 6, Step : 3620, Loss : 0.41557, Acc : 0.800, Sensitive_Loss : 0.10834, Sensitive_Acc : 23.600, Run Time : 19.31 sec
INFO:root:2024-04-19 11:56:20, Train, Epoch : 6, Step : 3630, Loss : 0.41146, Acc : 0.809, Sensitive_Loss : 0.18263, Sensitive_Acc : 21.200, Run Time : 16.92 sec
INFO:root:2024-04-19 11:56:36, Train, Epoch : 6, Step : 3640, Loss : 0.40908, Acc : 0.838, Sensitive_Loss : 0.12839, Sensitive_Acc : 24.400, Run Time : 16.39 sec
INFO:root:2024-04-19 11:56:54, Train, Epoch : 6, Step : 3650, Loss : 0.34578, Acc : 0.853, Sensitive_Loss : 0.18617, Sensitive_Acc : 21.400, Run Time : 17.37 sec
INFO:root:2024-04-19 11:57:10, Train, Epoch : 6, Step : 3660, Loss : 0.35178, Acc : 0.853, Sensitive_Loss : 0.10948, Sensitive_Acc : 22.000, Run Time : 16.45 sec
INFO:root:2024-04-19 11:57:28, Train, Epoch : 6, Step : 3670, Loss : 0.37135, Acc : 0.831, Sensitive_Loss : 0.12804, Sensitive_Acc : 20.100, Run Time : 17.24 sec
INFO:root:2024-04-19 11:57:46, Train, Epoch : 6, Step : 3680, Loss : 0.36435, Acc : 0.828, Sensitive_Loss : 0.12818, Sensitive_Acc : 20.300, Run Time : 18.16 sec
INFO:root:2024-04-19 11:58:04, Train, Epoch : 6, Step : 3690, Loss : 0.42577, Acc : 0.797, Sensitive_Loss : 0.14653, Sensitive_Acc : 21.700, Run Time : 17.95 sec
INFO:root:2024-04-19 11:58:21, Train, Epoch : 6, Step : 3700, Loss : 0.36585, Acc : 0.869, Sensitive_Loss : 0.14502, Sensitive_Acc : 21.000, Run Time : 17.72 sec
INFO:root:2024-04-19 12:02:08, Dev, Step : 3700, Loss : 0.53527, Acc : 0.777, Auc : 0.857, Sensitive_Loss : 0.20440, Sensitive_Acc : 21.602, Sensitive_Auc : 0.995, Mean auc: 0.857, Run Time : 226.80 sec
INFO:root:2024-04-19 12:02:20, Train, Epoch : 6, Step : 3710, Loss : 0.38031, Acc : 0.825, Sensitive_Loss : 0.14709, Sensitive_Acc : 21.100, Run Time : 238.77 sec
INFO:root:2024-04-19 12:02:37, Train, Epoch : 6, Step : 3720, Loss : 0.40120, Acc : 0.831, Sensitive_Loss : 0.11963, Sensitive_Acc : 22.600, Run Time : 17.03 sec
INFO:root:2024-04-19 12:02:54, Train, Epoch : 6, Step : 3730, Loss : 0.38546, Acc : 0.828, Sensitive_Loss : 0.09925, Sensitive_Acc : 19.600, Run Time : 16.75 sec
INFO:root:2024-04-19 12:03:10, Train, Epoch : 6, Step : 3740, Loss : 0.34729, Acc : 0.856, Sensitive_Loss : 0.11817, Sensitive_Acc : 21.200, Run Time : 16.36 sec
INFO:root:2024-04-19 12:03:28, Train, Epoch : 6, Step : 3750, Loss : 0.35811, Acc : 0.850, Sensitive_Loss : 0.15167, Sensitive_Acc : 21.000, Run Time : 18.02 sec
INFO:root:2024-04-19 12:03:45, Train, Epoch : 6, Step : 3760, Loss : 0.39825, Acc : 0.841, Sensitive_Loss : 0.16045, Sensitive_Acc : 18.100, Run Time : 16.91 sec
INFO:root:2024-04-19 12:04:04, Train, Epoch : 6, Step : 3770, Loss : 0.37636, Acc : 0.831, Sensitive_Loss : 0.12402, Sensitive_Acc : 19.900, Run Time : 18.36 sec
INFO:root:2024-04-19 12:04:21, Train, Epoch : 6, Step : 3780, Loss : 0.43166, Acc : 0.787, Sensitive_Loss : 0.13477, Sensitive_Acc : 21.400, Run Time : 17.09 sec
INFO:root:2024-04-19 12:04:38, Train, Epoch : 6, Step : 3790, Loss : 0.41580, Acc : 0.841, Sensitive_Loss : 0.12088, Sensitive_Acc : 19.200, Run Time : 16.98 sec
INFO:root:2024-04-19 12:04:55, Train, Epoch : 6, Step : 3800, Loss : 0.41453, Acc : 0.825, Sensitive_Loss : 0.09473, Sensitive_Acc : 20.900, Run Time : 17.30 sec
INFO:root:2024-04-19 12:08:45, Dev, Step : 3800, Loss : 0.51320, Acc : 0.782, Auc : 0.856, Sensitive_Loss : 0.21012, Sensitive_Acc : 21.737, Sensitive_Auc : 0.996, Mean auc: 0.856, Run Time : 230.27 sec
INFO:root:2024-04-19 12:12:30
INFO:root:y_pred: [0.04446556 0.00411797 0.24330084 ... 0.50897485 0.02149933 0.01557818]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [1.81354675e-03 2.03819037e-03 4.89473939e-02 8.08266774e-02
 6.82729390e-03 9.56282078e-04 4.52820817e-03 6.20334875e-04
 2.76834443e-02 9.99963641e-01 1.11030035e-01 2.00415307e-04
 3.68682407e-02 3.67872854e-05 9.99878883e-01 1.30877970e-02
 3.93259712e-03 9.99842048e-01 9.97977078e-01 8.34277347e-02
 8.70169222e-01 8.33817030e-05 1.57695450e-02 2.30666992e-04
 1.88611552e-01 2.75524944e-01 5.04552561e-04 4.61000530e-03
 1.03824103e-04 2.29939260e-03 3.00806877e-03 9.95986164e-01
 2.82644272e-01 4.15597439e-01 3.16029618e-04 5.04844320e-05
 6.21418076e-05 1.09827951e-01 4.80154045e-02 3.84500138e-02
 3.74810070e-01 9.95286822e-01 2.62579066e-03 1.12681277e-03
 9.99149442e-01 6.75678372e-01 1.32936656e-01 4.04060781e-01
 3.48335356e-02 9.95284855e-01 9.83115971e-01 9.99426126e-01
 9.97419119e-01 8.99630177e-05 4.79286686e-02 5.24281338e-02
 4.54337113e-02 4.22485359e-02 9.89344120e-01 5.54908293e-05
 1.37513762e-05 1.06459600e-03 9.42578074e-03 6.71467860e-04
 9.99839544e-01 3.45059156e-01 1.48659339e-04 1.70985356e-01
 2.67427899e-02 9.90009487e-01 9.99889493e-01 9.99868274e-01
 1.09224522e-03 2.86610484e-01 3.73354647e-03 8.01468134e-01
 1.38614327e-02 2.28886211e-06 4.63458809e-06 1.38449576e-02
 2.61619896e-01 6.07145892e-04 9.99082327e-01 9.80429053e-01
 1.80026016e-03 3.27092223e-03 5.54896193e-03 7.93409272e-05
 3.37865698e-04 2.35120766e-03 3.67591088e-03 3.68282571e-02
 3.30958501e-05 1.66437712e-06 1.81532640e-04 8.52507714e-04
 2.51770864e-04 3.43017310e-01 1.48176923e-02 1.07763447e-02
 1.55778427e-04 7.30739348e-03 6.00605980e-02 5.67748677e-04
 2.56760512e-02 1.75537236e-04 5.74669205e-02 2.92851597e-01
 3.01171769e-03 5.05588651e-02 1.18107913e-04 9.99140978e-01
 9.99725282e-01 6.33295494e-05 7.15830997e-02 3.25500569e-03
 1.63504239e-02 2.49465720e-05 3.03544641e-01 3.00471880e-03
 1.31118402e-04 7.74819346e-04 3.64279151e-02 5.83203946e-05
 2.87545100e-03 9.21743333e-01 1.68177896e-04 9.98218834e-01
 1.46761723e-02 1.77133858e-01 1.34753156e-02 3.55909299e-03
 1.84692952e-04]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-19 12:12:31, Dev, Step : 3804, Loss : 0.51091, Acc : 0.782, Auc : 0.856, Sensitive_Loss : 0.19333, Sensitive_Acc : 21.857, Sensitive_Auc : 0.996, Mean auc: 0.856, Run Time : 223.25 sec
INFO:root:2024-04-19 12:12:45, Train, Epoch : 7, Step : 3810, Loss : 0.21349, Acc : 0.516, Sensitive_Loss : 0.08078, Sensitive_Acc : 14.100, Run Time : 13.12 sec
INFO:root:2024-04-19 12:13:02, Train, Epoch : 7, Step : 3820, Loss : 0.35784, Acc : 0.844, Sensitive_Loss : 0.12302, Sensitive_Acc : 20.800, Run Time : 17.29 sec
INFO:root:2024-04-19 12:13:19, Train, Epoch : 7, Step : 3830, Loss : 0.31775, Acc : 0.850, Sensitive_Loss : 0.11867, Sensitive_Acc : 20.200, Run Time : 16.93 sec
INFO:root:2024-04-19 12:13:37, Train, Epoch : 7, Step : 3840, Loss : 0.31218, Acc : 0.897, Sensitive_Loss : 0.14069, Sensitive_Acc : 23.300, Run Time : 17.60 sec
INFO:root:2024-04-19 12:13:53, Train, Epoch : 7, Step : 3850, Loss : 0.34404, Acc : 0.838, Sensitive_Loss : 0.17411, Sensitive_Acc : 22.900, Run Time : 16.13 sec
INFO:root:2024-04-19 12:14:10, Train, Epoch : 7, Step : 3860, Loss : 0.35325, Acc : 0.844, Sensitive_Loss : 0.09736, Sensitive_Acc : 18.800, Run Time : 17.41 sec
INFO:root:2024-04-19 12:14:29, Train, Epoch : 7, Step : 3870, Loss : 0.42377, Acc : 0.841, Sensitive_Loss : 0.12438, Sensitive_Acc : 17.600, Run Time : 18.11 sec
INFO:root:2024-04-19 12:14:45, Train, Epoch : 7, Step : 3880, Loss : 0.35318, Acc : 0.844, Sensitive_Loss : 0.12258, Sensitive_Acc : 22.000, Run Time : 16.39 sec
INFO:root:2024-04-19 12:15:04, Train, Epoch : 7, Step : 3890, Loss : 0.37011, Acc : 0.838, Sensitive_Loss : 0.11291, Sensitive_Acc : 24.000, Run Time : 18.60 sec
INFO:root:2024-04-19 12:15:20, Train, Epoch : 7, Step : 3900, Loss : 0.37089, Acc : 0.869, Sensitive_Loss : 0.09151, Sensitive_Acc : 21.900, Run Time : 16.82 sec
INFO:root:2024-04-19 12:19:08, Dev, Step : 3900, Loss : 0.53407, Acc : 0.779, Auc : 0.858, Sensitive_Loss : 0.19437, Sensitive_Acc : 21.857, Sensitive_Auc : 0.997, Mean auc: 0.858, Run Time : 227.63 sec
INFO:root:2024-04-19 12:19:22, Train, Epoch : 7, Step : 3910, Loss : 0.32789, Acc : 0.828, Sensitive_Loss : 0.14212, Sensitive_Acc : 22.800, Run Time : 241.19 sec
INFO:root:2024-04-19 12:19:37, Train, Epoch : 7, Step : 3920, Loss : 0.33107, Acc : 0.847, Sensitive_Loss : 0.11027, Sensitive_Acc : 23.100, Run Time : 15.30 sec
INFO:root:2024-04-19 12:19:54, Train, Epoch : 7, Step : 3930, Loss : 0.32572, Acc : 0.847, Sensitive_Loss : 0.24998, Sensitive_Acc : 20.800, Run Time : 17.44 sec
INFO:root:2024-04-19 12:20:13, Train, Epoch : 7, Step : 3940, Loss : 0.35890, Acc : 0.869, Sensitive_Loss : 0.12188, Sensitive_Acc : 22.700, Run Time : 18.27 sec
INFO:root:2024-04-19 12:20:30, Train, Epoch : 7, Step : 3950, Loss : 0.34026, Acc : 0.863, Sensitive_Loss : 0.10165, Sensitive_Acc : 22.900, Run Time : 17.07 sec
INFO:root:2024-04-19 12:20:47, Train, Epoch : 7, Step : 3960, Loss : 0.29947, Acc : 0.872, Sensitive_Loss : 0.10327, Sensitive_Acc : 19.300, Run Time : 17.10 sec
INFO:root:2024-04-19 12:21:03, Train, Epoch : 7, Step : 3970, Loss : 0.32417, Acc : 0.847, Sensitive_Loss : 0.11374, Sensitive_Acc : 18.700, Run Time : 16.30 sec
INFO:root:2024-04-19 12:21:21, Train, Epoch : 7, Step : 3980, Loss : 0.34628, Acc : 0.834, Sensitive_Loss : 0.13048, Sensitive_Acc : 21.000, Run Time : 17.50 sec
INFO:root:2024-04-19 12:21:38, Train, Epoch : 7, Step : 3990, Loss : 0.42980, Acc : 0.834, Sensitive_Loss : 0.14578, Sensitive_Acc : 20.700, Run Time : 17.10 sec
INFO:root:2024-04-19 12:21:55, Train, Epoch : 7, Step : 4000, Loss : 0.31627, Acc : 0.872, Sensitive_Loss : 0.11810, Sensitive_Acc : 22.900, Run Time : 16.95 sec
INFO:root:2024-04-19 12:25:45, Dev, Step : 4000, Loss : 0.53075, Acc : 0.783, Auc : 0.859, Sensitive_Loss : 0.23012, Sensitive_Acc : 21.226, Sensitive_Auc : 0.996, Mean auc: 0.859, Run Time : 230.71 sec
INFO:root:2024-04-19 12:25:58, Train, Epoch : 7, Step : 4010, Loss : 0.30472, Acc : 0.825, Sensitive_Loss : 0.13233, Sensitive_Acc : 21.500, Run Time : 242.92 sec
INFO:root:2024-04-19 12:26:15, Train, Epoch : 7, Step : 4020, Loss : 0.39251, Acc : 0.838, Sensitive_Loss : 0.14875, Sensitive_Acc : 23.200, Run Time : 17.50 sec
INFO:root:2024-04-19 12:26:34, Train, Epoch : 7, Step : 4030, Loss : 0.32863, Acc : 0.844, Sensitive_Loss : 0.13531, Sensitive_Acc : 21.200, Run Time : 18.40 sec
INFO:root:2024-04-19 12:26:51, Train, Epoch : 7, Step : 4040, Loss : 0.37713, Acc : 0.863, Sensitive_Loss : 0.10918, Sensitive_Acc : 19.200, Run Time : 17.51 sec
INFO:root:2024-04-19 12:27:09, Train, Epoch : 7, Step : 4050, Loss : 0.36641, Acc : 0.859, Sensitive_Loss : 0.12271, Sensitive_Acc : 23.500, Run Time : 17.66 sec
INFO:root:2024-04-19 12:27:27, Train, Epoch : 7, Step : 4060, Loss : 0.40352, Acc : 0.806, Sensitive_Loss : 0.12704, Sensitive_Acc : 22.100, Run Time : 17.84 sec
INFO:root:2024-04-19 12:27:42, Train, Epoch : 7, Step : 4070, Loss : 0.37188, Acc : 0.806, Sensitive_Loss : 0.09097, Sensitive_Acc : 21.000, Run Time : 15.44 sec
INFO:root:2024-04-19 12:28:00, Train, Epoch : 7, Step : 4080, Loss : 0.31563, Acc : 0.859, Sensitive_Loss : 0.16954, Sensitive_Acc : 21.900, Run Time : 17.58 sec
INFO:root:2024-04-19 12:28:16, Train, Epoch : 7, Step : 4090, Loss : 0.33377, Acc : 0.853, Sensitive_Loss : 0.11982, Sensitive_Acc : 23.800, Run Time : 16.61 sec
INFO:root:2024-04-19 12:28:32, Train, Epoch : 7, Step : 4100, Loss : 0.34050, Acc : 0.859, Sensitive_Loss : 0.14868, Sensitive_Acc : 24.200, Run Time : 16.21 sec
INFO:root:2024-04-19 12:32:23, Dev, Step : 4100, Loss : 0.53001, Acc : 0.779, Auc : 0.855, Sensitive_Loss : 0.20266, Sensitive_Acc : 21.692, Sensitive_Auc : 0.994, Mean auc: 0.855, Run Time : 230.98 sec
INFO:root:2024-04-19 12:32:36, Train, Epoch : 7, Step : 4110, Loss : 0.42528, Acc : 0.828, Sensitive_Loss : 0.12766, Sensitive_Acc : 22.400, Run Time : 243.82 sec
INFO:root:2024-04-19 12:32:53, Train, Epoch : 7, Step : 4120, Loss : 0.36461, Acc : 0.841, Sensitive_Loss : 0.13504, Sensitive_Acc : 21.900, Run Time : 16.56 sec
INFO:root:2024-04-19 12:33:09, Train, Epoch : 7, Step : 4130, Loss : 0.36873, Acc : 0.819, Sensitive_Loss : 0.12449, Sensitive_Acc : 18.700, Run Time : 16.57 sec
INFO:root:2024-04-19 12:33:27, Train, Epoch : 7, Step : 4140, Loss : 0.38510, Acc : 0.825, Sensitive_Loss : 0.08874, Sensitive_Acc : 20.700, Run Time : 17.86 sec
INFO:root:2024-04-19 12:33:43, Train, Epoch : 7, Step : 4150, Loss : 0.37005, Acc : 0.866, Sensitive_Loss : 0.10235, Sensitive_Acc : 23.900, Run Time : 15.83 sec
INFO:root:2024-04-19 12:34:01, Train, Epoch : 7, Step : 4160, Loss : 0.33894, Acc : 0.844, Sensitive_Loss : 0.13750, Sensitive_Acc : 24.100, Run Time : 17.99 sec
INFO:root:2024-04-19 12:34:17, Train, Epoch : 7, Step : 4170, Loss : 0.38980, Acc : 0.856, Sensitive_Loss : 0.12560, Sensitive_Acc : 18.100, Run Time : 16.11 sec
INFO:root:2024-04-19 12:34:34, Train, Epoch : 7, Step : 4180, Loss : 0.31403, Acc : 0.866, Sensitive_Loss : 0.12002, Sensitive_Acc : 21.500, Run Time : 17.20 sec
INFO:root:2024-04-19 12:34:52, Train, Epoch : 7, Step : 4190, Loss : 0.31802, Acc : 0.866, Sensitive_Loss : 0.17979, Sensitive_Acc : 20.200, Run Time : 17.71 sec
INFO:root:2024-04-19 12:35:08, Train, Epoch : 7, Step : 4200, Loss : 0.36571, Acc : 0.863, Sensitive_Loss : 0.13725, Sensitive_Acc : 22.200, Run Time : 16.18 sec
INFO:root:2024-04-19 12:38:58, Dev, Step : 4200, Loss : 0.58003, Acc : 0.765, Auc : 0.854, Sensitive_Loss : 0.19283, Sensitive_Acc : 21.857, Sensitive_Auc : 0.994, Mean auc: 0.854, Run Time : 229.92 sec
INFO:root:2024-04-19 12:39:11, Train, Epoch : 7, Step : 4210, Loss : 0.38506, Acc : 0.816, Sensitive_Loss : 0.12144, Sensitive_Acc : 22.500, Run Time : 242.43 sec
INFO:root:2024-04-19 12:39:28, Train, Epoch : 7, Step : 4220, Loss : 0.40251, Acc : 0.812, Sensitive_Loss : 0.10263, Sensitive_Acc : 20.300, Run Time : 17.83 sec
INFO:root:2024-04-19 12:39:46, Train, Epoch : 7, Step : 4230, Loss : 0.35960, Acc : 0.853, Sensitive_Loss : 0.13166, Sensitive_Acc : 19.400, Run Time : 17.15 sec
INFO:root:2024-04-19 12:40:01, Train, Epoch : 7, Step : 4240, Loss : 0.38129, Acc : 0.847, Sensitive_Loss : 0.11162, Sensitive_Acc : 24.300, Run Time : 15.80 sec
INFO:root:2024-04-19 12:40:19, Train, Epoch : 7, Step : 4250, Loss : 0.34502, Acc : 0.850, Sensitive_Loss : 0.09604, Sensitive_Acc : 20.700, Run Time : 17.30 sec
INFO:root:2024-04-19 12:40:36, Train, Epoch : 7, Step : 4260, Loss : 0.38681, Acc : 0.831, Sensitive_Loss : 0.12919, Sensitive_Acc : 18.400, Run Time : 17.27 sec
INFO:root:2024-04-19 12:40:55, Train, Epoch : 7, Step : 4270, Loss : 0.38207, Acc : 0.831, Sensitive_Loss : 0.08646, Sensitive_Acc : 17.500, Run Time : 18.65 sec
INFO:root:2024-04-19 12:41:13, Train, Epoch : 7, Step : 4280, Loss : 0.34297, Acc : 0.866, Sensitive_Loss : 0.10273, Sensitive_Acc : 20.200, Run Time : 17.92 sec
INFO:root:2024-04-19 12:41:29, Train, Epoch : 7, Step : 4290, Loss : 0.36816, Acc : 0.816, Sensitive_Loss : 0.10270, Sensitive_Acc : 19.100, Run Time : 16.55 sec
INFO:root:2024-04-19 12:41:46, Train, Epoch : 7, Step : 4300, Loss : 0.40238, Acc : 0.834, Sensitive_Loss : 0.10166, Sensitive_Acc : 21.200, Run Time : 16.93 sec
INFO:root:2024-04-19 12:45:35, Dev, Step : 4300, Loss : 0.56157, Acc : 0.772, Auc : 0.854, Sensitive_Loss : 0.20343, Sensitive_Acc : 21.571, Sensitive_Auc : 0.994, Mean auc: 0.854, Run Time : 229.05 sec
INFO:root:2024-04-19 12:45:48, Train, Epoch : 7, Step : 4310, Loss : 0.36125, Acc : 0.847, Sensitive_Loss : 0.11264, Sensitive_Acc : 25.500, Run Time : 241.79 sec
INFO:root:2024-04-19 12:46:04, Train, Epoch : 7, Step : 4320, Loss : 0.37647, Acc : 0.822, Sensitive_Loss : 0.12380, Sensitive_Acc : 22.700, Run Time : 16.45 sec
INFO:root:2024-04-19 12:46:22, Train, Epoch : 7, Step : 4330, Loss : 0.44818, Acc : 0.816, Sensitive_Loss : 0.11084, Sensitive_Acc : 20.900, Run Time : 17.80 sec
INFO:root:2024-04-19 12:46:39, Train, Epoch : 7, Step : 4340, Loss : 0.31658, Acc : 0.853, Sensitive_Loss : 0.14808, Sensitive_Acc : 18.700, Run Time : 17.28 sec
INFO:root:2024-04-19 12:46:55, Train, Epoch : 7, Step : 4350, Loss : 0.40904, Acc : 0.831, Sensitive_Loss : 0.17637, Sensitive_Acc : 23.000, Run Time : 15.97 sec
INFO:root:2024-04-19 12:47:13, Train, Epoch : 7, Step : 4360, Loss : 0.35969, Acc : 0.831, Sensitive_Loss : 0.12484, Sensitive_Acc : 18.500, Run Time : 17.63 sec
INFO:root:2024-04-19 12:47:30, Train, Epoch : 7, Step : 4370, Loss : 0.37690, Acc : 0.850, Sensitive_Loss : 0.12544, Sensitive_Acc : 25.100, Run Time : 17.17 sec
INFO:root:2024-04-19 12:47:47, Train, Epoch : 7, Step : 4380, Loss : 0.36633, Acc : 0.859, Sensitive_Loss : 0.11861, Sensitive_Acc : 23.400, Run Time : 17.02 sec
INFO:root:2024-04-19 12:48:04, Train, Epoch : 7, Step : 4390, Loss : 0.32963, Acc : 0.834, Sensitive_Loss : 0.10064, Sensitive_Acc : 24.300, Run Time : 17.35 sec
INFO:root:2024-04-19 12:48:22, Train, Epoch : 7, Step : 4400, Loss : 0.34539, Acc : 0.866, Sensitive_Loss : 0.11008, Sensitive_Acc : 22.100, Run Time : 17.48 sec
INFO:root:2024-04-19 12:52:12, Dev, Step : 4400, Loss : 0.53056, Acc : 0.781, Auc : 0.856, Sensitive_Loss : 0.21514, Sensitive_Acc : 21.346, Sensitive_Auc : 0.995, Mean auc: 0.856, Run Time : 229.87 sec
INFO:root:2024-04-19 12:52:24, Train, Epoch : 7, Step : 4410, Loss : 0.34955, Acc : 0.850, Sensitive_Loss : 0.09014, Sensitive_Acc : 22.700, Run Time : 242.02 sec
INFO:root:2024-04-19 12:52:44, Train, Epoch : 7, Step : 4420, Loss : 0.39262, Acc : 0.812, Sensitive_Loss : 0.12977, Sensitive_Acc : 24.700, Run Time : 19.90 sec
INFO:root:2024-04-19 12:53:02, Train, Epoch : 7, Step : 4430, Loss : 0.33597, Acc : 0.850, Sensitive_Loss : 0.08686, Sensitive_Acc : 23.100, Run Time : 17.99 sec
INFO:root:2024-04-19 12:57:18
INFO:root:y_pred: [0.01994969 0.00143614 0.16937214 ... 0.36320573 0.00802739 0.004153  ]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [2.0499914e-03 2.3680516e-03 2.0196448e-01 4.8611540e-02 1.8335486e-02
 5.6057930e-04 4.7033289e-03 7.2947034e-04 4.2609960e-02 9.9998128e-01
 1.3358860e-01 1.2225127e-04 1.0926610e-01 5.1784886e-05 9.9980754e-01
 1.7211793e-02 4.6404894e-03 9.9973220e-01 9.9801898e-01 6.7901447e-02
 9.4301480e-01 1.1402058e-04 1.4628331e-02 5.5714325e-05 3.1236777e-01
 3.3652705e-01 1.7797596e-04 2.8022912e-03 9.4034644e-05 1.9573933e-03
 1.5732709e-03 9.9633151e-01 2.2007662e-01 4.5285147e-01 2.0311822e-04
 1.0135092e-04 7.3877156e-05 6.6430159e-02 5.5484343e-02 2.9999167e-02
 2.7954748e-01 9.9845076e-01 5.6399773e-03 2.7872212e-03 9.9998212e-01
 8.8005245e-01 1.1659837e-01 3.4499714e-01 3.3489447e-02 9.9203730e-01
 9.9141204e-01 9.9958307e-01 9.9855942e-01 2.0413990e-04 8.3487965e-02
 5.4153565e-02 1.0360154e-01 8.3865799e-02 9.8648524e-01 1.8275269e-04
 8.6675127e-06 1.3463681e-03 1.0533265e-02 5.3359190e-04 9.9984014e-01
 5.9552616e-01 2.7846656e-04 3.7481660e-01 4.3200038e-02 9.9697638e-01
 9.9992132e-01 9.9994373e-01 5.6723325e-04 2.2978716e-01 3.5307051e-03
 7.4824274e-01 2.5362747e-02 3.2948535e-07 2.5980162e-06 7.9760933e-03
 1.7396808e-01 3.9942097e-04 9.9885857e-01 9.9159873e-01 2.1415306e-03
 1.7012261e-03 1.1261087e-02 1.3265328e-04 5.4522051e-04 3.3877750e-03
 6.1784741e-03 6.0835704e-02 1.9271409e-05 2.2254204e-07 7.3962752e-04
 1.5577964e-03 4.4046808e-04 4.4274968e-01 5.7312012e-02 1.9979721e-02
 1.2985586e-04 8.0870073e-03 4.9124807e-02 1.1966394e-03 1.2266375e-02
 1.7892181e-04 1.7328192e-01 4.3332663e-01 1.6724524e-03 2.5813160e-02
 1.0668055e-04 9.9926192e-01 9.9963677e-01 6.8941728e-05 2.2633111e-01
 6.9191293e-03 3.8428247e-02 7.8944635e-05 3.2425979e-01 2.6466174e-03
 6.0412724e-04 5.8341830e-04 4.9534261e-02 6.5656575e-05 1.0321521e-02
 8.9893734e-01 9.7566430e-05 9.9882942e-01 1.6030494e-02 9.4437204e-02
 1.6894190e-02 1.4764432e-02 3.1053825e-04]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-19 12:57:18, Dev, Step : 4438, Loss : 0.55143, Acc : 0.776, Auc : 0.855, Sensitive_Loss : 0.19705, Sensitive_Acc : 21.692, Sensitive_Auc : 0.997, Mean auc: 0.855, Run Time : 239.09 sec
INFO:root:2024-04-19 12:57:25, Train, Epoch : 8, Step : 4440, Loss : 0.07498, Acc : 0.169, Sensitive_Loss : 0.00918, Sensitive_Acc : 4.700, Run Time : 5.90 sec
INFO:root:2024-04-19 12:57:44, Train, Epoch : 8, Step : 4450, Loss : 0.33173, Acc : 0.859, Sensitive_Loss : 0.09619, Sensitive_Acc : 19.400, Run Time : 19.10 sec
INFO:root:2024-04-19 12:58:02, Train, Epoch : 8, Step : 4460, Loss : 0.40116, Acc : 0.844, Sensitive_Loss : 0.15935, Sensitive_Acc : 22.000, Run Time : 17.57 sec
INFO:root:2024-04-19 12:58:18, Train, Epoch : 8, Step : 4470, Loss : 0.35573, Acc : 0.853, Sensitive_Loss : 0.16634, Sensitive_Acc : 25.000, Run Time : 16.23 sec
INFO:root:2024-04-19 12:58:39, Train, Epoch : 8, Step : 4480, Loss : 0.30194, Acc : 0.863, Sensitive_Loss : 0.14434, Sensitive_Acc : 24.600, Run Time : 21.19 sec
INFO:root:2024-04-19 12:59:01, Train, Epoch : 8, Step : 4490, Loss : 0.34628, Acc : 0.866, Sensitive_Loss : 0.14736, Sensitive_Acc : 23.900, Run Time : 21.40 sec
INFO:root:2024-04-19 12:59:18, Train, Epoch : 8, Step : 4500, Loss : 0.31376, Acc : 0.878, Sensitive_Loss : 0.10237, Sensitive_Acc : 23.000, Run Time : 17.78 sec
INFO:root:2024-04-19 13:03:07, Dev, Step : 4500, Loss : 0.53966, Acc : 0.781, Auc : 0.857, Sensitive_Loss : 0.18323, Sensitive_Acc : 21.692, Sensitive_Auc : 0.996, Mean auc: 0.857, Run Time : 228.33 sec
INFO:root:2024-04-19 13:03:19, Train, Epoch : 8, Step : 4510, Loss : 0.33254, Acc : 0.856, Sensitive_Loss : 0.09747, Sensitive_Acc : 17.900, Run Time : 240.93 sec
INFO:root:2024-04-19 13:03:38, Train, Epoch : 8, Step : 4520, Loss : 0.40292, Acc : 0.850, Sensitive_Loss : 0.12341, Sensitive_Acc : 15.600, Run Time : 18.65 sec
INFO:root:2024-04-19 13:03:54, Train, Epoch : 8, Step : 4530, Loss : 0.26820, Acc : 0.903, Sensitive_Loss : 0.07753, Sensitive_Acc : 22.200, Run Time : 15.72 sec
INFO:root:2024-04-19 13:04:12, Train, Epoch : 8, Step : 4540, Loss : 0.36368, Acc : 0.831, Sensitive_Loss : 0.10432, Sensitive_Acc : 19.200, Run Time : 17.80 sec
INFO:root:2024-04-19 13:04:28, Train, Epoch : 8, Step : 4550, Loss : 0.29185, Acc : 0.875, Sensitive_Loss : 0.15290, Sensitive_Acc : 26.100, Run Time : 16.97 sec
INFO:root:2024-04-19 13:04:46, Train, Epoch : 8, Step : 4560, Loss : 0.31109, Acc : 0.869, Sensitive_Loss : 0.12276, Sensitive_Acc : 19.300, Run Time : 17.74 sec
INFO:root:2024-04-19 13:05:03, Train, Epoch : 8, Step : 4570, Loss : 0.31012, Acc : 0.875, Sensitive_Loss : 0.11065, Sensitive_Acc : 21.300, Run Time : 16.96 sec
INFO:root:2024-04-19 13:05:20, Train, Epoch : 8, Step : 4580, Loss : 0.36645, Acc : 0.866, Sensitive_Loss : 0.11882, Sensitive_Acc : 17.300, Run Time : 16.52 sec
INFO:root:2024-04-19 13:05:37, Train, Epoch : 8, Step : 4590, Loss : 0.32139, Acc : 0.863, Sensitive_Loss : 0.07256, Sensitive_Acc : 25.100, Run Time : 17.33 sec
INFO:root:2024-04-19 13:05:55, Train, Epoch : 8, Step : 4600, Loss : 0.33826, Acc : 0.850, Sensitive_Loss : 0.14202, Sensitive_Acc : 20.700, Run Time : 18.05 sec
INFO:root:2024-04-19 13:09:45, Dev, Step : 4600, Loss : 0.52983, Acc : 0.782, Auc : 0.853, Sensitive_Loss : 0.20227, Sensitive_Acc : 21.571, Sensitive_Auc : 0.996, Mean auc: 0.853, Run Time : 229.97 sec
INFO:root:2024-04-19 13:09:58, Train, Epoch : 8, Step : 4610, Loss : 0.35944, Acc : 0.844, Sensitive_Loss : 0.12371, Sensitive_Acc : 18.600, Run Time : 242.73 sec
INFO:root:2024-04-19 13:10:15, Train, Epoch : 8, Step : 4620, Loss : 0.36056, Acc : 0.831, Sensitive_Loss : 0.13382, Sensitive_Acc : 19.200, Run Time : 17.07 sec
INFO:root:2024-04-19 13:10:33, Train, Epoch : 8, Step : 4630, Loss : 0.33029, Acc : 0.881, Sensitive_Loss : 0.16991, Sensitive_Acc : 25.600, Run Time : 17.64 sec
INFO:root:2024-04-19 13:10:49, Train, Epoch : 8, Step : 4640, Loss : 0.34822, Acc : 0.844, Sensitive_Loss : 0.14963, Sensitive_Acc : 24.700, Run Time : 16.12 sec
INFO:root:2024-04-19 13:11:07, Train, Epoch : 8, Step : 4650, Loss : 0.39515, Acc : 0.850, Sensitive_Loss : 0.07654, Sensitive_Acc : 23.100, Run Time : 17.91 sec
INFO:root:2024-04-19 13:11:23, Train, Epoch : 8, Step : 4660, Loss : 0.31644, Acc : 0.878, Sensitive_Loss : 0.13442, Sensitive_Acc : 23.900, Run Time : 16.18 sec
INFO:root:2024-04-19 13:11:41, Train, Epoch : 8, Step : 4670, Loss : 0.30984, Acc : 0.872, Sensitive_Loss : 0.13280, Sensitive_Acc : 23.800, Run Time : 17.96 sec
INFO:root:2024-04-19 13:11:57, Train, Epoch : 8, Step : 4680, Loss : 0.34919, Acc : 0.869, Sensitive_Loss : 0.09669, Sensitive_Acc : 21.200, Run Time : 16.36 sec
INFO:root:2024-04-19 13:12:13, Train, Epoch : 8, Step : 4690, Loss : 0.28820, Acc : 0.853, Sensitive_Loss : 0.10189, Sensitive_Acc : 21.200, Run Time : 16.17 sec
INFO:root:2024-04-19 13:12:32, Train, Epoch : 8, Step : 4700, Loss : 0.34175, Acc : 0.875, Sensitive_Loss : 0.11300, Sensitive_Acc : 23.700, Run Time : 19.01 sec
INFO:root:2024-04-19 13:16:21, Dev, Step : 4700, Loss : 0.53977, Acc : 0.782, Auc : 0.853, Sensitive_Loss : 0.20248, Sensitive_Acc : 21.571, Sensitive_Auc : 0.996, Mean auc: 0.853, Run Time : 229.22 sec
INFO:root:2024-04-19 13:16:33, Train, Epoch : 8, Step : 4710, Loss : 0.32595, Acc : 0.847, Sensitive_Loss : 0.11074, Sensitive_Acc : 17.000, Run Time : 240.28 sec
INFO:root:2024-04-19 13:16:50, Train, Epoch : 8, Step : 4720, Loss : 0.36448, Acc : 0.853, Sensitive_Loss : 0.14286, Sensitive_Acc : 19.500, Run Time : 17.35 sec
INFO:root:2024-04-19 13:17:07, Train, Epoch : 8, Step : 4730, Loss : 0.34933, Acc : 0.847, Sensitive_Loss : 0.19596, Sensitive_Acc : 23.100, Run Time : 16.62 sec
INFO:root:2024-04-19 13:17:28, Train, Epoch : 8, Step : 4740, Loss : 0.35007, Acc : 0.834, Sensitive_Loss : 0.10202, Sensitive_Acc : 23.700, Run Time : 21.30 sec
INFO:root:2024-04-19 13:17:45, Train, Epoch : 8, Step : 4750, Loss : 0.33103, Acc : 0.856, Sensitive_Loss : 0.14716, Sensitive_Acc : 18.000, Run Time : 17.60 sec
INFO:root:2024-04-19 13:18:03, Train, Epoch : 8, Step : 4760, Loss : 0.27594, Acc : 0.869, Sensitive_Loss : 0.09703, Sensitive_Acc : 23.900, Run Time : 17.28 sec
INFO:root:2024-04-19 13:18:19, Train, Epoch : 8, Step : 4770, Loss : 0.36478, Acc : 0.831, Sensitive_Loss : 0.07686, Sensitive_Acc : 23.600, Run Time : 16.32 sec
INFO:root:2024-04-19 13:18:37, Train, Epoch : 8, Step : 4780, Loss : 0.30905, Acc : 0.881, Sensitive_Loss : 0.07647, Sensitive_Acc : 18.800, Run Time : 18.42 sec
INFO:root:2024-04-19 13:18:53, Train, Epoch : 8, Step : 4790, Loss : 0.38628, Acc : 0.831, Sensitive_Loss : 0.12297, Sensitive_Acc : 23.600, Run Time : 15.66 sec
INFO:root:2024-04-19 13:19:11, Train, Epoch : 8, Step : 4800, Loss : 0.33596, Acc : 0.847, Sensitive_Loss : 0.10117, Sensitive_Acc : 22.100, Run Time : 18.42 sec
INFO:root:2024-04-19 13:23:01, Dev, Step : 4800, Loss : 0.56622, Acc : 0.772, Auc : 0.848, Sensitive_Loss : 0.20017, Sensitive_Acc : 21.737, Sensitive_Auc : 0.996, Mean auc: 0.848, Run Time : 229.72 sec
INFO:root:2024-04-19 13:23:13, Train, Epoch : 8, Step : 4810, Loss : 0.35654, Acc : 0.856, Sensitive_Loss : 0.10152, Sensitive_Acc : 24.100, Run Time : 241.99 sec
INFO:root:2024-04-19 13:23:31, Train, Epoch : 8, Step : 4820, Loss : 0.30991, Acc : 0.872, Sensitive_Loss : 0.06517, Sensitive_Acc : 18.800, Run Time : 17.35 sec
INFO:root:2024-04-19 13:23:48, Train, Epoch : 8, Step : 4830, Loss : 0.38996, Acc : 0.847, Sensitive_Loss : 0.10856, Sensitive_Acc : 27.100, Run Time : 17.41 sec
INFO:root:2024-04-19 13:24:06, Train, Epoch : 8, Step : 4840, Loss : 0.31665, Acc : 0.863, Sensitive_Loss : 0.09269, Sensitive_Acc : 20.900, Run Time : 18.17 sec
INFO:root:2024-04-19 13:24:23, Train, Epoch : 8, Step : 4850, Loss : 0.31318, Acc : 0.891, Sensitive_Loss : 0.10002, Sensitive_Acc : 21.100, Run Time : 16.96 sec
INFO:root:2024-04-19 13:24:39, Train, Epoch : 8, Step : 4860, Loss : 0.31048, Acc : 0.853, Sensitive_Loss : 0.17286, Sensitive_Acc : 17.700, Run Time : 15.43 sec
INFO:root:2024-04-19 13:24:57, Train, Epoch : 8, Step : 4870, Loss : 0.29565, Acc : 0.866, Sensitive_Loss : 0.10351, Sensitive_Acc : 23.800, Run Time : 17.83 sec
INFO:root:2024-04-19 13:25:14, Train, Epoch : 8, Step : 4880, Loss : 0.33954, Acc : 0.850, Sensitive_Loss : 0.13077, Sensitive_Acc : 25.700, Run Time : 17.26 sec
INFO:root:2024-04-19 13:25:31, Train, Epoch : 8, Step : 4890, Loss : 0.31615, Acc : 0.866, Sensitive_Loss : 0.17322, Sensitive_Acc : 20.500, Run Time : 17.06 sec
INFO:root:2024-04-19 13:25:47, Train, Epoch : 8, Step : 4900, Loss : 0.37414, Acc : 0.853, Sensitive_Loss : 0.14497, Sensitive_Acc : 22.800, Run Time : 16.45 sec
INFO:root:2024-04-19 13:29:38, Dev, Step : 4900, Loss : 0.56872, Acc : 0.769, Auc : 0.852, Sensitive_Loss : 0.19428, Sensitive_Acc : 21.692, Sensitive_Auc : 0.997, Mean auc: 0.852, Run Time : 230.24 sec
INFO:root:2024-04-19 13:29:49, Train, Epoch : 8, Step : 4910, Loss : 0.36978, Acc : 0.834, Sensitive_Loss : 0.12445, Sensitive_Acc : 22.600, Run Time : 241.35 sec
INFO:root:2024-04-19 13:30:07, Train, Epoch : 8, Step : 4920, Loss : 0.35862, Acc : 0.844, Sensitive_Loss : 0.16800, Sensitive_Acc : 26.100, Run Time : 18.49 sec
INFO:root:2024-04-19 13:30:26, Train, Epoch : 8, Step : 4930, Loss : 0.34708, Acc : 0.863, Sensitive_Loss : 0.14133, Sensitive_Acc : 17.800, Run Time : 18.27 sec
INFO:root:2024-04-19 13:30:42, Train, Epoch : 8, Step : 4940, Loss : 0.38397, Acc : 0.809, Sensitive_Loss : 0.09767, Sensitive_Acc : 20.300, Run Time : 16.41 sec
INFO:root:2024-04-19 13:30:59, Train, Epoch : 8, Step : 4950, Loss : 0.33325, Acc : 0.847, Sensitive_Loss : 0.09020, Sensitive_Acc : 24.300, Run Time : 17.05 sec
INFO:root:2024-04-19 13:31:16, Train, Epoch : 8, Step : 4960, Loss : 0.38008, Acc : 0.822, Sensitive_Loss : 0.10724, Sensitive_Acc : 19.500, Run Time : 17.32 sec
INFO:root:2024-04-19 13:31:32, Train, Epoch : 8, Step : 4970, Loss : 0.40736, Acc : 0.847, Sensitive_Loss : 0.10993, Sensitive_Acc : 20.500, Run Time : 15.62 sec
INFO:root:2024-04-19 13:31:49, Train, Epoch : 8, Step : 4980, Loss : 0.33880, Acc : 0.850, Sensitive_Loss : 0.19185, Sensitive_Acc : 22.100, Run Time : 17.29 sec
INFO:root:2024-04-19 13:32:06, Train, Epoch : 8, Step : 4990, Loss : 0.28019, Acc : 0.853, Sensitive_Loss : 0.14959, Sensitive_Acc : 19.700, Run Time : 16.64 sec
INFO:root:2024-04-19 13:32:23, Train, Epoch : 8, Step : 5000, Loss : 0.37161, Acc : 0.841, Sensitive_Loss : 0.10700, Sensitive_Acc : 18.600, Run Time : 17.04 sec
INFO:root:2024-04-19 13:36:14, Dev, Step : 5000, Loss : 0.55190, Acc : 0.781, Auc : 0.854, Sensitive_Loss : 0.20355, Sensitive_Acc : 21.857, Sensitive_Auc : 0.994, Mean auc: 0.854, Run Time : 230.85 sec
INFO:root:2024-04-19 13:36:25, Train, Epoch : 8, Step : 5010, Loss : 0.28270, Acc : 0.881, Sensitive_Loss : 0.14306, Sensitive_Acc : 21.500, Run Time : 242.46 sec
INFO:root:2024-04-19 13:36:43, Train, Epoch : 8, Step : 5020, Loss : 0.35198, Acc : 0.838, Sensitive_Loss : 0.19125, Sensitive_Acc : 21.100, Run Time : 17.81 sec
INFO:root:2024-04-19 13:37:01, Train, Epoch : 8, Step : 5030, Loss : 0.26670, Acc : 0.894, Sensitive_Loss : 0.11584, Sensitive_Acc : 19.600, Run Time : 17.73 sec
INFO:root:2024-04-19 13:37:18, Train, Epoch : 8, Step : 5040, Loss : 0.34938, Acc : 0.863, Sensitive_Loss : 0.15126, Sensitive_Acc : 23.800, Run Time : 17.52 sec
INFO:root:2024-04-19 13:37:39, Train, Epoch : 8, Step : 5050, Loss : 0.30862, Acc : 0.850, Sensitive_Loss : 0.09821, Sensitive_Acc : 20.600, Run Time : 20.78 sec
INFO:root:2024-04-19 13:37:55, Train, Epoch : 8, Step : 5060, Loss : 0.28485, Acc : 0.878, Sensitive_Loss : 0.12343, Sensitive_Acc : 23.800, Run Time : 16.00 sec
INFO:root:2024-04-19 13:38:12, Train, Epoch : 8, Step : 5070, Loss : 0.26911, Acc : 0.884, Sensitive_Loss : 0.12309, Sensitive_Acc : 22.000, Run Time : 16.53 sec
INFO:root:2024-04-19 13:42:03
INFO:root:y_pred: [0.01891615 0.0015724  0.13935824 ... 0.37532684 0.00119437 0.00744442]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [3.85407987e-03 2.06411211e-03 1.04788736e-01 4.35235724e-02
 1.46071706e-02 8.58616258e-04 2.97151972e-03 4.34692454e-04
 1.00038936e-02 9.99979258e-01 7.03515634e-02 2.90489115e-04
 5.76463416e-02 1.96843321e-04 9.99839902e-01 7.49514950e-03
 4.93415818e-03 9.99907970e-01 9.98596132e-01 3.01766414e-02
 9.68913496e-01 7.67679521e-05 4.11616964e-03 1.81840496e-05
 1.60537720e-01 4.50657576e-01 5.04566764e-04 5.94174210e-03
 7.91018319e-05 4.43199620e-04 7.54591892e-04 9.94231105e-01
 1.07546121e-01 5.16271710e-01 3.97786032e-04 6.03722256e-05
 3.93017508e-05 6.88180253e-02 5.22198826e-02 2.59354226e-02
 2.67880023e-01 9.97006238e-01 3.15853860e-03 2.46066949e-04
 9.99982953e-01 8.88884187e-01 1.00747786e-01 6.65943205e-01
 6.55943900e-02 9.90734696e-01 9.94704306e-01 9.99608696e-01
 9.99420285e-01 5.78655745e-05 8.37343112e-02 6.80558980e-02
 9.64000300e-02 5.30243628e-02 9.89354014e-01 7.75089065e-05
 1.46011780e-05 9.73210321e-04 8.19344539e-03 3.39070539e-04
 9.99702632e-01 4.08018172e-01 3.97254218e-04 3.30612630e-01
 8.65642354e-02 9.98580098e-01 9.99925613e-01 9.99966264e-01
 4.48943814e-04 4.74482358e-01 6.73272414e-03 8.42451811e-01
 1.68643519e-02 6.02427974e-07 2.88378260e-06 1.11258375e-02
 1.93617389e-01 8.84933863e-04 9.99356687e-01 9.96059656e-01
 6.76173309e-04 1.87264010e-03 7.30392477e-03 5.27702468e-05
 1.05621664e-04 2.62016337e-03 5.11617772e-03 5.05210198e-02
 3.71252972e-05 3.33523715e-08 1.02673468e-04 1.98086747e-03
 2.26722972e-04 3.31782818e-01 3.72132286e-02 1.29544511e-02
 4.67459358e-05 6.66558044e-03 8.37653577e-02 7.27034931e-04
 3.17718834e-02 1.83272539e-04 6.26960546e-02 4.20496643e-01
 7.10397493e-04 2.26283669e-02 1.79937386e-04 9.99537706e-01
 9.99554694e-01 8.42354711e-05 9.14609134e-02 1.10894926e-02
 4.96742316e-02 4.83525109e-05 3.73089939e-01 1.89164316e-03
 4.97554371e-04 9.42782557e-04 8.65361094e-02 5.29584904e-05
 2.64029391e-03 9.17767286e-01 5.62031310e-05 9.99096036e-01
 1.25047639e-02 1.94196030e-01 1.51882078e-02 4.25862484e-02
 4.73948021e-04]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-19 13:42:03, Dev, Step : 5072, Loss : 0.55589, Acc : 0.778, Auc : 0.855, Sensitive_Loss : 0.21871, Sensitive_Acc : 21.617, Sensitive_Auc : 0.995, Mean auc: 0.855, Run Time : 228.57 sec
INFO:root:2024-04-19 13:42:20, Train, Epoch : 9, Step : 5080, Loss : 0.26888, Acc : 0.684, Sensitive_Loss : 0.13657, Sensitive_Acc : 16.100, Run Time : 15.52 sec
INFO:root:2024-04-19 13:42:39, Train, Epoch : 9, Step : 5090, Loss : 0.34579, Acc : 0.866, Sensitive_Loss : 0.11913, Sensitive_Acc : 20.100, Run Time : 19.24 sec
INFO:root:2024-04-19 13:42:56, Train, Epoch : 9, Step : 5100, Loss : 0.35140, Acc : 0.856, Sensitive_Loss : 0.17893, Sensitive_Acc : 20.300, Run Time : 16.49 sec
INFO:root:2024-04-19 13:46:43, Dev, Step : 5100, Loss : 0.54678, Acc : 0.779, Auc : 0.853, Sensitive_Loss : 0.25434, Sensitive_Acc : 20.880, Sensitive_Auc : 0.993, Mean auc: 0.853, Run Time : 227.68 sec
INFO:root:2024-04-19 13:46:56, Train, Epoch : 9, Step : 5110, Loss : 0.35985, Acc : 0.831, Sensitive_Loss : 0.19212, Sensitive_Acc : 23.300, Run Time : 240.08 sec
INFO:root:2024-04-19 13:47:13, Train, Epoch : 9, Step : 5120, Loss : 0.27567, Acc : 0.897, Sensitive_Loss : 0.12467, Sensitive_Acc : 18.900, Run Time : 16.90 sec
INFO:root:2024-04-19 13:47:31, Train, Epoch : 9, Step : 5130, Loss : 0.26460, Acc : 0.875, Sensitive_Loss : 0.08463, Sensitive_Acc : 24.800, Run Time : 18.35 sec
INFO:root:2024-04-19 13:47:48, Train, Epoch : 9, Step : 5140, Loss : 0.30093, Acc : 0.872, Sensitive_Loss : 0.11986, Sensitive_Acc : 20.500, Run Time : 16.59 sec
INFO:root:2024-04-19 13:48:05, Train, Epoch : 9, Step : 5150, Loss : 0.31273, Acc : 0.847, Sensitive_Loss : 0.10677, Sensitive_Acc : 16.000, Run Time : 17.25 sec
INFO:root:2024-04-19 13:48:22, Train, Epoch : 9, Step : 5160, Loss : 0.32526, Acc : 0.869, Sensitive_Loss : 0.08627, Sensitive_Acc : 23.500, Run Time : 16.90 sec
INFO:root:2024-04-19 13:48:38, Train, Epoch : 9, Step : 5170, Loss : 0.28986, Acc : 0.844, Sensitive_Loss : 0.08467, Sensitive_Acc : 22.200, Run Time : 16.61 sec
INFO:root:2024-04-19 13:48:56, Train, Epoch : 9, Step : 5180, Loss : 0.29476, Acc : 0.869, Sensitive_Loss : 0.11627, Sensitive_Acc : 16.900, Run Time : 17.26 sec
INFO:root:2024-04-19 13:49:16, Train, Epoch : 9, Step : 5190, Loss : 0.32720, Acc : 0.869, Sensitive_Loss : 0.13154, Sensitive_Acc : 22.500, Run Time : 20.00 sec
INFO:root:2024-04-19 13:49:35, Train, Epoch : 9, Step : 5200, Loss : 0.32909, Acc : 0.881, Sensitive_Loss : 0.08140, Sensitive_Acc : 22.400, Run Time : 19.06 sec
INFO:root:2024-04-19 13:53:35, Dev, Step : 5200, Loss : 0.56976, Acc : 0.777, Auc : 0.852, Sensitive_Loss : 0.21616, Sensitive_Acc : 21.256, Sensitive_Auc : 0.994, Mean auc: 0.852, Run Time : 240.22 sec
INFO:root:2024-04-19 13:53:47, Train, Epoch : 9, Step : 5210, Loss : 0.31472, Acc : 0.875, Sensitive_Loss : 0.11388, Sensitive_Acc : 21.700, Run Time : 252.60 sec
INFO:root:2024-04-19 13:54:05, Train, Epoch : 9, Step : 5220, Loss : 0.35079, Acc : 0.859, Sensitive_Loss : 0.14765, Sensitive_Acc : 21.800, Run Time : 17.18 sec
INFO:root:2024-04-19 13:54:21, Train, Epoch : 9, Step : 5230, Loss : 0.37572, Acc : 0.856, Sensitive_Loss : 0.09421, Sensitive_Acc : 26.000, Run Time : 16.89 sec
INFO:root:2024-04-19 13:54:38, Train, Epoch : 9, Step : 5240, Loss : 0.24161, Acc : 0.909, Sensitive_Loss : 0.10836, Sensitive_Acc : 24.300, Run Time : 16.64 sec
INFO:root:2024-04-19 13:54:56, Train, Epoch : 9, Step : 5250, Loss : 0.30043, Acc : 0.891, Sensitive_Loss : 0.11031, Sensitive_Acc : 19.000, Run Time : 17.79 sec
INFO:root:2024-04-19 13:55:13, Train, Epoch : 9, Step : 5260, Loss : 0.31379, Acc : 0.859, Sensitive_Loss : 0.12741, Sensitive_Acc : 20.000, Run Time : 16.83 sec
INFO:root:2024-04-19 13:55:31, Train, Epoch : 9, Step : 5270, Loss : 0.32165, Acc : 0.875, Sensitive_Loss : 0.14001, Sensitive_Acc : 18.100, Run Time : 17.91 sec
INFO:root:2024-04-19 13:55:48, Train, Epoch : 9, Step : 5280, Loss : 0.30376, Acc : 0.866, Sensitive_Loss : 0.11148, Sensitive_Acc : 20.600, Run Time : 17.35 sec
INFO:root:2024-04-19 13:56:04, Train, Epoch : 9, Step : 5290, Loss : 0.34531, Acc : 0.825, Sensitive_Loss : 0.09973, Sensitive_Acc : 21.000, Run Time : 15.62 sec
INFO:root:2024-04-19 13:56:22, Train, Epoch : 9, Step : 5300, Loss : 0.30986, Acc : 0.863, Sensitive_Loss : 0.08446, Sensitive_Acc : 24.200, Run Time : 18.18 sec
INFO:root:2024-04-19 14:00:12, Dev, Step : 5300, Loss : 0.59182, Acc : 0.768, Auc : 0.851, Sensitive_Loss : 0.20182, Sensitive_Acc : 21.346, Sensitive_Auc : 0.995, Mean auc: 0.851, Run Time : 229.81 sec
INFO:root:2024-04-19 14:00:24, Train, Epoch : 9, Step : 5310, Loss : 0.38444, Acc : 0.866, Sensitive_Loss : 0.08849, Sensitive_Acc : 20.900, Run Time : 242.02 sec
INFO:root:2024-04-19 14:00:41, Train, Epoch : 9, Step : 5320, Loss : 0.34065, Acc : 0.844, Sensitive_Loss : 0.15812, Sensitive_Acc : 16.700, Run Time : 16.94 sec
INFO:root:2024-04-19 14:00:58, Train, Epoch : 9, Step : 5330, Loss : 0.31456, Acc : 0.875, Sensitive_Loss : 0.07259, Sensitive_Acc : 23.300, Run Time : 16.88 sec
INFO:root:2024-04-19 14:01:15, Train, Epoch : 9, Step : 5340, Loss : 0.27571, Acc : 0.887, Sensitive_Loss : 0.11160, Sensitive_Acc : 20.100, Run Time : 17.20 sec
INFO:root:2024-04-19 14:01:32, Train, Epoch : 9, Step : 5350, Loss : 0.26621, Acc : 0.872, Sensitive_Loss : 0.10932, Sensitive_Acc : 21.600, Run Time : 16.66 sec
INFO:root:2024-04-19 14:01:49, Train, Epoch : 9, Step : 5360, Loss : 0.31527, Acc : 0.878, Sensitive_Loss : 0.08114, Sensitive_Acc : 21.900, Run Time : 17.30 sec
INFO:root:2024-04-19 14:02:06, Train, Epoch : 9, Step : 5370, Loss : 0.28430, Acc : 0.869, Sensitive_Loss : 0.14395, Sensitive_Acc : 18.600, Run Time : 17.21 sec
INFO:root:2024-04-19 14:02:23, Train, Epoch : 9, Step : 5380, Loss : 0.33727, Acc : 0.869, Sensitive_Loss : 0.18273, Sensitive_Acc : 22.500, Run Time : 16.87 sec
INFO:root:2024-04-19 14:02:40, Train, Epoch : 9, Step : 5390, Loss : 0.31710, Acc : 0.875, Sensitive_Loss : 0.23125, Sensitive_Acc : 23.100, Run Time : 17.08 sec
INFO:root:2024-04-19 14:02:57, Train, Epoch : 9, Step : 5400, Loss : 0.34111, Acc : 0.834, Sensitive_Loss : 0.10434, Sensitive_Acc : 25.000, Run Time : 16.75 sec
INFO:root:2024-04-19 14:06:46, Dev, Step : 5400, Loss : 0.57812, Acc : 0.774, Auc : 0.851, Sensitive_Loss : 0.20992, Sensitive_Acc : 21.180, Sensitive_Auc : 0.994, Mean auc: 0.851, Run Time : 229.61 sec
INFO:root:2024-04-19 14:06:59, Train, Epoch : 9, Step : 5410, Loss : 0.27011, Acc : 0.878, Sensitive_Loss : 0.14091, Sensitive_Acc : 21.300, Run Time : 242.54 sec
INFO:root:2024-04-19 14:07:16, Train, Epoch : 9, Step : 5420, Loss : 0.29037, Acc : 0.891, Sensitive_Loss : 0.11320, Sensitive_Acc : 16.600, Run Time : 16.75 sec
INFO:root:2024-04-19 14:07:34, Train, Epoch : 9, Step : 5430, Loss : 0.26160, Acc : 0.894, Sensitive_Loss : 0.11679, Sensitive_Acc : 23.600, Run Time : 17.54 sec
INFO:root:2024-04-19 14:07:51, Train, Epoch : 9, Step : 5440, Loss : 0.25860, Acc : 0.906, Sensitive_Loss : 0.11536, Sensitive_Acc : 16.900, Run Time : 17.47 sec
INFO:root:2024-04-19 14:08:08, Train, Epoch : 9, Step : 5450, Loss : 0.23440, Acc : 0.903, Sensitive_Loss : 0.08485, Sensitive_Acc : 16.800, Run Time : 16.65 sec
INFO:root:2024-04-19 14:08:24, Train, Epoch : 9, Step : 5460, Loss : 0.34528, Acc : 0.831, Sensitive_Loss : 0.10061, Sensitive_Acc : 22.100, Run Time : 16.47 sec
INFO:root:2024-04-19 14:08:41, Train, Epoch : 9, Step : 5470, Loss : 0.30128, Acc : 0.850, Sensitive_Loss : 0.12418, Sensitive_Acc : 18.400, Run Time : 16.34 sec
INFO:root:2024-04-19 14:08:57, Train, Epoch : 9, Step : 5480, Loss : 0.30661, Acc : 0.897, Sensitive_Loss : 0.09604, Sensitive_Acc : 21.700, Run Time : 16.92 sec
INFO:root:2024-04-19 14:09:13, Train, Epoch : 9, Step : 5490, Loss : 0.29894, Acc : 0.891, Sensitive_Loss : 0.08808, Sensitive_Acc : 25.000, Run Time : 15.17 sec
INFO:root:2024-04-19 14:09:29, Train, Epoch : 9, Step : 5500, Loss : 0.34505, Acc : 0.884, Sensitive_Loss : 0.12576, Sensitive_Acc : 20.100, Run Time : 16.60 sec
INFO:root:2024-04-19 14:13:20, Dev, Step : 5500, Loss : 0.56488, Acc : 0.775, Auc : 0.852, Sensitive_Loss : 0.21309, Sensitive_Acc : 21.180, Sensitive_Auc : 0.994, Mean auc: 0.852, Run Time : 230.92 sec
INFO:root:2024-04-19 14:13:32, Train, Epoch : 9, Step : 5510, Loss : 0.28376, Acc : 0.869, Sensitive_Loss : 0.09722, Sensitive_Acc : 13.500, Run Time : 243.21 sec
INFO:root:2024-04-19 14:13:49, Train, Epoch : 9, Step : 5520, Loss : 0.33990, Acc : 0.859, Sensitive_Loss : 0.08715, Sensitive_Acc : 22.400, Run Time : 16.91 sec
INFO:root:2024-04-19 14:14:06, Train, Epoch : 9, Step : 5530, Loss : 0.32949, Acc : 0.850, Sensitive_Loss : 0.09997, Sensitive_Acc : 19.700, Run Time : 16.53 sec
INFO:root:2024-04-19 14:14:23, Train, Epoch : 9, Step : 5540, Loss : 0.28138, Acc : 0.863, Sensitive_Loss : 0.12247, Sensitive_Acc : 24.200, Run Time : 16.75 sec
INFO:root:2024-04-19 14:14:40, Train, Epoch : 9, Step : 5550, Loss : 0.33145, Acc : 0.866, Sensitive_Loss : 0.10150, Sensitive_Acc : 20.400, Run Time : 17.66 sec
INFO:root:2024-04-19 14:14:58, Train, Epoch : 9, Step : 5560, Loss : 0.32975, Acc : 0.875, Sensitive_Loss : 0.13325, Sensitive_Acc : 19.200, Run Time : 17.55 sec
INFO:root:2024-04-19 14:15:14, Train, Epoch : 9, Step : 5570, Loss : 0.35378, Acc : 0.841, Sensitive_Loss : 0.09311, Sensitive_Acc : 18.200, Run Time : 16.32 sec
INFO:root:2024-04-19 14:15:31, Train, Epoch : 9, Step : 5580, Loss : 0.30965, Acc : 0.869, Sensitive_Loss : 0.11419, Sensitive_Acc : 18.200, Run Time : 17.02 sec
INFO:root:2024-04-19 14:15:49, Train, Epoch : 9, Step : 5590, Loss : 0.32184, Acc : 0.869, Sensitive_Loss : 0.10398, Sensitive_Acc : 20.500, Run Time : 17.71 sec
INFO:root:2024-04-19 14:16:05, Train, Epoch : 9, Step : 5600, Loss : 0.28529, Acc : 0.887, Sensitive_Loss : 0.11388, Sensitive_Acc : 22.000, Run Time : 16.48 sec
INFO:root:2024-04-19 14:19:55, Dev, Step : 5600, Loss : 0.59653, Acc : 0.766, Auc : 0.849, Sensitive_Loss : 0.19289, Sensitive_Acc : 21.571, Sensitive_Auc : 0.995, Mean auc: 0.849, Run Time : 230.13 sec
INFO:root:2024-04-19 14:20:07, Train, Epoch : 9, Step : 5610, Loss : 0.32013, Acc : 0.869, Sensitive_Loss : 0.12713, Sensitive_Acc : 25.100, Run Time : 241.72 sec
INFO:root:2024-04-19 14:20:26, Train, Epoch : 9, Step : 5620, Loss : 0.36695, Acc : 0.841, Sensitive_Loss : 0.11951, Sensitive_Acc : 26.200, Run Time : 18.50 sec
INFO:root:2024-04-19 14:20:43, Train, Epoch : 9, Step : 5630, Loss : 0.34833, Acc : 0.850, Sensitive_Loss : 0.12037, Sensitive_Acc : 19.000, Run Time : 17.63 sec
INFO:root:2024-04-19 14:21:00, Train, Epoch : 9, Step : 5640, Loss : 0.29681, Acc : 0.881, Sensitive_Loss : 0.06992, Sensitive_Acc : 21.500, Run Time : 16.96 sec
INFO:root:2024-04-19 14:21:18, Train, Epoch : 9, Step : 5650, Loss : 0.34844, Acc : 0.863, Sensitive_Loss : 0.12325, Sensitive_Acc : 22.100, Run Time : 17.85 sec
INFO:root:2024-04-19 14:21:39, Train, Epoch : 9, Step : 5660, Loss : 0.28901, Acc : 0.859, Sensitive_Loss : 0.09375, Sensitive_Acc : 20.500, Run Time : 21.05 sec
INFO:root:2024-04-19 14:22:07, Train, Epoch : 9, Step : 5670, Loss : 0.37454, Acc : 0.834, Sensitive_Loss : 0.09908, Sensitive_Acc : 26.100, Run Time : 27.82 sec
INFO:root:2024-04-19 14:22:27, Train, Epoch : 9, Step : 5680, Loss : 0.30849, Acc : 0.894, Sensitive_Loss : 0.09873, Sensitive_Acc : 26.000, Run Time : 19.68 sec
INFO:root:2024-04-19 14:22:45, Train, Epoch : 9, Step : 5690, Loss : 0.31132, Acc : 0.866, Sensitive_Loss : 0.11956, Sensitive_Acc : 22.100, Run Time : 18.30 sec
INFO:root:2024-04-19 14:23:02, Train, Epoch : 9, Step : 5700, Loss : 0.30470, Acc : 0.863, Sensitive_Loss : 0.10434, Sensitive_Acc : 17.600, Run Time : 17.46 sec
INFO:root:2024-04-19 14:26:59, Dev, Step : 5700, Loss : 0.56455, Acc : 0.782, Auc : 0.854, Sensitive_Loss : 0.20960, Sensitive_Acc : 21.376, Sensitive_Auc : 0.995, Mean auc: 0.854, Run Time : 236.42 sec
INFO:root:2024-04-19 14:30:51
INFO:root:y_pred: [0.01665848 0.00368729 0.05795741 ... 0.45246544 0.00140935 0.03788964]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [1.60244748e-03 6.19821541e-04 9.83229727e-02 3.96736786e-02
 1.62596498e-02 3.71216942e-04 2.91792699e-03 3.68572597e-04
 6.81980001e-03 9.99973178e-01 8.00086632e-02 8.92054595e-05
 1.93995014e-02 2.96977996e-05 9.99919415e-01 2.35128850e-02
 3.30848899e-03 9.99924898e-01 9.98845339e-01 8.85960087e-02
 9.09159958e-01 6.10099560e-05 3.80229019e-03 2.96197046e-04
 1.72307581e-01 5.61353266e-01 3.39471473e-04 1.45744882e-03
 1.37333671e-04 8.78705701e-04 5.03221177e-04 9.97869611e-01
 1.42007053e-01 5.73407829e-01 1.34531307e-04 2.75024395e-05
 1.03565442e-04 7.60341659e-02 7.57998824e-02 2.56662462e-02
 3.58245641e-01 9.97456729e-01 7.99380802e-03 9.58613236e-04
 9.99984741e-01 8.58767271e-01 1.22030959e-01 4.48405594e-01
 1.08961742e-02 9.86550331e-01 9.91961420e-01 9.99353707e-01
 9.99130189e-01 6.94163755e-05 1.39258578e-01 8.77601802e-02
 1.18157648e-01 1.05382636e-01 9.88245368e-01 6.23211265e-04
 8.58785825e-06 6.46586821e-04 8.55122786e-03 3.21857573e-04
 9.99845028e-01 6.10635996e-01 2.41756381e-04 2.58681685e-01
 4.81364653e-02 9.97727454e-01 9.99948263e-01 9.99935150e-01
 1.00712804e-03 3.45291585e-01 6.63819769e-03 8.14379871e-01
 1.50218438e-02 1.12432996e-08 4.74746685e-06 7.89106544e-03
 2.44039446e-01 9.01943364e-04 9.99328971e-01 9.92858768e-01
 1.22260128e-04 7.27637322e-04 1.33471126e-02 3.63368490e-05
 2.33529398e-04 4.26147692e-03 5.85218519e-03 4.10757847e-02
 5.73602374e-05 4.37683639e-06 1.25385559e-04 4.66911634e-03
 2.57490115e-04 3.29299003e-01 7.01733083e-02 9.95713659e-03
 1.30541186e-04 9.10724420e-03 8.30653906e-02 9.41235281e-04
 3.95733900e-02 7.21977500e-04 5.16874604e-02 4.06992793e-01
 7.48093519e-03 3.08831874e-02 1.26276223e-04 9.99618173e-01
 9.99560535e-01 1.19798788e-04 1.79022908e-01 8.87665991e-03
 3.13803628e-02 9.42619517e-05 3.95789266e-01 2.48473487e-03
 8.25835887e-05 1.05590501e-03 9.34949517e-02 9.95628798e-05
 2.66983872e-03 8.87705445e-01 5.63094582e-05 9.98134077e-01
 4.86571640e-02 1.43590152e-01 1.22485301e-02 1.71324059e-01
 4.02770791e-04]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-19 14:30:51, Dev, Step : 5706, Loss : 0.56420, Acc : 0.782, Auc : 0.854, Sensitive_Loss : 0.20427, Sensitive_Acc : 21.496, Sensitive_Auc : 0.995, Mean auc: 0.854, Run Time : 227.00 sec
INFO:root:2024-04-19 14:31:01, Train, Epoch : 10, Step : 5710, Loss : 0.12459, Acc : 0.347, Sensitive_Loss : 0.03225, Sensitive_Acc : 6.600, Run Time : 9.59 sec
INFO:root:2024-04-19 14:31:23, Train, Epoch : 10, Step : 5720, Loss : 0.27773, Acc : 0.891, Sensitive_Loss : 0.08634, Sensitive_Acc : 21.700, Run Time : 21.15 sec
INFO:root:2024-04-19 14:31:41, Train, Epoch : 10, Step : 5730, Loss : 0.29757, Acc : 0.900, Sensitive_Loss : 0.08498, Sensitive_Acc : 19.500, Run Time : 18.22 sec
INFO:root:2024-04-19 14:31:58, Train, Epoch : 10, Step : 5740, Loss : 0.26360, Acc : 0.884, Sensitive_Loss : 0.14456, Sensitive_Acc : 23.500, Run Time : 17.65 sec
INFO:root:2024-04-19 14:32:16, Train, Epoch : 10, Step : 5750, Loss : 0.24753, Acc : 0.881, Sensitive_Loss : 0.12101, Sensitive_Acc : 19.100, Run Time : 17.16 sec
INFO:root:2024-04-19 14:32:34, Train, Epoch : 10, Step : 5760, Loss : 0.23407, Acc : 0.894, Sensitive_Loss : 0.09829, Sensitive_Acc : 18.200, Run Time : 18.90 sec
INFO:root:2024-04-19 14:32:52, Train, Epoch : 10, Step : 5770, Loss : 0.25841, Acc : 0.887, Sensitive_Loss : 0.08188, Sensitive_Acc : 21.400, Run Time : 17.13 sec
INFO:root:2024-04-19 14:33:09, Train, Epoch : 10, Step : 5780, Loss : 0.30788, Acc : 0.887, Sensitive_Loss : 0.08809, Sensitive_Acc : 22.100, Run Time : 17.47 sec
INFO:root:2024-04-19 14:33:26, Train, Epoch : 10, Step : 5790, Loss : 0.32980, Acc : 0.859, Sensitive_Loss : 0.09392, Sensitive_Acc : 22.800, Run Time : 17.17 sec
INFO:root:2024-04-19 14:33:46, Train, Epoch : 10, Step : 5800, Loss : 0.27639, Acc : 0.878, Sensitive_Loss : 0.11862, Sensitive_Acc : 24.400, Run Time : 19.67 sec
INFO:root:2024-04-19 14:37:33, Dev, Step : 5800, Loss : 0.57231, Acc : 0.778, Auc : 0.849, Sensitive_Loss : 0.21054, Sensitive_Acc : 21.150, Sensitive_Auc : 0.995, Mean auc: 0.849, Run Time : 226.98 sec
INFO:root:2024-04-19 14:37:45, Train, Epoch : 10, Step : 5810, Loss : 0.29254, Acc : 0.872, Sensitive_Loss : 0.14352, Sensitive_Acc : 23.900, Run Time : 239.22 sec
INFO:root:2024-04-19 14:38:03, Train, Epoch : 10, Step : 5820, Loss : 0.31933, Acc : 0.878, Sensitive_Loss : 0.14902, Sensitive_Acc : 19.600, Run Time : 17.47 sec
INFO:root:2024-04-19 14:38:20, Train, Epoch : 10, Step : 5830, Loss : 0.26990, Acc : 0.878, Sensitive_Loss : 0.07139, Sensitive_Acc : 26.800, Run Time : 17.18 sec
INFO:root:2024-04-19 14:38:37, Train, Epoch : 10, Step : 5840, Loss : 0.33028, Acc : 0.859, Sensitive_Loss : 0.10862, Sensitive_Acc : 22.300, Run Time : 17.30 sec
INFO:root:2024-04-19 14:38:55, Train, Epoch : 10, Step : 5850, Loss : 0.30578, Acc : 0.844, Sensitive_Loss : 0.10235, Sensitive_Acc : 23.000, Run Time : 17.97 sec
INFO:root:2024-04-19 14:39:13, Train, Epoch : 10, Step : 5860, Loss : 0.29869, Acc : 0.869, Sensitive_Loss : 0.14461, Sensitive_Acc : 23.300, Run Time : 18.35 sec
INFO:root:2024-04-19 14:39:31, Train, Epoch : 10, Step : 5870, Loss : 0.28890, Acc : 0.866, Sensitive_Loss : 0.11213, Sensitive_Acc : 22.900, Run Time : 17.39 sec
INFO:root:2024-04-19 14:39:48, Train, Epoch : 10, Step : 5880, Loss : 0.27044, Acc : 0.894, Sensitive_Loss : 0.10598, Sensitive_Acc : 19.100, Run Time : 17.33 sec
INFO:root:2024-04-19 14:40:05, Train, Epoch : 10, Step : 5890, Loss : 0.27428, Acc : 0.869, Sensitive_Loss : 0.11009, Sensitive_Acc : 19.800, Run Time : 17.11 sec
INFO:root:2024-04-19 14:40:21, Train, Epoch : 10, Step : 5900, Loss : 0.32324, Acc : 0.869, Sensitive_Loss : 0.11085, Sensitive_Acc : 21.400, Run Time : 16.02 sec
INFO:root:2024-04-19 14:44:11, Dev, Step : 5900, Loss : 0.56421, Acc : 0.780, Auc : 0.853, Sensitive_Loss : 0.21373, Sensitive_Acc : 21.451, Sensitive_Auc : 0.994, Mean auc: 0.853, Run Time : 230.08 sec
INFO:root:2024-04-19 14:44:23, Train, Epoch : 10, Step : 5910, Loss : 0.26679, Acc : 0.891, Sensitive_Loss : 0.10790, Sensitive_Acc : 25.900, Run Time : 242.13 sec
INFO:root:2024-04-19 14:44:41, Train, Epoch : 10, Step : 5920, Loss : 0.27285, Acc : 0.887, Sensitive_Loss : 0.08489, Sensitive_Acc : 16.900, Run Time : 17.40 sec
INFO:root:2024-04-19 14:44:57, Train, Epoch : 10, Step : 5930, Loss : 0.29755, Acc : 0.875, Sensitive_Loss : 0.07133, Sensitive_Acc : 23.900, Run Time : 16.33 sec
INFO:root:2024-04-19 14:45:15, Train, Epoch : 10, Step : 5940, Loss : 0.23947, Acc : 0.897, Sensitive_Loss : 0.14050, Sensitive_Acc : 18.300, Run Time : 17.84 sec
INFO:root:2024-04-19 14:45:33, Train, Epoch : 10, Step : 5950, Loss : 0.36618, Acc : 0.841, Sensitive_Loss : 0.08268, Sensitive_Acc : 21.600, Run Time : 17.79 sec
INFO:root:2024-04-19 14:45:51, Train, Epoch : 10, Step : 5960, Loss : 0.32805, Acc : 0.872, Sensitive_Loss : 0.13218, Sensitive_Acc : 22.700, Run Time : 18.34 sec
INFO:root:2024-04-19 14:46:10, Train, Epoch : 10, Step : 5970, Loss : 0.26458, Acc : 0.881, Sensitive_Loss : 0.13162, Sensitive_Acc : 17.900, Run Time : 19.03 sec
INFO:root:2024-04-19 14:46:28, Train, Epoch : 10, Step : 5980, Loss : 0.29028, Acc : 0.881, Sensitive_Loss : 0.12818, Sensitive_Acc : 22.500, Run Time : 18.37 sec
INFO:root:2024-04-19 14:46:47, Train, Epoch : 10, Step : 5990, Loss : 0.21648, Acc : 0.912, Sensitive_Loss : 0.11797, Sensitive_Acc : 22.500, Run Time : 18.66 sec
INFO:root:2024-04-19 14:47:06, Train, Epoch : 10, Step : 6000, Loss : 0.26159, Acc : 0.859, Sensitive_Loss : 0.10898, Sensitive_Acc : 23.400, Run Time : 18.93 sec
INFO:root:2024-04-19 14:50:57, Dev, Step : 6000, Loss : 0.59864, Acc : 0.771, Auc : 0.852, Sensitive_Loss : 0.22573, Sensitive_Acc : 21.496, Sensitive_Auc : 0.993, Mean auc: 0.852, Run Time : 231.20 sec
INFO:root:2024-04-19 14:51:09, Train, Epoch : 10, Step : 6010, Loss : 0.28985, Acc : 0.887, Sensitive_Loss : 0.10090, Sensitive_Acc : 22.400, Run Time : 242.91 sec
INFO:root:2024-04-19 14:51:27, Train, Epoch : 10, Step : 6020, Loss : 0.28741, Acc : 0.869, Sensitive_Loss : 0.10662, Sensitive_Acc : 23.600, Run Time : 18.29 sec
INFO:root:2024-04-19 14:51:44, Train, Epoch : 10, Step : 6030, Loss : 0.30278, Acc : 0.872, Sensitive_Loss : 0.12145, Sensitive_Acc : 23.400, Run Time : 16.60 sec
INFO:root:2024-04-19 14:52:00, Train, Epoch : 10, Step : 6040, Loss : 0.35261, Acc : 0.853, Sensitive_Loss : 0.08514, Sensitive_Acc : 20.500, Run Time : 16.21 sec
INFO:root:2024-04-19 14:52:17, Train, Epoch : 10, Step : 6050, Loss : 0.29855, Acc : 0.844, Sensitive_Loss : 0.12993, Sensitive_Acc : 24.000, Run Time : 16.87 sec
INFO:root:2024-04-19 14:52:36, Train, Epoch : 10, Step : 6060, Loss : 0.27078, Acc : 0.850, Sensitive_Loss : 0.05878, Sensitive_Acc : 25.800, Run Time : 18.82 sec
INFO:root:2024-04-19 14:52:54, Train, Epoch : 10, Step : 6070, Loss : 0.34726, Acc : 0.856, Sensitive_Loss : 0.17163, Sensitive_Acc : 23.000, Run Time : 18.16 sec
INFO:root:2024-04-19 14:53:12, Train, Epoch : 10, Step : 6080, Loss : 0.28539, Acc : 0.891, Sensitive_Loss : 0.10817, Sensitive_Acc : 22.300, Run Time : 18.06 sec
INFO:root:2024-04-19 14:53:29, Train, Epoch : 10, Step : 6090, Loss : 0.34679, Acc : 0.841, Sensitive_Loss : 0.12031, Sensitive_Acc : 17.400, Run Time : 16.93 sec
INFO:root:2024-04-19 14:53:48, Train, Epoch : 10, Step : 6100, Loss : 0.29065, Acc : 0.887, Sensitive_Loss : 0.12703, Sensitive_Acc : 24.600, Run Time : 19.07 sec
INFO:root:2024-04-19 14:57:41, Dev, Step : 6100, Loss : 0.58432, Acc : 0.775, Auc : 0.848, Sensitive_Loss : 0.21999, Sensitive_Acc : 21.271, Sensitive_Auc : 0.993, Mean auc: 0.848, Run Time : 233.37 sec
INFO:root:2024-04-19 14:57:58, Train, Epoch : 10, Step : 6110, Loss : 0.29681, Acc : 0.856, Sensitive_Loss : 0.16527, Sensitive_Acc : 19.700, Run Time : 249.77 sec
INFO:root:2024-04-19 14:58:20, Train, Epoch : 10, Step : 6120, Loss : 0.34938, Acc : 0.859, Sensitive_Loss : 0.08733, Sensitive_Acc : 18.900, Run Time : 22.32 sec
INFO:root:2024-04-19 14:58:42, Train, Epoch : 10, Step : 6130, Loss : 0.29598, Acc : 0.881, Sensitive_Loss : 0.08728, Sensitive_Acc : 22.000, Run Time : 21.88 sec
INFO:root:2024-04-19 14:59:01, Train, Epoch : 10, Step : 6140, Loss : 0.29689, Acc : 0.866, Sensitive_Loss : 0.11084, Sensitive_Acc : 20.200, Run Time : 19.18 sec
INFO:root:2024-04-19 14:59:21, Train, Epoch : 10, Step : 6150, Loss : 0.28357, Acc : 0.869, Sensitive_Loss : 0.09539, Sensitive_Acc : 15.400, Run Time : 19.48 sec
INFO:root:2024-04-19 14:59:44, Train, Epoch : 10, Step : 6160, Loss : 0.28136, Acc : 0.872, Sensitive_Loss : 0.11336, Sensitive_Acc : 25.600, Run Time : 23.10 sec
INFO:root:2024-04-19 15:00:01, Train, Epoch : 10, Step : 6170, Loss : 0.24038, Acc : 0.900, Sensitive_Loss : 0.15995, Sensitive_Acc : 21.600, Run Time : 17.33 sec
INFO:root:2024-04-19 15:00:20, Train, Epoch : 10, Step : 6180, Loss : 0.32449, Acc : 0.863, Sensitive_Loss : 0.09888, Sensitive_Acc : 16.700, Run Time : 18.49 sec
INFO:root:2024-04-19 15:00:37, Train, Epoch : 10, Step : 6190, Loss : 0.30714, Acc : 0.881, Sensitive_Loss : 0.10505, Sensitive_Acc : 22.600, Run Time : 17.32 sec
INFO:root:2024-04-19 15:00:54, Train, Epoch : 10, Step : 6200, Loss : 0.29184, Acc : 0.881, Sensitive_Loss : 0.13208, Sensitive_Acc : 22.400, Run Time : 17.13 sec
INFO:root:2024-04-19 15:04:43, Dev, Step : 6200, Loss : 0.60385, Acc : 0.770, Auc : 0.847, Sensitive_Loss : 0.22437, Sensitive_Acc : 21.376, Sensitive_Auc : 0.994, Mean auc: 0.847, Run Time : 229.38 sec
INFO:root:2024-04-19 15:04:55, Train, Epoch : 10, Step : 6210, Loss : 0.29389, Acc : 0.878, Sensitive_Loss : 0.14960, Sensitive_Acc : 22.200, Run Time : 241.08 sec
INFO:root:2024-04-19 15:05:13, Train, Epoch : 10, Step : 6220, Loss : 0.28460, Acc : 0.891, Sensitive_Loss : 0.09869, Sensitive_Acc : 22.400, Run Time : 17.66 sec
INFO:root:2024-04-19 15:05:29, Train, Epoch : 10, Step : 6230, Loss : 0.26969, Acc : 0.897, Sensitive_Loss : 0.10519, Sensitive_Acc : 19.600, Run Time : 16.18 sec
INFO:root:2024-04-19 15:05:47, Train, Epoch : 10, Step : 6240, Loss : 0.28593, Acc : 0.887, Sensitive_Loss : 0.11720, Sensitive_Acc : 22.200, Run Time : 18.10 sec
INFO:root:2024-04-19 15:06:04, Train, Epoch : 10, Step : 6250, Loss : 0.27735, Acc : 0.894, Sensitive_Loss : 0.10855, Sensitive_Acc : 21.000, Run Time : 16.51 sec
INFO:root:2024-04-19 15:06:20, Train, Epoch : 10, Step : 6260, Loss : 0.32145, Acc : 0.863, Sensitive_Loss : 0.08768, Sensitive_Acc : 23.900, Run Time : 15.96 sec
INFO:root:2024-04-19 15:06:37, Train, Epoch : 10, Step : 6270, Loss : 0.35341, Acc : 0.863, Sensitive_Loss : 0.16161, Sensitive_Acc : 24.000, Run Time : 17.50 sec
INFO:root:2024-04-19 15:06:54, Train, Epoch : 10, Step : 6280, Loss : 0.30931, Acc : 0.869, Sensitive_Loss : 0.09546, Sensitive_Acc : 20.500, Run Time : 16.64 sec
INFO:root:2024-04-19 15:07:12, Train, Epoch : 10, Step : 6290, Loss : 0.31624, Acc : 0.859, Sensitive_Loss : 0.11620, Sensitive_Acc : 18.400, Run Time : 18.72 sec
INFO:root:2024-04-19 15:07:27, Train, Epoch : 10, Step : 6300, Loss : 0.27584, Acc : 0.891, Sensitive_Loss : 0.09384, Sensitive_Acc : 25.000, Run Time : 15.10 sec
INFO:root:2024-04-19 15:11:19, Dev, Step : 6300, Loss : 0.61811, Acc : 0.770, Auc : 0.850, Sensitive_Loss : 0.21229, Sensitive_Acc : 21.692, Sensitive_Auc : 0.992, Mean auc: 0.850, Run Time : 231.31 sec
INFO:root:2024-04-19 15:11:31, Train, Epoch : 10, Step : 6310, Loss : 0.27705, Acc : 0.878, Sensitive_Loss : 0.14288, Sensitive_Acc : 19.700, Run Time : 243.25 sec
INFO:root:2024-04-19 15:11:48, Train, Epoch : 10, Step : 6320, Loss : 0.31536, Acc : 0.869, Sensitive_Loss : 0.09837, Sensitive_Acc : 19.200, Run Time : 17.01 sec
INFO:root:2024-04-19 15:12:05, Train, Epoch : 10, Step : 6330, Loss : 0.26909, Acc : 0.897, Sensitive_Loss : 0.14083, Sensitive_Acc : 21.100, Run Time : 16.79 sec
INFO:root:2024-04-19 15:12:21, Train, Epoch : 10, Step : 6340, Loss : 0.31805, Acc : 0.900, Sensitive_Loss : 0.12414, Sensitive_Acc : 22.100, Run Time : 16.30 sec
INFO:root:2024-04-19 15:16:07
INFO:root:y_pred: [1.3040604e-02 1.0460768e-03 8.3352439e-02 ... 6.0045809e-01 1.8285168e-04
 6.9462284e-03]
INFO:root:y_true: [0. 0. 0. ... 1. 0. 0.]
INFO:root:sensitive_y_pred: [9.24596749e-03 8.31094570e-04 3.06761354e-01 6.06687926e-02
 1.56958178e-02 5.33500337e-04 4.93686553e-03 2.75347894e-03
 8.35730415e-03 9.99989986e-01 3.09026837e-01 4.57345595e-04
 1.11367472e-01 1.91742045e-04 9.99945402e-01 3.05531025e-02
 6.32006116e-03 9.99952912e-01 9.95083749e-01 3.82684022e-02
 9.75034416e-01 1.16258634e-04 4.83200932e-03 1.43245957e-03
 2.64496475e-01 4.03643548e-01 1.89026585e-04 1.82470493e-03
 1.71611784e-04 1.56644650e-03 5.06786862e-04 9.98888671e-01
 1.68512121e-01 6.24894381e-01 2.62416899e-04 1.86616580e-05
 2.77615880e-04 5.88398688e-02 1.81843504e-01 2.39860304e-02
 3.20510924e-01 9.96231735e-01 4.19935538e-03 6.93195092e-04
 9.96094763e-01 9.57311988e-01 1.57600731e-01 5.91533840e-01
 2.39421353e-02 9.94014323e-01 9.85917509e-01 9.99750674e-01
 9.99542356e-01 3.48032859e-06 1.67508215e-01 8.37450996e-02
 7.81278089e-02 1.10209584e-01 9.92554963e-01 3.32627795e-03
 1.73179469e-05 6.42617815e-04 1.77580938e-02 7.52553577e-04
 9.99898911e-01 6.70779049e-01 2.64083210e-04 6.59896374e-01
 9.38043669e-02 9.97049034e-01 9.99945402e-01 9.99960542e-01
 8.87305592e-04 5.52100122e-01 6.71034353e-03 7.52389491e-01
 3.11942138e-02 5.23149481e-07 3.36572816e-06 1.38976602e-02
 5.12322843e-01 2.58269324e-03 9.99079108e-01 9.98576283e-01
 1.70431987e-04 2.17148149e-03 2.83827148e-02 1.13015711e-04
 1.65608391e-04 2.88631418e-03 6.52735215e-03 5.20276763e-02
 4.72476204e-05 4.91743208e-07 5.54652252e-05 3.48209380e-03
 5.39005501e-04 3.70238394e-01 8.58463645e-02 2.27996521e-02
 4.41852957e-04 9.30916797e-03 8.58787447e-02 9.53236071e-04
 5.40771820e-02 1.53721630e-04 7.13346526e-02 6.57384396e-01
 6.18713535e-03 6.79072589e-02 2.75481812e-04 9.99915600e-01
 9.99796808e-01 3.23429093e-04 2.38168314e-01 1.80281382e-02
 3.36224362e-02 1.34426553e-03 5.16568244e-01 5.32926992e-03
 5.03050222e-04 2.04965775e-03 5.40963076e-02 1.93237502e-04
 5.98013448e-03 9.44222629e-01 2.38527398e-04 9.98784363e-01
 8.25549755e-03 1.46046817e-01 1.69302635e-02 1.60239831e-01
 7.91862316e-04]
INFO:root:sensitive_y_true: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
INFO:root:2024-04-19 15:16:07, Dev, Step : 6340, Loss : 0.59601, Acc : 0.769, Auc : 0.849, Sensitive_Loss : 0.23738, Sensitive_Acc : 20.805, Sensitive_Auc : 0.994, Mean auc: 0.849, Run Time : 226.30 sec
